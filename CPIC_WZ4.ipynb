{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 11\n",
      "         Function evaluations: 1281\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from portfolio import Portfolio\n",
    "%matplotlib inline \n",
    "\n",
    "## read in data\n",
    "ret_df_raw= pd.read_excel( io= 'Data/cipc data1.xlsx', sheetname= 'Data_Input', index_col=0)\n",
    "\n",
    "ret_df= ret_df_raw[['US_RE', \n",
    "                   'US_PE',\n",
    "                   'US_CORP',\n",
    "                   'SP500',\n",
    "                   'Rusell2000',\n",
    "                   'EAFE',\n",
    "                   'EM']]\n",
    "                   #'USGOVT10Y']]\n",
    "ret_df_cov= ret_df.cov()\n",
    "\n",
    "UniverseProperty= {}\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "LW= LedoitWolf( ).fit(ret_df)\n",
    "LW_alpha= LW.shrinkage_\n",
    "\n",
    "LW_cov= pd.DataFrame(LW.covariance_)*4\n",
    "LW_cov.index= ret_df_cov.index\n",
    "LW_cov.columns= ret_df_cov.columns\n",
    "LW_vol= np.sqrt(np.diag(LW_cov))\n",
    "LW_corr= pd.DataFrame( np.dot( np.dot( np.diag(1/ LW_vol), LW_cov), np.diag(1/LW_vol)) , \n",
    "                      index= LW_cov.index, columns= LW_cov.columns)\n",
    "CMA_passive_geo= np.array( [7, 8.8, 2.75, 7.21, 8.06, 7.07, 8.03 ])/100\n",
    "CMA_active_geo= CMA_passive_geo+ np.array( [0,0, 0.5, 1,1,1,1])/100\n",
    "CMA_passive_arith= CMA_passive_geo+ 0.5* LW_vol**2\n",
    "LW_cov_active= LW_cov+ np.diag([0, 0, 4, 9,9,9,9])/10000\n",
    "LW_vol_active= np.sqrt(np.diag(LW_cov_active))\n",
    "CMA_active_arith= CMA_active_geo+ 0.5* LW_vol_active**2\n",
    "\n",
    "# the asset universe properties\n",
    "UniverseProperty['asset_name']= LW_cov.index.tolist()\n",
    "UniverseProperty['asset_count']= LW_cov.shape[0]\n",
    "UniverseProperty['LW_cov']= LW_cov\n",
    "UniverseProperty['LW_vol']= LW_vol\n",
    "UniverseProperty['LW_corr']= LW_corr\n",
    "UniverseProperty['CMA_active_geo']= CMA_active_geo\n",
    "UniverseProperty['CMA_active_arith']= CMA_active_arith\n",
    "UniverseProperty['LW_cov_active']= LW_cov_active\n",
    "UniverseProperty['LW_vol_active']= LW_vol_active\n",
    "\n",
    "\n",
    "# Portfolios\n",
    "\n",
    "portfolios= {}\n",
    "portfolios['EqualWeights']= Portfolio(asset_ret= UniverseProperty['CMA_active_geo'], \n",
    "                                      asset_cov= UniverseProperty['LW_cov_active'], \n",
    "                                      weight= [1/UniverseProperty['asset_count']]* UniverseProperty['asset_count'])\n",
    "\n",
    "tmp= np.array([0.14,0.29,0.05,0.24,0.03,0.21,0.05])\n",
    "tmp= tmp/ np.sum(tmp)\n",
    "portfolios['Peer']= Portfolio( asset_ret= UniverseProperty['CMA_active_geo'],\n",
    "                             asset_cov= UniverseProperty['LW_cov_active'], \n",
    "                             weight= tmp)\n",
    "\n",
    "\n",
    "# solve ERC\n",
    "\n",
    "def temp_ERC_func(w, sigma):\n",
    "    A= np.diag( w)\n",
    "    B= np.diag( np.dot( sigma, w))\n",
    "    C= np.diag( np.dot( A, B))/ np.dot( np.dot( w, sigma), w)- np.ones( w.size )* 1/ w.size\n",
    "    return np.dot( C, C)\n",
    "\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "ERC_opt_res= minimize( temp_ERC_func, \n",
    "                 x0= portfolios['EqualWeights'].weight ,\n",
    "                 args= LW_cov,\n",
    "                 method= 'Powell',\n",
    "                 options= {'disp': True},\n",
    "                 tol= 1e-16)\n",
    "\n",
    "weight_erc = ERC_opt_res.x/ np.sum( ERC_opt_res.x)\n",
    "\n",
    "# ERC portfolio\n",
    "portfolios['ERC']= Portfolio( asset_ret= UniverseProperty['CMA_active_geo'],\n",
    "                            asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                            weight= weight_erc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.099672</td>\n",
       "      <td>0.141276</td>\n",
       "      <td>0.062961</td>\n",
       "      <td>0.152548</td>\n",
       "      <td>0.197004</td>\n",
       "      <td>0.182005</td>\n",
       "      <td>0.252635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.099672</td>\n",
       "      <td>0.141276</td>\n",
       "      <td>0.066061</td>\n",
       "      <td>0.155470</td>\n",
       "      <td>0.199275</td>\n",
       "      <td>0.184461</td>\n",
       "      <td>0.254410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  0.070000  0.088000  0.027500  0.072100  0.080600  0.070700  0.080300\n",
       "1  0.070000  0.088000  0.032500  0.082100  0.090600  0.080700  0.090300\n",
       "2  0.099672  0.141276  0.062961  0.152548  0.197004  0.182005  0.252635\n",
       "3  0.099672  0.141276  0.066061  0.155470  0.199275  0.184461  0.254410"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([CMA_passive_geo, \n",
    "              UniverseProperty['CMA_active_geo'],\n",
    "              UniverseProperty['LW_vol'], \n",
    "              UniverseProperty['LW_vol_active']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.080028712871287128"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios['Peer'].expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50813229286899697"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios['Peer'].volatility\n",
    "portfolios['Peer'].SharpeRatio(risk_free= 1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07631428571428571"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios['EqualWeights'].expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47970113549596327"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios['EqualWeights'].SharpeRatio(risk_free= 1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061166237157224766"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios['ERC'].expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56189205685468546"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios['ERC'].SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5584415584415584"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43/77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.206808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.403146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.074384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.206808\n",
       "1  0.105522\n",
       "2  0.403146\n",
       "3  0.085036\n",
       "4  0.067863\n",
       "5  0.074384\n",
       "6  0.057241"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(portfolios['ERC'].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12226877477221214"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios['Peer'].volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Frontier Construction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014578097207650254\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014589163132461337\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014615953148293514\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014658467255146794\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014716705453021173\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014790667741916646\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014880354121833224\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00149857645927709\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015106899154729674\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015243757948351952\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015396340551710524\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015564647386732593\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001574867831277577\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001594843332984004\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016163912437925409\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016395115740838904\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001664204292715945\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001690469430830812\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017182772817978865\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017475901902151319\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017784080379176774\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001810730824459922\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018445585449816094\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018798912012908692\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019167169418202526\n",
      "            Iterations: 24\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019549823536987834\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001994680887461124\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020358126015505166\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002078377475184426\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002122375547873222\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021678067179232772\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022146711003052937\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002262968581368072\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0023126992669513582\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0023638630986238932\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00241646014060907\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002470490258463262\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025259535788803673\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002582850060928269\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026411797056573824\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002700942518078231\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002762138471641107\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002824767604256372\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0028888298836801498\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0029543253355215487\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0030212539413816226\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003089615708245667\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031594106670049717\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003230638535812508\n",
      "            Iterations: 34\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003303297747266218\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0033773824501618223\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0034528972648267438\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003529841502101294\n",
      "            Iterations: 28\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003608214227803333\n",
      "            Iterations: 28\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003688015136397207\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0037692433490048812\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0038519000321678943\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003935984620579595\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004021495793959856\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004108433644148469\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004196798161357849\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004286589336371189\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004377807160029008\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004470451622891747\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004564522629065059\n",
      "            Iterations: 29\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004660015985396029\n",
      "            Iterations: 35\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00475713252384554\n",
      "            Iterations: 33\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004859309329995179\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004967812486484322\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005082644444453851\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005203804390049591\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0053312923483736984\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005465133646127114\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0056058797390712055\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005753835924947908\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0059090022592390695\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006071378723450643\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006240965317582605\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006417762041634979\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006601768895607754\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006792985879500927\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006991412993314512\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007197050237048502\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0074098976107028845\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007629955114277678\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007857222747772863\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008091700511188462\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00833338840452446\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008582286427780863\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008838394580957667\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def frontier_obj(w, sigma):\n",
    "    return (np.dot(  np.dot( w, sigma), w)* .5)\n",
    "\n",
    "def frontier_obj_der( w, sigma): \n",
    "    return (np.dot( w, sigma))\n",
    "\n",
    "\n",
    "frontier_cons0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*w.size)}\n",
    "\n",
    "frontier_uncons={}\n",
    "\n",
    "for target_ret in np.linspace(0.045, 0.1, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['CMA_active_arith'])- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['CMA_active_arith']} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    \n",
    "    # unconstrained opt\n",
    "    MV_opt_1= minimize( frontier_obj, \n",
    "                    x0= portfolios['EqualWeights'].weight, \n",
    "                    args= UniverseProperty['LW_cov_active'], \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter': 1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None]]* UniverseProperty['asset_count'],\n",
    "                    tol= 1e-10)  # long only constrain\n",
    "    \n",
    "    frontier_uncons[target_ret]= Portfolio( asset_ret= UniverseProperty['CMA_active_geo'],\n",
    "                                         asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                                         weight= MV_opt_1.x)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0041620369331015475\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004166442358088477\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004174549595130644\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004186264235506788\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0042018178516663686\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004220414836918147\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004242854836497227\n",
      "            Iterations: 23\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004268870199874874\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004298052597064372\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004329496607723859\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004363167989505652\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004399071359981933\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004437206345568815\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004477570578338226\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004520161162530899\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004564984639614273\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004612381979719441\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004661383924715833\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0047127837486159166\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0047662138075351464\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004821581104259152\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004878810410399419\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00493791269645381\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004998804977243388\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0050612956332304546\n",
      "            Iterations: 24\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005126070511686845\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005192642465901125\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005261102327864426\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005331458694896875\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005403716416060382\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005477875348221044\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005553982339187245\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005632277179158973\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0057127718897694935\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005795445333929898\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005880273814585384\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005967250638660538\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006056374020060736\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006147641991161113\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006241052560690411\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006336602929010697\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00643428798074118\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00653419245537094\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006636118974723858\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006740358701184043\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0068466524445141945\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006955084237800826\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007065661023887423\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007178383274046788\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007293251420883877\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007410265832960262\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007529035158530415\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007650317868978875\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00777374574204829\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007899318777738654\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008027036976049952\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008156900336982206\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008288908860535411\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008423062546709551\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008559361395504653\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008697805406920677\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00883839458095767\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n"
     ]
    }
   ],
   "source": [
    "frontier_uncons_NoCorp={}\n",
    "\n",
    "\n",
    "\n",
    "for target_ret in np.linspace(0.07, 0.1, 100): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['CMA_active_arith'])- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['CMA_active_arith']} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    initial_guess= np.ones(UniverseProperty['asset_count'])* 1/UniverseProperty['asset_count']\n",
    "    initial_guess[2]=0\n",
    "    # unconstrained opt\n",
    "    MV_opt_2= minimize( frontier_obj, \n",
    "                    x0= initial_guess, \n",
    "                    args= UniverseProperty['LW_cov_active'], \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter':1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None], [0, None], [0, 1e-15]]+ [[0, None]]* ( UniverseProperty['asset_count']- 3),\n",
    "                    tol= 1e-8)  # long only constrain\n",
    "    \n",
    "    frontier_uncons_NoCorp[target_ret]= Portfolio( asset_ret= UniverseProperty['CMA_active_geo'],\n",
    "                                         asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                                         weight= MV_opt_2.x)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002685832491895796\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027135074196184233\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002750615687298132\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027924139614029534\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0028359365223310173\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002880231015780635\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002925293791610663\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0029711248483355697\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0030177241869349066\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003065091807080328\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031132277087718365\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031621318920094263\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0032118043567931067\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003262245103122867\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0033134541310936567\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0033654314404206504\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003418177031388667\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0034716909204254177\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0035259730579629573\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0035810234935692298\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003636842210721591\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003693429209420032\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0037507844896645607\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0038089080514551745\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0038677998947918733\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003927460019674653\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003987888426103522\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004049085114078486\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0041110500835995194\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004173783334666651\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004237284867279851\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0043015546814391585\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004366592777144545\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004432399154396009\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0044989738131935636\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0045663167535372065\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004634427975426943\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00470330747886276\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004772955263844676\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0048433713303726875\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004914555678446804\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004986508308067055\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005059229219233469\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005132718411946143\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005206975886205263\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005282001642011297\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005357795679365253\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005434357998271048\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0055116885991617895\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005589787480686993\n",
      "            Iterations: 22\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005668654644242901\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005748290089318193\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005828693815929978\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005909865824103143\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0059918061138223965\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006074514685087741\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00615799153789916\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006242236672256665\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006327250088160258\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006413031785609941\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006499581764605696\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00658690002514754\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0066749865672945325\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006764423758114425\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006857663785090154\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006954980131946667\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007056372798797876\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n"
     ]
    }
   ],
   "source": [
    "frontier_cons= {}\n",
    "\n",
    "for target_ret in np.linspace(0.06, 0.095, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['CMA_active_arith'])- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['CMA_active_arith']} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    # constrained opt \n",
    "    MV_opt_3= minimize( frontier_obj, \n",
    "                    x0= portfolios['EqualWeights'].weight, \n",
    "                    args= UniverseProperty['LW_cov_active'], \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter':1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.3]]* UniverseProperty['asset_count'],\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "    \n",
    "    frontier_cons[target_ret]=   Portfolio( asset_ret= UniverseProperty['CMA_active_geo'], \n",
    "                                        asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                                        weight= MV_opt_3.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006009245101045906\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006045081902177092\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006086341311098281\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006132435835675368\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006182157814984094\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0062348746416162225\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006290586315575836\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006349292836939575\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00641099420546787\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006475690421346831\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006543381484564759\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006614067395099601\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006687748152949647\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006764423758116825\n",
      "            Iterations: 22\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006844094210594406\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006926759510389422\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007012419657499495\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007101074651924606\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00719272449366477\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007287369182719972\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007385008719090219\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007485643102775511\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007589272333775845\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007695896412091239\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007805515337721657\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007918129110844248\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008033737730931929\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008152341198504057\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008276969820931995\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008412351764084027\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00854994268701193\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008689725972184401\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008831701619601449\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008975869629263049\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n"
     ]
    }
   ],
   "source": [
    "frontier_cons_NoCorp= {}\n",
    "\n",
    "for target_ret in np.linspace(0.07, 0.1, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['CMA_active_arith'])- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['CMA_active_arith']} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    # constrained opt \n",
    "    initial_guess= np.ones(UniverseProperty['asset_count'])* 1/UniverseProperty['asset_count']\n",
    "    initial_guess[2]=0\n",
    "    MV_opt_4= minimize( frontier_obj, \n",
    "                    x0= initial_guess, \n",
    "                    args= UniverseProperty['LW_cov_active'], \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter': 1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.3], [0, 0.3], [0, 1e-15]]+ [[0, 0.3]]* ( UniverseProperty['asset_count']-3) ,\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "    \n",
    "    frontier_cons_NoCorp[target_ret]=   Portfolio( asset_ret= UniverseProperty['CMA_active_geo'], \n",
    "                                        asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                                        weight= MV_opt_4.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xc16fa20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkRSj4BcRSTH/P7mXGE99M8h7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc154550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig= plt.figure()\n",
    "\n",
    "frontier_uncons_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_uncons.values()]\n",
    "frontier_uncons_pair.sort(key= lambda x: x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_uncons_pair], y= [x[0] for x in frontier_uncons_pair], \n",
    "            marker='o', c= 'pink', s=10, label= 'long only')\n",
    "\n",
    "frontier_uncons_NoCorp_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_uncons_NoCorp.values()]\n",
    "frontier_uncons_NoCorp_pair.sort(key= lambda x : x[0])\n",
    "plt.scatter( x= [x[1] for x in frontier_uncons_NoCorp_pair], y = [x[0] for x in frontier_uncons_NoCorp_pair], \n",
    "           marker= 'o', c= 'orange', s=10, label= 'long only(No Corp)')\n",
    "\n",
    "\n",
    "frontier_cons_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_cons.values()]\n",
    "frontier_cons_pair.sort(key= lambda x : x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_cons_pair], y= [x[0] for x in frontier_cons_pair], \n",
    "            marker= '*', c= 'blue' , s=10, label= 'long only and constrained')\n",
    "\n",
    "frontier_cons_NoCorp_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_cons_NoCorp.values()]\n",
    "frontier_cons_NoCorp_pair.sort(key= lambda x: x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_cons_NoCorp_pair], y= [x[0] for x in frontier_cons_NoCorp_pair], \n",
    "           marker= '*', c= 'red', s=10, label= 'long only and constrained(No Corp)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peer Implied Return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030963</td>\n",
       "      <td>0.059415</td>\n",
       "      <td>0.019873</td>\n",
       "      <td>0.066431</td>\n",
       "      <td>0.070149</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>0.068093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  0.030963  0.059415  0.019873  0.066431  0.070149  0.070369  0.068093"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_free= 179/10000\n",
    "gamma= 3.5\n",
    "\n",
    "UniverseProperty['impliedExpectedReturn_peer_arith']= portfolios['Peer'].implied_ExpectedReturn(gamma= gamma, risk_free= risk_free)\n",
    "UniverseProperty['impliedExpectedReturn_peer_geo']= UniverseProperty['impliedExpectedReturn_peer_arith']- .5* np.diag(UniverseProperty['LW_cov'])\n",
    "\n",
    "pd.DataFrame(UniverseProperty['impliedExpectedReturn_peer_geo']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0359304 ,  0.06939446,  0.02185507,  0.07806678,  0.0895547 ,\n",
       "        0.08693194,  0.10000493])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(UniverseProperty['impliedExpectedReturn_peer_arith'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Return (BL) and Frontier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from blacklitterman import naive_BlackLitterman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply BL to arithmatic expected return \n",
    "\n",
    "prior_ExpectedReturn= UniverseProperty['impliedExpectedReturn_peer_arith']\n",
    "prior_cov= UniverseProperty['LW_cov_active']\n",
    "tau= 0.05\n",
    "prior_risk= UniverseProperty['LW_cov']* tau\n",
    "\n",
    "views_weight= np.identity(UniverseProperty['asset_count'])\n",
    "views_expectedReturn= UniverseProperty['CMA_active_arith']\n",
    "views_risk = UniverseProperty['LW_cov_active']* 2*tau\n",
    "\n",
    "\n",
    "arithBL= naive_BlackLitterman( prior_ExpectedReturn= prior_ExpectedReturn, prior_uncertainty= prior_risk, prior_cov= prior_cov, \n",
    "                         views_weight= views_weight, views_return= views_expectedReturn, views_uncertainty= views_risk)\n",
    "\n",
    "UniverseProperty['arithBL_peer_CMAactive']= arithBL\n",
    "# Note: the prior, view and post are arithmatic \n",
    "# To convert the aithmatic post expected return to geometric, deduct half post return variance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04380985,  0.06861074,  0.02357064,  0.07104906,  0.07605534,\n",
       "        0.07312406,  0.07412406])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arithBL.post_ExpectedReturn- .5* np.diag( arithBL.post_cov) # post geometric expected return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.071049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.073124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.074124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.043810\n",
       "1  0.068611\n",
       "2  0.023571\n",
       "3  0.071049\n",
       "4  0.076055\n",
       "5  0.073124\n",
       "6  0.074124"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(arithBL.arith2geo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frontier based on BL post Expected Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018061111084892532\n",
      "            Iterations: 27\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018438935502451395\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018837359702019404\n",
      "            Iterations: 26\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019256384121274677\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019696008111688397\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002015623244475364\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002063681349189862\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021137477987597264\n",
      "            Iterations: 34\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021658260450978578\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002219908868591742\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022759969636436607\n",
      "            Iterations: 31\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002334096624146585\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002394209743778196\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002456324058458726\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025204474703292225\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025865797796155187\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002654720453988199\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027248696891363747\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027970272026150234\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0028711927449626765\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002947367161050373\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0030255561372847122\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031057412158818163\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031879386963194105\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003272140259817837\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003358345959133922\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0034465558288853523\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0035367698829103763\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0036289881271192085\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003723210559053306\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003819437174400825\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003917667967999779\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004017902934413841\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004120142067939975\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004224385362247124\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0043306328097403235\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004438884401113788\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004549140142109756\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004661399911435902\n",
      "            Iterations: 23\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004775664274811639\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004891932902794121\n",
      "            Iterations: 23\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005010200733230546\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005130476771690298\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005252756932518072\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005377041216749039\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005503329625779399\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005631622160882155\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00576191882319456\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005894219613636917\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006028524532956614\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006164833577161976\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0063031467499416885\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006444219782987739\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006589643003676063\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006739472596338107\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006893698777125272\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007052330740229416\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007215365400173616\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0073828027576228455\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007554642836299498\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007730885593877862\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00791153511782351\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008096581452356921\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008286030786115934\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008479883567169692\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008678140029789342\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008880800018636356\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009087863154355499\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00929933037406016\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009515191679322691\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009735461414541713\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009960133843033772\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010189208919377538\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010422686727507378\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010660567233413288\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01090285043621039\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011149536335841944\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011400624932299824\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011656117730152009\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011919954820885476\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012195778687274486\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012483589329155182\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01278338674656314\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01309517093948635\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013418941909021646\n",
      "            Iterations: 21\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01375469965187866\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014102444171361663\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014462419312675757\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014836279091863955\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015224337788358772\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015626583658323742\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016043027303087962\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016473667020766376\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016918501586634785\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017377530470799502\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017850753491138804\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.018338171181526846\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.018839783525227624\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01936132103593996\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01992240339936224\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n"
     ]
    }
   ],
   "source": [
    "frontier_BLuncons={}\n",
    "\n",
    "for target_ret in np.linspace(0.045, 0.1, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn)- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    \n",
    "    # unconstrained opt\n",
    "    MV_opt_5= minimize( frontier_obj, \n",
    "                    x0= portfolios['EqualWeights'].weight, \n",
    "                    args= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter': 1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None]]* UniverseProperty['asset_count'],\n",
    "                    tol= 1e-10)  # long only constrain\n",
    "    \n",
    "    frontier_BLuncons[target_ret]= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(),\n",
    "                                         asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                                         weight= MV_opt_5.x)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0055505959473478965\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005612169271008836\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005675397476558232\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005739679536866314\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005805445264733835\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005872633694433723\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00594113626214653\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006010949279501955\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006082072752011011\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006154506683846239\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006228251077805078\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006303305935166011\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0063796712553718625\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006457347035412637\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006536333268647495\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00661662994250125\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006698237033717518\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006781154497797813\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006865382242974429\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006950920056910465\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007037767361887608\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0071259222347549965\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007215645917923672\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007306399434298791\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007398264503098989\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00749167151914837\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007586385074839919\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007682409291675241\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007779743649563863\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007878387615791363\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007978341920163307\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008079606626647294\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008182181765501038\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008286067351442727\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008391263390991086\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008497769885438353\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008605586831617001\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008714714220953044\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008825152036294491\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008936900245841267\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009049958809532627\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009164328018422435\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009280010421621647\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00939700032839981\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009515300650489493\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009634913041547134\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009755834292887615\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009878065985594752\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010001608118592673\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010126460689884346\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010252623696941205\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010380097137332994\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010508881009211893\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01063897531144163\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010770380043443792\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01090309520495027\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011037120795796933\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011172456815800605\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01130910326470631\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011447060142177057\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011586327447803416\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011726906158378613\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011871122361014692\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01201889771411862\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012170238858121279\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012325145879220227\n",
      "            Iterations: 14\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01248361950661767\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012645658225271552\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012811262630105506\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012980432390017234\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01315316684763476\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01332947297431534\n",
      "            Iterations: 16\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01350934160112636\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013692770594188457\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013879766257505284\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014070339095554527\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014264485593270381\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014462436779829599\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014664599965525507\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014870982051867793\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015081587305762357\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015296417404878877\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01551547217560223\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01573875126961562\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015966254316520673\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01619798110682881\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016433931354307985\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016674104881304705\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01691850157135473\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01716712135894387\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017419964219378557\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017677030155005612\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017938329409407552\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.018203831409783374\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.018473566813785373\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01874752547851592\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01902571630214931\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.019312355628200134\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.019611253274249132\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01992240339936225\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n"
     ]
    }
   ],
   "source": [
    "frontier_BLuncons_NoCorp={}\n",
    "\n",
    "\n",
    "for target_ret in np.linspace(0.07, 0.1, 100): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn)- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    initial_guess= np.ones(UniverseProperty['asset_count'])* 1/UniverseProperty['asset_count']\n",
    "    initial_guess[2]=0\n",
    "    # unconstrained opt\n",
    "    MV_opt_6= minimize( frontier_obj, \n",
    "                    x0= initial_guess, \n",
    "                    args= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter':1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None], [0, None], [0, 1e-15]]+ [[0, None]]* ( UniverseProperty['asset_count']- 3),\n",
    "                    tol= 1e-8)  # long only constrain\n",
    "    \n",
    "    frontier_BLuncons_NoCorp[target_ret]= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(),\n",
    "                                         asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                                         weight= MV_opt_6.x)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0035367698829103776\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003595222330470245\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003654486391746533\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0037145619725133055\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0037754491811689\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003837147979081446\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0038996583662416068\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003962980379169276\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004027116553540862\n",
      "            Iterations: 26\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004092068439455495\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004157836036498013\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00422441934552596\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004291818365083571\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004360033096139265\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0044290635387916255\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0044989096927286\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00456957155807048\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004641049135009848\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004713342423225504\n",
      "            Iterations: 34\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004786451422172339\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004860376132884377\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004935116554992003\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005010672688463535\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005087044533313426\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005164233620491127\n",
      "            Iterations: 29\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005242265944741724\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005321150844779449\n",
      "            Iterations: 29\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005400888320643248\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005481478372432149\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005562921000063614\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005645216203017214\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005728363982092699\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0058123643369748295\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0058972172676641284\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0059829227741609045\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006069480856462204\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006156891514567034\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006245154748460774\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006334270558159249\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006424238943664404\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0065150599049863\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00660675220002971\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00670177147232894\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0067990355862834395\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Current function value: 0.006898102835007779\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0069989732178093\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0071016467346596175\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007206123386208559\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007312403171685916\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007420486091731696\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007530372145867796\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0076420613345419205\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007755553657210739\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007870849114315681\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007987947705709608\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008106849431399117\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008227554291460817\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008350062285625334\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0084743734141752\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008600487677014062\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008728405074141911\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008858125605558747\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008989649271264569\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009122976071259373\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009258106005543172\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009395039074115952\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00953377527697771\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009674314614128467\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0098166570855682\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009960802691296915\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010106751431314632\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01025450330562133\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010404058314217007\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010555416457101676\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010708577734275328\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010863542145737974\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011020309691489597\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011178880371530213\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011339254185859803\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011501431134478397\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01166541121738596\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01183119443458252\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011998780786068058\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012168170271867113\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012340961646189252\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012520048232744302\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01270548965208598\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012897285904214264\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013095436989129182\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01329982011066441\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013509323430661798\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01372368089930911\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013942892518318015\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014166958283047527\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014395969863994156\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0146305962624639\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014871497410691705\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015119145770158535\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015373541340864359\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01563468412280922\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n"
     ]
    }
   ],
   "source": [
    "frontier_BLcons= {}\n",
    "\n",
    "for target_ret in np.linspace(0.06, 0.095, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn)- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    # constrained opt \n",
    "    MV_opt_7= minimize( frontier_obj, \n",
    "                    x0= portfolios['EqualWeights'].weight, \n",
    "                    args= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter':1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.3]]* UniverseProperty['asset_count'],\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "    \n",
    "    frontier_BLcons[target_ret]=   Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(), \n",
    "                                        asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                                        weight= MV_opt_7.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006231036541667296\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006281329583466524\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006337892054847513\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006400723955810257\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006469156222268315\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006542263216691641\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0066200390678561585\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006701771472132177\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006785030383456623\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006869613913335845\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006955522261559798\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007042755361506271\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00713131321317526\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007221195816566773\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00731240317168081\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007404935278517365\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007498792137151183\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007593973747417068\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007690480109362186\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00778831122308878\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007887467088537938\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007987947705709616\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008089753074603813\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008192883195220522\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008297338067559763\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008403117691621524\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008510222067405801\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008618651194912596\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00872840507414192\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008839483705093753\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008951887087768118\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00906561522216499\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009180668108284388\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009297045746126317\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009414748135690747\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009533775276977715\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009654127169987196\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009775803814719203\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009898805211173723\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010023131359350767\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010148782259250326\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010275757910872407\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01040405831421701\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010533683469284138\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010664633376073776\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010796908034585943\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010930507444820629\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011065431606777832\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01120168052045756\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011339254185859814\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01147815260298458\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011618375771831864\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011759923692401673\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011902796364693997\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012046993788708854\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012192515964450175\n",
      "            Iterations: 23\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012340961646189254\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012494075363269923\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012651857937091757\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012814309367654802\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012981429654959038\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01315321879900445\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013329451963593385\n",
      "            Iterations: 22\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013509323430669174\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013692761211018542\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01387976530476619\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014070335711911776\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014264472432733499\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014462419308892863\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014664597617645079\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014871497410691712\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015083354338526195\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015300168401148524\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015521939598558685\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015748667930756716\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015980353397742574\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0162169959995163\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016463427322370754\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016728655193512527\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01706895086190988\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.01723417336372432\n",
      "            Iterations: 164\n",
      "            Function evaluations: 1492\n",
      "            Gradient evaluations: 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017104545848404262\n",
      "            Iterations: 11\n",
      "            Function evaluations: 42\n",
      "            Gradient evaluations: 7\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.01702767363626406\n",
      "            Iterations: 17\n",
      "            Function evaluations: 117\n",
      "            Gradient evaluations: 13\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.016954447432581565\n",
      "            Iterations: 34\n",
      "            Function evaluations: 352\n",
      "            Gradient evaluations: 34\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.016884614805973596\n",
      "            Iterations: 21\n",
      "            Function evaluations: 191\n",
      "            Gradient evaluations: 21\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.017248799926123038\n",
      "            Iterations: 94\n",
      "            Function evaluations: 505\n",
      "            Gradient evaluations: 91\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.016754231764034188\n",
      "            Iterations: 75\n",
      "            Function evaluations: 594\n",
      "            Gradient evaluations: 71\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01728834930259829\n",
      "            Iterations: 108\n",
      "            Function evaluations: 846\n",
      "            Gradient evaluations: 104\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.016634917831361153\n",
      "            Iterations: 114\n",
      "            Function evaluations: 727\n",
      "            Gradient evaluations: 111\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016578980237462286\n",
      "            Iterations: 77\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 73\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.01652532154431492\n",
      "            Iterations: 88\n",
      "            Function evaluations: 459\n",
      "            Gradient evaluations: 84\n"
     ]
    }
   ],
   "source": [
    "frontier_BLcons_NoCorp= {}\n",
    "\n",
    "for target_ret in np.linspace(0.07, 0.1, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn)- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    # constrained opt \n",
    "    initial_guess= np.ones(UniverseProperty['asset_count'])* 1/UniverseProperty['asset_count']\n",
    "    initial_guess[2]=0\n",
    "    MV_opt_8= minimize( frontier_obj, \n",
    "                    x0= initial_guess, \n",
    "                    args= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter': 1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.3], [0, 0.3], [0, 1e-15]]+ [[0, 0.3]]* ( UniverseProperty['asset_count']-3) ,\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "    \n",
    "    frontier_BLcons_NoCorp[target_ret]=   Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(), \n",
    "                                        asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                                        weight= MV_opt_8.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAJCCAYAAABAuEcoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XtYlVX+///nBglE0DTEqRxDrTwAmw1omgLxgejkscxC\nDUTUtCaZSftMdPqqY1lNlo6OM8TMz0NdiJhmjpT50UkdMEtFAU9b0mZPOiJ5GBNQjMP+/bHjHpEN\nAkJqvR7XxbX3vtda73vd9154xbu11m2y2+2IiIiIiIiIiIgAuFztDoiIiIiIiIiIyLVDySIRERER\nERERETEoWSQiIiIiIiIiIgYli0RERERERERExKBkkYiIiIiIiIiIGJQsEhERERERERERg5JFIiIi\nIiIiIiJiULJIREREREREREQMShaJiIiIiIiIiIih1dXugDM+Pj52Pz+/q90NaQalpaW0adPmandD\nrkEaG1IfjQ+pi8aG1EfjQ+qisSH10fiQ+vzUxkdOTs5Ju93e8XL1rslkkZ+fHzt37rza3ZBmsHnz\nZiIjI692N+QapLEh9dH4kLpobEh9ND6kLhobUh+ND6nPT218mEymfzWknpahiYiIiIiIiIiIQcki\nERERERERERExKFkkIiIiIiIiIiKGa3LPIhEREREREbk6ysvLOXr0KGVlZVe7Kz+Kdu3aceDAgavd\nDblGXa/jw8PDg86dO+Pm5tak9koWiYiIiIiIiOHo0aN4e3vj5+eHyWS62t1pccXFxXh7e1/tbsg1\n6nocH3a7nVOnTnH06FG6du3apBhahiYiIiIiIiKGsrIybrrppp9Fokjkp8hkMnHTTTdd0exAJYtE\nRERERESkBiWKRK5vV/o7rGSRiIiIiIiIiIgYlCwSERERERGRa8rx48eJjY2le/fuhIaG8tBDD1FQ\nUIDNZsNkMvHyyy8bdU+ePImbmxvPPPNMjRgWi4XY2NgGnW/z5s0MHjy4Wa/hStlsNgICAq52N+Rn\nSskiERERERERaRq7HYpOQc5++DzX8Vp0ynG8ySHtPPzww0RGRnL48GFycnJ4/fXXKSoqAqBr1658\n/PHHRv0PPvgAf3//GjEOHDhAZWUlWVlZlJaWNrkvIj9XShaJiIiIiIhI49ntsO8wFPwLSs5BeYXj\nteBfjuNNTBht2rQJNzc3Jk+ebBwLCgoiPDwcAE9PT3r16sXOnTsByMjI4LHHHqsRIz09nbi4OO67\n7z7WrFnTqPOfPn2a4cOHYzab6d+/P/n5+QDMmDGDxMREIiMj6datG/PnzzfazJo1ix49ehAWFsao\nUaOYM2dOrbg2m42oqCjMZjPR0dF88803ACQkJJCUlMSAAQPo1q0bK1eurNU2IiKC3Nxc43NYWBh5\neXmNui6RxlCySERERERERBrv29Pwn7NQVVXzeFWV4/i3p5sUdu/evYSGhtZbJzY2luXLl3PkyBFc\nXV255ZZbapRnZGQQGxvLqFGjSE9PN46npKSQkpJSb+zp06cTHBxMfn4+s2fPJj4+3iizWq2sX7+e\n7du3M3PmTMrLy9mxYwerVq0iLy+PdevWGUmsS02ZMoWxY8eSn5/PmDFjSEpKMsoKCwvJzs4mMzOT\n5OTkWm3Hjx/PkiVLACgoKKCsrIygoKB6r0PkSihZJCIiIiIiIo13tKh2oqhaVZWjvIU88MADbNiw\ngeXLl/P444/XKNu5cyc+Pj506dKF6Ohodu/ezenTjsTV5MmTa8xYciY7O5u4uDgAoqKiOHXqFGfP\nngVg0KBBuLu74+Pjg6+vL0VFRWzdupVhw4bh4eGBt7c3Q4YMcRp327ZtjB49GoC4uDiys7ONsuHD\nh+Pi4kLv3r2N5XYXGzlyJJmZmZSXl7No0SISEhIadqNEmkjJIhEREREREWm8C99fWXkd/P39ycnJ\nqbfODTfcQGhoKG+//TaPPvpojbL09HSsVit+fn50796ds2fPsmrVqib15VLu7u7Ge1dXVyoqKpo9\nrt3J8j1PT09iYmJYs2YNK1asYMyYMc1yXpG6KFkkIiIiIiIijed+w5WV1yEqKooLFy6QmppqHMvP\nzycrK6tGvWnTpvHmm2/SoUMH41hVVRUrVqxgz5492Gw2bDYba9asqbEU7XLCw8NJS0sDHE9J8/Hx\noW3btnXWHzhwIGvXrqWsrIySkhIyMzOd1hswYADLly8HIC0tzdiDqaEmTJhAUlISffv2pX379o1q\nK9JYra52B0REREREROQ61LmTYzNrZ0vRXFwc5U1gMplYvXo1v/nNb3jzzTfx8PDAz8+PefPm1ajn\n7+9f6yloWVlZ3HrrrTX2MIqIiGD//v0UFhYam13XtxSteiNrs9mMp6cnS5curbe/ffv2ZejQoZjN\nZjp16kRgYCDt2rWrVW/BggWMGzeOt956i44dO7J48eLL3ouLhYaG0rZtW8aNG9eodiJNYXI2xe1q\n69Onj72uTcHk+rJ582YiIyOvdjfkGqSxIfXR+JC6aGxIfTQ+pC4aG41z4MABevXqdfmK1U9Du3ST\naxcXaN8W/LuDydRyHW0mxcXFeHt7X1GMkpISvLy8OHfuHBEREaSmphISEtJMPXQ4duwYkZGRWK1W\nXFy0SOjH0hzj42px9rtsMply7HZ7n8u11QgTERERERGRxjOZHAmhO28DL09wa+V4vfO26yZR1Fye\nfPJJLBYLISEhjBgxotkTRe+99x79+vXjtddeU6JIfhRahiYiIiIiIiJNYzJBp5scPz9jy5Yta9H4\n8fHxxMfHt+g5RC6mlKSIiIiIiIiIiBiULBIREREREREREYOSRSIiIiIiIiIiYlCySERERERERERE\nDEoWiYiIiIiIyDXl+PHjxMbG0r17d0JDQ3nooYcoKCjAZrNhMpl4+eWXjbonT57Ezc2NZ555pkYM\ni8VCbGxsg863efNmBg8e3KzXcKVsNhsBAQGXrffRRx/xu9/9DoAZM2bg6enJt99+a5R7eXk16rwl\nJSVMmjTJuPeRkZF8+eWXjet8HZ577jk+++yzZoklLUvJIhEREREREWkaexX8Mw3W9YFVnRyv/0xz\nHG9qSLudhx9+mMjISA4fPkxOTg6vv/46RUVFAHTt2pWPP/7YqP/BBx/g7+9fI8aBAweorKwkKyuL\n0tLSJvflevD73/+ep59+2vjs4+PD22+/3eR4EyZMoEOHDnz11Vfk5OSwePFiTp482aC2drudqqq6\nv/spU6bwxhtvNLlv8uNRskhEREREREQaz14FWY/A9knwnxy48K3jdfskyBrR5ITRpk2bcHNzY/Lk\nycaxoKAgwsPDAfD09KRXr17s3LkTgIyMDB577LEaMdLT04mLi+O+++5jzZo1jTr/6dOnGT58OGaz\nmf79+5Ofnw84Zu0kJiYSGRlJt27dmD9/vtFm1qxZ9OjRg7CwMEaNGsWcOXNqxbXZbERFRWE2m4mO\njuabb74BICEhgaSkJAYMGEC3bt1YuXJlrbYRERHk5uYan8PCwsjLy6OgoAB3d3d8fHyMssTERDIy\nMjh9+nStOO+88w4BAQEEBAQwb968WuWHDx/myy+/5NVXX8XFxZEu6Nq1K4MGDaqzvc1mo0ePHsTH\nxxMQEMCRI0fw8vLi2Wefxd/fn+joaE6cOAHAbbfdxqlTpzh+/PhlvgW52pQsEhERERERkcazpUPh\nRqi8ZOZOZSkUboB/LW9S2L179xIaGlpvndjYWJYvX86RI0dwdXXllltuqVGekZFBbGwso0aNIj09\n3TiekpJCSkpKvbGnT59OcHAw+fn5zJ49m/j4eKPMarWyfv16tm/fzsyZMykvL2fHjh2sWrWKvLw8\n1q1bZySxLjVlyhTGjh1Lfn4+Y8aMISkpySgrLCwkOzubzMxMkpOTa7UdP348S5YsAaCgoICysjKC\ngoLYunUrISEhNep6eXmRmJjIH/7whxrHq2cJffnll3zxxRf85S9/Yffu3TXq7Nu3D4vFgqura60+\n1Nf+q6++4umnn2bfvn3cdtttlJaW0qdPH/bt28c999zDzJkzjTghISFs3brV6T2Sa4eSRSIiIiIi\nItJ41rm1E0XVKkvB+k6LnfqBBx5gw4YNLF++nMcff7xG2c6dO/Hx8aFLly5ER0eze/duY5bN5MmT\na8xYciY7O5u4uDgAoqKiOHXqFGfPngVg0KBBxkweX19fioqK2Lp1K8OGDcPDwwNvb2+GDBniNO62\nbdsYPXo0AHFxcWRnZxtlw4cPx8XFhd69exvL7S42cuRIMjMzKS8vZ9GiRSQkJACOJFPHjh1r1U9K\nSmLp0qUUFxfXuK6HH36YNm3a4OXlxSOPPEJWVla99+LS+1JX+9tuu43+/fsbdV1cXIzv5Yknnqhx\nrb6+vhw7dqzB55WrQ8kiERERERERabxzRy5TfrRJYf39/cnJyam3zg033EBoaChvv/02jz76aI2y\n9PR0rFYrfn5+dO/enbNnz7Jq1aom9eVS7u7uxntXV1cqKiqaPa7dbq9V7unpSUxMDGvWrGHFihWM\nGTMGgNatW1NWVlar/o033sjo0aNZuHBho/rh7+9PXl4elZWVjWrXpk2bestNJpPxvqysjNatWzcq\nvvz4lCwSERERERGRxvP85WXKOzcpbFRUFBcuXCA1NdU4lp+fX2sWzLRp03jzzTfp0KGDcayqqooV\nK1awZ88ebDYbNpuNNWvW1FiKdjnh4eGkpaUBjqek+fj40LZt2zrrDxw4kLVr11JWVkZJSQmZmZlO\n6w0YMIDlyx1L89LS0ow9mBpqwoQJJCUl0bdvX9q3bw9Ar169OHTokNP6U6dO5d133zUSWuHh4Xz0\n0UecO3eO0tJSVq9eXasP3bt3p0+fPkyfPt1IWtlsNj7++OMGta9WVVVl7L20bNkywsLCjLKCgoIG\nPeVNri4li0RERERERKTxej4LrnXMKHFtAz2nNimsyWRi9erVbNy4ke7du+Pv788LL7zAL37xixr1\n/P39GTt2bI1jWVlZ3HrrrTX2MIqIiGD//v0UFhY2aM+iGTNmkJOTg9lsJjk5maVLl9Zbv2/fvgwd\nOhSz2cyDDz5IYGAg7dq1q1VvwYIFLF68GLPZzPvvv19rT6HLCQ0NpW3btowbN67Gte3evdvpbCQf\nHx8efvhhLly4ADj2CkpISOCuu+6iX79+TJgwgeDg4Frt/vrXv1JUVMTtt99OQEAACQkJ+Pr6Nrg9\nOGYabd++nYCAAD777DP+3//7fwCUl5dz6NAh+vTp06hrlx+fydmgutr69Oljr2tTMLm+bN68mcjI\nyKvdDbkGaWxIfTQ+pC4aG1IfjQ+pi8ZG4xw4cIBevXpdvmL109Au3eTatQ3cHAPhq8B07c9PKC4u\nxtvb+4pilJSU4OXlxblz54iIiCA1NbXWxtNX6tixY0RGRmK1Wo0nlQH8+te/ZsiQIdx7773Ner4r\n4eXlRUlJSa3jq1evZteuXcyaNesq9KppmmN8XC3OfpdNJlOO3W6/bLbu2v/NFRERERERkWuPyQXC\nP4R+qdAhFDw6OV77pV43iaLm8uSTT2KxWAgJCWHEiBHNnih677336NevH6+99lqNRBHAiy++yLlz\n55r1fC2loqKCadOmXe1uSAO0utodEBERERERkeuUyQX8Rjt+fsaWLVvWovHj4+OJj493WtapUyeG\nDh3aoudvLGezisDxVDe5Pvx8Ur0iIiIiIiIiInJZShaJiIiIiIiIiIhBySIRERERERERETEoWSQi\nIiIiIiIiIgYli0REREREROSacvz4cWJjY+nevTuhoaE89NBDFBQUYLPZMJlMvPzyy0bdkydP4ubm\nxjPPPFMjhsViITY2tkHn27x5M4MHD27Wa7hSNpuNgICAH+18V+Me2Gy2Jm8OPmDAgGbrw495n68X\nShaJiIiIiIhIk1RVQVoa9OkDnTo5XtPSHMebym638/DDDxMZGcnhw4fJycnh9ddfp6ioCICuXbvy\n8ccfG/U/+OAD/P39a8Q4cOAAlZWVZGVlUVpa2vTOSIuqL1lUUVFRb9vPP/+8JbokP1CySERERERE\nRBqtqgoeeQQmTYKcHPj2W8frpEkwYkTTE0abNm3Czc2NyZMnG8eCgoIIDw8HwNPTk169erFz504A\nMjIyeOyxx2rESE9PJy4ujvvuu481a9Y06vynT59m+PDhmM1m+vfvT35+PgAzZswgMTGRyMhIunXr\nxvz58402s2bNokePHoSFhTFq1CjmzJlTK67NZiMqKgqz2Ux0dDTffPMNAAkJCSQlJTFgwAC6devG\nypUra7WNiIggNzfX+BwWFkZeXl6t+OHh4YSEhBASEmIkUzZv3kxkZCSPPvooPXv2ZMyYMdjtdgA+\n/fRTevbsSUhICB9++KHT+1FZWclzzz1HQEAAZrOZBQsWAPD3v/+d4OBgAgMDSUxM5MKFCwD4+fkx\nffp0QkJCCAwMxGq1ArBlyxYsFgsWi4Xg4GCKi4tJTk4mKysLi8XC3LlzWbJkCUOHDiUqKoro6GhK\nSkqIjo42Yl38XXp5eV32+nJycrjnnnsIDQ3l/vvvp7Cw0DgeFBREUFAQCxcudHrdP3cNShaZTKYH\nTCbTQZPJdMhkMiU7KTeZTKb5P5Tnm0ymkIvKfm0ymfaaTKZ9JpPpN83ZeREREREREbk60tNh40a4\ndOJOaSls2ADLlzct7t69ewkNDa23TmxsLMuXL+fIkSO4urpyyy231CjPyMggNjaWUaNGkZ6ebhxP\nSUkhJSWl3tjTp08nODiY/Px8Zs+eTXx8vFFmtVpZv34927dvZ+bMmZSXl7Njxw5WrVpFXl4e69at\nM5JYl5oyZQpjx44lPz+fMWPGkJSUZJQVFhaSnZ1NZmYmycm1/uRm/PjxLFmyBICCggLKysoICgqq\nUcfX15cNGzawa9cuMjIyasTfvXs38+bNY//+/Xz99dds3bqVsrIyJk6cyNq1a8nJyeH48eNO+52a\nmorNZiM3N9foe1lZGQkJCWRkZLBnzx4qKir485//bLTx8fFh165dPPXUU0bibM6cOSxcuJDc3Fyy\nsrJo3bo1b7zxBuHh4eTm5vLss88CsGvXLlauXMmWLVvw8PBg9erV7Nq1i02bNjFt2jQjEXQxZ9dX\nXl7OlClTWLlyJTk5OSQmJvLSSy8BMG7cOBYsWFAr4Sb/ddlkkclkcgUWAg8CvYFRJpOp9yXVHgTu\n+OHnSeDPP7QNACYCdwFBwGCTyXR7s/VeREREREREroq5c2sniqqVlsI777TcuR944AE2bNjA8uXL\nefzxx2uU7dy5Ex8fH7p06UJ0dDS7d+/m9OnTAEyePLnGjCVnsrOziYuLAyAqKopTp05x9uxZAAYN\nGoS7uzs+Pj74+vpSVFTE1q1bGTZsGB4eHnh7ezNkyBCncbdt28bo0aMBiIuLIzs72ygbPnw4Li4u\n9O7d21hud7GRI0eSmZlJeXk5ixYtIiEhoVad8vJyJk6cSGBgICNHjmT//v1G2V133UXnzp1xcXHB\nYrFgs9mwWq107dqVO+64A5PJxBNPPOG03xs3bmTSpEm0atUKgA4dOnDw4EG6du3KnXfeCcDYsWP5\nxz/+YbR55JFHAAgNDcVmswEwcOBApk6dyvz58zlz5owR71IxMTF06NABcCxJfPHFFzGbzdx77738\n+9//dnp/nF3fwYMH2bt3LzExMVgsFl599VWOHj3KmTNnOHPmDBEREcZ3IbU5/3Zqugs4ZLfbvwYw\nmUzLgWHA/ovqDAPesztSfF+YTKYbTSbTzUAv4Eu73X7uh7ZbgEeA3zfjNYiIiIiIiMiP7MiR+suP\nHm1aXH9/f6dLsS52ww03EBoayttvv83+/fv529/+ZpSlp6djtVrx8/MD4OzZs6xatYqJEyc2rUMX\ncXd3N967urpedl+dpsR1NnPG09OTmJgY1qxZw4oVK8jJyalVZ+7cuXTq1Im8vDyqqqrw8PBo8X7X\npfp8F58rOTmZQYMG8cknnzBw4EDWr1/vtG2bNm2M92lpaZw4cYKcnBzc3Nzw8/OjrKyszvNdfE67\n3Y6/vz/btm2rUffMmTNXfH0/Bw1ZhnYrcPE/A0d/ONaQOnuBcJPJdJPJZPIEHgJ+2fTuioiIiIiI\nyLXgl5f5y65z56bFjYqK4sKFC6SmphrH8vPzycrKqlFv2rRpvPnmm8YsFICqqipWrFjBnj17sNls\n2Gw21qxZU2Mp2uWEh4eTlpYGOPbD8fHxoW3btnXWHzhwIGvXrqWsrIySkhIyMzOd1hswYADLf1ib\nl5aWZuzB1FATJkwgKSmJvn370r59+1rl3333HTfffDMuLi68//77VFZW1huvZ8+e2Gw2Dh8+DFDn\nPYqJieHdd981kj6nT5+mR48e2Gw2Dh06BMD777/PPffcU+/5Dh8+TGBgIM8//zx9+/bFarXi7e1N\ncXFxnW2+++47fH19cXNzY9OmTfzrX/+q9xwX69GjBydOnDCSReXl5ezbt48bb7yRG2+80ZjZVf1d\nS00NmVnUZHa7/YDJZHoT+D+gFMgFnI5Yk8n0JI4lbHTq1InNmze3ZNfkR1JSUqLvUpzS2JD6aHxI\nXTQ2pD4aH1IXjY3GadeuXb1/wFebPLkVv/61B+fOmWqVeXraeeqpMoqLmzaD5f333yc5OZnXX38d\nDw8PunTpwhtvvEFJSQlVVVUUFxfTpUsXunTpQnFxMWVlZXz//fesX7+eX/ziFzWSEMHBwezbt4+v\nvvrKeIra+PHjjXNVVlZy7tw5KioqKC4uZtq0afzqV78iICCA1q1b86c//Yni4mIuXLiAm5ubEbeq\nqoqSkhJ69uzJ/fffT0BAAL6+vvTq1Qt3d/da9/D111/n6aef5s0338THx8eIW15ezvnz52vULy4u\nrnGtAHfeeSdeXl48/vjjTr+f+Ph44uLiWLJkCffeey9t2rShuLi4xrUBfP/995SVlVFeXs68efN4\n8MEH8fT05O677+Y///lPrdiPP/44e/fuJSAgADc3N8aOHcukSZNYuHAhI0aMoKKigpCQEMaMGUNx\ncTF2u52SkhLc3d0pLS2lsrKS4uJifv/735OVlYWLiws9e/YkLCwMFxfH/JXAwEBGjx5N+/bt+f77\n740+DBs2jMceewx/f3+Cg4O58847KSkpMcrru74LFy6wdOlSnnvuOc6ePUtFRQVPP/00Xbp04Y9/\n/CNPPfUUJpOJqKioGvf5UtX9vx6VlZU1+d8+k7MpbjUqmEx3AzPsdvv9P3x+AcBut79+UZ13gc12\nuz39h88HgUi73V54SazZwFG73f6n+s7Zp08fe12bgsn1pXpnepFLaWxIfTQ+pC4aG1IfjQ+pi8ZG\n4xw4cIBevXpdtl7109Au3eS6TRuIiYFVq8DlOnj+dnFxMd7e3lcUo6SkBC8vL86dO0dERASpqamE\nhIRcvmEjHDt2jMjISKxWq5FkkZbXHOPjanH2u2wymXLsdnufy7VtyAjbAdxhMpm6mkymG4BY4G+X\n1PkbEP/DU9H6A99VJ4pMJpPvD69dcOxXtKwB5xQREREREZFrmIsLfPghpKZCaCh06uR4TU29fhJF\nzeXJJ5/EYrEQEhLCiBEjmj1R9N5779GvXz9ee+01JYrkR3HZZWh2u73CZDI9A6wHXIFFdrt9n8lk\nmvxDeQrwCY79iA4B54BxF4VYZTKZbgLKgV/Z7XbtJiUiIiIiIvIT4OICo0c7fn7Oli1r2TkR8fHx\nxMfHt+g5RC7WoD2L7Hb7JzgSQhcfS7novR34VR1tG7drl4iIiIiIiIiIXDWavyYiIiIiIiIiIgYl\ni0RERERERERExKBkkYiIiIiIiIiIGJQsEhERERERkWvK8ePHiY2NpXv37oSGhvLQQw9RUFCAzWbD\nZDLx8ssvG3VPnjyJm5sbzzzzTI0YFouF2NjYBp1v8+bNDB48uFmv4UrZbDYCAgJ+tPNdjXtgs9ma\nvDn4gAEDmq0PF9/n3bt3M378eACWLFlCu3btyM/PN8oDAgKw2WwNjl9eXk5ycjJ33HEHISEh3H33\n3axbt65Z+v7HP/6RRYsWNUusSylZJCIiIiIiIk1TVQVpadCnD3Tq5HhNS3McbyK73c7DDz9MZGQk\nhw8fJicnh9dff52ioiIAunbtyscff2zU/+CDD/D3968R48CBA1RWVpKVlUVpaWmT+yItq75kUUVF\nRb1tP//885boErNnzyYpKcn4fOutt/Laa681Od4rr7xCYWEhe/fuZdeuXXz00UcUFxc3uH1lZWWd\nZYmJiSxYsKDJfauPkkUiIiIiIiLSeFVV8MgjMGkS5OTAt986XidNghEjmpww2rRpE25ubkyePNk4\nFhQURHi440Hbnp6e9OrVi507dwKQkZHBY489ViNGeno6cXFx3HfffaxZs6ZR5z99+jTDhw/HbDbT\nv39/Y1bJjBkzSExMJDIykm7dujF//nyjzaxZs+jRowdhYWGMGjWKOXPm1Iprs9mIiorCbDYTHR3N\nN998A0BCQgJJSUkMGDCAbt26sXLlylptIyIiyM3NNT6HhYWRl5dXK354eDghISGEhIQYyZTNmzcT\nGRnJo48+Ss+ePRkzZgyOB5rDp59+Ss+ePQkJCeHDDz90ej8qKyt57rnnCAgIwGw2G8mJv//97wQH\nBxMYGEhiYiIXLlwAwM/Pj+nTpxMSEkJgYCBWqxWALVu2YLFYsFgsBAcHU1xcTHJyMllZWVgsFubO\nncuSJUsYOnQoUVFRREdHU1JSQnR0tBHr4u/Sy8vrsteXk5PDPffcQ2hoKPfffz+FhYXG8aCgIIKC\ngli4cKERs7i4mPz8fIKCgoxj999/P/v27ePgwYO17k16ejqBgYEEBATw/PPP1yo/d+4cf/nLX1iw\nYAHu7u4AdOrUyRivdbX38vJi2rRpBAUFsW3bNvz8/Pjtb39LYGAgd911F4cOHQIcvwt+fn5s377d\n6Xd3JZQsEhERERERkcZLT4eNG+HSmTulpbBhAyxf3qSwe/fuJTQ0tN46sbGxLF++nCNHjuDq6sot\nt9xSozwjI4PY2FhGjRpFenq6cTwlJYWUlJR6Y0+fPp3g4GDy8/OZPXs28fHxRpnVamX9+vVs376d\nmTNnUl6L5WCAAAAgAElEQVRezo4dO1i1ahV5eXmsW7fOSGJdasqUKYwdO5b8/HzGjBlTY/ZKYWEh\n2dnZZGZmkpycXKvt+PHjWbJkCQAFBQWUlZXVSGgA+Pr6smHDBnbt2kVGRkaN+Lt372bevHns37+f\nr7/+mq1bt1JWVsbEiRNZu3YtOTk5HD9+3Gm/U1NTsdls5ObmGn0vKysjISGBjIwM9uzZQ0VFBX/+\n85+NNj4+PuzatYunnnrKSJzNmTOHhQsXkpubS1ZWFq1bt+aNN94gPDyc3Nxcnn32WQB27drFypUr\n2bJlCx4eHqxevZpdu3axadMmpk2bZiSCLubs+srLy5kyZQorV64kJyeHxMREXnrpJQDGjRvHggUL\naiXcdu7cWWvpn4uLC7/97W+ZPXt2jePHjh3j+eef57PPPiM3N5cdO3bw0Ucf1ahz6NAhunTpQtu2\nbWv1ub72paWl9OvXj7y8PMLCwgBo164de/bs4ZlnnuE3v/mNEadPnz5kZWU5/e6uhJJFIiIiIiIi\n0nhz59ZOFFUrLYV33mmxUz/wwANs2LCB5cuX8/jjj9co27lzJz4+PnTp0oXo6Gh2797N6dOnAZg8\neXKNGUvOZGdnExcXB0BUVBSnTp3i7NmzAAwaNAh3d3d8fHzw9fWlqKiIrVu3MmzYMDw8PPD29mbI\nkCFO427bto3Ro0cDEBcXR3Z2tlE2fPhwXFxc6N27t7Hc7mIjR44kMzOT8vJyFi1aREJCQq065eXl\nTJw4kcDAQEaOHMn+/fuNsrvuuovOnTvj4uKCxWLBZrNhtVrp2rUrd9xxByaTiSeeeMJpvzdu3Mik\nSZNo1aoVAB06dODgwYN07dqVO++8E4CxY8fyj3/8w2jzyCOPABAaGmrs7zNw4ECmTp3K/PnzOXPm\njBHvUjExMXTo0AFwLEl88cUXMZvN3Hvvvfz73/92en+cXd/BgwfZu3cvMTExWCwWXn31VY4ePcqZ\nM2c4c+YMERERxndRrbCwkI4dO9aKP3r0aL744gv++c9/Gsd27NhBZGQkHTt2pFWrVowZM6bGPbic\n+tq7uroyYsSIGvVHjRplvG7bts047uvry7Fjxxp83oZy/u2IiIiIiIiI1OfIkfrLjx5tUlh/f3+n\nS7EudsMNNxAaGsrbb7/N/v37+dvf/maUpaenY7Va8fPzA+Ds2bOsWrWKiRMnNqk/F6teSgSOP+gv\nt69OU+I6mznj6elJTEwMa9asYcWKFeTk5NSqM3fuXDp16kReXh5VVVV4eHi0eL/rUn2+i8+VnJzM\noEGD+OSTTxg4cCDr16932rZNmzbG+7S0NE6cOEFOTg5ubm74+flRVlZW5/kuPqfdbsff379GYgXg\nzJkzdfa7devWTuO3atWKadOm8eabb9Zz1bXdfvvtfPPNN5w9e9bp7KK6eHh44OrqWuOYyWRy+r6s\nrIzWrVs3ql8NoZlFIiIiIiIi0ni//GX95Z07NylsVFQUFy5cIDU11TiWn59fa6lN9R/v1bNQAKqq\nqlixYgV79uzBZrNhs9lYs2ZNjaVolxMeHk5aWhrg2A/Hx8en3j/0Bw4cyNq1aykrK6OkpITMzEyn\n9QYMGMDyH5bmpaWlGXswNdSECRNISkqib9++tG/fvlb5d999x80334yLiwvvv/9+vRsjA/Ts2ROb\nzcbhw4cB6rxHMTExvPvuu0bS5/Tp0/To0QObzWbsnfP+++9zzz331Hu+w4cPExgYyPPPP0/fvn2x\nWq14e3vXu9nzd999h6+vL25ubmzatIl//etf9Z7jYj169ODEiRNGsqi8vJx9+/Zx4403cuONNxoz\nu6q/a4BevXoZ13SphIQENm7cyIkTJwDHbKYtW7Zw8uRJKisrSU9Pr3UPPD09GT9+PL/+9a/5/vvv\nAThx4gQffPBBg9pfLCMjw3i9++67jeMFBQUt8tQ8JYtERERERESk8Z59Fi6aBVJDmzYwdWqTwppM\nJlavXs3GjRvp3r07/v7+vPDCC/ziF7+oUc/f35+xY8fWOJaVlcWtt95aYw+jiIgI9u/fT2FhYYP2\nLJoxYwY5OTmYzWaSk5NZunRpvfX79u3L0KFDMZvNPPjggwQGBtKuXbta9RYsWMDixYsxm828//77\n/OEPf7jcraghNDSUtm3bMm7cOKflTz/9NEuXLiUoKAir1Vpjho4zHh4epKamMmjQIEJCQvD19XVa\nb8KECXTp0gWz2UxQUBDLli3Dw8ODxYsXM3LkSAIDA3Fxcbns8r558+YZm2S7ubnx4IMPYjabcXV1\nJSgoiLlz59ZqM2bMGHbu3ElgYCDvvfcePXv2rPccF7vhhhtYuXIlzz//PEFBQVgsFmPT78WLF/Or\nX/0Ki8VSYyZXz549+e6775wmsG644QaSkpL49ttvAbj55pt54403+J//+R+CgoIIDQ1l2LBhtdq9\n+uqrdOzYkd69exMQEMDgwYNp27Ztg9tX+89//oPZbOYPf/hDjXu1detWYmJiGnxfGsrkbIrb1dan\nTx97XZuCyfWlemd6kUtpbEh9ND6kLhobUh+ND6mLxkbjHDhwgF69el2+YvXT0C7d5LpNG4iJgVWr\nwOXan59QXFyMt7f3FcUoKSnBy8uLc+fOERERQWpqKiEhIc3UQ4djx44RGRmJ1WrF5Tq4r9eruXPn\n4u3tzYQJE4DmGR9Xys/Pz9iL62K7d+/mnXfe4f3333faztnvsslkyrHb7X0ud06NMBEREREREWk8\nFxf48ENITYXQUOjUyfGamnrdJIqay5NPPonFYiEkJIQRI0Y0e6Lovffeo1+/frz22mtKFLWwp556\nqsYeSNeykydPMmvWrBaJrQ2uRUREREREpGlcXGD0aMfPz9iyZctaNH58fDzx8fEteg5x8PDwqPGE\ntGtB9RPlLtUSy8+qKSUpIiIiIiIiIiIGJYtERERERERERMSgZJGIiIiIiIiIiBiULBIRERERERER\nEYOSRSIiIiIiInJNcXV1xWKxEBQUREhICJ9//jng2Og3ICCgwXE2b97M4MGDW6qbTdLYaxC5GvQ0\nNBEREREREbkyFRWw7zD4d4dWV/5nZuvWrcnNzQVg/fr1vPDCC2zZsuWK44pIw2hmkYiIiIiIiFyZ\nI0Vwptjx2szOnj1L+/btrzjO6dOnGT58OGazmf79+5Ofnw/A7NmzSUxMJDIykm7dujF//nyjzaxZ\ns+jRowdhYWGMGjWKOXPm1Iprs9mIiorCbDYTHR3NN998A0BCQgJJSUkMGDCAbt26sXLlylptIyIi\njKQYQFhYGHl5eVd8rSJXSskiERERERERabqKCjj6Q5LoaJHj8xU6f/48FouFnj17MmHCBF555ZV6\n66ekpJCSklJvnenTpxMcHEx+fj6zZ88mPj7eKLNaraxfv57t27czc+ZMysvL2bFjB6tWrSIvL491\n69axc+dOp3GnTJnC2LFjyc/PZ8yYMSQlJRllhYWFZGdnk5mZSXJycq2248ePZ8mSJQAUFBRQVlZG\nUFBQvdch8mNQskhERERERESa7kgRYP/hg71ZZhdVL0OzWq18+umnxMfHY7fb66w/efJkJk+eXG/M\n7Oxs4uLiAIiKiuLUqVOcPXsWgEGDBuHu7o6Pjw++vr4UFRWxdetWhg0bhoeHB97e3gwZMsRp3G3b\ntjF69GgA4uLiyM7ONsqGDx+Oi4sLvXv3pqio9n0ZOXIkmZmZlJeXs2jRIhISEuq9BpEfi/YsEhER\nERERkaapnlVU9UMip8ru+PzLTs2ydxHA3XffzcmTJzlx4kSzxHPG3d3deO/q6kpFM8yOujSus2SX\np6cnMTExrFmzhhUrVpCTk9Ms5xW5UppZJCIiIiIiIk1TY1ZRteaZXVTNarVSWVnJTTfddEVxwsPD\nSUtLAxxPSfPx8aFt27Z11h84cCBr166lrKyMkpISMjMzndYbMGAAy5cvByAtLY3w8PBG9WvChAkk\nJSXRt2/fZtmbSaQ5aGaRiIiIiIiINN6ls4qqNcPsouo9i8AxI2fp0qW4uroCcPDgQTp37mzUnTt3\nLqdOnQKodynajBkzSExMxGw24+npydKlS+vtQ9++fRk6dChms5lOnToRGBhIu3btatVbsGAB48aN\n46233qJjx44sXry4UdcaGhpK27ZtGTduXKPaibQkJYtERERERESk8Y4UQV37CNl/mF3U9dYmha6s\nrHR63M/Pj/Ly8gbHiYyMJDIyEoAOHTrw0Ucf1arz4osv4u3tbXzeu3ev8f65555jxowZnDt3joiI\nCEJDQ2u1v+222/jss89qHa/euLpaSUmJcQ0Xn+PYsWNUVVVx3333Nfi6RFqalqGJiIiIiIhI45We\nh1au4Naq9k8rV0f5de7JJ5/EYrEQEhLCiBEjCAkJadb47733Hv369eO1117DxUV/nsu1QzOLRERE\nREREpPECbr/aPWhxy5Yta9H48fHxxMfHt+g5RJpCqUsRERERERERETEoWSQiIiIiIiIiIgYli0RE\nRERERERExKBkkYiIiIiIiIiIGJQsEhERERERkWuKq6srFouFoKAgQkJC+PzzzwGw2WwEBAQ0OM7m\nzZsZPHhwS3WzSRp6DR999BG/+93vAJgxYwaenp58++23RrmXl1ejzltSUsKkSZPo3r07oaGhREZG\n8uWXXzau83V47rnn+Oyzz5olllwblCwSERERERGRK/P9Gfj7vY7XZtC6dWtyc3PJy8vj9ddf54UX\nXmiWuNeT3//+9zz99NPGZx8fH95+++0mx5swYQIdOnTgq6++Iicnh8WLF3Py5MkGtbXb7VRVVdVZ\nPmXKFN54440m902uPUoWiYiIiIiIyJU5MAeKPgPrO80e+uzZs7Rv3/6K45w+fZrhw4djNpvp378/\n+fn5AMyePZvExEQiIyPp1q0b8+fPN9rMmjWLHj16EBYWxqhRo5gzZ06tuDabjaioKMxmM9HR0Xzz\nzTcAJCQkkJSUxIABA+jWrRsrV66s1TYiIoLc3Fzjc1hYGHl5eRQUFODu7o6Pj49RlpiYSEZGBqdP\nn64V55133iEgIICAgADmzZtXq/zw4cN8+eWXvPrqq7i4ONIAXbt2ZdCgQXW2t9ls9OjRg/j4eAIC\nAjhy5AheXl48++yz+Pv7Ex0dzYkTJwC47bbbOHXqFMePH7/MtyDXCyWLRERERH7OqiohLwVW+cPy\nmxyveSmO4yIiDfH9GbDOA+yOZFEzzC46f/48FouFnj17MmHCBF555ZV666ekpJCSklJvnenTpxMc\nHEx+fj6zZ88mPj7eKLNaraxfv57t27czc+ZMysvL2bFjB6tWrSIvL49169axc+dOp3GnTJnC2LFj\nyc/PZ8yYMSQlJRllhYWFZGdnk5mZSXJycq2248ePZ8mSJQAUFBRQVlZGUFAQW7duJSQkpEZdLy8v\nEhMT+cMf/lDjePUsoS+//JIvvviCv/zlL+zevbtGnX379mGxWHB1da3Vh/raf/XVVzz99NPs27eP\n2267jdLSUvr06cO+ffu45557mDlzphEnJCSErVu3Or1Hcv1RskhERETkp85eBf9Mg3V9YFUnx+s/\n06CyHD55APZPhQv7oeq043X/VPjkQSWMRKRhDswBfliiZK9qltlF1cvQrFYrn376KfHx8djt9jrr\nT548mcmTJ9cbMzs7m7i4OACioqI4deoUZ8+eBWDQoEHGTB5fX1+KiorYunUrw4YNw8PDA29vb4YM\nGeI07rZt2xg9ejQAcXFxZGdnG2XDhw/HxcWF3r17U1RUVKvtyJEjyczMpLy8nEWLFpGQkAA4kkwd\nO3asVT8pKYmlS5dSXFxc47oefvhh2rRpg5eXF4888ghZWVn13otL70td7W+77Tb69+9v1HVxceHx\nxx8H4Iknnqhxrb6+vhw7dqzB55VrW6ur3QERERERaSZ2O3x7Go4WwYXvwf0GuLUjHJwIxzdCZamj\n3oVvYfsk2PMWlBaA/fwlcc5DcTbs+SsETfrxr0NErh/Vs4oqf/h3pPK8I1nUcyrccGOznOLuu+/m\n5MmTxpKnluDu7m68d3V1paKiotnjOkt2eXp6EhMTw5o1a1ixYgU5OTmAI1n23Xff1ap/4403Mnr0\naBYuXNiofvj7+5OXl0dlZaXT2UV1adOmTb3lJpPJeF9WVkbr1q0b1S+5dmlmkYiIiMhPQVUlZL8D\n/wiHr8Lh36Ph21WQmwKF//ffRFG1ylIoya+dKKpmPw+HFrR8v0Xk+nbxrKJqzTS7qJrVaqWyspKb\nbrrpiuKEh4eTlpYGOJ6S5uPjQ9u2beusP3DgQNauXUtZWRklJSVkZmY6rTdgwACWL18OQFpaGuHh\n4Y3q14QJE0hKSqJv377G3ky9evXi0KFDTutPnTqVd99910hohYeH89FHH3Hu3DlKS0tZvXp1rT50\n796dPn36MH36dCNpZbPZ+PjjjxvUvlpVVZWx99KyZcsICwszygoKChr1pDq5tmlmkYiIiMj1wl4F\ntnSwzoVzR8Dzl9DzWbjtcdg4FE5t/m/yp+o0nHkdcK07IUTdSzoAKC9sxs6LyE/OpbOKqjXD7KLq\nPYvAMSNn6dKlxoyYgwcP0rlzZ6Pu3LlzOXXqFEC9S9FmzJhBYmIiZrMZT09Pli5dWm8f+vbty9Ch\nQzGbzXTq1InAwEDatWtXq96CBQsYN24cb731Fh07dmTx4sWNutbQ0FDatm3LuHHjjGMRERFMmzYN\nu91eY/YOOJ6K9vDDDzN37lzAsVdQQkICd911F+BIPgUHB9c6z1//+lemTZvG7bffTuvWrfHx8eGt\nt96qs73NZqsVo02bNmzfvp1XX30VX19fMjIyACgvL+fQoUP06dOnUdcu1y5Tfes+r5Y+ffrY69o8\nTK4vmzdvJjIy8mp3Q65BGhtSH40PqcvPamxcuqTshlZw+rfwn3/UnCXk2gba9YT/7K8nKdRE7v4w\nYm/zxmxBP6vxIY2isdE4Bw4coFevXpevmPeyY2ZR1YXaZS7u0Pu3YP5d83ewmRUXF+Pt7e20rKSk\nBC8vL86dO0dERASpqam1Np6+UseOHSMyMhKr1Wo8qQzg17/+NUOGDOHee+9t1vNdCS8vL0pKSmod\nX716Nbt27WLWrFlXoVctq77xca1z9rtsMply7Hb7ZbN6mlkkIiIici2xV4FtGeS+CReOgWsn8Brl\nSB59t7l2QqiyFE7vptYykAYz4XSGkak13D6liTFF5Gfhu33g5g3U8Yf0mT0/andawpNPPsn+/fsp\nKytj7NixzZ4oeu+993jppZd45513aiSKAF588UW+/PLLZj1fS6moqGDatGlXuxvSjJQsEhEREfmx\n1becLPtROLYBqs456jZoOVkTE0UunnBDN7hwuGZsU2vwDoPACU2LKyI/DxGrr3YPWtyyZctaNH58\nfDzx8fFOyzp16sTQoUNb9PyN5WxWETie6iY/LUoWiYiIiLS0i5eUlZXByf+F81/8NyFU/XSyg3Ph\nO+t/jxvtr3B5mckLTFU147q2gZtjYOAK2LvIsZl1eSG43eyYURQ4ATBBWhrMnQtHjsAvfwnPPguj\nRoGLnpMiIiLyU6VkkYiIiEhLuHj2ULENTL7/XU52blsLLCdzcd7W1BpunQ6/vNmRjDp3FDw7Ozae\nvS3WsQJtrxfM9YAjreCXHvCsF/jb4dERsHEjlP6wR9K338KkSbByJaxapYSRiIjIT5SSRSIiIiJN\ndbnlZIUbL9qM+lTLLidr1wvOWmtufm1qDTf9D4Q9Cy6u0HXMJaergkcecZ4QmjsXrNb/Hq9WWgob\nNsDy5TB6dNP6KyIiItc0/e8gERERkcay2+H4CfhbDHwxEf6T41hK9p8cx3Ky/+t/SaKout15sDvf\n76FBTF6OBNDFXNvALffB/V9Av1ToEAoenRyvd/8VotdA+nLo0wc6dXK8pqU5EkXp6TUTRdVKS2H3\n7trHLy5/552mX4eIiIhc05QsEhEREamPvQr+mQbr+sCqTo7X7HcgN6X+5WSXJooarI7/PDO1hht/\nC51fhfYXJYT6pcLADyA9Ax59B8Yegdmd4dSz0PkxGPGoY6ZQTo5j1lBOjuPziBGO2UN1JYSqLjPL\n6ejRJl6fiMjlubq6YrFYCAoKIiQkhM8//xwAm81GQEBAg+Ns3ryZwYMHt1Q3m6Sx13ClrsY9sNls\nTd4cfMCAAc3Whx/zPv/UaBmaiIiI/LzZ7VB0Eg4shlNLoPJbx54+Ac859vS5dDnZhW/hzH5+9OVk\nre+Gr31g8f9Xc7Pp6oRQU5aSubo2rZ8AnTs3va2I/OScOQOPPurY0uzGG688XuvWrcnNzQVg/fr1\nvPDCC2zZsuXKA8uPojpZNNrJcuWKigpatao7FVGdGJSrSzOLRERE5OfLboe9X8Hnj8HxGfD9Aag8\nBcV58OWT185ysn6psMQbnv/f2jOE+vdv+lKyior6+1nXBtZt2sDUqQ27VhH5WZgzBz77rGVWqJ49\ne5b27dtfcZzTp08zfPhwzGYz/fv3Jz8/H4DZs2eTmJhIZGQk3bp1Y/78+UabWbNm0aNHD8LCwhg1\nahRz5sypFddmsxEVFYXZbCY6OppvvvkGgISEBJKSkhgwYADdunVj5cqVtdpGREQYSTGAsLAw8vLy\nasUPDw8nJCSkxiyrzZs3ExkZyaOPPkrPnj0ZM2YMdrsdgE8//ZSePXsSEhLChx9+6PR+VFZW8txz\nzxEQEIDZbGbBggUA/P3vfyc4OJjAwEASExO5cOECAH5+fkyfPp2QkBACAwOxWq0AbNmyBYvFgsVi\nITg4mOLiYpKTk8nKysJisTB37lyWLFnC0KFDiYqKIjo6mpKSEqKjo41Ya9asMfrl5eV12evLycnh\nnnvuITQ0lPvvv5/CwkLjeFBQEEFBQSxcuNDpdUvDKFkkIiIiPx+XLinLDIavX4ILX9aeJVR1Hk7v\nav7lZHYP2HU/TG8PT7vCK60g1w/6ptS9nGyrvWkJocstJWvVypH4ccbTE4KDa5e3aQMxMRAbW39s\nEfnZOHMG5s1z5N/fecfx+UqdP38ei8VCz549mTBhAq+88kq99VNSUkhJSam3zvTp0wkODiY/P5/Z\ns2cTHx9vlFmtVtavX8/27duZOXMm5eXl7Nixg1WrVpGXl8e6devYuXOn07hTpkxh7Nix5OfnM2bM\nGJKSkoyywsJCsrOzyczMJDk5uVbb8ePHs2TJEgAKCgooKysjKCioRh1fX182bNjArl27yMjIqBF/\n9+7dzJs3j/379/P111+zdetWysrKmDhxImvXriUnJ4fjx4877Xdqaio2m43c3Fyj72VlZSQkJJCR\nkcGePXuoqKjgz3/+s9HGx8eHXbt28dRTTxmJszlz5rBw4UJyc3PJysqidevWvPHGG4SHh5Obm8uz\nzz4LwK5du1i5ciVbtmzBw8OD1atXs2vXLjZt2sS0adOMRNDFnF1feXk5U6ZMYeXKleTk5JCYmMhL\nL70EwLhx41iwYEGthJs0npJFIiIi8tNSVQl5KbDKH5bf5HjNS4HKcsh6xLEBdfWG1MV5ULqqnuVk\ntf/DtUFcPKF9sGO2UI1wHjDfCxZ+Al8dg+8q4esK+NMJmLqy7v2FkpKanhCqz+23w733Ok8I3Xcf\nfPEFpKZCaKhjc+zQUMfnVavqnnUkIj87c+b895+iqqrmmV1UvQzNarXy6aefEh8f7zSZUG3y5MlM\nnjy53pjZ2dnExcUBEBUVxalTpzh79iwAgwYNwt3dHR8fH3x9fSkqKmLr1q0MGzYMDw8PvL29GTJk\niNO427ZtM5ZbxcXFkZ2dbZQNHz4cFxcXevfuTVFRUa22I0eOJDMzk/LychYtWkRCQkKtOuXl5Uyc\nOJHAwEBGjhzJ/v37jbK77rqLzp074+LigsViwWazYbVa6dq1K3fccQcmk4knnnjCab83btzIpEmT\njCVhHTp04ODBg3Tt2pU777wTgLFjx/KPf/zDaPPII48AEBoais1mA2DgwIFMnTqV+fPnc+bMmTqX\nmMXExNChQwcA7HY7L774ImazmXvvvZd///vfTu+Ps+s7ePAge/fuJSYmBovFwquvvsrRo0c5c+YM\nZ86cISIiwvgupOm0Z5GIiIj8dFRVwicPQPHW/yaALpyG/VPh64Xw/T+dzBRqYkIIHMvJqKyZbHLx\ndCwnG5ABf3wW/rQEvj0Pvq2h3wDYtw3OX5KcKi2FTz/9ob8XapddCRcX5wmlNm1g2jTHDKHlyx1/\n3R096tiLaOpUx3EXFxg92vEjIuJE9ayi6n/Wzp93/HMydWrz7F0EcPfdd3Py5ElOnDjRPAGdcHd3\nN967urpScblluk2I6yzZ5enpSUxMDGvWrGHFihXk5OTUqjN37lw6depEXl4eVVVVeHh4tHi/61J9\nvovPlZyczKBBg/jkk08YOHAg69evd9q2zUX/YyItLY0TJ06Qk5ODm5sbfn5+lJWV1Xm+i89pt9vx\n9/dn27ZtNeqeaY4pbWLQ/xISERGR65Ozp5RlTayZKDLqnofz+5q4pKyep5O1+19omwxf3AIvuzqW\nlb3WCWzD4dHH4OWl8NU5+M7ueF32Wd3JnwsXaieKGtzFOvrYkKVk1QmhnTvh+HHH6+jRmjkkIg1y\n8ayias01u6ia1WqlsrKSm2666YrihIeH8/+zd+fhUdVn/8ffZybrhJAISGpFC1YqiyyyaF1QXOij\nRWt/damKCyKuFdTYR23FapHyqE2TKFgVa1EogopaKypWBRQ3ZN8DggZBMKwTErLNzDm/P87MZPaE\nZAIBPq/rmivJzNkSRzL5zH3f32nTpgH2PJwOHTrQtm3buNufeeaZvP3229TU1FBZWcmsWbNibnfG\nGWcwY8YMwA5BBg0atF/XNXLkSEaPHs3AgQNjzmYqLy/nmGOOweFwMHXqVHw+X8LjdevWjdLSUjZu\n3AjA9OnTY243ZMgQnnvuuWDos3v3bk466SRKS0vZsGEDAFOnTuWcc85JeL6NGzfSq1cv7r//fgYO\nHH9F98sAACAASURBVEhJSQnZ2dlUVFTE3ae8vJyOHTuSmprK3Llz2bRpU8JzhDrppJPYsWNHMCzy\neDysXr2a3NxccnNzg5Vdgf/W0jSqLBIREZHWyzKh9GVYVQBVWyDtzzD3K+h2A6y/FX6IWKVszxLi\nVwo1oYLIyITcHvbqZJ598AXwHrAb6JgKw1Lgow9g0R6o9r94L/8WbrnVHh4d+YK+OS1jhmEPBInk\nckH37tGrngUCoddeg1dfjV85JCLSRJFVRQHJqC4KzCwCuyLnpZdewulfwXHdunV0ClmRsaioiF27\ndgEkbEV75JFHGDFiBL1798blcvHSSy8lvIaBAwfyq1/9it69e5OXl0evXr3IycmJ2m7ChAnceOON\n/PWvf+Xoo49m8uTJ+/W99u/fn7Zt23LjjTfGfPyOO+7gsssuY8qUKVx44YVhFTqxZGRkMGnSJIYO\nHYrL5WLQoEExg5uRI0eyfv16evfuTWpqKjfffDN33nknkydP5oorrsDr9TJw4MAG2/uKi4uZO3cu\nDoeDnj17ctFFF+FwOHA6nfTp04fhw4dHhWDDhg3jkksuoVevXgwYMIBu3bo18FOql5aWxsyZMxk9\nejTl5eV4vV7uvvtuevbsyeTJkxkxYgSGYfCLX/yi0ceUaEaivs+DZcCAAVa84WFyaAlMsBeJpOeG\nJKLnhwB2UPTJb2Dbf+1h08C8jAIG1z4EKZ3BW5pg1lBTGIBlr3r/BfCeAe40OKEnXHMavPYyLN0L\ntSGvndLTY4dCLSEnxz6XAqG49G+HxKPnxv5Zu3Yt3bt3b3C7MWPsyqJYRZHp6XDffTB2bAtcYJJV\nVFSQnZ0d87HKykratGlDVVUVZ599NpMmTaJfv35JPf/WrVsZPHgwJSUlOI6gf7MPFYmeH61drP+X\nDcNYbFnWgIb2VWWRiIiIHHyWCaXToaQIqjaD6zhofyps+yAYFNVvWw2eEpo2a8io3y8YCgG7gI65\ncFEmfL4DVvmg1gRqYfESWLXaHwpFnLOpbWOxBOYyxDpmVhZMnGgHP5otJCKtxOrVkJ1t32JZufLA\nXk9LuOWWW1izZg01NTXccMMNSQ+KpkyZwoMPPkhhYaGCImlVFBaJiIjIgREaCO37DoyjIXsYHHUx\n7HkA9nwS0VK2FDvRiXmwxp83tFJotxPamXChCQuA1UAgm9m7ByZVgdcEX8R5kxkKQfTQ6awse1Uy\ngA8/jF09FJgjpEBIRFqJN9882FfQ8l5++eUWPf7111/P9ddf36LnEGkKhUUiIiLS8izTXrZ+W8iM\nIXZA3Tgo/1eclrJmzPcJbSkrBlbhbx/zQjnwD8OuEoo8RbJDoVhcLhg+HBYsiK4QgsQrk4mIiIgc\nAAqLREREpPksC7bvhi1lUFMDdR9C5ctQty2kpezD6NXIktVSFmACX6bBB9lQ5oY0E/YA3ojtPAdg\nZqPTCSkp4QFUoEpowoT44Y/ayUREROQgU1gkIiIiTRPaVlZRCkZHyPot1MyB2oX1lULJbCkLMNPh\nq/YwaxvssqA9cCHwlQNW+6BmV5O+pSaJFwpdcAFcfrm9VJCqhEREROQQorBIRERE9l/MtrJd4P4L\n4CM6GGpGS1noIOrRwJOAIxW27YFqf9C0F7u1zKTlViZraih07bUtcz0iIiIiLURva4mIiEhslgVl\nu2DRKvjveHi9J8zsCO8NgIV3xm4rw0PTgiHD/mACnwFjgNuBB4G/HA0vOOBb7ByqFPimEqojZhx5\nrOjB1E3hdNavTBaQlQUXXwz/+Af07w95efbHSZPgjTfsQGjRIvjhB/tjYBi1iIg0idPppG/fvvTp\n04d+/frx+eefA1BaWsrJJ5/c6OPMmzePiy++uKUus0n293toroPxMygtLW3ycPAzzjgjadcQ+nNe\nunQpN910EwAvvvgiDoeDFStWBB8/+eSTKS0tbfTxPR4PDzzwAF27dqVfv36cfvrpvPfee0m59okT\nJ/LPf/4zKcdqKlUWiYiIiC1y+XpHR8i4Aqo/Cm8rq9vRQFtZI/krhqx3DWrKMvnWezx1vjR+Zn2N\nK3CuvQA7mneeeFQpJCKSPG63/W/nzJmQm9vsw2VmZrJs2TIA3n//ff7whz/w8ccfN/u4cmAEwqJr\nYszg83q9pKTEjyICwWCyjR8/njFjxgS/7tSpE3/5y1945ZVXmnS8hx56iG3btrFq1SrS09MpKyvb\nr+eoz+fD6XTGfGzEiBGceeaZjBgxoknXlgx6y0tERETq28q+uhX2LLbnDFWvgj3joObTpKxUZpoG\n0z67lgFjFvKj275n7q3n4JmUglFqkVldRQ9PCX3MFfVBUUtSpZCISHIVFMCcOfZqjkm2d+9ejjrq\nqGYfZ/fu3fz617+md+/e/PznPw9WlYwfP54RI0YwePBgTjjhBJ566qngPo8++ignnXQSZ511Fldf\nfTUFBQVRxy0tLeW8886jd+/enH/++Xz33XcADB8+nNGjR3PGGWdwwgknMHPmzKh9zz777GAoBnDW\nWWexfPnyqOMPGjSIfv36hVVZzZs3j8GDB3P55ZfTrVs3hg0bhmXZ7dmzZ8+mW7du9OvXjzfeeCPm\nz8Pn8/H73/+ek08+md69ezNhwgQAPvroI0455RR69erFiBEjqPW/qdK5c2cefvhh+vXrR69evSgp\nKQHg448/pm/fvvTt25dTTjmFiooKHnjgAebPn0/fvn0pKirixRdf5Fe/+hXnnXce559/PpWVlZx/\n/vnBY7311lvB62rTpk2D39/ixYs555xz6N+/P//zP//Dtm3bgvf36dOHPn368PTTTwePWVFRwYoV\nK+jTp0/wvosvvpjVq1ezbt26qJ/N9OnT6dWrFyeffDJ/+tOfoh6vqqri+eefZ8KECaT7q5Hz8vK4\n8soro/a///77w763e++9lz59+vDFF1/QuXNn7rvvPnr16sWpp57Khg0bAHC5XHTu3Jmvvvoq5n+7\nA0GvekRERI4klgU/7IC5T8DMHvBKB3i7Lyz8XZLbysKZXij+0910f2YNs74dyucVZ3J61Zeker1h\n2xnNPlMc6enQpYtCIRGRluB229WYlmWHRW53sw9ZXV1N37596datGyNHjuShhx5KuP2zzz7Ls88+\nm3Cbhx9+mFNOOYUVK1Ywfvx4rr/++uBjJSUlvP/++3z11Vf8+c9/xuPxsHDhQl5//XWWL1/Oe++9\nx6JFi2Ied9SoUdxwww2sWLGCYcOGMXr06OBj27Zt49NPP2XWrFk88MADUfvedNNNvPjiiwCsX7+e\nmpqasEADoGPHjnzwwQcsWbKEV155Jez4S5cupbi4mDVr1vDNN9/w2WefUVNTw80338zbb7/N4sWL\n+eGHH2Je96RJkygtLWXZsmXBa6+pqWH48OG88sorrFy5Eq/XyzPPPBPcp0OHDixZsoTbb789GJwV\nFBTw9NNPs2zZMubPn09mZiaPPfYYgwYNYtmyZdxzzz0ALFmyhJkzZ/Lxxx+TkZHBm2++yZIlS5g7\ndy733ntvMAgKFev783g8jBo1ipkzZ7J48WJGjBjBgw8+CMCNN97IhAkTogK3RYsWRbX+ORwO7rvv\nPsaPHx92/9atW7n//vuZM2cOy5YtY8mSJfz73/8O22bDhg0cf/zxtG3bNuqaI/dfuHBhcP99+/Zx\n2mmnsXz5cs466ywAcnJyWLlyJXfeeSd333138DgDBgxg/vz5Mf/bHQh6NSQiInK4skz4dpo9Y+j1\nPPvj/AL4/Ar44RGoWwu+XVCxHDY8FyMoaiLTwJzvZNfdR7HrunYsu7YXq0aczC3fTqKftYQfsZ0T\nKCWD2oaPtb/izRu66CLYsEGhkIhISygoANP/xoJpJqW6KNCGVlJSwuzZs7n++utjhgkBt912G7fd\ndlvCY3766adcd911AJx33nns2rWLvXv3AjB06FDS09Pp0KEDHTt2pKysjM8++4xLL72UjIwMsrOz\nueSSS2Ie94svvgi2W1133XV8+umnwcd+/etf43A46NGjB2VlZVH7XnHFFcyaNQuPx8M///lPhg8f\nHrWNx+Ph5ptvplevXlxxxRWsWbMm+Nipp55Kp06dcDgc9O3bl9LSUkpKSujSpQtdu3bFMAyujdM+\n/eGHH3LrrbcGW8LatWvHunXr6NKlCz/72c8AuOGGG/jkk0+C+/zmN78BoH///sH5PmeeeSb5+fk8\n9dRTuN3uuC1mQ4YMoV27dgBYlsUf//hHevfuzQUXXMD3338f8+cT6/tbt24dq1atYsiQIfTt25dx\n48axZcsW3G43brebs88+O/jfImDbtm0cffTRUce/5ppr+PLLL/n222+D9y1cuJDBgwdz9NFHk5KS\nwpVXXhn2M2hI5P7Dhg0L7u90OrnsssvCtr/66quDH7/44ovg/R07dmTr1q2NPm+yaWaRiIjI4SjW\namW122HPCmKvVtaE5esB0+vgi6mncdQnbjp4drAzpQN5uXtx7dpDe3MPAO3ZjeVrwaqhAC1XLyJy\n4AWqigKLDlRX22FRfn5SZhcBnH766ezcuZMdO1pohh0EW4nA/oPeG1H5mozjxgq7XC4XQ4YM4a23\n3uLVV19l8eLFUdsUFRWRl5fH8uXLMU2TjIyMFr/ueALnCz3XAw88wNChQ3n33Xc588wzef/992Pu\nm5WVFfx82rRp7Nixg8WLF5Oamkrnzp2pqamJe77Qc1qWRc+ePcOCFQB3goq2zMzMmMdPSUnh3nvv\n5fHHH0/wXUc78cQT+e6779i7d2/M6qJ4MjIyouYUGYYR8/OamhoyMzP367qSSa+aREREDnWmD5Y/\na69WNqO9/fGTkS3TVhayWpl1G1SNcNH/wyX0qFtLR2snPTwltNuxlUwzfO5Q0oMil8tuJ9O8IRGR\ngyu0qiggSdVFASUlJfh8Ptq3b9+s4wwaNIhp06YB9jycDh06JPxD/8wzz+Ttt9+mpqaGyspKZs2a\nFXO7M844gxkzZgB2CDJo0KD9uq6RI0cyevRoBg4cGHM2U3l5OccccwwOh4OpU6fi8/kSHq9bt26U\nlpayceNGwJ6fE8uQIUN47rnngqHP7t27OemkkygtLQ3Ozpk6dSrnnHNOwvNt3LiRXr16cf/99zNw\n4EBKSkrIzs6moqIi7j7l5eV07NiR1NRU5s6dy6ZNmxKeI9RJJ53Ejh07gmGRx+Nh9erV5Obmkpub\nG6zsCvy3BujevXvwe4o0fPhwPvzww2AYeeqpp/Lxxx+zc+dOfD4fM2fOjPoZuFwubrrpJu666y7q\n6uoA2LFjB6+99lrU/tOnT0/4MwwM2H7llVc4/fTTg/evX7/+gK6aF0mVRSIiIoeKyNXKXMfBSaNh\nzVSo+Kx+CHXtbvh+LU2tFgryr1bGe8AusI6C3VVHkbmzBpdVjQG0oTJqt+YGQ1bkMVwu6N7d/jw1\n1Q6GVC0kInLwRVYVBSShuigwswjsipyXXnopWJGxbt06OnXqFNy2qKiIXbt2ASRsRXvkkUcYMWIE\nvXv3xuVy8dJLLyW8hoEDB/KrX/2K3r17k5eXR69evcjJyYnabsKECdx444389a9/5eijj2by5Mn7\n9b3279+ftm3bcuONN8Z8/I477uCyyy5jypQpXHjhhWEVOrFkZGQwadIkhg4disvlYtCgQTGDm5Ej\nR7J+/Xp69+5NamoqN998M3feeSeTJ0/miiuuwOv1MnDgwAbb+4qLi5k7dy4Oh4OePXty0UUX4XA4\ncDqd9OnTh+HDh0eFYMOGDeOSSy6hV69eDBgwgG7dujXwU6qXlpbGzJkzGT16NOXl5Xi9Xu6++256\n9uzJ5MmTGTFiBIZh8Itf/CK4T7du3SgvL6eiooLs7Oyo440ePZq77roLgGOOOYbHHnuMc889F8uy\nGDJkCJdeemnUdYwbN44xY8bQo0cPMjIyyMrKYuzYsVH7Dx06NOb+AXv27KF3796kp6eHBXufffYZ\njzzySKN/LslmJOr7PFgGDBhgxRseJoeWwAR7kUh6bkgien7EEKutDMBIA8tLMoZQ2xz2sUygGFgF\noaOFooKcJKvExRq6k2LACWlbyDm5E0ZIMKTnhiSi54fEo+fG/lm7di3dAyF9ImPG2JVFtTFm0KWn\nw333wdixyb/AJIsVIARUVlbSpk0bqqqqOPvss5k0aRL9+vVL6vm3bt3K4MGDKSkpwaE3QVpMUVER\n2dnZjBw5cr/2S/T8aK7OnTuzaNEiOnToEHb/0qVLKSwsZOrUqc06fqz/lw3DWGxZ1oCG9lVlkYiI\nSGtkmVD6MqwqgKotQDqYO8Gqi9iuLubuTTtnBnxzFkz9HGtLNVYNOCLeVEp2UFRDOm7Xj8lJqeJb\nbycmpOSz6MSruOdeB32vAkOvmUVEWq/VqyE7277FsnLlgb2eFnDLLbewZs0aampquOGGG5IeFE2Z\nMoUHH3yQwsJCBUUt7Pbbb+e111472JfRKDt37uTRRx89qNegsEhERORgitladhdsngnbPoCI2T/J\n4QCcYHrq28x2Yq9v750PtbUYJD8YiqxKqnJksavfEI794nUcKQ56AM/E2VdERFqhN9882FfQ4l5+\n+eUWPf7111/P9ddf36LnEFtGRkbYCmmtQWBFuUhDhgw5sBcSg8IiERGRA82yYPtu2LwNNo+CmgUh\n84a2w4Kb/a1liQdYNo5BcHaRCSxIh/fTYbsPPD6oMyG4cIqXkC+aJTIYqsTFOqM7OW3hp+lbMI7r\nhCs/H5fmDomItEqWZYWtzCQih5bmjhxSWCQiInKgBFrLlj0OtVvByADfDuwVykK3izH7oUky4Jir\n4b25MHMzbDbBV5fE48dWiYttOd1pdxSwZQub6cRrx+XTc+xVXHWNQ61lIiKtXEZGBrt27aJ9+/YK\njEQOQZZlsWvXLjIyMpp8DIVFIiIiLSGyvSyzExgGlK8FsyrJJ/O3leEJWcHMgN0+4A2oqYHaZFQp\n2SKrhmpIp9bIpJY0dmYex57h+Zz+5FU4UuxUqD3QN2lnFxGRltapUye2bNkSXEr8cFdTU9OsP6rl\n8HaoPj8yMjLCVg3cXwqLREREkqWh9rKW4MyCH10AORfC1xPgia9hpRdqLeyKpfKkni6wWpkD6MQW\ntjo6Me+UfO7+8ipyUhx0TOrZRETkYEhNTaVLly4H+zIOmHnz5nHKKacc7MuQVupIfX4oLBIREWmO\n0AqiilIwOkJqj/CgKKlSwXk0OD3Q5njolg/HXQkzXoExVVDqafgQ+8mHgwra8DVdmZiSz6edrmJf\ntYNOnSA/H+7W2CERERGRw4rCIhERkcaK11q2twR8+/wb7QJPCcGh0k3mBMMJVl39XUYmpJ8GXZ+D\nHj+FGTPgsr/BqhvB6wXTbOY5o1WSxX8ZwuW8jivLwZAh8PXrCodEREREDmcKi0RERBrD9MGHl8Cu\neY1oLWtmUBRoLTvuclhdAFVbwJkHR10HJTnwl6th1aoWCYhqSKcae/7QZo7j72n5zM69in7HOcjP\nBy1eJiIiInL4U1gkIiISS2QVkZkGnjKiVi5LCn9rmVEL2Z2hez785CowHND5Gpg+HZ4ohFUPJz0g\nigyHishnBldh4SArCyZNgsnXJO10IiIiInIIUFgkIiLSqPayFmJkQtYZcOp0yOtgn9c04eXpUFjY\nIhVEPhx4SGUVJ1MYEg6FysqCIUPsSiIRERERObIoLBIRkSObZcInv4FtH9QvaZ+0lcsMwlrSHC7I\n7W7fVb0FXJ3sAdU/uQoefgQefTRJ5w2XqHooID0dfvxjqKoiOLhaLWciIiIiRyaFRSIicuQJW8Hs\na/BW0PyB1JEyIOtiqFsN1vbo9rJQf/pTiwRFJlBKF8YwLiwcMgywQr7dQBXR6xpcLSIiIiI0Miwy\nDONC4EnACfzDsqzHIh43/I//EqgChluWtcT/2D3ASOxX4SuBGy3LqknadyAiIpKI6YOVz8OGCeD5\nAVLyID0Nqja0XIuZkQkZP4djH4bjjoGO7eyEJp4WCIpCVzGLbDHr3BnatYMtW1RFJCIiIiLRGgyL\nDMNwAk8DQ4AtwELDMP5jWdaakM0uArr6b6cBzwCnGYZxLDAa6GFZVrVhGK8CVwEvJvW7EBERicX0\nwbsXQsVn9SuY1e2GusS77Z8MaHMSpKZEt5ZFVhC1sMbOIho3Dq7R0GoRERERiaMxlUWnAhssy/oG\nwDCMGcClQGhYdCkwxbIsC/jSMIxcwzCOCTlHpmEYHsAFbE3a1YuIiISKHFRtZEDNNpK7gpl/5TKr\nxl7O/kcj4cy7wOFM4jkarzEBUYCGVouIiIhIYxiWlXhGg2EYlwMXWpY10v/1dcBplmXdGbLNLOAx\ny7I+9X/9EXC/ZVmLDMO4C/gLUA3817KsYXHOcwtwC0BeXl7/GTNmNPubk4OvsrKSNm3aHOzLkFZI\nzw1JZL+eH9U77IHUpgcMyz+MJ9nzh/wMBziyIKWT/XlaKqQkISRavHi/d7EwqCaTMvLYTbuY2xgG\npKXZC6mlpkJent1+dijTvx2SiJ4fEo+eG5KInh+SyOH2/Dj33HMXW5Y1oKHtWnTAtWEYR2FXHXUB\n3MBrhmFca1nWvyK3tSxrEjAJYMCAAdbgwYNb8tLkAJk3bx76bymx6LkhiTTq+RGrxSypMiC1C2Sk\n2bOOWrK97NxzG9zExKCOtEZVEMHhO7Ra/3ZIInp+SDx6bkgien5IIkfq86MxYdH3wHEhX3fy39eY\nbS4AvrUsaweAYRhvAGcAUWGRiIhIQgekxcwAwwUpx0P2MDj2Cji5a+Lh1Mnw0ENY/iHXkWeygErS\nuY1/MJ1rEgZELhdkZ2totYiIiIg0T2PCooVAV8MwumAHQFcBkWMx/wPc6Z9ndBpQblnWNsMwvgN+\nbhiGC7sN7XxgUdKuXkREDm+WBdt3w+ZtsHkU1CxooSoiwOEC1+nQ/gnIyIBOeQ2vYpYk5iNjebQY\nHqqIXhVtPL/moRgrmkXKyoJJkzS4WkRERESar8GwyLIsr2EYdwLvA07gn5ZlrTYM4zb/488C7wK/\nBDYAVcCN/scWGIYxE1gCeIGl+FvNREREEjJ98Fkx/PACeL8Dq4rkzSLKgMwTISP9oKxgZpowfToU\nFcHmzXZF0La6sTzC2CYdT4OrRURERCSZGjWzyLKsd7EDodD7ng353AJ+F2ffh4GHm3GNIiJyJAht\nM6u5Dl67FHzVJKXNzEizVzAzqyH1GDhxFPQaeVBWMDNN+M1v4MMPYd++ph0jPR1+/GOoqlLLmYiI\niIgkX4sOuBYREWmQZUHZTlhwFVR9YbeZZVwNvr3JOb4zC44ZAoNePyBVQw2ZPr15QdHhOrhaRERE\nRFoPhUUiInLghVYRVZSClQ6+HSRnWHUqODIgNROyjjug7WWxRLacVVbaFUH7Q4OrRURERORAUlgk\nIiItLzQc2vcdWHXgqwGztvnHbkUtZpGS0XKmwdUiIiIicqApLBIRkZZl+uDDS2DXvOSvZNbKWsxi\nDq7eBrVNzMQ0uFpEREREDgaFRSIiknyhlUTl68DcR/JWMjPAkQU5J0H3g9tiFkqDq0VERETkcKGw\nSEREkiMQEK0thL2rwPQCZnLPYWRC+3Phgv+0ijazUBpcLSIiIiKHC4VFIiLSfC3VamakQYoLHGmt\nYlh1KA2uFhEREZHDlcIiERFpmhZpNUu1h1UbKZB5MvR9ADpf3SrCoVAaXC0iIiIihzOFRSIi0jgt\nuaIZ2C1mGT+H454CdxmcvwIMIznHbiYNrhYRERGRI4nCIhERaZhlwvzfwLYPwdfEUpooqeDMhJSM\n6BazeTtbVVCkwdUiIiIiciRRWCQiIvEFqomWj4Gq0iQc0ADDBSnHw49Gwpl3tbpB1ZE0uFpERERE\njjQKi0REJLZkVxOFtpkddwx0bNdqqodCaXC1iIiIiBzpFBaJiEi4pFYTGWCkQm4v6N56VjKLR4Or\nRUREREQUFomISNIHVx86rWYaXC0iIiIiEk1hkYjIkewIbTUDDa4WEREREYlHYZGIyJEoaa1mqWCk\ngyMdcjqHr2jWymlwtYiIiIhIbAqLRESOFIGAaG0h7F0Fphcwm34854+h7e2QdSGc1AXy2iftUluC\nBleLiIiIiDSOwiIRkSNBMtvNjExIPw3aPQ7OFDiqrd1u1oppcLWIiIiISOMpLBIROdxZJiy8E7a8\nTbMqicCuJup4F6RdABkZ0CmvVc4l0uBqEREREZGmU1gkInI4imo5q2ve8QLVRMdPgAEnJ+caW4gG\nV4uIiIiINI/CIhGRw01SWs78g6uNNHDmQZtr7NlExx2T1EttCRpcLSIiIiLSPAqLREQOJ8loOXP+\nGHLugIwh9auaORytdjaRBleLiIiIiCSXwiIRkUNdslrOAq1mHQuga2fYUga1dZCe1qpnE2lwtYiI\niIhIciksEhE5lCWr5Sz1p9BmGGT+AjIzIa+9fWtlNLhaRERERKTlKSwSETlUNbvlzICsyyDnf8Pb\nzTrlJfMqk0aDq0VEREREDgyFRSIih6JARVFTg6JAy1lkUNRK5xKBBleLiIiIiBwoCotERA41zaoo\n8rectb8RetwI3+9otXOJNLhaREREROTgUFgkInIoaXJFUUTLWWoK/Oho+9ZKaXC1iIiIiMjBofdX\nRUQOJaXTYOts9isoMjIh45zwlrP0tBa5vKYyTZg2DQYMgLw8WLkSZs9ufsuZBleLiIiIiOw/VRaJ\niBwqLBMWjQKzsUt/Raxy1kqHWMcaXF1Xt38rnGlwtYiIiIhI8igsEhE5FATmFHnKG7Gxv+Ws3f2A\nw05jAlrhEGsNrhYRERERaV0UFomItHaWCZ/8Br7/TyM2NupbzhxOOPF42FLWqoZYa3C1iIiIiEjr\nprBIRKS1+3YabH0PsBreNnSIdUY65LW3b61ErJaz/aXB1SIiIiIiLUthkYhIaxZoP7PqGt7WaFMf\nFLWSuUSRVUQuF2zbtn/ziEJpcLWIiIiISMtTWCQi0pqVTgPf3kZsmBoeFLWCuUTJqCLS4GoRDUvK\ngQAAIABJREFUERERkQNPYZGISGsVWP2sQQa0ORtyLoaMjFYxlwg0uFpERERE5FClsEhEpLWwLNi+\nu34gde1/G7f6We5v4aJpdlXRQZTMwdUulz2XSFVEIiIiIiIHnsIiEZHWwLJg9UbYs7d+qfudkxve\nz2gD/Z5qFUFRMgdXz5sHgwcn8wpFRERERKSxFBaJiLQG23eHB0UA3s0N73fsw5DXoeWuKw4NrhYR\nEREROXwpLBIRaQ22lIUHRZYJVnUDOzngrHsO+GwiDa4WERERkUNKnRvmXw6DZkJabuJtq3bCB7+C\nIf8B14F/U7a10MtyEZEDzbKgbBcsXgOfL7M/VteEb1P9PmDG3D0oJQsczha7zHiSMbj6ootgwwb4\n4QdYtMhuPVNQJCIiInKE8Xph+Tr7Y6g6N3x0gf0xkcB2VTtjHydgbQGUzYGSwoavaeGjsO9LWDiu\ncd/DYUovzUVEDqTAbKL1m6CyCjxe+6MvIhja80zDx8ru2jLXGME0Ydo0GDAA8vLgllv2Pyhyuex9\n+/e35xJphTMRERGRw0xjAp7IbTaXgbvC/hiqseFOYLuF42IfJ3DOkmLAso+X6PqqdsLWSfa2WyfZ\nXx+h9FJdRORAijWbKKZtDR+r+71JuaREAi1nt94KixfD9u37v8JZVhY8/7yqiEREREQOSbFCoFgV\nQY0JeEK38XrtUQxgfwwcq7HhTuh2WyeBWRF+nNBzBir2LTPx9S181H5zN7DtEVxdpJfrIiIHUuRs\noub4SctMgw6tJDrqKHj77ea1nGlwtYiIiEgrEhr0NKYaKFYIFFkR1JiAJ3Kbb9fbn4P9MXCsxoY7\nkdtVTgs/Tug5ff5ZoL7q+NcXrCoKrNhS6w+h4rS2HeYUFomItIRYc4nKdkFtXeL9nA5o42rcOYzk\n/xMeWUm0tzFFUCHS06FLF7WciYiIiCSF2w0XXGB/DGhKu1eo0KCnoWqgWCFQrIqgxgQ8oduYJqwr\nAtMfFpmWfayqnY0LdyJDIGqh8mXw7g2vLgo9Z0C86wutKgrdtqoRFf+HIb18FxFJtnhzidZvqv+F\nGE9mBvTvcWCuM4bmDK/W4GoRERGRZgqEPNs3wTnnQJ8+MGcOFPrDDa8X5v1h/9q9QoUGPd9tgJIi\nElYDxQqBNpcRVhH07fqGA57IcMeshoppdutYkGUHNo0Jd+KFQKHVRVGBEvGvL6qqKKAW6nYekbOL\n9BJeRCTZ4s0lMk37Fm+pe4cDOuW1/PVFXFJzhldrcLWIiIhII1XthLfOCA8eIiuHAiHPmGvhk0/g\nu+/sNyILC+1tvl0Pu15kv9q9QrcJDXr2Tql/vRorkInVwrW20A6ZQiuCSgppMOBJGO74effagU1D\n4U68ECiyumj1E2DFaSEzveHXt/BRsHyxt8U6ImcX6SW9iEiyJZpLZFngMKITFYcDjmoLHdvZXw94\nO/E5Gnq8EZo7vFqDq0VEROSIEW+J94DGtIbFWpK9oKC+cigQguyz4KVPw/f1+extSwrrW6XMRrR7\nhYY2gaoi07IreipfBqvGf/wY1TaxAh7TBxVTQ76usAOfRAFPQ+FOoLqo8l/xA5vQcGdtQfwQyPLa\n12NZ8MMSSM2G9A7Rt9RscK+s369iDTiywJEbfTMcULE69vkOYykH+wJERA47Dc0lMgzoerz9y7q2\nDtLT7Iqiju3qq45+djHwNiy6JHr/AW/7H2+e5racaXC1iIiIHPLq3FCxHur6Qlpu/G0+uARcY2Fz\nG+hybPQ2gYqgr8bDI0tg5kzIDTle1JLsY6AuBYqL6yuHhlQBJrwDeCKOX1MDRYXwpAkuf6uU6Q9k\nuuXXX3u8gc7d8uH7fQSriir/FXs+T0kh9B4bP+CxaqDiZcgaBo7sxgU8lpk43KmaDkfdAd5v7MDG\nMCDFGb1tINwpX22HPV5X9PcA4N1o73/cRDj5xNjnjXTxB/EfmzcPBt/duOMcRhQWiYg0h2XZbWeh\nwU9D5TUZ6ZDX3r4l8rOL4WcNzDjaD6ZpB0RFRbB5M1RW7l8lkcMBbdpA166Qn28HRaokEhERkVar\nzg3zL4dBM8HRxp4p2fOnkBLyZ/DaAvAcVR+SxLL6Cdj6KTx9LYx/GY7LCz9GaNtXYTHM8drhz9iQ\n48Vakv2DNvXV6D4fXPY3eBB4j/qRQKE8dXaQdEXIfaYZfu3x2r3WFEDFb8KriiLn84QGS42p3ml7\nG3g22gEP2C8MnREvDgMBT2o2kB37eNk74Iy+wNzYj0c6+83GbSfNorBIRKSpAoOsQ+cTebzxZxLB\nQZlLBPUtZ82tJNJMIhERETkovN7osCc0DIpVFbS2AL75CB48BZ57B9xV9syeQGVQIORx/hmG/QU+\nugk6/iT8GHVuWFdshzTLt8KMF6D7ieHVRYGAZh/wrscOegoL7XfXcnNjL8n+9XNQ5IBqf+VOTQ3U\nABOIrioK8PjsIOmXgD+fCasuggQDnYvgRxeA0aZx1UCB6p3QgMfrqw+8vBshNQV+VFz/eNs2ja/k\nkVZPYZGISFPFG2Qd+CVqGOGlsZFziVpQZBWRywXbtkFt5AIPCbhckJ0NnTqpkkhEREQOsMggaHMZ\n7s1VXH6Hl5nvpNgdXgvGwV0fwbPj4awnovcv8Yc8X5XC3x6Dm0bb1eCByqBAyFMOrDbhoevguU/C\nj7P6CajwwWz/169Nh6tuqj9GaLvWO9RXBJm++uqiWEuyz/JArMKdjQ38XHzAu0RUFzWy3Wvfy+Ht\nXqFCW7/cK1W9IxpwLSLSZIkGWQOkpUIbl/2uSxsX/Own9rthiSqPkiDW4OrS0v0LijS8WkRERJos\n3rDn0CHR2zdBv3aUf70pbDGwoEAQ9NX44GDmglfzmPNFOoUFPvvYRU/BaqCoOPpcawtgnz/ksbBD\nnooKopZV31tth0UW8NJ8+7pCv491xfBOXX0I5PPa1UWby+rPE6gqmg0ERldW19hh0daN0Uuy7wNm\n+6Au3upbCTiALSkRQ5iz7IAnUA0Ua6BzWtv6dq//Nxeu2hN+++1uuGyHfVNQJCgsEhFpmGVB2S5Y\nvAY+X2Z/LNvV8CBr04T+Pexfyv172DOKWjgoguYNrgYNrxYREZEEvF7KZ33M4uzTKP96U+xt/EFP\n+Ud/Cw+CNpeBu8L++OAwWLqHJb99KLgYWFBkEPTtetwVDopfy8OyDAqLDMo//Kvd8gXwjscOlUL3\nLymG/9SEhzyvTrZn9gSWVQ8Mkw6wsKuLAkKrigIv+zzYwdPaDXZ7WayqogDTBw9cHd7ytQ/4I3aF\nUEOM0JsBKalw2mB4ciEcP7f+1mOBHfCc/WZ94BPrphBI9oPCIhGRRAJzidZvgsoqeyZRZZX9tdnA\n8On0tANzjdi51LRpMGAADB++/0GRywV5edC/P0yapNlEIiIiRyK3Gy64ADsE6tcuvMomYHMZS+77\nO6dULmTpbx+Kfjwk6Flyz+fMmWPZQVBg2XaA1Uth6mcADFz6Bm0tN4WFIaHSgnHhQdDixyiY0TFY\n0G36LJbmfx7S8kV4dVFoVVFkyFNRAeZeu2Job3V95RH+bQPVRbGqigIC1UULH/W3dxF+roDqGnht\nCVRn1lcBvZsOO4k9wDrA4YCHHvIPow7cTHvA9Sdz7TciQ2+aEyQtQH8KiIgkEm8ukWnat3iVQgdw\nkHVk25k3Tqt6PGo5ExEROcxsjw57AkGQ243dGtUn1/4YoqAA5syBpVeOgaV7wqtswK4qWrCCU9fO\nwoHFgKVvRFcXhQQ9A9ctoK1VbgdBq7cTTEimjgl+6sBHPoWYpr+6KBA2hQRB1dPeoPi1PKrr7Jk6\nabUVDFz3VXgQFKguilVVFBCoLto71Z7zE7MaCPv7XlsAld7YIVAgeNq23G77mp0Zv1LISoFNd8GF\n38IzveG//rlAiSqLAj+MqN48kQNHfw6IiCSSaC6RZYHDiE5WWniQdWgVUV4e/PSnMHt281Y5U8uZ\niIjIISQQBn08B7ze8CAIgi1eoWFPIAgqLMRujVpRDg9cE3zc7YbiYmhruRm47A37zsgZPpvLWDL2\nRQz/0uwOfOHVRRFBTzAI8pkUFhp2hczebfDW8mAA46KGfApJq7ari4LtZSFBkOM9D9m+ncHT3EtB\n8BqCAtVFq8ZBpSdxyONeZ1f7xNtmyuewZSm8lxI/1PGZsOZsu73L/B/I7QAdYtyys2HlSvs/wCef\nQF0DYwwCvN6I3jyRA0thkYhIQKzZRNU1ifcxDHtw9QEaZN3c4dXp6dCli1rOREREWrWQyqCoIAjq\nw6Bn7oXNZeFB0PZNwRavQNgTCIIsC1742x6sVxbaj7/6VbC6qKDAfp0RFsSEzvAJqSpyYb8+clET\nXl0UqCqKDIJq9lL4akfcFU7410NR1TwOTH91UUR7mZ/P5+B2z9MA5ODmHoqD1xAUqC5a9xa860wQ\n8vhgTg+YfyWYcUYGWCmwoH/iECinnR0CAbz5JuzYEf82ebK9RK3/55hQ+/bhIZPIQaI/D0REIP5s\nIl+C1c4AMtLtwdUHaJB1c4ZXZ2XBRRfBhg1qORMRETnotm/C0+doLj1rO+75X4eHCCGVQWFBkH+/\nYBj072WUL1hBcZGFZdnbVP/vDfVhiz/sCQRBAKNqn8DrTbG/MIEHrgmGSWnVEUFM6AyfiKqigGB1\nUWT7WPBxfxBkwd//5QyrKgpwUU0+hRxd/V14e1nwcTt0ysHNvRSQEnPNef/3M9vZQMjTHtw7oHwn\n5LS170tJiV0N1FAI9GacgdGRCV9BQeMqitLT4Y47Gj6+yAGQcrAvQESkVYg3myiRAzCXyDTtgKio\nCDZvhspKqKrav2OkpECfPpCfb7ebKRwSERFJku2b4MJTYPZSaHes/cZTz59CSgrlX29iQ78rOXHJ\nq+R0/Un0vg8OI2XFTvozgcLnb2dspzLocmxYGGS99CmTHXuwrKMoLLR/l+c+OCxsns+SR1/C9P0P\nYJDt24Nz2uf1VTV19ceorj6KHNzc6ZtAaiBs8QCvfsXEo77HNI/lXgpwRLZ3WcCYayk/749hVUUB\nweqiN9qSE9o+FnzcDoIKa/NxznwZy7AX94qUgpepXIszTklQCh7GpI+nu/k1ld5sKskGIDXVznyC\n9nbf/5Bl3jw7nEmW0IQvP99+IZeooqh9yBuNqiaSVkJ/MoiIQOLZRLG08FwiiN1ytr9BUVYWvPSS\nqohERET2h3unlwt+vo/ytd/EXBUsUDhS/b831M8GCl0WHlhy5Zj4K4Zt34Q15XMMIJ8iXng1Dffa\nnXagEBIGeTxOfldXANivC/7+6DY7SAqZ5zNwzSzSavcCcEfN3/D6nGGnCj1GrDDIMsH59NMhVUXV\n4ddaB0z5lBUPP5cgyPGyZ9R7cVu/UvCSTyHdzLVUObIoT2nLTqNd2K3SyOJnxtdUGtmUp0VXBGV0\naMvvL/qaoXVv0sHcEbzl1Day2udACe35KyyEceMSVxWpmkhaKf3ZICICUNtAabDT0eJziZI5uBo0\nvFpERCSesC6hGCuHFTxSxZyvXCy98sGYq4IVFMDij/xVPGC3aq1ean++pYzytd9w6rI34q8Y9uAw\nvF471HFg8jtPEYWvHA3LF4WFQWmml9G+J8nBTXU1OJ96Civiva3AEOl4s3wCxzieTTHDIMMDo3xP\n8SDj4rd3+aDLpsVUGllRIU8g6GlbXg65HShP68BOI/xWaWTTP3UlI9u/xbW/rCTHU04Hc1fU7Ufm\nD7EDoEMpSAnt+fP54Kmn4lcVtW+v2UTSaqkNTUSOPJZlt51tKbNDovS0hktuMjPseUQtJFBF1NR5\nRGC/MfXjH9vVR506qe1MRESOMG43XH455S/M5LKbcpk5E3Jzsf9Qr6ywA6HZS6HjT8K6hMZuC1k5\n7LlPcO/0UvxCFm2tcgau+o997Jfmw6OboONPgoUj92NX8aThsWfl/OshuP15wGLJlWM4LWTFsEW/\nfYjBS6bYx/JXFaWadvmQi2pGm09y0iv38Ie9o8iMM/OnkHzu9D4V1cIVmOeTSVXcsCfQ4hX/cQ+/\nNt6ikiwqyQp7LNXpJSezgk59vDB/V4P/GXLi3D8USGKjV+vhf94xc6b9dXExVPsDuZoEC6UEKorG\njm35axRpAoVFInJkCQyyDp1P5PEmrhA6ALOJmjO4GuqriLSymYiIHNa2boSL+lM+YwmXjTqhPhAC\neHwczPmIJdc8zpwv/s8OgsZit4Vt3xwMhNyPfxK2MtifvXY7WCAQKhh7FKbZJvaqYM99QkEBZPv2\nhFfxeIB/L4Nh2yivdHLqqrdirBj2qD27yF9VlBoS3Dgwya8bj/Pt5VGtXIGZP5lUJWwDu4RZVJBN\nBdmAhSutBq/pxOOz/+T7mbWeSiM8DAoEQRl46NqzHL5oOAwSv0BI1LdvffJomrHHGrhc9i2SKoqk\nFVNYJCJHlniDrC3/23iGUf85tOhsotDh1cuXN7ySaiSXy65cVhWRiIgckkIrMoKJD1Dnpvy1a9gw\nqpYTl75Ozk9CHnvgalhRzpLfPsScVdPqAyG3G560V+Ia+PkE2nI/hYW55I/2krt6Kbj9lR4vzWei\naxumeQzgXxnM8gc3lj2DqPjVj0ir2xtzVbDy32+iuPgn3F/zt+hB0CYw7U8sWfGzYFVRQLC6aPaj\nYVVFAS6qudOaiOWL/eZVeBjUJioIAtjoPJFBbVZDit3edtZZh0bX1iGroAA++gg++cR+7fi3v9n3\nV1dHb2sY8PXX4c9zkVZOf1aIyJGloUHWaaktPpsIoodX729QlJUFzz8PP/yg4dUiInLocW8v51/d\n7sWaMwfu+2P4L8K1BSwZW8Upe+ay9LrC+vu3boRXFwIwcOVbtLXcFBb65w49Pg58HqB+ho9pQuGf\nq2DqmOAhLBOcEydSXU39ymCm/9x14Jj2Bdk+d9xVwZb89qGQqqKIUMAD1pvLOHXt23FXDKsZ9Vt8\n3ti/sFPw4cXJvrToAdCVRhYbU06kR4cd9OiwM+bcn6GeWezY4zykxvscktxuOOcc+90+AI/9vKOu\nDmprY+/j9dqVRyKHEP1pISKHJ8uCsl2weA18vsz+WLar4UHWpmnPJjqjr/0xr31SgqJkDq/W4GoR\nEWmVvF5Yvi48+Klzw1vnwHmD/amObeLvP+HXZa9gWBZMfRFWrw9uXz7/BU5dv9AeDj2/kPJN/v0e\nuDq4SlhoIPT38f6qIv+v+MAMn7RqNy8878H69/LgfoYHRnntgdGxAiGfz8Hdnsfjrgo2cOkb5Nf8\nJe7sH7POID1y7Xi/FLxUvPst+xyxh0TvMXKZl3Ie1562hZyli6OGPw/1zFIQ1BoUFNjVRJHBkNdr\nD7Ru3z5qJTcNsZZDkdrQROTwE28u0fpNDQc/6WlJv5zmDq/W4GoREWkV6tww/3IYNBPScqPvP/4p\ncFfZM4K6HGt3mV24k7fbLyBzXi2BnjH39nJSX/40GNRYpolRWAQvPGNXFU3szml8AdizfBZdV8jg\nGTfYVUURgVBhdT7O4gIsPGGDnwNDodM8HrwRf/I4MPkD4/kdf48KhFzUcDfFWFFjpG3Rs4EC7BlB\naZ5aTMvAbcQe87wxrRs/r/g47o94qP8Galdqldzu+ooiX4z5UZmZGlothw2FRSJy+Ik3l8g07bAo\nci5RQAsNsm7O8GoNrhYRkYPK67XfgOn5U1hbAGVzoKQQeof8MRy4f8dj8NcSePSvcFweBY97WLyg\nHU6naVf2FBZCfj4Tfz+fe3wTg0GNUVcLr06D0TdR/sULnLpub8hw6GoGzC+k5nezyYixStgfGM+d\nnqdjrBBWTT5/wzAJGyQdeKyhQKiWDHYa4fMKDexvY6PzRAbllkTtFzojKD3Oj7NDnPvlEFFQYLeb\nxVNdHXyeaz6RHOr0p4eIHH4SzSWyLHAY0clLkgdZh7adDR++/0FRSgr07w+TJikoEhGRA6zODR9d\nYH/cXAbuCvh2PZQUA5YdFtXZrWHu7eVccO35uPe1hVemw9JF8MpU3Ku3U/ykk3wK8frsgct4a6l+\ndDypL3+KQXjyY5km/PV2lkzsXr8CmZ8DH6lvLSayuysQ+jjjtISlU0s6sWfIpODFxBnWBlae0hay\nDZzZ4DorJ6oNrH2MdrDQm1rDDnOBqqKGBk1qPpEcJlRZJCKHNsuyK4m2lNnziNLToLom8T6GAV2P\nD9+nU54dFCVpPlFz2s6ysuyQ6Jprmn0pIiIi8cVrKwtUCq0pgIrf2PeVFAIm7AOeqoYfj4eznqDg\nwSXMWX0Of//37fzxo8fs0ptXX2Zi7WiyvYSvKFbrxfHkU9zpc0S1fxl1tfZw6LrMmMOhYxUEgz0U\nuoYMdtDWDqCM+g2zrQoA3EYOPsMJ2fW/452Aq08OrvnbmvCDkyNSQ1VFYC9V63JpPpEcFhQWicih\nK95sooZkpNuDq/PaJ+UyTNNuNSsqgs2b7dcI27bFXxAjEQ2vFhGRFtVQW1md264g2mfBdf9H+YNn\nctlfT2Pm7bPIdVXDO8AqE4qKcXe+k+Kpp2JZDpzv+7Ac/lYt08Q5cwZ3+BxRA6QNnzdui1ai4dAA\n1WSwz3BF3b/AcRrDXVM4q/sC3rxveMgjOXD0WaSf/SbOefNgb4LVUEUScbuhuDh+VVF7/4Ioob2I\nIoc4hUUicuiKN5sokSTPJdLwahERadUiq4fitZV1y7cfX1sAmMFQaMmjLzFn7YUUvjOKsb8cA7P9\nx33Hw0THLExruH8J+qcx/PN+jbpaRvEkBkRVEKXhwwR20j5iZpBFDnuxIM5waIMNeYP4+bboP8SH\nAjsiPhNJqoKC+EFRerqGWsthSWGRiBy6Es0miiXJc4lAw6tFRKSVC60e6vEn+3cnhLWVeYo8XP7E\nt7z07gnklhTD3upgKDRwzSzaUk7he3fxh7pHybTsslnLBOeb31Htc/EHxkfNIEqjDgexe8fqSOPF\ntOE8nv5A2P1ndV/Lm0XZpLdtAyefGLWfhkPLQbN6NWRn27dY1HYmhyGFRSJy6KptoG/c6YDMjKTO\nJYpsOaustKuC9kdKCvTpoyoiERFJEq8XViyF3Q/A2a/Xzx8KtJQFqocyr7I/NyugchpYNfAOpKyt\noz9vUPjg2Yy9wF9V5M95HPjIp5BnfLfhfN+EQPWQB0YxkWe53T+XKLKCyBujgsheXj4r08Pvz93I\n79+MjH8GtciPR6TZ1FomRyCFRSJyaIg1yLqhlCUzA/r3SNolNLflDDS8WkREWsDmMvj+WaiYGz5/\nKNBSBpSXZbGh302c+Pzj5GT9y/69ug+s9+w5Q/kUcdKUW7n35FRyZlcHVx5zUUM+hWR6q/DiJA1P\n8LQOTKZyLSlxViOrI50XM+/g8az69hyNdBEROTTo/WwRaf0Cg6zXb4LKKnuIdWUV1Hni75Ok2USm\nCdOmwYABcNRR8PbbzQuKNLxaRESaJXRZe7Crir7bAJUvAxas9S9rH6gq8tkVP0smduOUygUsHT/D\nv20tvANer/3esQOT33mfZunf+xLZPebAx108FWOVsmrO4AsqacMOOgRv+1wdoEMHMjpk8/v/Wanl\n5UVEDkGqLBKR1i/eIOvAOrqGQdiaukmaTaTh1SIi0upErmC2uQz2TsFd2ZYbCqczkytJPXY8ZKcR\nrCra0ZZT1y/CgcWAlVMo3+4ix1WD9R6kmnZVkItqRptPYayPnjPkoibO9CHwkqLqIRGRw5DCIhFp\n/RoaZJ2WCqkpSZ1NBBpeLSIiB1HVTvjgVzDkP+Dyz/aJnEF04uhgVVHBO39kYMlCUvBAYRH8Nq2+\nqujvfTmNrwC7SmjRM30Z3P0zvF4fqSEtZImGUgPsw0UVLlwuyPKvYJ8B/P6slfxe4ZCIyGFFYZGI\ntC6xZhNV1yTexzSTMpuoucOrXS57kQxVEYmISLMtfBT2fQkLx8E5xQC4F0zk8nH/4fWR/4+cf1SC\n6yGw6nBXtmXyezeyjm4YgPWuF+OXJrjqq4oCLWQuahiw7kvMUiNYVRQQOpQ61hsuC1LOYnjOm6oc\nEhE5AigsEpHWIzCbKLTlzBN7aGaY9LRmn7q5LWcaXC0iIk1S54b5l8OgmfWrmFXthK2TYJ8Fv5sA\n/x0FHdpTUJTKnFWDWfr3vgxe/wm88DxcmUrBO39klHcCDn/bmceTQto7XhjWniXP9OU0Pgs7ZRp1\nWLXxlrVP5znnHdT+cSxjx4Y/NhTYkezvX0REWiW95y0irUe82USJNGOQdbKGV2twtYiINKjODR+e\nD0sW2kOpA0JnEAFuN1wwaBfuyrb2EvarTXjgGtwLJlL87p20ZS8D1y+y933PR/n2dCa/dyN3mk8H\nl69PM71Y70G5dSOnrvsyajB1Gl4MfOw22rPT6BB2qzSy6etYycqVB+KHIiIirZXCIhFpPRqaTRSp\nGYOsA5VEt94KixfD3iZkVG3bQv/+dkWRZhOJiEhCawtg+1z4/jl7KDXUzyDaZ8Gwv8D2TRT83z7m\nLOnK3/89Amb79331KyY+7sG0DO6lAMNfQYRpzyMKrSoK8HhS2PO7WTgTLGu/4qw76GDuiLoNrXtT\nbWYiIkc4taGJyMFTtmv/ZhM5HZCZkZRB1hpeLSIiLSJWW1mdG0qKAAsqX8a9ejiXjzyGmY9MJBcz\nWEFUfd9wil+ZjYUD5/s+LAf2DCITnLNrSfPVcQ/F9ZVCHhi4fiGnsjBYVRSQZnrptONr9hq5VJId\n81Izvlb5kIiIxNaosMgwjAuBJwEn8A/Lsh6LeNzwP/5LoAoYblnWEsMwTgJeCdn0BOBPlmUVJ+Pi\nReQQZVlQUwvrN+3fbKLMjCYPstbwahEROSAil7YP3GeasA94soaJXbcwZ65BYa6TsRdW2xVEFjj+\n9TnZjl2k4OJO39MYPnt3wwOjmEgK3qgKokQrmFnOFNr98Q6ihg/5dUjStywiIoefBsMiwzCcwNPA\nEGALsNAwjP9YlrUmZLOLgK7+22nAM8BplmWtA/qGHOd7QEWtIke67bvB6zugs4k0vFo2rSC4AAAg\nAElEQVRERJIqUEF0+gz4ehf0/CmYlcGl7d2LX+Dyux9i5owqckuKwKqBd8BabeEsWYZlXUXhO6P4\nQ82fybRqAfD5HNzuexYDEyMiAHLg4y6eIg1P2P1peLGA3UZ7TMIrbVOdkKPhQyIi0gSNeV/8VGCD\nZVnfWJZVB8wALo3Y5lJgimX7Esg1DOOYiG3OBzZalrWp2VctIoe2LWX7t30TZhNpeLWIiLSoQAXR\nwnHgrrDnEK0tAOwKop33Z7J4biWFY5bUVxXNttvKRvkmkoObbN9enO+bUGcf0kUN+fyNfIqi2spc\n1JAaERQFGOnptBsTPX8op3aH1rgXEZEmaUwb2rHA5pCvt2BXDzW0zbHAtpD7rgKmN+EaReRwU1uX\n+PFmziZqbiWRwwFt2kDXrmo5ExE54sWdQWRXELF1EvzoUvhuH/xQBL5qqv+dzgk7vuEeinhiyn3k\nD0wn950aLNMOixyY5FOI4TXx4gyrFkrUVgZQhYsqwxX8OjUVcrJBy5eJiEgyGZYV/5cRgGEYlwMX\nWpY10v/1ddgtZneGbDMLeMyyrE/9X38E3G9Z1iL/12nAVqCnZVkxSwoMw7gFuAUgLy+v/4wZM5r7\nvUkrUFlZSZs2bQ72ZcjB5vVBnceeVWQYYFlUej20ccbJqx0OcGU0+XS7d8OmTfvX5RZ66rZt4ac/\nbfLpJQn0b4fEo+eGJJLU50d1LWSmQ/VWqN4GmcdA5o/9j22FmjJ8HoPa79NJP86FMxXw7QLTwtpk\nYGBh4mCVcTId227nR3t/IDQDMv0F/pEziAK8Ie/pOhwhb1q0aaNfUk2gfzskET0/JJHD7flx7rnn\nLras/8/evcfHWdb5/39dM5NMOzk00JFUwOWLBdZfQa22gsu3aF0L62Ef4pft7rJSXYVdXQuIRNZd\nXNmVWFlhp9NYSkUOAkoFoQgCLe0qsQt1EUo5hdLScLAW0TQBpodkkpn7vq/fH/fMZCaZZKZNMs3h\n/Xw85pHOzD3JPTqZkE/e1/uy80sdV06y6PfAO/KuH5u57WCO+Tjw1FCDIgBr7Q3ADQDz58+3Cxcu\nLOPUZLzbtGkT+v9yCrMWtr0Mb+2Dqrz/GDaGTfs6WFh31ODHBAJw0nHQOPOgvlR+gfWzz4JTRl92\nlsqrxx+9d8hQ9NqQ4Yzo9ZGfIPp9N/zuD3B0BJ76S9jXDSsD8PAr0DAD7v1LcLv51ZUf4mM7H+WR\nP/0wC//jN2B7Sa4JY9cbIvTSw3Q2cxnJYC9/E4gRSPdPi1KECGAJ4Q46lV7CrJr+da6u8YupFyzQ\narKR0nuHDEevDxnOVH19lDMs2gKcaIw5Hn8AdC4wsOb1fuAiY8yd+EvU9lpr85eg/R1agiYy9ex5\n0x8UDYz4ZBONmZRRziF0E8HIlp2pvFpERID+DqIXYrD/HP+2HXES3XU8+I2zOa/rJ5grPgtLPwR4\n7O2s59SdTxLAMv/FLezdE2ZGpJfgRi+3rCxCkiaWY1wIuIVp/mocPKCLmVgMkQjUZFaXTQMuW9DG\nZRoQiYjIYVLyb+fWWge4CNgIbAfustZuM8b8kzHmnzKHrQdeAV4CbgSWZh9vjKnB30ntZ6N87iIy\n3r3WMfxasOoqqI1AVcj/eNJx/m4yJbqJ8surGxv9NP6GDYc2KFJ5tYjIFOE48OyL0NMFDy/yk0RZ\n2Q6ibguf/U/Y+zp4++HAGlbd8wU+3fVzf5+x2x6FrXFwkzy1ei4ms4QsgMvT338vyfvqcdxgwZet\nJkWYvqKnlCLMrdOXMifayZKzOqEz76IokYiIHEblJIuw1q7HHwjl33Z93r8tcOEQj+0GDm49iYhM\nPNb6SaLXOvqLqZO9wz/G82DenIP6MiqvFhGRsgwspt7d4e9atmW1nyDaEYf3+Mu8Eo+vYvGy+3ng\nTz7B9Of74PYr4Lz3kzhQT9VGJ9crZD0wD/ay98N+qiiC/3MuQi/zX3yS4Esu1QMGQ9kE0RvMZFrE\n5NJDoASRiIiMX2UNi0REhpXfTZRNEqXLKA0KVx/0l7rjjkMfFGWTRPfcowGRiMikl11WtiMOc/49\nk3bdD3+8wU8QnfcdePgCaJhBbEUVW5+fS3B75mfYfc/Aou2suq+JS93v5baxN2lgveW5trnM44mC\nL1dN36ClZlkpwtwyfSm/PqtZgSEREZkQ9OuSiIzcUN1EpRzbWNZh+cvOPv/5gx8UhUIwb57fTaRB\nkYjIJJNKDL2sDOsPi17dSWJ/gEWXNpI4UA/rgG0eXPFZEo+vomX9RTQR719C5kHyPkPVRgczYBt7\nz4XTXnoslyrKqsYlgId3xEyIRgsu06J1XPYXbRoUiYjIhKFfmURk5Ep1Ew0UCEAoWFaRdXbZ2Ze+\nBFu3HtwuZ+CniW67DZ580i+x1qBIRGQScRzYdHl/gihrewzwoBv4dhK2fpfYHQ20PvsuVt93PmzA\n38b+tkdZdXWaOm8vl9LSPwBKQ+Ahh4vcVblUUVbAgapMgfVAKcI8csrSwu4hdRCJiMgEpF+bRGTk\n+lLD3x8MDC6ynhYessg6P0l0xBHwwAMjW3amAmsRkUmgWILo1Z3wxq25ZWVuX4pFf54msfUWcJN+\nguh5j+San9Fy9ywsAYIbXWzm7xvWg+CGPpamV+d6ibKMZwkz9M+3HiJ0mWjB5YCpY1p72+g/dxER\nkQpTZ5GIHJxiRdal4jrTpw0ust5e/NCRFFiHw3D00dDTA8ceqwJrEZFJJb+D6D3NfqpoR9z/uZRZ\nVtbzyuu0bgoRP+JCmj/2b36CCAg8lKYu8CYhIlzkXodx/dtNGi7mWgwMShBV4xZsbZ8vEoGasxYQ\nKZIWio7+MxcREak4DYtEpHxDFVkPt9V9IFB2NxEceoG1yqtFRCaJni74xafgzPshkhm95G1tnz73\nahbPvJjbWt6g4cAa6O7LLSur6XmLeruX+LqvcHlvM9OtvzOZ6wb4sns9Bm9QB1E1KQIMXUx96/Sl\nXF3TXHD7ggVaVSYiIpObhkUiUr6hiqxt5j+yjen/N/hTmyPqh+0m8jx/QLRiBezeDQcO+MmgcoVC\n8N73KkUkIjJpbPk2dP8GtiyDD7f4t2U7iNZBaHuKeawk/l8foPlTmVRR7kePpYk433f/ieBGDzIJ\nogi9NLF8iASRUzRBFIlATURb24uIyNSkYZGIlK9UkXV1ld9LlF2edmyjPygappvoUJecgZ8muuEG\nv7haREQmmFQCHl0MZ6yF6gb/tp4ueP0G9nbW8dIXH+WELa8wY/aRfqpoXxL7EBigiRX86b07+Nqf\nhZmxoY9stVAgMyya7vTgEKQ6r4j6YBNESg+JiMhUpmGRiBRXrJso2Tv8YzxvcDdRkUPuuAP27YOz\nz/aTRAezkVqWyqtFRCYQx/GXMZ8824+EwuAOIvBTRdby1Oq5fLj7UR752ytY+OPjyaaKHCdEFQ4B\nPC50ruPp1XNZaB8p+FIBXC5hZcGgCIoniLLpoWkoQSQiIpJPCzZEZLBsN9HOXXCgx+8lOtADbomp\nTrh62LuzSaIvfclfaravyIq24QQCUF8P8+b5iSL1E4mITACpBGz8CLz5OuzuyN2W2HoLZ3/7Z6TP\nvRr27MpLFYU5deeTBLDMb/s5ex+9KZcqqvIcwF9K9hVvJR/YuYWBG5ZF6B12a/tbpy9lTrSTOdFO\nlpylre1FRESKUbJIRAYbqptoOGUUWR9qeTWowFpEZEIotrRs2zWw99fgrYHXlsI7GmF7jNiDF/OB\nHVsIkYIrPgufeV8uVXQaTwB+SujJVe9i4bs6cqmirOGWlQF0E6GHSC49BEoQiYiIlEu/conIYKW6\niQYapsja82DNGpg/Hz7/+YMbFEUi0NioJJGIyISRv7QMSOzZy6LPLWJvZx1cfgvsfR1e3Uli6y3c\nsm4JX+V7GMDethnaf5BLFUXwlz1H6GX+i1vwHjK5VFFWNQ4BXLqYSZeJ0mWiOIToMlHeMFE2VZ01\nOD2kBJGIiEhZlCwSmeoOpZsoGIDp00oWWY+kwFrl1SIi41g2QfRnd0L7G34XkXcAtq6AuIWvLYd3\nNRH7xlO0Pr/Q7xba+QjcfgWcN4/YgxdzsXMtAfw/TKTTQarX9fHUC6flUkVZ1fRhUwaKpIhShPlB\ncCl932imuRlCmzYR9ToB+CTQOdb/O4iIiExSGhaJTGXZbqL8JWdpZ/jHgD8oGqLIOltgvWIFtLcf\nWoG1yqtFRMa5bIJoyzIS+/+exUsd1n53FQ0PpmAb8GCKxOw4Lbf/C/Xs4wM7n/Qfd98z7D3999yy\n7ile9N6V28a+2nPw1sGp6S25VFFWNS4e8KaZicfg3TXnBtq4qW2Mn6+IiMgUo2GRyFQ2yt1EI0kS\nBQJQWwsnnghNTf6gSEvOREQOs2IdRKmEv5V9t4ULr2XVyefT+liY1dek+MYvMn9wWOewqtfiWcPX\niGEyCSI8eOq6OQWpoiw3HSQ8sK06exqEeW7BUhY+0jzovk9mLiIiIjJ6NCwSmcpGsZsIDr3AWuXV\nIiLjSP4293kdRIk/aWbxYlj7H6toyGxlb7d5BHfcibXvIfhQLzaA30HkQXBjmmo3xaW09KeF0vCB\nnVs4lS25VFFWFS6WoRNE09oVHxIREakUDYtEprK+4n/BzSmjmyh/2dmzz/q/Y5QrFIL3vldJIhGR\nwy4/QfT7bkjsh1d39ieIzvsOqxZ9mdbWWcRnBGn+WBI2+IOhi92VXM+XuMi9DuP6n86k4WJWEcIZ\nlCCqpm/IHVacYJgjv7EUmgcniKKj+4xFRERkGBoWiUwVxYqsS01nhukmgpEvO7vtNhVYi4iMC5kE\nUeLxVSy+9Cus/dYeGnbEIZsget4juGMV1n6H+LqLubz3SqZ5fRgggMePWYIZUEAdwOUSVlJNuuD2\n6mESRFVBmNGmBJGIiMjhpr/ji0wF2SLrnbvgQI9fYn2gB1LpoR9TpJvI82DNGpg/39/SfvZs2LDh\n0Jad1derwFpEpKIcB559EXq64OFFfpoICjqIuv7qVrZudYnfdQQcWAP78hJEzveYQYI6dx/BjR4m\n8yMkQpIz2DxoWVmEXqoo/nPGhMMc+c2lRL3OgsuMPm1tLyIiMh4oWSQyFQxVZG0zfwU2pv/fULSb\naCQpouynzC+wPvpoLTsTEamo3R3+8rItq3M9RLyn2U8V4ZG8L8w7O1/hUlZwzd3foOmMehrW9WI9\ncgmiJuIYx8MhOCgxNJQeIvSYSO56VRXMqAOUIBIRERm39KuayFRQqsi6ugpqI1AV8j+edJxfbJrX\nTXSo5dXgJ4k+9Sl46y148kktPRMRqYhUoj9B5DiZnwX72fvsHWz94lz2PnojHNjlp4r2JQlu9Ahg\naSJOnfMmq+87308V5SWImlhOEysGbW9vAA/oYiadROmORCEaxUSjRD591uD0UKcSRCIiIuOZhkUi\nk5G10PEGbH0B/vcZf8nZcDzP7yY6fa7/sXEmGFOw7Ozznz/4QVEoBPPmwQ03aKczEZExlT8Yytoe\ng1cehg+9D7btBCwcuJ2nrjuZ93U/w9Or3gWPLSGbKnLcIOAniL7sXE9wozvo7wzVpAjTV/wUCHPr\n9KXMiXay5KzMQEhDIRERkQlJy9BEJptsP1GxZWdDCVcPummky85qavwhkVJEIiJjzHFg0+XQlbe0\nLJUgsfUWHvzGZziv6yeY5d+FL3yBva8+wKk7uwlgmb9jC3tfCDIjkiS4sSq3rCybIDKuJeAWfqlq\nnFyCyGKIRKAms8JsGnDZgjYu02xIRERkwtPf+UUmm6H6iYaSV2SdnyQ64gh44IFDHxSdeaYKrEVE\nRl2xBNGrO+F3t8BVFrYu9+/bHmPVz/6BT3f93N9v7O474I8389R1J2MyW9kHcHn6+3MLUkVZfoIo\nVfwUhkoQKUUkIiIyaShZJDLZlOonypdXZD2SJFE47BdW9/TAscf6BdbnnqtlZyIioy6zxX02QZTo\nclj81/DAMUGmbwMeSMHcq0g8vYaqDecRyAyGrOvQe9u9nLqTXN9QhF7mv/gkwXavyPb2foLoDWYy\nLWJy6SFQgkhERGQq0LBIZCKz1k8SvdYBfSl/OVmyt/TjqkL+scc2+jueGcMdPzm0QVE2RaROIhGR\nUdTTBb/4FJx5P0Si/m15W9xz3nfg4QuIfSvC1mdnEXw+M+xZ78AnVrDqvsu51F2e287epKHqv3tJ\nU7jsuJo+Ap6lmBRhbpm+lF+f1azAkIiIyBSjX+1EJqpsN9HOXX6BddrxP7olUkW1kVyRtfe2maz5\niTmkAmuVV4uIjKEt34bu38CWZQAkErDoQ10kuutgHbDNI/nPf0/LD+tpIt6/jMyD5H1Bqjb0Yigc\nAgWtx/QBu5hV4xLAw6urhmi04DItWsdlf9GmQZGIiMgUpF/vRCaqg+0mgkH9ROecA1/6Emzd6vej\nlqumBm67DZ580i+w1qBIRGQEBvYQ9XTB6zf4CaILr4XXXyZ2dZLWJ97J6ns+DxsAC4E1j3GM+wqX\n0tK/lX0aAg+5XOSuyqWKssxQX54wj8z9l8LuIXUQiYiITGn6FU9kojqYbiKAQABvRj1rfnHkiAqs\nVV4tIjICjgPPvlg4oc/0ECWeWM2iRZBojfnp0WyCqOlztHwviLUBghtdbOat33UD3Oh8MddLlGU8\nO2Q5tQV6iNBlornLAVPHtPa2sXm+IiIiMiGps0hkouor/otATjAA06fluoy8oxs558tH8stfmoMe\nEAUCUFsLJ56o8moRkRF5dSe89HmI3AonzinoIeo654ds7fwy8fp6mj/e5yeIgMDaJ6kLdBEiwkXu\ndZjMdvYRejmDzYMSQ9W4Bdvb54tEoOasBUQGJIaiY/FcRUREZMLSsEhkIihWZF1qWjN9Gsybk7t6\nxxoVWIuIHFaOA0/+J+nmp1gc2sdtv3Jo+H0M8EjeF+adna9wKSu4Zv3Xubyvmem2D/ATRF92r8fg\nDeohGkp2e/ura5oLbl+wQCvLREREpDQNi0TGu2yRdX4/UdoBM1T7BLluIs+DO+6AFSvg2WcPrpco\nFIL3vldJIhGRQ5JKwKOL4Yy1UN3g3/bqTrjrDkI7XOaxjvgVx9K8sAX2JQlurCKApYk4a5y/I7jR\ng7wEURPLMVC0h8gD3sxLEUUiUBPR9vYiIiJy6PTrn8h4N1SRtc38dXnA0MgjwJpfH828TxzJ9Onw\nuc+pwFpEZExlC6p7uvr7iLbH2Pv8Fra+7ZPs3ZXIpYrsehcDNLGCm38YINFdR/K+cG43swAeN7pf\n7N/dLKOaFGH6in/5TIpoTrSTOdFOlpylcmoREREZGSWLRMa7EkXWXqiKO1qPZMXtR/K7PdWk3AC9\nfYa+vmGSR8NQgbWIyEHKFFT729wv8RNEO1p4avU8PrzvUR4572oW3vJZuOsOHCdEFQ4BPC50rmX1\nPZ/nso3LqSYN+Mmh4j1EzqAeomyCaBpKEYmIiMjo0rBIZLwZ2E+ULh4J+uXDcOa334+/COHQBkNZ\nKrAWESlDkaVliT17+fu/O421NkDV134As8+GHdezt7OGU3c+SQDL/F9fy96HXqd+vUtVZvYfIclX\nvGu5acP5OF4wNywa9ssP6CFS/5CIiIiMFQ2LRMaTYv1ERfiDonmZayMbFKnAWkSkBMfx35u92/wE\n0Y44vMcf2MT+7Sk+sP03hHD9re6/8EPoXstT157KaTwBQACXris3EcmkirICuCz1rh80KMr2EL3F\nTKZFDDUR/3YliERERKRS9KuhyHgyVD/RAH6iCEYyKAqFYN48uOEGDYpERAbJ9hClErC7g8Tv9rDo\nc4vY21kH530H9uwisWcvt/zoJL7K9zCAfciFjjvYu8dPFUXoBfyC6uPe/B1VXmFSNEIvVUMkilKE\nuWX60v7+oU71EImIiEjl6NdDkfGkRD9Rv5EtPVOBtYhICdtj8MrDcMb7YPtLxG5P0Pr8Qp5ePRe2\neXDFZ4n921Nc7KwkgP++nU6HYL3LU6tPxlDOe7mvm+l0R6IQ7b9Mi9Zx2V+0aTYkIiIih4WWoYkc\nTmX2ExWoGtm3rQqsRUQyssvLTpwJj50LZ6wl0dPA4nPSrF1yCw3rgC2/JfmjH9Dy8xupZx8f2Pkk\nAPa2zdzjNbLFuy63nX215+Ctg1PTW3Kpoqzs0rKEmYk3YNj/eGgBN511rwZDIiIiMm4oTyByuGT7\niXbuggM95Q2KaiNw+lwONlUUCEA4rGVnIiIFdndAYj+0fhMueRieuIpYDFo3hVh97/mwAbAQWPsz\n6ry9fI1YLjGUTge5Mf0PuVRRlpsOEiZV9MulCPPcgqVEvc6CyydTGhSJiIjI+KJfF0UOlzL7iXIC\nATi2sexP39AARx3lD4h+/GPo6dGyMxGRbBdR4vU3WPTXdST2JeHmm2AbJK/5Pi0rPKw1BB/qw2be\nnl3X8NV0C5fSkksMVXsO/5fHcqmirCpcgri8aY6gy0QLLgdMHdPa2yr9jEVEREQOmn5lFDlcyu4n\nwp/uHFEPRx0JwC9+Mfzhl18Ob7wBHR0aEImIFHh8GVzyMKua/ofWp+pYfctueMgFILA+RV16DzNI\ncJF7HSbTPR2hl6/SQgC3rC/hBMMc+c2LBiWIol4nH/yDIkQiIiIy/qmzSORw6Su+TKFAVQjC1X6i\n6KgjwfjLzxYt8gdGZ545+CG/+IV/v4jIlNbTBb/4FIkPPMDiz81k7VpoiCRgxUrsNgjueAJrzyF4\n/zPYgL+413UDfNldjcHDYAs+XTVpTJEt7i3w1oAeoqogzGhTgkhEREQmLg2LRCphYJF1uLp01Kc2\nAvPmDHn3okX+pxURmfJSCXh0MZyxFqob/Nu2fBv2PEbXvEVs/eOviMcbaD5zGaxPY4CL3VVcz5f9\nBFEmMBShlyaWY2DQ8rKhmuJMOMyRX18Kzc1j9exEREREKk4LU0TGWrEi6wM9kEoP/ZiD7CcSEZnS\ntsegoxV2xP3rPV3w+g0k7wvzzj8+y6XEicctyat/kOshCuDxY5YUSRClCNNX9MtYoIdIroNob3UU\n6upAKSIRERGZZJQsEhlrQxVZZ2NBxhRGhAb0E4mISB7PgZ+fDmfeD5Gonyra0cLezjpeOn0dJzx9\nATNej8MBj+BGSwBLE3HWpD5LcENfXoooyRlsHpQYqsbBA7qYic3cG4lATcRPF0UWLCCirctERERk\nklOySGSslSqyrq7yl5xVhfyPJx0HJ8/O9ROJiEie/a/Dvz0GrVf417fHAI+nVs/lfd1P8/Tf/Fsm\nVWRw3CDgp4huTJ+fu15KimpuDZ/PnGgnc6KdLDmrEzozFw2KREREZApQskhktA3sJ0o7wx/vecN2\nE4mITFkDu4h6urCdb+BtM/T94MdMX3CZnyr6YxWn7nySAJb5z9zH3t9OZ/rGA1RnCqmHShEZwAPe\nzKSIsgmiacBlC9q5THMhERERmaKULBIZTcX6iUoJV4/9eYmITESZbe554ir/eus3Ya+/tCzwUBoe\n+muyqSKDn+AM4PLGNfWHlCJSgkhERETEp2GRyGgaqp9oKCqyFhHxpRLwy4/CU1vAcUjs2cvtf9WB\n3QasaIHEyyS/f3uujtp1AyTXvJBLFUXoBfwdzY5P7Mpdz8qmiN5gJt2RKET9y7RoPZd9vF3zIRER\nEZE8GhaJjKZS/UT5VGQtItLv8WXw1VZ4cSXs7mDVZY/w6c57/aVj69Kw9v8R3JgikBkXReglsMHj\nuWtPyaWKSkkR5pbpSwsTRJoSiYiIiAyiziKR0dSXKn1MVchfenZsoz8oUpG1iEw1eV1EiZ4GFp+T\n5oHID5i+Dbj7ThK151H1k80EMkMg64Fz9Qs4blXBp3HdAKe9vCXXTZSVTRFxxEwCwf73WL+LqE1d\nRCIiIiIlaFgkMhIDy6xdd/jjayMqsxaRqclx/E63k2f3dxFdfxWxDdew9VcHCAb7/OPWO9zY8zQX\nuauIkATApCH0kksVhe+xEfpyy9IGShHmN6csZeEjzWP4pEREREQmJy1DEzlUxcqsvaF+bUH9RCIy\nNaUS8PAiEs++xKLz307i2ZdgxUrYBslrvk/LCo8mlucKqa0Hp//3A5ghx0CD9TCdLhMtuBwwdUxr\nbxurZyUiIiIyqSlZJHKoDqbMWv1EIjIVDNzqHnIpolUnPkPr03/K6u88xTfW+8vGAutTHGPauZSW\nXCG1ScPpPDbkNvcOITqJFtzX+acLmLNj8Nqy6KBbRERERKQcGhaJHKpSZdYBA8Gg+olEZPLLLjHb\n+wPSF21icc2r3PbL99EQScCKldhtENzxDNaeS/D+Z7ABf/jjugFu5B9y3USlpKjmDRNlTrSz4PYF\n/x+ohkhERERk9GhYJFKugf1EaWf444NBOH1uZc5NRKTS8lNEv++GN1+HldcS2uEyj58R/6930fyx\nZbA+jQEudldxPV/mIvc6TKZ6KEIvZ7B5yBTRm8zE5t0biUDjjF46OxERERGRMaTOIpFyFOsnKiVc\nPfbnJSJyuGyPsff5LWx92yfZu+UV+OPN2PUOBmhiBTfH95G8+gfYTGgogMePWVJ2F1GKam6tPp85\nDX9kTrSTOdFOf8v72bPH7jmJiIiICKBhkUh5DqafCFRmLSKTz55d8P4j/Y+pBOxo4anVc3nfvsd4\netmdcNedOI4fWA7g0dT3XYIb+jCZXe0jJDmDzbkdzrKyKaIuZtJJlE6idEeiTIvWc9kn2ul8K0hn\nJ3R2wr1aayYiIiJSERoWiZSjVD9RPpVZi8hEl0jAokX+R8ch8Wg7t7/vGuzTb8EVn/VTRZ01nLrz\nSQJY5rfdirfOo8rzU5cRklxkr8PN7HBWSopqbg2fX5gg0nRIRERE5LDRsEikGGuh4w3Y+gL87zP+\n0rNSqkJQG4GTjoOTZ6vMWkQmjvzhEMDVy6D1Yfivq2B3B6tWJfn067f57UG3PQpb4zx17bswmWLq\navrw0oX/SVFNmumZHc6yBqaIuqfNhGgmRfTxdiWIRERERMYJDYtEBjqUfqLaiKmhkfkAACAASURB\nVF9mPW8ONM7UoEhEDr/8AdDAYdDA67EYtLZCPM7eXQmS16wGC6xoYe+WV6i6547cjmXWg+RdllN3\nPpnb7r4alxBuwZcf6l0wP0W05GNdaEIkIiIiMv5oWCQykPqJRGSiicX8IfW3v90/BMobABX8O3t8\na6v/8X9aYfl/+oPyeJzn/uZbuVJqnDTPXXkbF7krc11DJg1V/50qa7t7C3Qzne5IFKLRQSkizYdE\nRERExqfQ4T4BkXFH/UQiMtH88z/7H//93/2h0VVXwerV/gBo+XL/vswwiAsugJYWsJbkf7Zgnl7H\ntMx7nnVcTntiNdVkWqnTcOoLP8KlsHsoaD1CA5aYgb/ELGGOxMv7W9TjoQXcdNa9GgyJiIiITCAa\nFokM1JcqfUxVCMLVfqLoqCO17ExEDp9YrPC6tf4wKJgZ8KTy3tM8Dz5zLqT9lJD1XKofeo7sbvam\nr5eqAZ++mjQmOzzKGHqJWZjnFlzIwkeac7d9MnMRERERkYlDwyIRa/2lZ691+IMi1x3++NqI300k\nIjIeZFNF+dJp/wLg5PWuJZPwv7/JXY3Qi7WFDx04CBpqMGSBJNPpMTUFt09rbyvrtEVERERk/NKw\nSKa2bJl1uR1F6icSkfFkYKroEJSTi7RADxF6iORuiVT3UnNqHZFH/1BwbHTEZyQiIiIih5uGRTK1\nHUyZtfqJRGS8KZYqGgUDh0MGj8dDp/P5mkzxkDEsWBhUD5GIiIjIJKVhkUxtpcqsA8bv/VA/kYiM\nN6OQKsryh0PT6aF/SdlmFnAO9xKu6uXrZ6+i+eJf0/kh/WeDiIiIyFSg/+qTqWVgP1HaGf74YBBO\nn1uZcxMRORhlpoosYDGYTIu1zSw8S1PFPupzx23m//KPtTdhjIVgBEI1mSVl02hzLoMPXTa65y8i\nIiIi45aGRTJ1HGw/EfiJIhGRCcAWu63W8GDPJznbe2DAkYMTkuFQL18/cyXNf/tdePuH4UNaYyYi\nIiIyVQUO9wmIVMzB9BOByqxFZPxIJeDhRf7HzPXEzW9n0cm/IHFDI/xkGlec3UxNdTcBLDVV3fzH\np6/k3z96JeeGfjro00Wqu4nWdfZfGrqpa5hGm/06/O2bGhSJiIiITHFKFsnUUaqfKJ/KrEVkPNke\ng45W2BGH9zTD9hixBy6mddufE19/IU2faKFlw6UkU34hdTIdYfn6JsDkbutnMAbaV32Qhpp9/k1v\nW6ABkYiIiIjkaFgkk9fB9hMBVIVUZi0ih18qAY/8FRz5XXjX8SS23sLi+H+z9mt/T8M7LyCx9Ye0\nPLQTS4D4Q5fSk5qGZwvDwimnGjtEgNihhvhLL9PcXIknIyIiIiITjYZFMjkdSj9RbQTmzRnb8xIR\nKcf2GOz5FSR/APtriD2YSRE9eCHNxy4h9sDFueGQ6wZYufES0m5hx5rjVQOWmTOLz73b2irwPERE\nRERkQtKwSCYn9ROJyESSSsCji+GMtf71HSsAC/vXkOiYQcv6l/wU0bqvcMGHfkDLQxfnlpf1OhGK\n11tDuCrN0qXVShCJiIiIyEFRwbVMTuonEpHxamBZNeQ6iRJPrGbRh7pI7K/L3JEm9mB/isjzAixZ\n/eNBS84gU1pdv5/oES7RKESjUDejWgkiERERETloGhbJ5NSXKn1MVchfenbScXDybPUTiUhl5JdV\ngz802tECWGLxAK1PvJP4uqUAJLpradlwSUFx9eadZwxRWm1pv+7v6HzkVTo7yV3uVW+1iIiIiBwk\nDYtk8rAWOt6ArS+ULrOujcDpc/2OosYhCj1EREZDfpIobzCUePJmFp22l8RvVgIeie4ZtKy/GGsD\nxB9qItE9g9i6rxVNERXjUEt854Nwyglj+nREREREZPJTZ5FMDgdTaK1+IhGppPwkkfUA/z0q9sBF\ntG6pI94Sonlxkti6y/GsP7j2vABX3Xc5qx++sGiKCCwz6/djqusL7tGSMxEREREZDUoWyeRQbqG1\n+olEZKwNkSRi+3K/uNpN+imihzIpovVfYVfnn9Cy4dKC5WYtG79K2i3+N51w2LD0kvqC5WZaciYi\nIiIio0XJIpkcyim0ro34iaKjjtSyMxEZO0WSRInuGSz+3j2s/erf0hDpKVheNlRptesFmVaVor6u\ny7/BhCBQB6EgoBSRiIiIiIwdDYtkYrLWTxO91uGXWZfqKKoK+f1EIiKjbdC295kk0QvL/WGR7SW2\n7nJat32E+Lqv0PSJ+KAU0eadZ+AvL+vn2RCmKkT77yI0NFT2KYmIiIjI1KZlaDLxZPuJdu6CAz2l\nB0UA4eqxPy8RmZrykkSJx1exaNn9JLpngNcHNu0vOdtwKRa/uHrZff9Wfmm1A/H4GJ+/iIiIiMgA\nGhbJxFNuP1GWCq1FZDQN00kUWxGi9fmFxNc3AS7gFiw5c90AKzdeMnRp9ZGWaJTcpa5Oy81ERERE\npPLKGhYZYz5mjHnRGPOSMeZfi9xvjDErM/c/Z4x5f959DcaYtcaYHcaY7caYPxvNJyBTUDn9RFkq\ntBaR0ZbfSbQ9RnZ3s8T+6bSsvziXIEp0z8ilirLDoV4nQtqtKvppw1WWpZ/Zr9JqERERETnsSnYW\nGWOCwHXAmcBrwBZjzP3W2hfyDvs4cGLmchrw/cxHgO8BG6y1i40x1cDAP6eKlJbfUXSgp/TxVSF/\n6ZkKrUVkpIboJEo8fgOLV/6EtV9ZRUNNktiDl+BZ/73G8wLE1zfhWVN0yVmkupfI9ME/gtteUOBX\nRERERA6/cgquTwVesta+AmCMuRM4G8gfFp0N/Mhaa4HfZNJEbwd6gA8Bnwew1qaA1OidvkwJ2Y6i\ncpee1UZUZi0io6fI7mYAsXUX55acFSutXr6+CTBFl5yZqmm0/5YixdW1Y/tcRERERETKYPz5zjAH\nGLMY+Ji19h8y1z8LnGatvSjvmAeB71prN2euPwz8C+AAN+APlt4LbAUusdZ2F/k6XwS+CNDY2Djv\nzjvvHPmzk8PuwIED1NaO8Jcfx4XevvKPnxbObS0t49eovDZk0ho3rw/rQuI5XNfw8p7ZzG58laBJ\n43pBnvvde/BsgIDxeFt9J5373laQIjJYLMVTjcbArFlw9NGVeiKTx7h5bci4pNeHDEWvDRmOXh8y\nnMn2+vjIRz6y1Vo7v9Rx5SSLRiIEvB+42Fr7uDHme8C/AlcMPNBaewP+YIn58+fbhQsXjvGpSSVs\n2rSJEf9/ufWF8paeZfuJTp6tZWcTwKi8NmTSGjevj2e/CXvifPOOy7nq55/km//vKpoXX8E372om\n/tAHSaYiTAv14NoQabfYrouWmfUuxmT+MBMIQNAfZi9YoD6iQzFuXhsyLun1IUPRa0OGo9eHDGeq\nvj7KGRb9HnhH3vVjM7eVc4wFXrPWPp65fS3+sEikfH1lrFysjaifSERGj+PAc09D+woS+6pp2XCp\nX1y9/qtc8OEbB5VW+z/uBgtXWZae00XzP/7Rv6G+Fk45oUJPQkRERETk0JQzLNoCnGiMOR5/AHQu\n8JkBx9wPXJTpMzoN2Gut/QOAMWa3MeZPrbUvAh+lsOtIpLj8Quu0M/yx6igSkVGUSMDiTzqsveg2\nGvCIrftabnmZ5wVYsvrHxUurI/6lUIC2xCw4fdbYn7iIiIiIyCgpOSyy1jrGmIuAjUAQ+KG1dpsx\n5p8y918PrAc+AbyEX2r9hbxPcTGwJrMT2isD7hMZ7GAKrQMBP1EkIjJKYte4tD4WJt54NE0fDw8q\nrt688wwY1EVkMMbS3m6KlFaLiIiIiEwsZXUWWWvX4w+E8m+7Pu/fFrhwiMc+A5QsTxLJ2fNm+YOi\nI+r9pWciIgcpkYDFi2Ht2v5dyRIJaGkxWGuIr/8KPX1VRVNExThpiMehuXkMT1pEREREpALK+y9g\nkUp6raP0oKg2AicdpzJrETk0jkPsn7tobbXE4/03x65x8Vz/364bYOXGS3Kpon4Gv7jaITqj/1IX\n8Whrq9QTEBEREREZO2O9G5pIefI7ikrtfFYVUkeRiIxIYtseWm5v9BNEcWhq8m9vaTEkU/7fUYYt\nrg4bll4SUopIRERERCYlDYvk8DuYjiKAcLHtqUVEhlaw5KzWIRY3ubcbz7PE4wbPcfHcwUnFSNgl\nMs3zB9V5XUVKEYmIiIjIZKVhkRx+5XYUgQqtReSQxGLQ2up3CjX91R5a7mokmQoCkEwali8HbH+q\nqJ/BGGhfs42GOW+D44+p+LmLiIiIiFSaOovk8CunowhUaC0iZUkkYNFHPRKPtoPjZEqr/RBjPG5Z\n9p+BQW85qZSlr694/5njGuJrZ0F3sgJnLyIiIiJy+ClZJIdfX6r0MbURP1F01JEqtBaRYcVi0Por\nQ/yYGpqP7SB28zG54ZDrWFbecxRpp/BvJY7jv6/MnFnsLSZAW2IWnDL25y4iIiIiMh5oWCSVl19m\n3ZcC1x3++NqICq1FpCyJBLSssH5x9d2NXPCXL9Cy4miSSX8C1NsXYOjSasvSpUal1SIiIiIy5WlY\nJJV1sGXW6igSkWEUFFc3+Kkiz7WAwbOwZNlxuev5cqXV+QIB2tqCFTt3EREREZHxSsMiqayDLbNW\nR5GIDOQ4/tD55NnEYqH+4uomP1WU7POXmCX7gmxuq2PgoAgMJgDtP91BQ11esrG+Fk45oWJPQ0RE\nRERkvNKwSCqrVJl1wEAwCOFqdRSJSIFcimj5HhoS+0ls20NLy9GZ4mro6aFoiqgYxwsS//W7teRM\nRERERKQIDYukMrI9RQd6hj8uGITT51bmnERkQonFoLXVEo8bms+HWNzgef5wyHVh5UpLOj1wk08D\nWGbWu5jqIPmDpLa2Cp68iIiIiMgEMvC/qkVGX7anaOeu0seGq8f+fERkwkkkoKUFv7j6rqPY9Ydq\nWu46qr+4uhfS6eKPDVdZln56D51PvE5nJ7nLvfdW8AmIiIiIiEwgShbJ2Cu3p0hl1iICJLocdu7w\nmHuKQ0PU/zEVi5FLEXkWlnzn/xR9S/GLqwfvdtb2agS6u8b4zEVEREREJgcNi2TsleopApVZi0hO\n7Fs9HHF8gPiVPTRfW59LFWVTRMm+IJufH6K4OhSk/bf+zmiFGjIXEREREREpRcvQZOz1pUofc9Jx\ncPJslVmLTDGJBCxa5H8EP1XUcnMNAPGbakh0OXmpotIcxy+7FhERERGRQ6dhkYwNa6HjDejphbQz\n/LG1EWicqUGRyBTkl1b3D3hi3+rB8/z3As/CVd/oKUgV9csWVztEZ6SJHuESjUJdnYqrRURERERG\nSsvQZPRlC63VUyQixTgObHuZxDGzaWkJYa0/LLrg7/1UUTLl/x0j2Rek5Ye1mKDfVTRQuMqy9Jwu\nmv/xj1BfC6ecUOEnIiIiIiIyOWlYJKPvYAqt1VMkMmUkErB4MaxdvoeGxH5iN/bgefWA/3ax5FwH\nzyvcEdG1MC1gqY8WSx4GaEvMgtNnVeDsRURERESmDg2LZPSVU2hdG/ETRUcdqeVnIlOEv+TMEo8b\nmv466KeIev37kknY/GSYgQkizwtgcGnf3r8zmoiIiIiIjC39l7eMDmv9RNFrHXCgZ/hjq0Iwb05l\nzktExoXsjmbWGuJ3HUVPL7luolIc1xC/spvma+vH+CxFRERERARUcC2jIdtRtHNX6UERQLi69DEi\nMnE5DolH21n0US+3y1n+jmauByt/1pjrJurXX1odCkJ0hkN0hkNdxKPtBf24EhERERGpFCWLZOTK\n7SgCFVqLTAW7O4jdWEPrrwzxODQ1UbCjWW8qCNiiDw2HDUsvCfHeudCZyP8RVTv25y0iIiIiIoCG\nRTIayukoAhVai0xSueLqtdBQ65DY3kXL3af4S87ilp4ek0kVFS47i4RdItMy7x1Vodz9bW3w539e\n2ecgIiIiIiL9NCySketLlT5GhdYik5ZfXA3xODR/oYPYT9+Wmx+7jmXlSkM6PfD73mAMtN/+PA31\nHrxjFhx/TO7eTZsqdvoiIiIiIjKASiDk0FkLHW+A6w5/XG3EL7RunKlBkchk4Djw7It+N1GuuBri\nccuuLW/SclcjyVQQgN6+AOl08SVnjmuI3/N2CAWhO1nJZyAiIiIiIsNQskgOTbbU+q194BX/RTBH\nHUUik0YiAYs/6bD28h4a6juI3XxMLkXkuZYly44ruio1EvEvhQK0JWbB6bPG+rRFREREROQgaFgk\nh6acUutAwE8MqKNIZNKIXePS+liY+F2NNJ3bScuKo3PF1cneAJvb6hjYTeQvObO0txsaGip+yiIi\nIiIicpC0DE0OTalS64CBk46DaWEtPROZoBIJWLTI/5i93tJi/OLquxtZ9qNGPLdEsjDDSfudRiIi\nIiIiMv5pWCSHplSpdTDodxSJyMST6SSKXePmiqvBTxV5mYoy14OV9xxFsm/gjxEDWGbWO0Rn9F/q\nIh5tbZV8EiIiIiIicqg0LJLyZQutt74AaWf4Y8PVlTknERl9uztI7O7JpIj8YdGuXX6qKJnyf2z0\npoKkneKpwXDYsPSSEJ2JvMtbQe69t5JPQkREREREDpU6i6Q8BYXWwyw/A7+rSKXWIhNKIgGLF8Pa\nOx0aXusgdtesXIrI82DJeV7uer5I2CUyzYOqEPldRUoRiYiIiIhMXBoWSXnKKbQGf1B0RL1KrUUm\nmFgMf8nZlT00fTxAy92NuRRRMgmbf20oXlwN7Wu20TDnbXD8MRU/bxERERERGX1ahiblKVVoDVAb\n8UutT56tUmuRcSyRgEUf9Ug82g6Okymu9gOE8ZtqWHZbY8lv9yzHNcTXzoLu5NietIiIiIiIVIyS\nRTI8a/1U0YGe4Y+rCsG8OZU5JxEZkVgMWn9liB9TQ/OxHcRuPiY3HHI9WPmzRtJOseJqmDlz4Cw4\nQFtiFpxSiTMXEREREZFKULJIhpbtKdq5q/SxKrQWmRASCWhZYbHWEL+7kV1b3qRlhSWZCQYNX1wN\nS5dCZ2fhRcXVIiIiIiKTi4ZFMrSD6SlSobXIuJRIwKJF/kfwU0WeawHwLCxZdlzuer5I2CU6I91/\nOcKlrk7F1SIiIiIiU4GWocnQyukpUqG1yPjkOLDtZWI/PYHW1iDxODQ1+amiZF+muLovyOa2OooW\nVweg/ac7aKjLbIFWXwunnFDRpyAiIiIiIoeHhkUytL5U6WNOOs4fFKnQWuSwSyRg8WJYuxYa3uog\nsbuHlhbjF1fHoacnmyoq/f3qeEHiv343zc1jf94iIiIiIjK+aBmaDGYtdLwBrjv8cbURaBzUdisi\nh0ksBq2tEI+58FoHsbsa8TLfxq4LK1f2p4r6GcAys94hGrVEoxCNoiVnIiIiIiJTmJJFUihbav3W\nPr/QZCjqKRIZVxIJaGnxv4XjKwwXvKeKlrsbSab84VBv79CPDVdZln56D83fsnD8MRU6YxERERER\nGa+ULJJC5ZRaq6dI5LBLdDks+mA3iS4HyBRXZ75tPdey5NvHFf029ournYJLXcSj7dUIdCcr+AxE\nRERERGS8UrJICpUqtQ4Y9RSJjAOxb/XQ+kQd8Sv30/TtelpaIJmZ9ST7gmx+foji6lCQ9t9CQ8PA\nz9iQuYiIiIiIyFSnZJH4sj1FB3qGPy4YVE+RyGGW6HJoubkGaw3xm2pY1uyW3Lgwy3H8smsRERER\nEZGhaFgk/T1FO3eVPjZcPfbnIyIFEglYtMj/CH6qyPP8ga3rwcprA7lUUb+84uoZaf9yhKviahER\nERERKUnDIimvpwhUai1SSY4Dz74IjtO/y1m8P1WUK65OBUk7xT9FuMqy9JwuOtdv8y+PvEpnJ9x7\nbwWfh4iIiIiITDjqLJLSPUWgUmuRCkkkYPFiWLt8Dw2J/SS27aGl5Wh/l7M49PyhB8+rHfS4yDSP\nSO3A+X+AtsQsOH1WZU5eREREREQmBQ2LBPpSpY9RqbVIRfgpIks8bmg+H2Jxg+dZwOC6lpW31pJ2\nBg6FDAaP9u0ODVG9rYuIiIiIyMhoGdpUli21dt3hj6uNqNRapAISCWhpwS+uvusodv2hmpa7jiKZ\n9L/3ensNaaf496HjGuJXliioFxERERERKYOGRVNVfqm1Z4c+Tj1FImPDcUg82s6ij3r9xdUxMiki\n/9tyyXf+T9EVopGwS3SGU3Cpi3i0vaC3dBERERERGTmtV5iqyim1Vk+RyNjZ3UHsxhpaf2WIx6Gp\nyU8VZVNEyb4gm5+vw9/VLJ/BhIK0/xYaGgZ+0sFdRiIiIiIiIgdLf4aeqkqVWgeM31N08mwtPxMZ\nBYkELFrkf8RxSGzvouXuRn/JWdyybFl/qqgUx/HLrkVERERERMaChkVTValS62BQPUUio8gvrs4M\neXZ3EPvp23LzWtexrFzZnyrqZwDLzHqH6Iw00SNcolGoq4O2tgo/ARERERERmTK0DG0qstZfYjac\ncHVlzkVkMnMc2PYyiWNm09ISwlqIxy0XnPImLXfNIZkKAtDbFwD8Hc8GCldZlp7TRfM//hHqa+GU\nEyr7HEREREREZMrRsGiqyRZbp9JDH6NSa5ERSSRg8WJYu3wPDYn9xG7swfPqAfBcy5JlxxUvro74\nl0IB2hKz4PRZY37eIiIiIiIioGHR1JMttrZDdKMYo1JrkRHyl5xZ4nFD018Habm5hmSvf1+yN8Dm\ntiGKq42lvd0UKa4WERERERGpHHUWTTWliq2rq1RqLXKQ8surEwl/VzNrDfG7jmLZj2fheeV9Pzlp\nFVeLiIiIiMjhp2TRVGGtnyo60DP8cZ6nQZFIuTKdRLGfnkBra5B43P8W8nc1M7gerPxZI2ln4Fw+\nW1ztFn67GUNbW7By5y8iIiIiIlKEhkVTQban6K19pY9VsbVI+XZ3kNjdQ0uLwVpYvty/OburWW8q\niF9cPVg4bFh6SYjm5gqdq4iIiIiISJm0DG0qyPYUDbf8DFRsLVKG3JKzLgde6yB2VyOe69+XSkEq\nNXg4FAm7RGek/UvUEo1CXR20tVX45EVERERERMqgZNFUUKqnCPxBkYqtRUryy6shfmUPTR8P0HJ3\nI8mUP3d3HCheXA3ttz9PQ70H75gFxx9T6dMWEREREREpm5JFU0FfqvQxJx2nYmuRARIJWPRRj8Sj\n7eA4eeXVEL+phmW3NZacwwI4riF+z9shFITu5NifuIiIiIiIyAgoWTTZWeunhoZTG4HGmZU5H5EJ\nJBaD1l8Z4sfU0HxsB7Gbj8kNh4Yur/bNnJk/ew3QlpgFp8+qyHmLiIiIiIiMhJJFk1m22DqVHvoY\n9RSJFJVIQMsKi7WG+N2N7NryJi0rLMlMMKg3FSTtFE/ihcOwdCl0dvZf7r23gicvIiIiIiIyAhoW\nTWbZYmtbfDcmjFFPkUhGrrg64V+PxcBz/e8dz8KSZcflrucrKK+ekSZ6hKvyahERERERmdC0DG0y\nK1VsXV2lniIRx4FtLxP76Qm0tgaJx6GpyU8VJfv8eXqyL8jmtjqKllcHoP2nO2ioy2yJVl8Lp5xQ\n0acgIiIiIiIymjQsmsxKFVt7ngZFIrs7SOzuoaXF+MXVcejpyaaKSn9/OF6Q+K/fTXPz2J+qiIiI\niIhIJWgZ2mRVTrF1uLoy5yIyDuV2OtveReyuRrxMMMh1YeXK/lRRPwNYZtY7RKOWaBSiUbTkTERE\nREREJh0liyYjFVuLlJTd6eyqo45i9X1HkUz5w6He3qEfE66yLP30Hpq/ZeH4Yyp0piIiIiIiIpWl\nZNFkpGJrkQKJLodFH+wm0eX41/N2Omu5uxHXG7zczC+udgoudRGPtlcj0J2s9FMQERERERGpGCWL\nJiMVW4sUiH2rh9Yn6ohfuZ/ma+vzdjozpF3/UshgQkHafwsNDQM/W0PmIiIiIiIiMjkpWTTZWAvJ\nYdbRgIqtZUpJdDm03FyDtYb4TTXsetkp2OlsqBJrx/HLrkVERERERKYaJYsmk2xXkTtMqghUbC1T\nSuxbPXheLQCehSXnOnhugMIhkSUS9ohMy3zvBAIQDKq4WkREREREpiQNiyaTbFfRcFRsLZOV4/jD\n0pNnQ8h/a8umirLl1cm+IJufHDgoAjCYALT/dAcNdS7U18IpJ1T2/EVERERERMYJLUObTEp1FYGK\nrWXy2t0Bif3+xww/VVTekkvHCxL/9bvh9LkaFImIiIiIyJSmZNFk0pca/v5gQMXWMjk5jj8sBf/j\nOxr9Hc/yUkX9DGCZeSSYQOH3gpadiYiIiIiIaFg0eVjrLzEbzvRpGhTJ5LS7A7CZKxZ2dxBbXofj\n1hY9PFxlWfqZAzRfW1+xUxQREREREZkoNCyaDLLF1qn00Meoq0gmuiKdRLnbX+vw26vB//haB9te\nmEFdxKOO4ksz217QKlwREREREZFiNCyaDLLF1tYWv98YdRXJxJffSXT8MYW3M/C1b7n35r1wfPFk\nkW+4+0RERERERKYu/Wl9MihVbF1dpa4imdgGdhI5TuHt3oBhUSZdlDtOREREREREyqZh0WRQqtja\n8zQokomtSCdR7vahEnXWFuyMJiIiIiIiIuXRsGgyCFeP7H6R8cJx4NkXCxNBQ3QS4TjQnYRQEKpC\ngy+hoH+/iIiIiIiIHBR1Fk10Q6UqslRsLRNJsV6iITqJ2N0Bp5xQ6TMUERERERGZ9JQsmuj2vDl8\neiIyTcXWMjEU6yVSJ5GIiIiIiEjFaVg00b02TGcL+Pepr0gmgmK9ROokEhERERERqbiyhkXGmI8Z\nY140xrxkjPnXIvcbY8zKzP3PGWPen3ffb40xbcaYZ4wxT47myQuly61T6cqch0i5sr1EA28r1kt0\noEedRCIiIiIiIhVWsrPIGBMErgPOBF4Dthhj7rfWvpB32MeBEzOX04DvZz5mfcRa2zVqZy0+awcv\nzxlI5dYy3mR7ifIHmUP1EtVG4N0nVvLsREREREREprxykkWnAi9Za1+x1qaAO4GzBxxzNvAj6/sN\n0GCMefson6sMtOdN8Lyh7zdG5dYyvuT3EqXS6iUSEREREREZh8oZFh0DD1yhzAAAEZlJREFU7M67\n/lrmtnKPscAvjTFbjTFfPNQTlSJK9RUFjMqtZXwZmCBSL5GIiIiIiMi4U3IZ2ihYYK39vTHmKOAX\nxpgd1tpHBh6UGSR9EaCxsZFNmzZV4NQmuO7k8MMiY+B//qdy51PEgQMH9P/lVJXsg+nhwtsO9PT/\n03XYtO1ZCAaHT8i92AW72sfoJGW80nuHDEWvDRmOXh8yFL02ZDh6fchwpurro5xh0e+Bd+RdPzZz\nW1nHWGuzH/cYY+7FX9Y2aFhkrb0BuAFg/vz5duHCheU9g6nKWni8bfiC69oIzJtTuXMqYtOmTej/\nyyno1d/D7/4Af/J2OP6Y/tte+2Nuudmm/XtYOKMRjp3Vf4xIht47ZCh6bchw9PqQoei1IcPR60OG\nM1VfH+UsQ9sCnGiMOd4YUw2cC9w/4Jj7gc9ldkX7ILDXWvsHY0yNMaYOwBhTA5wFPD+K5z81WQvb\nXh5+p7NAQH1Fcnjk9xJlO4fUSyQiIiIiIjJhlEwWWWsdY8xFwEYgCPzQWrvNGPNPmfuvB9YDnwBe\nAnqAL2Qe3gjca4zJfq2fWGs3jPqzmGr2vAlv7Rt6CZoxcES9+ork8CjoJcrrHCrVS6R0kYiIiIiI\nyLhQVmeRtXY9/kAo/7br8/5tgQuLPO4V4L0jPEcZ6LWO4Tteqqvg5Nn+0EhkrDiOn3A7eTaEQv23\n5SeIssmhhjoIBQsfbwxUZR7XnazceYuIiIiIiMiwKlFwLaNtuJ4i8AdJGhTJWNvdAYn9hamggbud\ngX+9NgLvPrHw5k0JOH1uJc5UREREREREDkI5nUUy3oSrR3a/yEipl0hERERERGTS0rBoIjrmqOHv\nV7G1jLVivUS7O0r3EomIiIiIiMi4p2HRZDTUL+wiB8tx4NkXC1NBQ/USHejxe4mqQoMvoaB6iURE\nRERERCYIdRZNRL/fU/r+WdHKnItMbv9/e/cWI+dZ3gH8/3g3B0xI01MosSmxaAQKp4IMDVQq6Uni\nJHLRG6oCEqqEkKCFqhWFXvSmt1VFkSgIAZUQqFxQLiKUll5QX3FQgBRocFMFMLVTx045GRNMvPjt\nxcxOJuOd2dmd3Zn5Zn8/aWTvvN+3flZ+dvzt4/f7z6y5RAAAAHSOnUVdtF3A9XbrMA25RAAAAAeS\nYVHXtHb1D+qjBFyzF+QSAQAAHEiGRV1z/nvJlSvj16sEXLMzcokAAAAYIrOoa85M2NmRJIcqufkX\n5lcP3SeXCAAAgCF2FnXNdnlEVb0HTEMuEQAAACMMi7pmuzyi66+bTx2sBrlEAAAAjHAbWpdMuv0s\nSQ4dklfE9MblEt30lF7+0DhyiQAAAFaaYVGXnP/e5B/UD18vr4jxNjaS+7+ZPOeZyfq6XCIAAAC2\n5Da0Ltku3Lo1eUWMNxxkLZcIAACAMQyLumS7cOvHLs+nDrpnNMj6O2flEgEAALAlt6F1yXXXJpcn\n7PjYLvyag2s0yPq7P5BLBAAAwJYMi7rkyM3JA6fGrwu3ZjSXaPO50SDrn15OXvr8x48BAACAPreh\nrZLt3i2N1TecSzT83FZB1m41AwAAYAuGRV3y0PnZ1llto7lEGxuCrAEAANgxw6Iu2S7gert1Vtto\nLtHpc72HIGsAAAB2wLCoS7YLsBZwfXBsbCRffeDxnUFb5RKdOZdcfLQXZH3N+tWP9TVB1gAAAFxF\num2XPOm63g//4xy+bn61sFjD2UTHjozPJbrhcPK82xZRIQAAAB1lZ1GXPPL9yevnt1lnNYxmE126\nJJcIAACAPWNYBF0zmk108pRcIgAAAPaMYREsq9Fcos3nRrOJLlxM1g7JJQIAAGBPyCyCZTWaS7T5\n3Gg20aFKbrn58WMAAABgBnYWwTIazSXa2Lh6V9Em2UQAAADsIcOiLnnx7bOt0x2juUSnz/UesokA\nAADYZ4ZFXXL48PiB0Itv763TPaPZRFvlEp05l1x8tJdBJJsIAACAfSSzqGsOH05efnzRVbCXRrOJ\ntsolSktuOJw877ZFVAgAAMABYmcRLNJoNtGlS3KJAAAAWCjDIlik0Wyik6fkEgEAALBQhkUwL9Nk\nE124mKwdkksEAADAwsgsgnmZJpvoUCW33NxbBwAAgAWwswjmQTYRAAAAHWFYBPMgmwgAAICOMCyC\nvSabCAAAgA6TWQR7TTYRAAAAHWZnEewl2UQAAAB0nGER7CXZRAAAAHScYRHslmwiAAAAVpDMItgt\n2UQAAACsIDuLYDdkEwEAALCiDItgN2QTAQAAsKIMi2A7sokAAAA4QGQWwXZkEwEAAHCA2FkEk8gm\nAgAA4IAxLIJJZBMBAABwwBgWwSbZRAAAACCzCAZkEwEAAICdRZBENhEAAAD0GRZBIpsIAAAA+gyL\nOJiG84lkEwEAAMCAzCIOpuF8oiSyiQAAAKDHziIOnuF8otMPyyYCAACAIYZFHDzD+UStJVeubH2c\nbCIAAAAOIMMiVt+kfKJN62uyiQAAACAyizgI5BMBAADA1OwsYrXJJwIAAIAdMSxitcknAgAAgB0x\nLGJ1DGcTbX4snwgAAAB2RGYRq2M4m+jYkSfuKtoknwgAAAAmsrOI1TCcTXTmXHLpknwiAAAA2AXD\nIlbDE3YRteTkqV4O0VbkEwEAAMBYhkV003A+0Wg20ZWWXLiYrB26OptIPhEAAABMJLOIbhrOJ0oi\nmwgAAAD2hp1FdM9wPtHph2UTAQAAwB4yLKJ7hvOJWkuuXNn6ONlEAAAAsGOGRSy/SflEm9bXZBMB\nAADAHpBZxPKTTwQAAABzY2cRy00+EQAAAMyVYRHLTT4RAAAAzJXb0Fhek/KJqq4+Xj4RAAAAzMyw\niOWysZHc/83kOc984q6iTfKJAAAAYF+5DY3lshlm/Z2z8okAAABgAQyLWB7DYdZnzvVyiLYinwgA\nAAD2jdvQWB6jt51VkvUxLSqfCAAAAPaFYRGLtZlR9KxnbHHbWSUvee74gREAAACw59yGxmJtZhSd\nPJWrwqzjdjMAAACYN8MiFmc4o+jCRWHWAAAAsAQMi1ic0YyirQizBgAAgLkyLGJ+NjaSrz7Q+3Vz\nV9HobqL1teSa9ccf62vCrAEAAGCOJAczP5v5RIOdQiODokOV3HJzcuzI3EsDAAAAeuwsYj6G84lO\nP7z1riIZRQAAALBwhkXMx3A+UWvJlStbHyejCAAAABZqqmFRVb2iqh6oqger6l1brFdVvbe//rWq\netHI+lpV3VdVn96rwumAjY3kJz9NLl2aLp9IRhEAAAAs3LaZRVW1luR9SX4/yZkk91bV3a21bwwd\n9sokt/Ufv5Hk/f1fN709yckkN+5R3XTB6XPJz36WnDwV+UQAAADQDdPsLHpJkgdba99qrT2W5BNJ\n7ho55q4kH209X0hyU1U9LUmq6miSVyf50B7WzbIbzii6cFE+EQAAAHTENO+GdiTJ6aGPz+SJu4bG\nHXMkydkk70nyziRPmfSHVNWbk7w5SZ761KfmxIkTU5TG0nrscvLY5Vz82UZO/Oj8+OM++93k2mvm\nVxdL4+LFi77PGUt/MI7eYBL9wTh6g0n0B5Mc1P6YZli0a1X1miTnW2tfrqo7Jx3bWvtgkg8myfHj\nx9udd048nGW2sZF8/mvJdVdy4kfnc+dTbu49v76WVD3x2BtvSJ77a/OvkYU7ceJEfJ8zjv5gHL3B\nJPqDcfQGk+gPJjmo/THNsOihJE8f+vho/7lpjvmDJK+tqlcluT7JjVX1sdba63dfMktv+J3PNsko\nAgAAgE6YJrPo3iS3VdWxqro2yeuS3D1yzN1J3th/V7Q7kvywtXa2tfbu1trR1tqt/fM+a1C04jaz\nimQUAQAAQCdtu7OotbZRVW9L8pkka0k+0lq7v6re0l//QJJ7krwqyYNJHk3ypv0rmaV2+lzS2tZr\nrfXW7S4CAACApTVVZlFr7Z70BkLDz31g6PctyVu3+RwnkpzYcYV0y49/0ssm2lSVXLP+xHUAAABg\nae1rwDUH0GhY9YkfJC/79cXUAgAAAOzYNJlFAAAAABwQhkUAAAAADBgWAQAAADBgWAQAAADAgGER\nAAAAAAOGRQAAAAAMGBYBAAAAMGBYBAAAAMCAYREAAAAAA4ZFAAAAAAwYFgEAAAAwYFgEAAAAwIBh\nEQAAAAADhkUAAAAADBgWAQAAADBgWAQAAADAgGERAAAAAAOGRQAAAAAMGBYBAAAAMGBYBAAAAMCA\nYREAAAAAA4ZFAAAAAAwYFgEAAAAwUK21Rddwlap6JMl3Fl0He+KXkvzfootgKekNJtEfjKM3mER/\nMI7eYBL9wSSr1h/PaK398nYHLeWwiNVRVV9qrR1fdB0sH73BJPqDcfQGk+gPxtEbTKI/mOSg9ofb\n0AAAAAAYMCwCAAAAYMCwiP32wUUXwNLSG0yiPxhHbzCJ/mAcvcEk+oNJDmR/yCwCAAAAYMDOIgAA\nAAAGDIvYlap6RVU9UFUPVtW7tlivqnpvf/1rVfWiobWbquqTVfVfVXWyql463+rZbzP2x59V1f1V\n9Z9V9U9Vdf18q2c/TdEbz66qz1fVT6vqL3ZyLt232/6oqqdX1b9X1Tf6rx9vn2/l7LdZXjv662tV\ndV9VfXo+FTNPM/7b4rp0hc3YG65JV9wU/fFH/Z9Vvl5Vn6uqF0x77iowLGLHqmotyfuSvDLJ7Un+\nsKpuHznslUlu6z/enOT9Q2t/n+RfW2vPTvKCJCf3vWjmZpb+qKojSf40yfHW2nOTrCV53ZxKZ59N\n2RvfS68H/nYX59Jhs/RHko0kf95auz3JHUneqj9Wx4y9sentcb2xkvagP1yXrqgZrztck664Kfvj\n20le3lp7XpK/ST+76KBclxoWsRsvSfJga+1brbXHknwiyV0jx9yV5KOt5wtJbqqqp1XVzyX5rSQf\nTpLW2mOttR/Ms3j23a77o7+2nuRJVbWe5HCS/51X4ey7bXujtXa+tXZvkss7PZfO23V/tNbOtta+\n0v/9j9L7Ye/IfMpmDmZ57UhVHU3y6iQfmkexzN2u+8N16cqb6bUjrklX3TT98bnW2vf7H34hydFp\nz10FhkXsxpEkp4c+PpOrL8rHHXMsySNJ/rG/HfxDVfXk/SyWudt1f7TWHkrvf3b+J8nZJD9srf3b\nPtbKfE3TG/txLt2wJ3/HVXVrkhcm+eKeVMUymLU33pPknUmu7GVRLI1Z+sN16WrbdW+4Jj0Qdtof\nf5zkX3Z5bicZFjFv60lelOT9rbUXJvlxkpW8x5Odq6qfT28qfyzJLUmeXFWvX2xVQFdU1Q1J/jnJ\nO1prFxZdD4tXVa9Jcr619uVF18JScl3KllyTMqyqfju9YdFfLrqWeTIsYjceSvL0oY+P9p+b5pgz\nSc601jb/x/eT6f0jzeqYpT9+L8m3W2uPtNYuJ/lUkpftY63M1zS9sR/n0g0z/R1X1TXpDYo+3lr7\n1B7XxmLN0hu/meS1VXUqvdsEfqeqPra35bFgs/SH69LVNktvuCZdfVP1R1U9P73bmO9qrX13J+d2\nnWERu3Fvktuq6lhVXZte2NvdI8fcneSN1XNHels3z7bWHk5yuqqe1T/ud5N8Y26VMw+77o/0tvre\nUVWHq6rS6w9Bk6tjmt7Yj3Pphl3/HfdfLz6c5GRr7e/2sUYWY9e90Vp7d2vtaGvt1v55n22t2R2w\nWmbpD9elq22WawfXpKtv2/6oql9Nb1D4htbaf+/k3FWwvugC6J7W2kZVvS3JZ9J7Z4CPtNbur6q3\n9Nc/kOSeJK9K8mCSR5O8aehT/EmSj/e/sb41skbHzdIfrbUvVtUnk3wlvXc3ui/9dx2g+6bpjar6\nlSRfSnJjkitV9Y4kt7fWLmx17mK+EvbDLP2R5PlJ3pDk61X1H/1P+VettXvm/oWw52Z97VhY4czF\nHvSH69IVNWNvuCZdcVP+zPLXSX4xyT/0ZobZaK0dH3fuQr6QfVSttUXXAAAAAMCScBsaAAAAAAOG\nRQAAAAAMGBYBAAAAMGBYBAAAAMCAYREAAAAAA4ZFAAAAAAwYFgEAAAAwYFgEAAAAwMD/A+EOvu21\nDwqJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc2bc0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig= plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.scatter(x= [x[1] for x in frontier_uncons_pair], y= [x[0] for x in frontier_uncons_pair], \n",
    "            marker='o', c= 'pink', s=60, label= 'CMA: long only')\n",
    "plt.scatter( x= [x[1] for x in frontier_uncons_NoCorp_pair], y = [x[0] for x in frontier_uncons_NoCorp_pair], \n",
    "           marker= 'o', c= 'orange', s=60, label= 'CMA: long only(No Corp)')\n",
    "plt.scatter(x= [x[1] for x in frontier_cons_pair], y= [x[0] for x in frontier_cons_pair], \n",
    "            marker= 'o', c= 'blue' , s=60, label= 'CMA: long only and constrained')\n",
    "plt.scatter(x= [x[1] for x in frontier_cons_NoCorp_pair], y= [x[0] for x in frontier_cons_NoCorp_pair], \n",
    "           marker= 'o', c= 'red', s=60, label= 'CMA: long only and constrained(No Corp)')\n",
    "\n",
    "\n",
    "frontier_BLuncons_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_BLuncons.values()]\n",
    "frontier_uncons_pair.sort(key= lambda x: x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_BLuncons_pair], y= [x[0] for x in frontier_BLuncons_pair], \n",
    "            marker='^', c= 'pink', s=60, label= 'BL: long only')\n",
    "\n",
    "frontier_BLuncons_NoCorp_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_BLuncons_NoCorp.values()]\n",
    "frontier_BLuncons_NoCorp_pair.sort(key= lambda x : x[0])\n",
    "plt.scatter( x= [x[1] for x in frontier_BLuncons_NoCorp_pair], y = [x[0] for x in frontier_BLuncons_NoCorp_pair], \n",
    "           marker= '^', c= 'orange', s=60, label= 'BL: long only(No Corp)')\n",
    "\n",
    "\n",
    "frontier_BLcons_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_BLcons.values()]\n",
    "frontier_BLcons_pair.sort(key= lambda x : x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_BLcons_pair], y= [x[0] for x in frontier_BLcons_pair], \n",
    "            marker= '^', c= 'blue' , s=60, label= 'BL: long only and constrained')\n",
    "\n",
    "frontier_BLcons_NoCorp_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_BLcons_NoCorp.values()]\n",
    "frontier_BLcons_NoCorp_pair.sort(key= lambda x: x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_BLcons_NoCorp_pair], y= [x[0] for x in frontier_BLcons_NoCorp_pair], \n",
    "           marker= '^', c= 'red', s=60, label= 'BL: long only and constrained(No Corp)')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "1. CMA results are represented by nodes while the BL results are triangles. BL result shifted down relative to CMA since BL post return is lower than CMA active. \n",
    "\n",
    "2. Applying BL slacks the concentration constrain (at 30% level)\n",
    "\n",
    "3. Applying BL makes US Corp less different from other assets, hence insensitive to the NoCorp Constrain. (Kicking out US Corp leads to smooth extension of the frontier and insignificant jump compared to the CMA cases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_mvo_BL= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(), \n",
    "                         asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                         weight= np.array( [0.228180399, 0.3, 3.41287E-17, 0.169087738, 0.066754889,0.154949295, 0.081027679]))\n",
    "blended_mvo_pi= Portfolio( asset_ret= UniverseProperty['impliedExpectedReturn_peer_geo'],\n",
    "                         asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                         weight= blended_mvo_BL.weight)\n",
    "blended_mvo_cma= Portfolio( asset_ret=UniverseProperty['CMA_active_geo'],\n",
    "                           asset_cov= UniverseProperty['LW_cov_active'], \n",
    "                           weight= blended_mvo_BL.weight)\n",
    "\n",
    "peer_BL= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(),\n",
    "                  asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                  weight= portfolios['Peer'].weight)\n",
    "peer_pi= Portfolio( asset_ret= UniverseProperty['impliedExpectedReturn_peer_geo'],\n",
    "                  asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                  weight= portfolios['Peer'].weight)\n",
    "peer_cma= Portfolio( asset_ret= UniverseProperty['CMA_active_geo'],\n",
    "                   asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                   weight= peer_BL.weight)\n",
    "\n",
    "cma_BL= Portfolio( asset_ret= blended_mvo_BL.asset_return,\n",
    "                 asset_cov= blended_mvo_BL.asset_cov,\n",
    "                 weight= np.array( [0.3, 0.3, 0, 0.3, 0, 0.1, 0]))\n",
    "cma_pi= Portfolio( asset_ret= peer_pi.asset_return,\n",
    "                 asset_cov= peer_pi.asset_cov,\n",
    "                 weight= cma_BL.weight)\n",
    "cma_cma= Portfolio( asset_ret= peer_cma.asset_return, \n",
    "                  asset_cov= peer_cma.asset_cov,\n",
    "                  weight= cma_pi.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064955163370140942"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_BL.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12428132380236374"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_BL.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37861813770964986"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_BL.SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058206927946181777"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_pi.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12226877477221214"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_pi.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32965839415070575"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_pi.SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.080028712871287128"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_cma.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12226877477221214"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_cma.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50813229286899697"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer_cma.SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.065006983747864081"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_mvo_BL.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12401999923261095"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_mvo_BL.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37983376906421834"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_mvo_BL.SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057226273716821437"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_mvo_pi.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12200839926345082"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_mvo_pi.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32232431499986186"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_mvo_pi.SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0821239316834"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_mvo_cma.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12200839926345082"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_mvo_cma.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52638942950740852"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_mvo_cma.SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062353300274537671"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma_BL.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11134354187460004"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma_BL.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39924453206817256"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma_BL.SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054079760745890479"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma_pi.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10954215777416304"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma_pi.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33028161468646872"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma_pi.SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.080099999999999991"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma_cma.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10954215777416304"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma_cma.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56781791836010997"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cma_cma.SharpeRatio(1.79/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_CORP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.296730</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.307848</td>\n",
       "      <td>0.313075</td>\n",
       "      <td>0.260839</td>\n",
       "      <td>0.233716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.296730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011812</td>\n",
       "      <td>0.692243</td>\n",
       "      <td>0.678817</td>\n",
       "      <td>0.611732</td>\n",
       "      <td>0.577800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_CORP</th>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.011812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143748</td>\n",
       "      <td>0.079756</td>\n",
       "      <td>0.176276</td>\n",
       "      <td>0.118270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.307848</td>\n",
       "      <td>0.692243</td>\n",
       "      <td>0.143748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840865</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.649903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.313075</td>\n",
       "      <td>0.678817</td>\n",
       "      <td>0.079756</td>\n",
       "      <td>0.840865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704161</td>\n",
       "      <td>0.695298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.260839</td>\n",
       "      <td>0.611732</td>\n",
       "      <td>0.176276</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.704161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.674103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.233716</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.118270</td>\n",
       "      <td>0.649903</td>\n",
       "      <td>0.695298</td>\n",
       "      <td>0.674103</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE   US_CORP     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       1.000000  0.296730  0.015200  0.307848    0.313075  0.260839   \n",
       "US_PE       0.296730  1.000000  0.011812  0.692243    0.678817  0.611732   \n",
       "US_CORP     0.015200  0.011812  1.000000  0.143748    0.079756  0.176276   \n",
       "SP500       0.307848  0.692243  0.143748  1.000000    0.840865  0.771825   \n",
       "Rusell2000  0.313075  0.678817  0.079756  0.840865    1.000000  0.704161   \n",
       "EAFE        0.260839  0.611732  0.176276  0.771825    0.704161  1.000000   \n",
       "EM          0.233716  0.577800  0.118270  0.649903    0.695298  0.674103   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.233716  \n",
       "US_PE       0.577800  \n",
       "US_CORP     0.118270  \n",
       "SP500       0.649903  \n",
       "Rusell2000  0.695298  \n",
       "EAFE        0.674103  \n",
       "EM          1.000000  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UniverseProperty['LW_corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12177224816007814"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolios['EqualWeights'].volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Management Optimization\n",
    "\n",
    "\n",
    "Treat Peer as bechmark, max the benefit from deviation with limited tracking error budget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -4.8332856665799196e-12\n",
      "            Iterations: 112\n",
      "            Function evaluations: 221\n",
      "            Gradient evaluations: 112\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -9.835394897054612e-05\n",
      "            Iterations: 26\n",
      "            Function evaluations: 41\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00019670789776518542\n",
      "            Iterations: 23\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0002950618469327435\n",
      "            Iterations: 21\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00039341579592502607\n",
      "            Iterations: 19\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0004917697444179066\n",
      "            Iterations: 20\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0005901236933130018\n",
      "            Iterations: 19\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.000688477642210267\n",
      "            Iterations: 18\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0007868315910535825\n",
      "            Iterations: 16\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0008851855399431118\n",
      "            Iterations: 16\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0009835394888580214\n",
      "            Iterations: 15\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0010818934376969343\n",
      "            Iterations: 15\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0011802473865447022\n",
      "            Iterations: 15\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.001278601335421493\n",
      "            Iterations: 14\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0013769552844575136\n",
      "            Iterations: 14\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0014753092331973258\n",
      "            Iterations: 13\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.001573663182060978\n",
      "            Iterations: 13\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0016720171309402097\n",
      "            Iterations: 14\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0017703710798678575\n",
      "            Iterations: 14\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0018687250287596482\n",
      "            Iterations: 14\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.001967078978599692\n",
      "            Iterations: 11\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0020654329265228774\n",
      "            Iterations: 13\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.002163786875358904\n",
      "            Iterations: 14\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.002262140824395588\n",
      "            Iterations: 14\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.002360494773247156\n",
      "            Iterations: 14\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.002458848722020543\n",
      "            Iterations: 14\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0025572026708619742\n",
      "            Iterations: 14\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0026555566201098436\n",
      "            Iterations: 13\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.002753910568614783\n",
      "            Iterations: 13\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0028522463919485796\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0029497503764604385\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.003043973772686172\n",
      "            Iterations: 12\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0031352770761374103\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.003224149057033371\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0033109658687378984\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0033960235005514195\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0034795592152871034\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.003561766206570401\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.003642803914118478\n",
      "            Iterations: 13\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0037228054684509105\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.003801883173302132\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0038801326257731934\n",
      "            Iterations: 13\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00395763585988106\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004034463780839258\n",
      "            Iterations: 13\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004110678076396108\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004186332732668895\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004261475250801696\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004336147633039918\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004410387188071216\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004484227194272854\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0045576974503740535\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004630824735355541\n",
      "            Iterations: 12\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004703633193107393\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004776144665070949\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004848378963016733\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004920354108488895\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004992086537420358\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005063591275678562\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005134882091717794\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005205971629654933\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0052768715245326255\n",
      "            Iterations: 15\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005347592503895269\n",
      "            Iterations: 15\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005418144477048746\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0054885366136444\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00555877741313178\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0056288747656808346\n",
      "            Iterations: 16\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005698836009316914\n",
      "            Iterations: 16\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005768667976401135\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005838377036993031\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005907969140892012\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005977449850239382\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00604682437188046\n",
      "            Iterations: 15\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0061160975861705045\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006185274071506161\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006254358129908511\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006323353805541238\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006392264906537239\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006461095020256689\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006529847529927921\n",
      "            Iterations: 16\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006598525630225475\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006667132339088638\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006735670510676528\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006804142846327929\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006872551904898119\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006940900112363276\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007009189769706204\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007077423062322287\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007145602065255333\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007213728752951466\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007281805002812844\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007349832602449036\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007417813254791995\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007485748583114677\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00755364013569392\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007621489390378872\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007689297757493607\n",
      "            Iterations: 17\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007757066586008512\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007824797164032669\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00789249072481273\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007960148447480282\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008027771461847005\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008095360850112532\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008162917648220202\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00823044285145095\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008297937413343896\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00836540224901133\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008432838238061478\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008500246223509067\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008567627017756704\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008634981399916798\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008702310120676656\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008769613901471917\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008836893437079944\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008904149396432297\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008971382422919054\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009038593138370018\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009105782140748878\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009172950007036456\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009240097293776943\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009307224537981326\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009374332257983354\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009441420954251836\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009508491109538547\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009575543191936646\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009642577652306469\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009709594926968376\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009776595437849925\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00984357959307864\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009910547787538911\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00997739769202816\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010043177005542393\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010107734500755479\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010171161435422038\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010233538823496285\n",
      "            Iterations: 17\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010294938957842985\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010355426652349425\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010415060272255049\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010473892582108898\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010531971461094292\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010589340505122384\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010646120477700532\n",
      "            Iterations: 15\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010702500089573654\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010758500274453362\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010814136318352409\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01086942260466387\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010924372685083204\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01097899934396632\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011033314656637013\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01108733004000646\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011141056301197133\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011194503680465692\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011247681890566467\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011300600152908725\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011353267229880809\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011405691456293165\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011457880765752443\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011509842717308937\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011561584516599872\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011613113041435686\n",
      "            Iterations: 21\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011664434858483536\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011715556242712014\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011766483194704507\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01181722145648946\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011867776525843768\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011918153670735347\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011968357941229635\n",
      "            Iterations: 21\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012018394181832925\n",
      "            Iterations: 21\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012068267042341575\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012117980988178276\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012167540310119837\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01221694913304697\n",
      "            Iterations: 17\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012266211425047956\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012315331003510933\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012364311545320965\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01241315659181673\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012461869554762828\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012510453725349565\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012558912276373742\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012607248270618156\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0126554646641221\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012703564311864937\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012751549971855208\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012799424310124288\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012847189903554001\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012894849245430585\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012942404747509084\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012989858744472099\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013037213495584017\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013084471190955224\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013131633951151854\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013178703831763533\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013225682825021722\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01327257286353121\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013319375821928742\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013366093519015318\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013412727720072758\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013459280138957199\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013505752440547573\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013552146241081729\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013598463111896955\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013644704579815287\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013690872129035667\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013736967203198329\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013782991205914658\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013828945503496781\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013874831423870103\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013920650261149192\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013966403274025638\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01401209168959116\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01405771670166388\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014103279473642163\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014148781139104474\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014194222802801177\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014239605541604793\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014284930406736247\n",
      "            Iterations: 18\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014330198418220048\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014375410578181652\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01442056785989949\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01446567121352449\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014510721566852151\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014555719825060116\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014600666871951086\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014645563570640861\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014690410763931395\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014735209274769196\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014779959907657769\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014824663447771705\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014869320663625315\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014913932305063118\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014958499105389968\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015003021782613047\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015047501037674167\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015091937556377893\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015136332009633477\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015180685053667538\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015224997330657393\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01526926946871795\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01531350208276991\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015357695774897814\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015401851134245588\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015445968737546382\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015490048143305945\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015534086257485364\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015578083367970055\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015622040091524235\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015665957030656093\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015709834776826193\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015753673909120462\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015797474994743273\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01584123858876025\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015884965235662296\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015928655468783227\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0159723098113273\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01601592877421254\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016059512861025523\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01610306256406458\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016146578365007352\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016190060738463234\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016233510147969338\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016276927049314688\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01632031188906151\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016363665105382154\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016406987128540253\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016450278380190392\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01649353927378812\n",
      "            Iterations: 21\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01653677021677609\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016579971607415624\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016623143837478496\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016666284051605813\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016709344192727377\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016752309446483808\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016795181477729335\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016837961908842777\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016880652321491933\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016923254258650093\n",
      "            Iterations: 20\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01696576922226544\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017008198681778566\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01705054406806246\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017092806778116358\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017134988175651893\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01717708959211422\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017219112326867382\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01726105765000978\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01730292680146287\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01734472099287066\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017386441408183025\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017428089204739358\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017469665512862602\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017511171439158223\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01755260806469907\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017593976447032054\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01763527762059028\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017676512597391194\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017717682367677554\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01775878790080742\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017799830144156557\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017840810027365657\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017881728459065306\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017922586329381186\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01796338451005162\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018004123854927306\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018044805200450726\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018085429366112085\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018125997154947802\n",
      "            Iterations: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018166509353929987\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018206966734396385\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018247370052554845\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018287720049721276\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018328017452356037\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018368262973571563\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018408457312499838\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01844860115485554\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01848869517263336\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018528740026711395\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018568736364244075\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018608684820743515\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01864858601990977\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018688440573918497\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018728249083723163\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018768012139319362\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018807726568553312\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018846341142101375\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01888321868267767\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01891858774451853\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018952631278107007\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018985498414850498\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019017312606421897\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019048177406434295\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01907818068097982\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019107397738781083\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019135893702194505\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019163725332287614\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w_b= portfolios['Peer'].weight\n",
    "expected_return= UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn\n",
    "cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov\n",
    "benchmark_portfolio= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(), \n",
    "                               asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                               weight= portfolios['Peer'].weight)\n",
    "\n",
    "\n",
    "frontier_activeM= {} # key tracking error, value the optmized portfolio \n",
    "\n",
    "\n",
    "\n",
    "def activeMang_obj(w):\n",
    "    return  -1*np.dot((w- w_b), expected_return )\n",
    "\n",
    "def activeMang_obj_der( w): \n",
    "    return -1* expected_return\n",
    "\n",
    "activeMang_cons0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*w.size)}\n",
    "\n",
    "for trackingError in np.linspace(0, .1, 400): \n",
    "    activeMang_cons1= {'type': 'ineq',\n",
    "                      'fun': lambda w: trackingError**2 - np.dot( np.dot( w- w_b, cov), w-w_b),\n",
    "                      'jac': lambda w: -2* np.dot(cov, w- w_b)}\n",
    "    \n",
    "    activeMang_cons= (activeMang_cons0, \n",
    "                     activeMang_cons1)\n",
    "    MV_opt_9= minimize( activeMang_obj, \n",
    "                      x0= w_b,\n",
    "                      jac= activeMang_obj_der,\n",
    "                      method= 'SLSQP', \n",
    "                      options= {'disp': True, 'maxiter': 1000},\n",
    "                      constraints= activeMang_cons,\n",
    "                      bounds= [[0, 0.3]]* UniverseProperty['asset_count'],\n",
    "                      tol= 1e-12)\n",
    "    frontier_activeM[trackingError]= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(),\n",
    "                                               asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                                               weight= MV_opt_9.x, benchmark_portfolio= benchmark_portfolio)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAD8CAYAAABHN8LqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPMYYY3xlwWOMMcZXFjzGGGN89f8BttMZ35bveMAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc0f30b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frontier_activeM_pair= [[x.active_expectedReturn, \n",
    "                         x.tracking_error, \n",
    "                         x.active_expectedReturn/ x.tracking_error,\n",
    "                         x.SharpeRatio(risk_free= 0) ,\n",
    "                         x.weight] \n",
    "                        for x in frontier_activeM.values()]\n",
    "frontier_activeM_pair.sort(key= lambda x: x[2], reverse= True)\n",
    "max_IR= frontier_activeM_pair[0]\n",
    "frontier_activeM_pair.sort(key= lambda x:x[3], reverse= True)\n",
    "max_SR= frontier_activeM_pair[0]\n",
    "frontier_activeM_pair.sort( key= lambda x: x[0])\n",
    "fig, ax1= plt.subplots()\n",
    "ax2= ax1.twinx()\n",
    "ax1.scatter( x= [ x[1] for x in frontier_activeM_pair ], y= [ x[0] for x in frontier_activeM_pair], marker='^', c= 'm', label= 'Active Return') \n",
    "ax2.scatter(x= [ x[1] for x in frontier_activeM_pair], y= [x[2] for x in frontier_activeM_pair], marker= '*', c= 'y', label= 'IR')\n",
    "ax2.scatter( x= [x[1] for x in frontier_activeM_pair], y= [x[3] for x in frontier_activeM_pair], marker= 'o', c= 'b', label= 'SR')\n",
    "# plt.xlim(- 0.01, 0.035 )\n",
    "ax1.set_ylim(-1e-3, 0.02)\n",
    "#plt.ylim( -1e-3, 0.02)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12428132380236374"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064955163370140942"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.808978230811031e-12,\n",
       "  1.2378057675891136e-11,\n",
       "  0.30772018765349712,\n",
       "  0.52264621409734613,\n",
       "  array([ 0.13861386,  0.28712871,  0.04950495,  0.23762376,  0.02970297,\n",
       "          0.20792079,  0.04950495])],\n",
       " [7.6326770228898172e-05,\n",
       "  0.00025062656665699747,\n",
       "  0.30454381292050925,\n",
       "  0.52233345196404746,\n",
       "  array([ 0.13878096,  0.2875812 ,  0.0478196 ,  0.2379904 ,  0.02981087,\n",
       "          0.20831528,  0.04970169])],\n",
       " [0.00015265345785325072,\n",
       "  0.00050125313285396731,\n",
       "  0.30454364840393733,\n",
       "  0.52202131767984072,\n",
       "  array([ 0.13894803,  0.2880337 ,  0.04613426,  0.23835704,  0.02991877,\n",
       "          0.20870977,  0.04989844])],\n",
       " [0.00022898011004047263,\n",
       "  0.00075187970000616978,\n",
       "  0.30454354604678602,\n",
       "  0.5217098150163304,\n",
       "  array([ 0.13911513,  0.28848619,  0.04444891,  0.23872367,  0.03002666,\n",
       "          0.20910426,  0.05009519])],\n",
       " [0.00030530667047810157,\n",
       "  0.0010025062667248013,\n",
       "  0.30454340347970266,\n",
       "  0.5213989424224158,\n",
       "  array([ 0.13928222,  0.28893868,  0.04276356,  0.23909032,  0.03013452,\n",
       "          0.20949874,  0.05029195])],\n",
       " [0.00038163377675606988,\n",
       "  0.0012531328321508869,\n",
       "  0.3045437538341651,\n",
       "  0.52108870217105052,\n",
       "  array([ 0.13944929,  0.28939117,  0.04107821,  0.239457  ,  0.03024243,\n",
       "          0.20989322,  0.05048867])],\n",
       " [0.00045796024947611933,\n",
       "  0.0015037593986023195,\n",
       "  0.30454356588013609,\n",
       "  0.52077908849974386,\n",
       "  array([ 0.13961637,  0.28984366,  0.03939287,  0.2398236 ,  0.03035035,\n",
       "          0.21028773,  0.05068542])],\n",
       " [0.00053428686242558963,\n",
       "  0.001754385965067056,\n",
       "  0.30454351155571868,\n",
       "  0.52047010640531521,\n",
       "  array([ 0.13978347,  0.29029613,  0.03770752,  0.24019023,  0.03045824,\n",
       "          0.21068224,  0.05088217])],\n",
       " [0.00061061375592336479,\n",
       "  0.0020050125313974864,\n",
       "  0.30454361075627256,\n",
       "  0.52016175947982746,\n",
       "  array([ 0.13995059,  0.29074861,  0.03602216,  0.24055687,  0.03056616,\n",
       "          0.21107672,  0.0510789 ])],\n",
       " [0.00068694037219956872,\n",
       "  0.0022556390978364324,\n",
       "  0.30454356499604451,\n",
       "  0.51985403615357728,\n",
       "  array([ 0.14011764,  0.29120112,  0.03433683,  0.24092351,  0.03067404,\n",
       "          0.2114712 ,  0.05127565])],\n",
       " [0.00076326712080761032,\n",
       "  0.0025062656643470831,\n",
       "  0.30454358117955221,\n",
       "  0.51954694504470234,\n",
       "  array([ 0.14028473,  0.2916536 ,  0.03265148,  0.24129018,  0.0307819 ,\n",
       "          0.2118657 ,  0.05147241])],\n",
       " [0.00083959379273763511,\n",
       "  0.0027568922306597634,\n",
       "  0.30454356662926518,\n",
       "  0.51924048405015932,\n",
       "  array([ 0.14045181,  0.2921061 ,  0.03096613,  0.24165679,  0.03088982,\n",
       "          0.21226019,  0.05166915])],\n",
       " [0.00091592052350378153,\n",
       "  0.0030075187969971109,\n",
       "  0.30454357406453852,\n",
       "  0.51893465252857096,\n",
       "  array([ 0.1406189 ,  0.2925586 ,  0.02928079,  0.24202343,  0.03099772,\n",
       "          0.21265468,  0.05186589])],\n",
       " [0.00099224724210734473,\n",
       "  0.0032581453634085902,\n",
       "  0.30454357661601705,\n",
       "  0.51862945042201614,\n",
       "  array([ 0.14078598,  0.29301109,  0.02759544,  0.24239007,  0.03110562,\n",
       "          0.21304917,  0.05206263])],\n",
       " [0.0010685739940935893,\n",
       "  0.0035087719302258724,\n",
       "  0.30454358828184119,\n",
       "  0.51832487774793856,\n",
       "  array([ 0.14095307,  0.29346358,  0.02591009,  0.24275671,  0.03121352,\n",
       "          0.21344366,  0.05225937])],\n",
       " [0.0011449006759273002,\n",
       "  0.0037593984962883461,\n",
       "  0.30454357979279412,\n",
       "  0.51802093364599422,\n",
       "  array([ 0.14112016,  0.29391607,  0.02422475,  0.24312334,  0.03132141,\n",
       "          0.21383815,  0.05245612])],\n",
       " [0.0012212273792166859,\n",
       "  0.0040100250626664271,\n",
       "  0.30454357769141788,\n",
       "  0.51771761764297797,\n",
       "  array([ 0.14128724,  0.29436856,  0.0225394 ,  0.24348999,  0.0314293 ,\n",
       "          0.21423265,  0.05265286])],\n",
       " [0.0012975540883797504,\n",
       "  0.0042606516290840573,\n",
       "  0.30454357721302244,\n",
       "  0.51741493035653163,\n",
       "  array([ 0.14145432,  0.29482105,  0.02085406,  0.24385662,  0.03153721,\n",
       "          0.21462713,  0.05284961])],\n",
       " [0.0013738808134291969,\n",
       "  0.0045112781956258416,\n",
       "  0.30454358030088208,\n",
       "  0.51711287107130199,\n",
       "  array([ 0.1416214 ,  0.29527355,  0.01916871,  0.24422324,  0.03164511,\n",
       "          0.21502163,  0.05304635])],\n",
       " [0.0014502075469258328,\n",
       "  0.0047619047620755068,\n",
       "  0.30454358484350502,\n",
       "  0.51681143948883268,\n",
       "  array([ 0.14178849,  0.29572604,  0.01748337,  0.24458988,  0.03175301,\n",
       "          0.21541612,  0.05324309])],\n",
       " [0.0015265383569088521,\n",
       "  0.0050125313314328124,\n",
       "  0.30454440201424082,\n",
       "  0.51651064843005789,\n",
       "  array([ 0.14195541,  0.29617856,  0.01579797,  0.24495726,  0.03186043,\n",
       "          0.21581062,  0.05343974])],\n",
       " [0.0016028610505154301,\n",
       "  0.0052631578949259225,\n",
       "  0.3045435995869909,\n",
       "  0.51621045675268284,\n",
       "  array([ 0.14212265,  0.29663103,  0.01411267,  0.24532318,  0.03196875,\n",
       "          0.21620513,  0.05363659])],\n",
       " [0.0016791876424183589,\n",
       "  0.0055137844612301364,\n",
       "  0.30454357696160811,\n",
       "  0.51591090630071756,\n",
       "  array([ 0.14228976,  0.2970835 ,  0.01242732,  0.24568982,  0.03207668,\n",
       "          0.21659959,  0.05383333])],\n",
       " [0.0017555142826759232,\n",
       "  0.0057644110280513109,\n",
       "  0.30454356466481602,\n",
       "  0.51561198014174381,\n",
       "  array([ 0.14245685,  0.29753597,  0.01074197,  0.24605648,  0.03218455,\n",
       "          0.2169941 ,  0.05403009])],\n",
       " [0.0018318408708331709,\n",
       "  0.0060150375944029296,\n",
       "  0.30454354475485285,\n",
       "  0.51531368115866893,\n",
       "  array([ 0.14262396,  0.29798845,  0.00905661,  0.2464231 ,  0.03229243,\n",
       "          0.21738861,  0.05422684])],\n",
       " [0.0019081676834709206,\n",
       "  0.0062656641605474709,\n",
       "  0.30454356227483981,\n",
       "  0.51501600623859101,\n",
       "  array([ 0.14279103,  0.29844095,  0.00737128,  0.24678973,  0.03240035,\n",
       "          0.2177831 ,  0.05442357])],\n",
       " [0.0019844944459150617,\n",
       "  0.0065162907268670389,\n",
       "  0.30454357073616706,\n",
       "  0.51471895671178802,\n",
       "  array([ 0.1429581 ,  0.29889344,  0.00568594,  0.24715637,  0.03250827,\n",
       "          0.21817758,  0.05462031])],\n",
       " [0.002060821112828353,\n",
       "  0.0067669172942530489,\n",
       "  0.3045435644053977,\n",
       "  0.51442252579013192,\n",
       "  array([ 0.14312516,  0.29934592,  0.0040006 ,  0.247523  ,  0.03261608,\n",
       "          0.21857219,  0.05481705])],\n",
       " [0.0021371476058297091,\n",
       "  0.0070175438596879894,\n",
       "  0.30454353382904686,\n",
       "  0.51412672788897928,\n",
       "  array([ 0.14329227,  0.29979842,  0.00231525,  0.24788964,  0.03272406,\n",
       "          0.21896655,  0.05501381])],\n",
       " [0.0022124711817423982,\n",
       "  0.0072681704265382613,\n",
       "  0.30440551774405356,\n",
       "  0.51381978893966351,\n",
       "  array([ 0.14352379,  0.3       ,  0.00063435,  0.24834169,  0.03287616,\n",
       "          0.2193921 ,  0.0552319 ])],\n",
       " [0.0022786739824309913,\n",
       "  0.0075187969926422925,\n",
       "  0.30306363965682875,\n",
       "  0.51334950373072907,\n",
       "  array([  1.42404165e-01,   3.00000000e-01,   3.43171428e-18,\n",
       "           2.48526625e-01,   3.35276354e-02,   2.19888089e-01,\n",
       "           5.56534854e-02])],\n",
       " [0.0023380668064139597,\n",
       "  0.0077694235589037446,\n",
       "  0.30093182443819011,\n",
       "  0.51280173147345587,\n",
       "  array([  1.40487761e-01,   3.00000000e-01,   2.48830983e-18,\n",
       "           2.48507948e-01,   3.44339692e-02,   2.20397366e-01,\n",
       "           5.61729560e-02])],\n",
       " [0.00239561916629387,\n",
       "  0.0080200501253194119,\n",
       "  0.29870376479703864,\n",
       "  0.51227119645411923,\n",
       "  array([ 0.13863074,  0.3       ,  0.        ,  0.24848987,  0.03531221,\n",
       "          0.22089086,  0.05667632])],\n",
       " [0.0024516389644019757,\n",
       "  0.0082706766917381783,\n",
       "  0.29642543842283059,\n",
       "  0.51175504872975697,\n",
       "  array([  1.36823167e-01,   3.00000000e-01,   4.56114917e-18,\n",
       "           2.48472281e-01,   3.61670633e-02,   2.21371214e-01,\n",
       "           5.71662740e-02])],\n",
       " [0.0025063633116066226,\n",
       "  0.0085213032581696064,\n",
       "  0.29412910627299921,\n",
       "  0.51125109645005617,\n",
       "  array([ 0.1350574 ,  0.3       ,  0.        ,  0.2484551 ,  0.03700215,\n",
       "          0.22184046,  0.0576449 ])],\n",
       " [0.0025599787960388452,\n",
       "  0.0087719298246509321,\n",
       "  0.2918375827454498,\n",
       "  0.51075761583732282,\n",
       "  array([  1.33327404e-01,   3.00000000e-01,   1.51994967e-17,\n",
       "           2.48438264e-01,   3.78203203e-02,   2.22300186e-01,\n",
       "           5.81138257e-02])],\n",
       " [0.0026126350021177403,\n",
       "  0.0090225563913077737,\n",
       "  0.28956704605744804,\n",
       "  0.5102732260598396,\n",
       "  array([  1.31628364e-01,   3.00000000e-01,   2.92294791e-17,\n",
       "           2.48421745e-01,   3.86238540e-02,   2.22751678e-01,\n",
       "           5.85743593e-02])],\n",
       " [0.0026644537336202733,\n",
       "  0.009273182958399637,\n",
       "  0.28732892962138901,\n",
       "  0.50979680353731371,\n",
       "  array([ 0.12995635,  0.3       ,  0.        ,  0.24840551,  0.03941461,\n",
       "          0.22319597,  0.05902757])],\n",
       " [0.0027155349284155809,\n",
       "  0.0095238095238231908,\n",
       "  0.28513116748322681,\n",
       "  0.50932741699137685,\n",
       "  array([  1.28308129e-01,   3.00000000e-01,   2.56051608e-18,\n",
       "           2.48389401e-01,   4.01940763e-02,   2.23634046e-01,\n",
       "           5.94743472e-02])],\n",
       " [0.0027659633082624075,\n",
       "  0.0097744360902486758,\n",
       "  0.28297932307540796,\n",
       "  0.50886430002500049,\n",
       "  array([ 0.12668097,  0.3       ,  0.        ,  0.24837356,  0.04096361,\n",
       "          0.22406645,  0.0599154 ])],\n",
       " [0.0028158093412825797,\n",
       "  0.010025062656673167,\n",
       "  0.280876981792053,\n",
       "  0.50840679840364877,\n",
       "  array([  1.25072611e-01,   3.00000000e-01,   3.24430775e-17,\n",
       "           2.48357906e-01,   4.17242551e-02,   2.24493866e-01,\n",
       "           6.03513619e-02])],\n",
       " [0.0028651333074778689,\n",
       "  0.010275689223070499,\n",
       "  0.2788263877273755,\n",
       "  0.50795435793360166,\n",
       "  array([  1.23481091e-01,   3.00000000e-01,   1.24738133e-17,\n",
       "           2.48342415e-01,   4.24769290e-02,   2.24916809e-01,\n",
       "           6.07827558e-02])],\n",
       " [0.0029139868835676851,\n",
       "  0.01052631578981536,\n",
       "  0.27682875392994444,\n",
       "  0.50750650586253254,\n",
       "  array([ 0.12190476,  0.3       ,  0.        ,  0.24832705,  0.0432225 ,\n",
       "          0.22533567,  0.06121002])],\n",
       " [0.0029624148142550046,\n",
       "  0.01077694235599254,\n",
       "  0.27488453741313257,\n",
       "  0.50706282735439123,\n",
       "  array([ 0.12034215,  0.3       ,  0.        ,  0.24831182,  0.04396148,\n",
       "          0.22575097,  0.06163358])],\n",
       " [0.0030104561472488224,\n",
       "  0.011027568922470142,\n",
       "  0.27299363698508533,\n",
       "  0.50662297039435733,\n",
       "  array([  1.18792006e-01,   3.00000000e-01,   1.63047589e-17,\n",
       "           2.48296816e-01,   4.46945257e-02,   2.26162893e-01,\n",
       "           6.20537590e-02])],\n",
       " [0.0030581446935808274,\n",
       "  0.011278195489435821,\n",
       "  0.27115549614699996,\n",
       "  0.50618662306052331,\n",
       "  array([ 0.11725325,  0.3       ,  0.        ,  0.24828192,  0.04542221,\n",
       "          0.22657177,  0.06247086])],\n",
       " [0.0031055102139481978,\n",
       "  0.011528822056096845,\n",
       "  0.26936925549179547,\n",
       "  0.5057535107446689,\n",
       "  array([ 0.11572492,  0.3       ,  0.        ,  0.24826708,  0.04614497,\n",
       "          0.2269779 ,  0.06288513])],\n",
       " [0.00315257929694321,\n",
       "  0.011779448622287143,\n",
       "  0.26763385944724238,\n",
       "  0.50532339246568247,\n",
       "  array([  1.14206156e-01,   3.00000000e-01,   4.29945073e-17,\n",
       "           2.48252281e-01,   4.68632428e-02,   2.27381507e-01,\n",
       "           6.32968132e-02])],\n",
       " [0.0031993755474554178,\n",
       "  0.012030075188363357,\n",
       "  0.26594809237353401,\n",
       "  0.50489605464576537,\n",
       "  array([ 0.1126962 ,  0.3       ,  0.        ,  0.24823755,  0.04757736,\n",
       "          0.22778279,  0.0637061 ])],\n",
       " [0.0032459199931661057,\n",
       "  0.012280701754624123,\n",
       "  0.26431062800982857,\n",
       "  0.50447130707067678,\n",
       "  array([ 0.11119437,  0.3       ,  0.        ,  0.24822291,  0.04828763,\n",
       "          0.2281819 ,  0.06411318])],\n",
       " [0.0032922313865228715,\n",
       "  0.012531328321768074,\n",
       "  0.26272006462427144,\n",
       "  0.50404898069056536,\n",
       "  array([ 0.10970005,  0.3       ,  0.        ,  0.24820849,  0.04899431,\n",
       "          0.22857889,  0.06451827])],\n",
       " [0.0033383187623088079,\n",
       "  0.012781954892335634,\n",
       "  0.26117435012312112,\n",
       "  0.50362892806619708,\n",
       "  array([ 0.1082132 ,  0.3       ,  0.        ,  0.24819291,  0.04969908,\n",
       "          0.22897311,  0.0649217 ])],\n",
       " [0.0033842191103407191,\n",
       "  0.013032581454880499,\n",
       "  0.25967373555707812,\n",
       "  0.50321098861920621,\n",
       "  array([  1.06731979e-01,   3.00000000e-01,   2.24331382e-21,\n",
       "           2.48179157e-01,   5.03983813e-02,   2.29367652e-01,\n",
       "           6.53228308e-02])],\n",
       " [0.0034299276617968154,\n",
       "  0.013283208020356018,\n",
       "  0.2582153088727196,\n",
       "  0.50279506288043052,\n",
       "  array([  1.05257078e-01,   3.00000000e-01,   4.91372680e-17,\n",
       "           2.48164969e-01,   5.10956348e-02,   2.29759793e-01,\n",
       "           6.57225252e-02])],\n",
       " [0.0034754601142071816,\n",
       "  0.013533834586705134,\n",
       "  0.25679788621188521,\n",
       "  0.5023810330353945,\n",
       "  array([  1.03787899e-01,   3.00000000e-01,   2.63748763e-17,\n",
       "           2.48150671e-01,   5.17904642e-02,   2.30150218e-01,\n",
       "           6.61207477e-02])],\n",
       " [0.0035208290891826817,\n",
       "  0.013784461152989081,\n",
       "  0.25542014664963603,\n",
       "  0.50196879462259991,\n",
       "  array([ 0.10232399,  0.3       ,  0.        ,  0.24813646,  0.05248275,\n",
       "          0.23053923,  0.06651757])],\n",
       " [0.003566044985179268,\n",
       "  0.014035087719587003,\n",
       "  0.25408070518879539,\n",
       "  0.50155825639191565,\n",
       "  array([  1.00865027e-01,   3.00000000e-01,   2.55089994e-17,\n",
       "           2.48122234e-01,   5.31727612e-02,   2.30926943e-01,\n",
       "           6.69130343e-02])],\n",
       " [0.003611117377953223,\n",
       "  0.014285714286214786,\n",
       "  0.25277821644786952,\n",
       "  0.50114933395017958,\n",
       "  array([  9.94106952e-02,   3.00000000e-01,   3.93122086e-17,\n",
       "           2.48108056e-01,   5.38605765e-02,   2.31313428e-01,\n",
       "           6.73072447e-02])],\n",
       " [0.0036560551600234494,\n",
       "  0.014536340852321573,\n",
       "  0.2515113808327869,\n",
       "  0.50074195058490878,\n",
       "  array([ 0.0979607 ,  0.3       ,  0.        ,  0.24809399,  0.05454629,\n",
       "          0.23169875,  0.06770028])],\n",
       " [0.0037008661389651316,\n",
       "  0.014786967418575539,\n",
       "  0.25027891346511427,\n",
       "  0.50033603597691634,\n",
       "  array([ 0.09651479,  0.3       ,  0.        ,  0.24807995,  0.05523008,\n",
       "          0.23208299,  0.06809219])],\n",
       " [0.0037455573736520009,\n",
       "  0.015037593984983945,\n",
       "  0.24907956534750128,\n",
       "  0.49993152467763813,\n",
       "  array([  9.50727557e-02,   3.00000000e-01,   9.85838817e-18,\n",
       "           2.48065915e-01,   5.59120583e-02,   2.32466205e-01,\n",
       "           6.84830657e-02])],\n",
       " [0.0037901358139502562,\n",
       "  0.015288220551390407,\n",
       "  0.2479121622565523,\n",
       "  0.49952835790232847,\n",
       "  array([ 0.09363436,  0.3       ,  0.        ,  0.24805192,  0.05659232,\n",
       "          0.23284845,  0.06887296])],\n",
       " [0.0038346077498595948,\n",
       "  0.015538847117860114,\n",
       "  0.24677556325605104,\n",
       "  0.49912648135705545,\n",
       "  array([  9.21993995e-02,   3.00000000e-01,   5.31438397e-18,\n",
       "           2.48037942e-01,   5.72709619e-02,   2.33229788e-01,\n",
       "           6.92619085e-02])],\n",
       " [0.0038789789215330208,\n",
       "  0.015789473684616456,\n",
       "  0.24566866502410881,\n",
       "  0.49872584486788463,\n",
       "  array([  9.07676964e-02,   3.00000000e-01,   5.48580888e-18,\n",
       "           2.48023972e-01,   5.79480983e-02,   2.33610263e-01,\n",
       "           6.96499700e-02])],\n",
       " [0.0039232546342516479,\n",
       "  0.016040100251837164,\n",
       "  0.24459040608566615,\n",
       "  0.49832640183010285,\n",
       "  array([ 0.08933908,  0.3       ,  0.        ,  0.24801001,  0.0586238 ,\n",
       "          0.23398991,  0.0700372 ])],\n",
       " [0.0039674400104503481,\n",
       "  0.016290726817052341,\n",
       "  0.24353977910288355,\n",
       "  0.49792810707849777,\n",
       "  array([ 0.08791335,  0.3       ,  0.        ,  0.24799624,  0.05929795,\n",
       "          0.23436878,  0.07042368])],\n",
       " [0.004011539562839366,\n",
       "  0.016541353383468561,\n",
       "  0.24251580084423449,\n",
       "  0.49753092447214492,\n",
       "  array([  8.64904007e-02,   3.00000000e-01,   3.02661697e-17,\n",
       "           2.47982390e-01,   5.99709017e-02,   2.34746922e-01,\n",
       "           7.08093858e-02])],\n",
       " [0.0040555576123172486,\n",
       "  0.016791979951384036,\n",
       "  0.24151753539837806,\n",
       "  0.49713481753731564,\n",
       "  array([  8.50701032e-02,   3.00000000e-01,   1.19213535e-17,\n",
       "           2.47968469e-01,   6.06427301e-02,   2.35124361e-01,\n",
       "           7.11943359e-02])],\n",
       " [0.0040994982519454827,\n",
       "  0.017042606517014305,\n",
       "  0.24054408859658835,\n",
       "  0.49673974799120085,\n",
       "  array([  8.36522781e-02,   3.00000000e-01,   5.31105540e-18,\n",
       "           2.47954714e-01,   6.13132054e-02,   2.35501143e-01,\n",
       "           7.15786597e-02])],\n",
       " [0.0041433651249840279,\n",
       "  0.017293233082988368,\n",
       "  0.23959459200604444,\n",
       "  0.49634568659180756,\n",
       "  array([ 0.08223684,  0.3       ,  0.        ,  0.24794097,  0.06198257,\n",
       "          0.23587729,  0.07196234])],\n",
       " [0.0041871617573743004,\n",
       "  0.017543859649212578,\n",
       "  0.23866822016911388,\n",
       "  0.49595260393252222,\n",
       "  array([ 0.08082366,  0.3       ,  0.        ,  0.24792723,  0.06265088,\n",
       "          0.23625283,  0.0723454 ])],\n",
       " [0.0042308914453216004,\n",
       "  0.01779448621555909,\n",
       "  0.23776418122273213,\n",
       "  0.49556047250828567,\n",
       "  array([  7.94126505e-02,   3.00000000e-01,   1.18186573e-17,\n",
       "           2.47913499e-01,   6.33181780e-02,   2.36627804e-01,\n",
       "           7.27278683e-02])],\n",
       " [0.0042745572512750589,\n",
       "  0.018045112782948392,\n",
       "  0.23688171432845093,\n",
       "  0.49516926801294714,\n",
       "  array([  7.80037171e-02,   3.00000000e-01,   9.59786267e-18,\n",
       "           2.47899691e-01,   6.39846132e-02,   2.37002235e-01,\n",
       "           7.31097438e-02])],\n",
       " [0.0043181621886019955,\n",
       "  0.01829573934889768,\n",
       "  0.23602009769898505,\n",
       "  0.49477896373581542,\n",
       "  array([ 0.07659673,  0.3       ,  0.        ,  0.24788603,  0.06464998,\n",
       "          0.23737613,  0.07349113])],\n",
       " [0.0043617087764647802,\n",
       "  0.018546365915770621,\n",
       "  0.23517862185366822,\n",
       "  0.49438953943780661,\n",
       "  array([ 0.07519163,  0.3       ,  0.        ,  0.24787232,  0.06531453,\n",
       "          0.23774953,  0.07387198])],\n",
       " [0.0044051997272809545,\n",
       "  0.018796992481227032,\n",
       "  0.23435662549104724,\n",
       "  0.49400097217159655,\n",
       "  array([ 0.07378831,  0.3       ,  0.        ,  0.24785876,  0.0659781 ,\n",
       "          0.23812245,  0.07425239])],\n",
       " [0.0044486373721151686,\n",
       "  0.019047619047769398,\n",
       "  0.23355346203420282,\n",
       "  0.49361324554044084,\n",
       "  array([  7.23867208e-02,   3.00000000e-01,   1.13115625e-17,\n",
       "           2.47845107e-01,   6.66409622e-02,   2.38494914e-01,\n",
       "           7.46322965e-02])],\n",
       " [0.0044920239507439058,\n",
       "  0.019298245614650145,\n",
       "  0.23276851380385652,\n",
       "  0.49322634000059873,\n",
       "  array([  7.09867862e-02,   3.00000000e-01,   8.02934294e-18,\n",
       "           2.47831455e-01,   6.73030706e-02,   2.38866941e-01,\n",
       "           7.50117478e-02])],\n",
       " [0.0045353615023352159,\n",
       "  0.019548872180456599,\n",
       "  0.23200118454246726,\n",
       "  0.49284023653159076,\n",
       "  array([ 0.06958842,  0.3       ,  0.        ,  0.24781788,  0.06796434,\n",
       "          0.23923855,  0.07539081])],\n",
       " [0.0045786522633782557,\n",
       "  0.019799498746893504,\n",
       "  0.23125091811208784,\n",
       "  0.49245492209872543,\n",
       "  array([  6.81915741e-02,   3.00000000e-01,   9.31752289e-18,\n",
       "           2.47804285e-01,   6.86249563e-02,   2.39609752e-01,\n",
       "           7.57694322e-02])],\n",
       " [0.0046218980393387399,\n",
       "  0.020050125313385913,\n",
       "  0.23051716471083886,\n",
       "  0.4920703805652889,\n",
       "  array([ 0.06679618,  0.3       ,  0.        ,  0.2477907 ,  0.06928489,\n",
       "          0.23998057,  0.07614766])],\n",
       " [0.004665100604319506,\n",
       "  0.020300751879928702,\n",
       "  0.22979940013610423,\n",
       "  0.49168659768663664,\n",
       "  array([  6.54021788e-02,   3.00000000e-01,   5.92169998e-18,\n",
       "           2.47777121e-01,   6.99441706e-02,   2.40351023e-01,\n",
       "           7.65255065e-02])],\n",
       " [0.0047082616342006365,\n",
       "  0.020551378446342531,\n",
       "  0.22909712097869289,\n",
       "  0.49130355990024044,\n",
       "  array([  6.40095169e-02,   3.00000000e-01,   7.33547407e-17,\n",
       "           2.47763567e-01,   7.06028008e-02,   2.40721116e-01,\n",
       "           7.69029991e-02])],\n",
       " [0.0047513827213145482,\n",
       "  0.020802005012593619,\n",
       "  0.22840984407214793,\n",
       "  0.49092125462696268,\n",
       "  array([ 0.06261814,  0.3       ,  0.        ,  0.24775004,  0.0712608 ,\n",
       "          0.24109087,  0.07728015])],\n",
       " [0.0047944656069366046,\n",
       "  0.021052631579459288,\n",
       "  0.22773711632395102,\n",
       "  0.49053967211063965,\n",
       "  array([  6.12280068e-02,   3.00000000e-01,   2.27522314e-18,\n",
       "           2.47736477e-01,   7.19182846e-02,   2.41460292e-01,\n",
       "           7.76569394e-02])],\n",
       " [0.0048375114700524892,\n",
       "  0.021303258145625965,\n",
       "  0.22707847959142993,\n",
       "  0.49015879846996202,\n",
       "  array([  5.98390576e-02,   3.00000000e-01,   5.89423758e-18,\n",
       "           2.47722975e-01,   7.25751327e-02,   2.41829401e-01,\n",
       "           7.80334337e-02])],\n",
       " [0.0048805219069809188,\n",
       "  0.021553884712877263,\n",
       "  0.22643351637048864,\n",
       "  0.48977862639905512,\n",
       "  array([  5.84512631e-02,   3.00000000e-01,   3.92009760e-17,\n",
       "           2.47709425e-01,   7.32315266e-02,   2.42198203e-01,\n",
       "           7.84095821e-02])],\n",
       " [0.0049234978186124901,\n",
       "  0.021804511278202088,\n",
       "  0.22580179650871138,\n",
       "  0.4893991412477568,\n",
       "  array([ 0.05706456,  0.3       ,  0.        ,  0.24769599,  0.07388724,\n",
       "          0.24256671,  0.0787855 ])],\n",
       " [0.0049664409732702438,\n",
       "  0.022055137844619307,\n",
       "  0.22518294867433278,\n",
       "  0.48902033917766558,\n",
       "  array([  5.56789310e-02,   3.00000000e-01,   1.24699425e-17,\n",
       "           2.47682500e-01,   7.45425460e-02,   2.42934932e-01,\n",
       "           7.91610906e-02])],\n",
       " [0.005009352330721549,\n",
       "  0.022305764411034736,\n",
       "  0.2245765820176692,\n",
       "  0.48864220941629377,\n",
       "  array([ 0.05429433,  0.3       ,  0.        ,  0.24766902,  0.07519737,\n",
       "          0.24330288,  0.0795364 ])],\n",
       " [0.0050522330233811006,\n",
       "  0.022556390977450623,\n",
       "  0.22398233070315915,\n",
       "  0.48826474382035695,\n",
       "  array([ 0.05291071,  0.3       ,  0.        ,  0.24765556,  0.07585172,\n",
       "          0.24367057,  0.07991144])],\n",
       " [0.0050950841358866203,\n",
       "  0.022807017543872213,\n",
       "  0.22339984288105952,\n",
       "  0.48788793473736941,\n",
       "  array([ 0.05152805,  0.3       ,  0.        ,  0.2476421 ,  0.07650562,\n",
       "          0.24403801,  0.08028622])],\n",
       " [0.005137906683110983,\n",
       "  0.023057644110297915,\n",
       "  0.22282877897383763,\n",
       "  0.48751177485036623,\n",
       "  array([  5.01463071e-02,   3.00000000e-01,   1.97867244e-17,\n",
       "           2.47628651e-01,   7.71590886e-02,   2.44405202e-01,\n",
       "           8.06607512e-02])],\n",
       " [0.005180701624190401,\n",
       "  0.023308270676715672,\n",
       "  0.22226881161826309,\n",
       "  0.48713625719772302,\n",
       "  array([  4.87654577e-02,   3.00000000e-01,   8.13747861e-18,\n",
       "           2.47615212e-01,   7.78121329e-02,   2.44772156e-01,\n",
       "           8.10350416e-02])],\n",
       " [0.005223470108000376,\n",
       "  0.023558897243963716,\n",
       "  0.22171963542727954,\n",
       "  0.48676137704532035,\n",
       "  array([ 0.04738547,  0.3       ,  0.        ,  0.24760174,  0.07846484,\n",
       "          0.24513889,  0.08140906])],\n",
       " [0.0052662124450000023,\n",
       "  0.023809523809535542,\n",
       "  0.22118092268989112,\n",
       "  0.48638712337103546,\n",
       "  array([  4.60063071e-02,   3.00000000e-01,   4.60794286e-17,\n",
       "           2.47588383e-01,   7.91170038e-02,   2.45505371e-01,\n",
       "           8.17829353e-02])],\n",
       " [0.0053089297246275112,\n",
       "  0.024060150376520022,\n",
       "  0.22065239167451026,\n",
       "  0.48601349518023323,\n",
       "  array([  4.46279641e-02,   3.00000000e-01,   3.85563310e-17,\n",
       "           2.47575001e-01,   7.97688781e-02,   2.45871572e-01,\n",
       "           8.21565849e-02])],\n",
       " [0.005351623233383662,\n",
       "  0.024310776942433797,\n",
       "  0.22013378042404519,\n",
       "  0.48564048417417016,\n",
       "  array([  4.32503913e-02,   3.00000000e-01,   8.48054019e-18,\n",
       "           2.47561522e-01,   8.04203693e-02,   2.46237752e-01,\n",
       "           8.25299653e-02])],\n",
       " [0.0053942930095889447,\n",
       "  0.024561403509355748,\n",
       "  0.21962478681375805,\n",
       "  0.48526808669706789,\n",
       "  array([ 0.04187359,  0.3       ,  0.        ,  0.24754808,  0.08107153,\n",
       "          0.24660361,  0.08290318])],\n",
       " [0.0054369408211477465,\n",
       "  0.024812030075355009,\n",
       "  0.21912519066902489,\n",
       "  0.48489629883788321,\n",
       "  array([  4.04974800e-02,   3.00000000e-01,   8.64020722e-17,\n",
       "           2.47534719e-01,   8.17223079e-02,   2.46969321e-01,\n",
       "           8.32761716e-02])],\n",
       " [0.0054795626232602831,\n",
       "  0.025062656641816613,\n",
       "  0.21863454866623064,\n",
       "  0.48452510144326211,\n",
       "  array([ 0.03912222,  0.3       ,  0.        ,  0.24752136,  0.08237259,\n",
       "          0.24733447,  0.08364937])],\n",
       " [0.0055221715407111341,\n",
       "  0.02531328320930536,\n",
       "  0.21815311332988763,\n",
       "  0.48415453207033077,\n",
       "  array([  3.77473789e-02,   3.00000000e-01,   2.26434936e-17,\n",
       "           2.47507926e-01,   8.30230099e-02,   2.47700152e-01,\n",
       "           8.40215340e-02])],\n",
       " [0.0055647551113312535,\n",
       "  0.025563909774440383,\n",
       "  0.21768012641380366,\n",
       "  0.48378453883683226,\n",
       "  array([ 0.03637334,  0.3       ,  0.        ,  0.24749459,  0.08367273,\n",
       "          0.24806531,  0.08439403])],\n",
       " [0.0056073191763864622,\n",
       "  0.025814536340861189,\n",
       "  0.21721556809489451,\n",
       "  0.48341513977854333,\n",
       "  array([ 0.03499994,  0.3       ,  0.        ,  0.24748123,  0.08432225,\n",
       "          0.24843028,  0.0847663 ])],\n",
       " [0.0056498641475789353,\n",
       "  0.026065162907611877,\n",
       "  0.21675921104367971,\n",
       "  0.48304632917349,\n",
       "  array([ 0.03362715,  0.3       ,  0.        ,  0.24746795,  0.08497145,\n",
       "          0.24879505,  0.0851384 ])],\n",
       " [0.0056923897469439363,\n",
       "  0.026315789473693594,\n",
       "  0.21631081038379246,\n",
       "  0.48267809966436659,\n",
       "  array([ 0.032255  ,  0.3       ,  0.        ,  0.24745451,  0.08562041,\n",
       "          0.24915973,  0.08551035])],\n",
       " [0.0057348966256794785,\n",
       "  0.026566416041750567,\n",
       "  0.2158701654249025,\n",
       "  0.48231045037346604,\n",
       "  array([  3.08834583e-02,   3.00000000e-01,   8.73261852e-18,\n",
       "           2.47441063e-01,   8.62691341e-02,   2.49524167e-01,\n",
       "           8.58821779e-02])],\n",
       " [0.0057773873302159034,\n",
       "  0.026817042607235553,\n",
       "  0.21543715370974936,\n",
       "  0.48194338201682041,\n",
       "  array([  2.95124118e-02,   3.00000000e-01,   2.72551380e-18,\n",
       "           2.47427827e-01,   8.69174822e-02,   2.49888496e-01,\n",
       "           8.62537834e-02])],\n",
       " [0.0058198610641949731,\n",
       "  0.027067669174336572,\n",
       "  0.21501153374938195,\n",
       "  0.4815768894007959,\n",
       "  array([  2.81419352e-02,   3.00000000e-01,   1.61419069e-17,\n",
       "           2.47414434e-01,   8.75657061e-02,   2.50252760e-01,\n",
       "           8.66251642e-02])],\n",
       " [0.0058623173257938456,\n",
       "  0.027318295739996612,\n",
       "  0.21459308375561836,\n",
       "  0.48121096423430881,\n",
       "  array([ 0.02677201,  0.3       ,  0.        ,  0.24740113,  0.08821354,\n",
       "          0.25061681,  0.08699651])],\n",
       " [0.0059047574782510647,\n",
       "  0.027568922306413349,\n",
       "  0.21418165761515615,\n",
       "  0.48084560862742315,\n",
       "  array([ 0.02540261,  0.3       ,  0.        ,  0.2473878 ,  0.08886117,\n",
       "          0.25098072,  0.0873677 ])],\n",
       " [0.0059471818739536813,\n",
       "  0.027819548872635092,\n",
       "  0.21377707816835489,\n",
       "  0.48048081880843213,\n",
       "  array([ 0.02403371,  0.3       ,  0.        ,  0.24737448,  0.08950855,\n",
       "          0.2513445 ,  0.08773876])],\n",
       " [0.0059895910661091935,\n",
       "  0.028070175439221537,\n",
       "  0.21337918172538864,\n",
       "  0.48011659339391399,\n",
       "  array([  2.26653112e-02,   3.00000000e-01,   1.80663657e-17,\n",
       "           2.47361158e-01,   9.01557178e-02,   2.51708144e-01,\n",
       "           8.81096686e-02])],\n",
       " [0.006031985471441661,\n",
       "  0.028320802006544136,\n",
       "  0.2129878055730145,\n",
       "  0.47975293030239796,\n",
       "  array([ 0.02129739,  0.3       ,  0.        ,  0.24734782,  0.09080271,\n",
       "          0.25207165,  0.08848043])],\n",
       " [0.006074364960584739,\n",
       "  0.028571428571446247,\n",
       "  0.21260277362033433,\n",
       "  0.47938982201456259,\n",
       "  array([ 0.01992994,  0.3       ,  0.        ,  0.24733455,  0.09144929,\n",
       "          0.25243507,  0.08885115])],\n",
       " [0.0061167307887022519,\n",
       "  0.028822055137904638,\n",
       "  0.21222396388583614,\n",
       "  0.47902727416911056,\n",
       "  array([  1.85629327e-02,   3.00000000e-01,   7.17151198e-18,\n",
       "           2.47321248e-01,   9.20957967e-02,   2.52798342e-01,\n",
       "           8.92216810e-02])],\n",
       " [0.0061590829423440767,\n",
       "  0.02907268170441453,\n",
       "  0.21185121499847237,\n",
       "  0.47866528152260807,\n",
       "  array([  1.71963717e-02,   3.00000000e-01,   4.96794684e-17,\n",
       "           2.47307943e-01,   9.27420957e-02,   2.53161499e-01,\n",
       "           8.95920900e-02])],\n",
       " [0.0062014217763986176,\n",
       "  0.029323308270994126,\n",
       "  0.21148438365438141,\n",
       "  0.47830384214986149,\n",
       "  array([  1.58302411e-02,   3.00000000e-01,   1.12163044e-17,\n",
       "           2.47294640e-01,   9.33881963e-02,   2.53524542e-01,\n",
       "           8.99623810e-02])],\n",
       " [0.0062437476357020691,\n",
       "  0.029573934837655684,\n",
       "  0.211123331067602,\n",
       "  0.477942954222494,\n",
       "  array([ 0.01446453,  0.3       ,  0.        ,  0.24728134,  0.0940341 ,\n",
       "          0.25388747,  0.09033256])],\n",
       " [0.0062860608550741621,\n",
       "  0.029824561404403236,\n",
       "  0.21076792278145962,\n",
       "  0.47758261600452334,\n",
       "  array([ 0.01309923,  0.3       ,  0.        ,  0.24726804,  0.09467982,\n",
       "          0.25425029,  0.09070262])],\n",
       " [0.0063283617593675517,\n",
       "  0.030075187971232147,\n",
       "  0.21041802848982447,\n",
       "  0.47722282584754111,\n",
       "  array([  1.17343217e-02,   3.00000000e-01,   6.02500888e-17,\n",
       "           2.47254739e-01,   9.53253531e-02,   2.54613006e-01,\n",
       "           9.10725807e-02])],\n",
       " [0.0063706506636480942,\n",
       "  0.030325814538133228,\n",
       "  0.21007352187151684,\n",
       "  0.47686358218893987,\n",
       "  array([  1.03698039e-02,   3.00000000e-01,   7.19699543e-17,\n",
       "           2.47241443e-01,   9.59707038e-02,   2.54975616e-01,\n",
       "           9.14424340e-02])],\n",
       " [0.0064129274174998261,\n",
       "  0.030576441102764342,\n",
       "  0.2097342655394924,\n",
       "  0.47650487947690101,\n",
       "  array([  9.00565917e-03,   3.00000000e-01,   1.94745874e-17,\n",
       "           2.47228227e-01,   9.66157024e-02,   2.55338144e-01,\n",
       "           9.18122677e-02])],\n",
       " [0.0064551932064930775,\n",
       "  0.030827067669182921,\n",
       "  0.20940016986909785,\n",
       "  0.47614672393453222,\n",
       "  array([ 0.00764188,  0.3       ,  0.        ,  0.24721495,  0.09726067,\n",
       "          0.25570056,  0.09218193])],\n",
       " [0.0064974478878955418,\n",
       "  0.031077694235602072,\n",
       "  0.20907110542493779,\n",
       "  0.47578911068867658,\n",
       "  array([ 0.00627847,  0.3       ,  0.        ,  0.24720168,  0.09790547,\n",
       "          0.25606288,  0.09255149])],\n",
       " [0.0065396917371033109,\n",
       "  0.03132832080202206,\n",
       "  0.20874696024822409,\n",
       "  0.47543203847038684,\n",
       "  array([ 0.0049154 ,  0.3       ,  0.        ,  0.24718842,  0.09855011,\n",
       "          0.25642511,  0.09292096])],\n",
       " [0.0065819250204946882,\n",
       "  0.031578947368443328,\n",
       "  0.20842762564885145,\n",
       "  0.47507550607143728,\n",
       "  array([  3.55267294e-03,   3.00000000e-01,   2.60216959e-17,\n",
       "           2.47175151e-01,   9.91945825e-02,   2.56787252e-01,\n",
       "           9.32903415e-02])],\n",
       " [0.0066241479957173787,\n",
       "  0.031829573934866476,\n",
       "  0.20811299608573183,\n",
       "  0.47471951234071197,\n",
       "  array([  2.19027910e-03,   3.00000000e-01,   3.19326640e-17,\n",
       "           2.47161891e-01,   9.98388999e-02,   2.57149302e-01,\n",
       "           9.36596284e-02])],\n",
       " [0.0066663608721098007,\n",
       "  0.03208020050126726,\n",
       "  0.20780296781020619,\n",
       "  0.47436405603281551,\n",
       "  array([  8.28211068e-04,   3.00000000e-01,   3.50525709e-17,\n",
       "           2.47148633e-01,   1.00483061e-01,   2.57511263e-01,\n",
       "           9.40288312e-02])],\n",
       " [0.0066984046823031947,\n",
       "  0.032330827068148549,\n",
       "  0.20718321458909664,\n",
       "  0.47397873074779401,\n",
       "  array([  2.37171509e-17,   3.00000000e-01,   0.00000000e+00,\n",
       "           2.45572474e-01,   1.01741532e-01,   2.57851176e-01,\n",
       "           9.48348174e-02])],\n",
       " [0.0067144573279217246,\n",
       "  0.032581453634163975,\n",
       "  0.20608219029494551,\n",
       "  0.4735501654701389,\n",
       "  array([  0.00000000e+00,   3.00000000e-01,   4.57635727e-18,\n",
       "           2.41624557e-01,   1.03923883e-01,   2.58153131e-01,\n",
       "           9.62984290e-02])],\n",
       " [0.0067302107533155336,\n",
       "  0.032832080200526574,\n",
       "  0.20498886187563564,\n",
       "  0.47312667205659997,\n",
       "  array([  0.00000000e+00,   3.00000000e-01,   6.68318578e-17,\n",
       "           2.37750287e-01,   1.06065492e-01,   2.58449160e-01,\n",
       "           9.77350605e-02])],\n",
       " [0.0067456886978489649,\n",
       "  0.033082706766930307,\n",
       "  0.20390377200308168,\n",
       "  0.47270784318381825,\n",
       "  array([  4.95585662e-18,   3.00000000e-01,   0.00000000e+00,\n",
       "           2.33943723e-01,   1.08169661e-01,   2.58740166e-01,\n",
       "           9.91464501e-02])],\n",
       " [0.006760910544223897,\n",
       "  0.033333333333336886,\n",
       "  0.20282731632669529,\n",
       "  0.47229331444067718,\n",
       "  array([ 0.        ,  0.3       ,  0.        ,  0.23020016,  0.11023903,\n",
       "          0.25902634,  0.10053448])],\n",
       " [0.0067758942214936266,\n",
       "  0.033583959901571196,\n",
       "  0.201759835390246,\n",
       "  0.47188276149830971,\n",
       "  array([  1.91505547e-17,   3.00000000e-01,   0.00000000e+00,\n",
       "           2.26515147e-01,   1.12276030e-01,   2.59308111e-01,\n",
       "           1.01900712e-01])],\n",
       " [0.0067906546295261987,\n",
       "  0.033834586466189927,\n",
       "  0.20070157016140669,\n",
       "  0.47147589076350577,\n",
       "  array([  1.83587377e-17,   3.00000000e-01,   1.62999912e-17,\n",
       "           2.22885076e-01,   1.14282643e-01,   2.59585527e-01,\n",
       "           1.03246754e-01])],\n",
       " [0.0068052069394817453,\n",
       "  0.034085213032874255,\n",
       "  0.1996527624139626,\n",
       "  0.47107244331477199,\n",
       "  array([  2.59608269e-17,   3.00000000e-01,   4.86447968e-18,\n",
       "           2.19306160e-01,   1.16260980e-01,   2.59859133e-01,\n",
       "           1.04573727e-01])],\n",
       " [0.0068195633834758386,\n",
       "  0.034335839599913834,\n",
       "  0.19861356130906879,\n",
       "  0.47067218100005898,\n",
       "  array([  0.00000000e+00,   3.00000000e-01,   9.08336123e-18,\n",
       "           2.15775415e-01,   1.18212661e-01,   2.60128995e-01,\n",
       "           1.05882929e-01])],\n",
       " [0.0068337364965670513,\n",
       "  0.034586466165571282,\n",
       "  0.19758412044332008,\n",
       "  0.4702748936087941,\n",
       "  array([  1.44514570e-17,   3.00000000e-01,   0.00000000e+00,\n",
       "           2.12289758e-01,   1.20139469e-01,   2.60395504e-01,\n",
       "           1.07175268e-01])],\n",
       " [0.0068477361319060044,\n",
       "  0.0348370927318691,\n",
       "  0.19656451198758243,\n",
       "  0.46988038366903312,\n",
       "  array([  0.00000000e+00,   3.00000000e-01,   1.08856519e-17,\n",
       "           2.08846778e-01,   1.22042676e-01,   2.60658683e-01,\n",
       "           1.08451863e-01])],\n",
       " [0.0068633812589089949,\n",
       "  0.035087719298351631,\n",
       "  0.19560636587831534,\n",
       "  0.46946550543673216,\n",
       "  array([  7.98123863e-18,   2.98799125e-01,   3.86877713e-17,\n",
       "           2.06839865e-01,   1.23740047e-01,   2.61083746e-01,\n",
       "           1.09537217e-01])],\n",
       " [0.0068793295326891922,\n",
       "  0.035338345864770644,\n",
       "  0.1946703889031576,\n",
       "  0.46904737359330073,\n",
       "  array([ 0.        ,  0.29732684,  0.        ,  0.20517906,  0.12538417,\n",
       "          0.26153493,  0.110575  ])],\n",
       " [0.0068951747460060612,\n",
       "  0.035588972431159965,\n",
       "  0.19374469884859566,\n",
       "  0.46863102857093653,\n",
       "  array([ 0.        ,  0.29586263,  0.        ,  0.20352908,  0.12701596,\n",
       "          0.26198752,  0.11160481])],\n",
       " [0.0069109168649746505,\n",
       "  0.035839598997604478,\n",
       "  0.19282907895918636,\n",
       "  0.46821647511330927,\n",
       "  array([  0.00000000e+00,   2.94407966e-01,   5.16825922e-17,\n",
       "           2.01889824e-01,   1.28637152e-01,   2.62437123e-01,\n",
       "           1.12627936e-01])],\n",
       " [0.0069265600397469323,\n",
       "  0.036090225564902371,\n",
       "  0.19192343442937607,\n",
       "  0.46780364026638133,\n",
       "  array([  1.58359786e-17,   2.92962506e-01,   2.02163000e-18,\n",
       "           2.00260858e-01,   1.30248232e-01,   2.62883768e-01,\n",
       "           1.13644636e-01])],\n",
       " [0.0069421080924164102,\n",
       "  0.036340852131591689,\n",
       "  0.19102766405363192,\n",
       "  0.46739244589185902,\n",
       "  array([  6.98161138e-17,   2.91525781e-01,   0.00000000e+00,\n",
       "           1.98641811e-01,   1.31849444e-01,   2.63327818e-01,\n",
       "           1.14655145e-01])],\n",
       " [0.0069575647384931272,\n",
       "  0.036591478696776161,\n",
       "  0.19014166648329828,\n",
       "  0.46698282303436695,\n",
       "  array([  8.00766484e-17,   2.90097414e-01,   6.12896328e-17,\n",
       "           1.97032296e-01,   1.33441129e-01,   2.63769486e-01,\n",
       "           1.15659675e-01])],\n",
       " [0.0069729332423624129,\n",
       "  0.03684210526319024,\n",
       "  0.18926533086395647,\n",
       "  0.4665747190380326,\n",
       "  array([ 0.        ,  0.28867728,  0.        ,  0.19543194,  0.13502385,\n",
       "          0.26420843,  0.1166585 ])],\n",
       " [0.0069882168582925527,\n",
       "  0.03709273182957494,\n",
       "  0.18839854908504411,\n",
       "  0.46616806839635255,\n",
       "  array([  0.00000000e+00,   2.87264974e-01,   4.00747042e-17,\n",
       "           1.93840430e-01,   1.36597809e-01,   2.64644974e-01,\n",
       "           1.17651812e-01])],\n",
       " [0.007003418656788025,\n",
       "  0.037343358395990685,\n",
       "  0.18754121101062879,\n",
       "  0.46576281650796814,\n",
       "  array([  4.12546067e-17,   2.85860237e-01,   0.00000000e+00,\n",
       "           1.92257439e-01,   1.38163353e-01,   2.65079160e-01,\n",
       "           1.18639810e-01])],\n",
       " [0.0070185415337023068,\n",
       "  0.037593984962498238,\n",
       "  0.18669320479602339,\n",
       "  0.46535891098206356,\n",
       "  array([ 0.        ,  0.28446282,  0.        ,  0.19068264,  0.13972079,\n",
       "          0.26551107,  0.11962268])],\n",
       " [0.0070335882582556759,\n",
       "  0.037844611528989845,\n",
       "  0.18585441821401139,\n",
       "  0.46495630028160118,\n",
       "  array([  3.86940814e-18,   2.83072424e-01,   7.65053506e-17,\n",
       "           1.89115787e-01,   1.41270373e-01,   2.65940814e-01,\n",
       "           1.20600602e-01])],\n",
       " [0.0070485614991944679,\n",
       "  0.038095238095979887,\n",
       "  0.18502473935025199,\n",
       "  0.46455493862120667,\n",
       "  array([  3.96047534e-17,   2.81688821e-01,   2.91544413e-17,\n",
       "           1.87556610e-01,   1.42812413e-01,   2.66368422e-01,\n",
       "           1.21573735e-01])],\n",
       " [0.0070634635047383222,\n",
       "  0.038345864661707744,\n",
       "  0.18420404826056538,\n",
       "  0.46415477666028687,\n",
       "  array([  0.00000000e+00,   2.80311751e-01,   1.53973902e-17,\n",
       "           1.86004841e-01,   1.44347025e-01,   2.66794117e-01,\n",
       "           1.22542266e-01])],\n",
       " [0.0070782969002178217,\n",
       "  0.038596491228126445,\n",
       "  0.18339223786901257,\n",
       "  0.46375577821224317,\n",
       "  array([  1.86465911e-17,   2.78941058e-01,   0.00000000e+00,\n",
       "           1.84460211e-01,   1.45874631e-01,   2.67217780e-01,\n",
       "           1.23506320e-01])],\n",
       " [0.0070930638161874797,\n",
       "  0.038847117794531066,\n",
       "  0.18258919113906691,\n",
       "  0.46335790046358882,\n",
       "  array([  8.31945936e-17,   2.77576503e-01,   7.98816314e-17,\n",
       "           1.82922509e-01,   1.47395385e-01,   2.67639548e-01,\n",
       "           1.24466055e-01])],\n",
       " [0.0071077661180160481,\n",
       "  0.039097744363164016,\n",
       "  0.18179478723873999,\n",
       "  0.46296111006550222,\n",
       "  array([  0.00000000e+00,   2.76218032e-01,   1.02345615e-16,\n",
       "           1.81391452e-01,   1.48909576e-01,   2.68059277e-01,\n",
       "           1.25421662e-01])],\n",
       " [0.0071224065537529536,\n",
       "  0.039348370927963214,\n",
       "  0.18100893088540451,\n",
       "  0.46256535934249876,\n",
       "  array([  1.78759290e-16,   2.74865105e-01,   0.00000000e+00,\n",
       "           1.79866956e-01,   1.50417251e-01,   2.68477549e-01,\n",
       "           1.26373139e-01])],\n",
       " [0.0071369866739133866,\n",
       "  0.039598997493749316,\n",
       "  0.18023149891711165,\n",
       "  0.46217062207645077,\n",
       "  array([ 0.        ,  0.27351776,  0.        ,  0.17834875,  0.15191874,\n",
       "          0.26889406,  0.12732069])],\n",
       " [0.0071515080956730415,\n",
       "  0.039849624060232167,\n",
       "  0.17946237296652118,\n",
       "  0.4617768666961824,\n",
       "  array([  2.45715118e-17,   2.72175907e-01,   7.71688267e-17,\n",
       "           1.76836594e-01,   1.53414218e-01,   2.69308799e-01,\n",
       "           1.28264481e-01])],\n",
       " [0.0071659728240706091,\n",
       "  0.040100250626712769,\n",
       "  0.1787014472996086,\n",
       "  0.46138406016619143,\n",
       "  array([  0.00000000e+00,   2.70839289e-01,   6.02592662e-17,\n",
       "           1.75330346e-01,   1.54903860e-01,   2.69721924e-01,\n",
       "           1.29204580e-01])],\n",
       " [0.0071803825666947813,\n",
       "  0.040350877193112304,\n",
       "  0.17794861143490673,\n",
       "  0.46099217273811621,\n",
       "  array([  6.45490030e-17,   2.69507741e-01,   0.00000000e+00,\n",
       "           1.73829836e-01,   1.56387834e-01,   2.70133489e-01,\n",
       "           1.30141099e-01])],\n",
       " [0.0071947388197772253,\n",
       "  0.04060150375986285,\n",
       "  0.177203752411005,\n",
       "  0.46060117740041484,\n",
       "  array([  5.37058381e-17,   2.68181161e-01,   7.10745812e-17,\n",
       "           1.72334872e-01,   1.57866313e-01,   2.70543488e-01,\n",
       "           1.31074166e-01])],\n",
       " [0.0072090435198950004,\n",
       "  0.040852130325867014,\n",
       "  0.17646677082419696,\n",
       "  0.46021104532059842,\n",
       "  array([  4.42916692e-17,   2.66859291e-01,   4.89538104e-17,\n",
       "           1.70845329e-01,   1.59339461e-01,   2.70952103e-01,\n",
       "           1.32003816e-01])],\n",
       " [0.007223297743842302,\n",
       "  0.041102756892318293,\n",
       "  0.17573754876749562,\n",
       "  0.45982175342527409,\n",
       "  array([  3.38902928e-18,   2.65542115e-01,   0.00000000e+00,\n",
       "           1.69361020e-01,   1.60807429e-01,   2.71359219e-01,\n",
       "           1.32930218e-01])],\n",
       " [0.0072375029412815655,\n",
       "  0.041353383458665023,\n",
       "  0.17501598021636722,\n",
       "  0.45943327560292857,\n",
       "  array([  0.00000000e+00,   2.64229461e-01,   2.84383590e-17,\n",
       "           1.67881810e-01,   1.62270323e-01,   2.71764948e-01,\n",
       "           1.33853457e-01])],\n",
       " [0.0072516606570567042,\n",
       "  0.041604010025088345,\n",
       "  0.17430196398577341,\n",
       "  0.45904559026680852,\n",
       "  array([  0.00000000e+00,   2.62921206e-01,   2.30877397e-17,\n",
       "           1.66407539e-01,   1.63728345e-01,   2.72169313e-01,\n",
       "           1.34773597e-01])],\n",
       " [0.0072657721873636396,\n",
       "  0.041854636591539394,\n",
       "  0.17359539537448432,\n",
       "  0.45865867488583817,\n",
       "  array([  7.50446368e-17,   2.61617216e-01,   4.42416384e-17,\n",
       "           1.64938087e-01,   1.65181617e-01,   2.72572354e-01,\n",
       "           1.35690726e-01])],\n",
       " [0.0072798386433267359,\n",
       "  0.042105263157894951,\n",
       "  0.1728961677790091,\n",
       "  0.45827250738789593,\n",
       "  array([  4.40412187e-17,   2.60317381e-01,   0.00000000e+00,\n",
       "           1.63473330e-01,   1.66630223e-01,   2.72974116e-01,\n",
       "           1.36604950e-01])],\n",
       " [0.0072938614102428714,\n",
       "  0.042355889724471546,\n",
       "  0.17220418359028752,\n",
       "  0.45788706910689342,\n",
       "  array([  1.19651568e-16,   2.59021594e-01,   0.00000000e+00,\n",
       "           1.62013114e-01,   1.68074345e-01,   2.73374627e-01,\n",
       "           1.37516320e-01])],\n",
       " [0.0073078415928002731,\n",
       "  0.042606516290755216,\n",
       "  0.1715193409132568,\n",
       "  0.45750234027770997,\n",
       "  array([  7.42624368e-17,   2.57729741e-01,   0.00000000e+00,\n",
       "           1.60557333e-01,   1.69514082e-01,   2.73773921e-01,\n",
       "           1.38424923e-01])],\n",
       " [0.0073217802005593165,\n",
       "  0.042857142858861511,\n",
       "  0.17084153800619964,\n",
       "  0.4571182993325224,\n",
       "  array([  7.80961109e-17,   2.56441557e-01,   5.27065846e-17,\n",
       "           1.59106188e-01,   1.70949468e-01,   2.74171906e-01,\n",
       "           1.39330881e-01])],\n",
       " [0.0073356786229092103,\n",
       "  0.043107769424332282,\n",
       "  0.170170684330713,\n",
       "  0.45673493695816109,\n",
       "  array([  1.31969357e-16,   2.55157347e-01,   0.00000000e+00,\n",
       "           1.57658767e-01,   1.72380822e-01,   2.74568928e-01,\n",
       "           1.40234136e-01])],\n",
       " [0.0073495379858567631,\n",
       "  0.043358395990467126,\n",
       "  0.16950668533662197,\n",
       "  0.45635223194443253,\n",
       "  array([  0.00000000e+00,   2.53876706e-01,   2.62969754e-17,\n",
       "           1.56215509e-01,   1.73808177e-01,   2.74964811e-01,\n",
       "           1.41134797e-01])],\n",
       " [0.007363359591946856,\n",
       "  0.043609022558161063,\n",
       "  0.16884945270503121,\n",
       "  0.45597016926344619,\n",
       "  array([ 0.        ,  0.2525995 ,  0.        ,  0.15477633,  0.1752317 ,\n",
       "          0.27535959,  0.14203289])],\n",
       " [0.0073771416122320188,\n",
       "  0.043859649122972091,\n",
       "  0.16819882875825698,\n",
       "  0.45558872417322543,\n",
       "  array([  0.00000000e+00,   2.51326005e-01,   1.48716216e-17,\n",
       "           1.53340999e-01,   1.76650883e-01,   2.75753230e-01,\n",
       "           1.42928883e-01])],\n",
       " [0.0073908884606448859,\n",
       "  0.044110275690083592,\n",
       "  0.16755480089430563,\n",
       "  0.45520789431087938,\n",
       "  array([ 0.        ,  0.25005571,  0.        ,  0.15190952,  0.17806659,\n",
       "          0.27614586,  0.14382232])],\n",
       " [0.0074045997659056206,\n",
       "  0.044360902255639094,\n",
       "  0.16691724896024537,\n",
       "  0.45482766139043079,\n",
       "  array([  0.00000000e+00,   2.48788709e-01,   3.68986226e-17,\n",
       "           1.50481730e-01,   1.79478637e-01,   2.76537475e-01,\n",
       "           1.44713449e-01])],\n",
       " [0.007418276393078964,\n",
       "  0.044611528822055255,\n",
       "  0.16628608319317409,\n",
       "  0.4544480119460268,\n",
       "  array([  0.00000000e+00,   2.47524907e-01,   2.11370617e-17,\n",
       "           1.49057558e-01,   1.80887113e-01,   2.76928099e-01,\n",
       "           1.45602323e-01])],\n",
       " [0.0074319191774756769,\n",
       "  0.044862155388477577,\n",
       "  0.16566121518504873,\n",
       "  0.45406893324919378,\n",
       "  array([  1.76177887e-17,   2.46264234e-01,   0.00000000e+00,\n",
       "           1.47636910e-01,   1.82292106e-01,   2.77317752e-01,\n",
       "           1.46488998e-01])],\n",
       " [0.0074455289093858885,\n",
       "  0.045112781955231246,\n",
       "  0.16504255749012858,\n",
       "  0.45369041431150625,\n",
       "  array([ 0.        ,  0.24500664,  0.        ,  0.1462197 ,  0.18369373,\n",
       "          0.2777064 ,  0.14737353])],\n",
       " [0.0074591063744767639,\n",
       "  0.045363408521417105,\n",
       "  0.16443002449772151,\n",
       "  0.45331243894486895,\n",
       "  array([  0.00000000e+00,   2.43751978e-01,   6.39563550e-18,\n",
       "           1.44805854e-01,   1.85091953e-01,   2.78094248e-01,\n",
       "           1.48255966e-01])],\n",
       " [0.0074726521520627007,\n",
       "  0.045614035088562606,\n",
       "  0.16382352794603816,\n",
       "  0.45293500128376052,\n",
       "  array([  5.34100510e-17,   2.42500298e-01,   3.44132080e-17,\n",
       "           1.43395290e-01,   1.86486968e-01,   2.78481052e-01,\n",
       "           1.49136392e-01])],\n",
       " [0.0074861676305632762,\n",
       "  0.045864661654157403,\n",
       "  0.1632229991581044,\n",
       "  0.45255808628157501,\n",
       "  array([  3.48781230e-17,   2.41251352e-01,   0.00000000e+00,\n",
       "           1.41987920e-01,   1.87878829e-01,   2.78867166e-01,\n",
       "           1.50014731e-01])],\n",
       " [0.0074996527349029682,\n",
       "  0.04611528822066828,\n",
       "  0.16262833919666841,\n",
       "  0.45218168641251183,\n",
       "  array([  1.15446440e-16,   2.40005251e-01,   0.00000000e+00,\n",
       "           1.40583690e-01,   1.89267579e-01,   2.79252307e-01,\n",
       "           1.50891173e-01])],\n",
       " [0.0075131084385366151,\n",
       "  0.04636591478730339,\n",
       "  0.16203947388942636,\n",
       "  0.45180579085480488,\n",
       "  array([  7.95370987e-17,   2.38761867e-01,   6.63379250e-17,\n",
       "           1.39182525e-01,   1.90653301e-01,   2.79636597e-01,\n",
       "           1.51765710e-01])],\n",
       " [0.0075265352820927077,\n",
       "  0.046616541355392158,\n",
       "  0.16145632136696708,\n",
       "  0.45143039168894383,\n",
       "  array([  3.34404268e-17,   2.37521179e-01,   3.34802834e-17,\n",
       "           1.37784377e-01,   1.92036091e-01,   2.80019941e-01,\n",
       "           1.52638412e-01])],\n",
       " [0.0075399346746510536,\n",
       "  0.046867167919887806,\n",
       "  0.16087882006310705,\n",
       "  0.45105547487295322,\n",
       "  array([  1.44047704e-17,   2.36282956e-01,   2.08001566e-17,\n",
       "           1.36389063e-01,   1.93415984e-01,   2.80402835e-01,\n",
       "           1.53509161e-01])],\n",
       " [0.0075533062337096255,\n",
       "  0.047117794486234849,\n",
       "  0.16030687166217583,\n",
       "  0.45068103677315052,\n",
       "  array([  2.12742448e-16,   2.35047347e-01,   0.00000000e+00,\n",
       "           1.34996657e-01,   1.94793049e-01,   2.80784746e-01,\n",
       "           1.54378200e-01])],\n",
       " [0.0075666508652768201,\n",
       "  0.047368421052763302,\n",
       "  0.15974040715539978,\n",
       "  0.45030706679193983,\n",
       "  array([  9.63398753e-17,   2.33814221e-01,   5.49065196e-17,\n",
       "           1.33607058e-01,   1.96167329e-01,   2.81165889e-01,\n",
       "           1.55245504e-01])],\n",
       " [0.0075799692042815437,\n",
       "  0.047619047620192166,\n",
       "  0.15917935328608646,\n",
       "  0.449933558409711,\n",
       "  array([  0.00000000e+00,   2.32583591e-01,   1.03581036e-17,\n",
       "           1.32220079e-01,   1.97538924e-01,   2.81546315e-01,\n",
       "           1.56111090e-01])],\n",
       " [0.0075932615983404696,\n",
       "  0.047869674186199876,\n",
       "  0.1586236323398561,\n",
       "  0.44956049961205719,\n",
       "  array([  3.34894955e-16,   2.31355218e-01,   7.26350600e-17,\n",
       "           1.30836036e-01,   1.98907769e-01,   2.81925911e-01,\n",
       "           1.56975066e-01])],\n",
       " [0.0076065294402000135,\n",
       "  0.048120300751958937,\n",
       "  0.15807318992889624,\n",
       "  0.44918789008078114,\n",
       "  array([ 0.        ,  0.2301292 ,  0.        ,  0.12945443,  0.20027419,\n",
       "          0.28230488,  0.15783729])],\n",
       " [0.0076197722615466319,\n",
       "  0.048370927318295877,\n",
       "  0.1575279343190206,\n",
       "  0.44881571723161934,\n",
       "  array([ 0.        ,  0.22890549,  0.        ,  0.12807543,  0.20163799,\n",
       "          0.28268311,  0.15869798])],\n",
       " [0.0076329909718300618,\n",
       "  0.048621553884969269,\n",
       "  0.15698780400742607,\n",
       "  0.44844397742593956,\n",
       "  array([  1.08022209e-16,   2.27684032e-01,   6.66867680e-18,\n",
       "           1.26698923e-01,   2.02999339e-01,   2.83060606e-01,\n",
       "           1.59557100e-01])],\n",
       " [0.0076461860962606645,\n",
       "  0.048872180451530405,\n",
       "  0.15645273089142944,\n",
       "  0.44807266001636026,\n",
       "  array([  6.45532449e-17,   2.26464691e-01,   0.00000000e+00,\n",
       "           1.25324912e-01,   2.04358194e-01,   2.83437529e-01,\n",
       "           1.60414674e-01])],\n",
       " [0.0076593580638599215,\n",
       "  0.049122807017552506,\n",
       "  0.1559226462999781,\n",
       "  0.44770176274321244,\n",
       "  array([  1.73163304e-16,   2.25247521e-01,   4.38069643e-17,\n",
       "           1.23953293e-01,   2.05714697e-01,   2.83813740e-01,\n",
       "           1.61270749e-01])],\n",
       " [0.0076725073423681497,\n",
       "  0.049373433585294273,\n",
       "  0.15539748373208911,\n",
       "  0.44733127753114832,\n",
       "  array([  7.43898334e-17,   2.24032400e-01,   6.48828850e-17,\n",
       "           1.22584123e-01,   2.07068846e-01,   2.84189268e-01,\n",
       "           1.62125362e-01])],\n",
       " [0.0076856344276285795,\n",
       "  0.049624060151471666,\n",
       "  0.15487717861394404,\n",
       "  0.44696120068399592,\n",
       "  array([  1.85815630e-16,   2.22819409e-01,   0.00000000e+00,\n",
       "           1.21217122e-01,   2.08420737e-01,   2.84564217e-01,\n",
       "           1.62978515e-01])],\n",
       " [0.0076987397363955153,\n",
       "  0.04987468671786105,\n",
       "  0.154361666068139,\n",
       "  0.44659152510913797,\n",
       "  array([  0.00000000e+00,   2.21608410e-01,   4.43023468e-17,\n",
       "           1.19852424e-01,   2.09770378e-01,   2.84938530e-01,\n",
       "           1.63830258e-01])],\n",
       " [0.0077118237242425553,\n",
       "  0.050125313284239831,\n",
       "  0.153850883295472,\n",
       "  0.44622224596071181,\n",
       "  array([ 0.        ,  0.22039938,  0.        ,  0.11848994,  0.21111783,\n",
       "          0.28531224,  0.16468061])],\n",
       " [0.0077248868115324153,\n",
       "  0.050375939849874429,\n",
       "  0.15334476804906044,\n",
       "  0.4458533579900078,\n",
       "  array([  6.09057246e-18,   2.19192276e-01,   2.89567410e-17,\n",
       "           1.17129664e-01,   2.12463118e-01,   2.85685335e-01,\n",
       "           1.65529606e-01])],\n",
       " [0.0077379293672172359,\n",
       "  0.050626566416355399,\n",
       "  0.15284325829210144,\n",
       "  0.44548485635678359,\n",
       "  array([ 0.        ,  0.21798707,  0.        ,  0.11577152,  0.21380629,\n",
       "          0.28605785,  0.16637727])],\n",
       " [0.0077509518201997231,\n",
       "  0.050877192982474409,\n",
       "  0.15234629439697434,\n",
       "  0.44511673656506967,\n",
       "  array([  0.00000000e+00,   2.16783714e-01,   1.98449026e-17,\n",
       "           1.14415467e-01,   2.15147400e-01,   2.86429790e-01,\n",
       "           1.67223629e-01])],\n",
       " [0.0077639543064040853,\n",
       "  0.051127819551417653,\n",
       "  0.15185381216181376,\n",
       "  0.44474899382625982,\n",
       "  array([ 0.        ,  0.21558225,  0.        ,  0.11306141,  0.21648643,\n",
       "          0.28680118,  0.16806874])],\n",
       " [0.0077769378390246937,\n",
       "  0.051378446117494932,\n",
       "  0.15136576573841848,\n",
       "  0.44438162442715085,\n",
       "  array([  1.30026496e-16,   2.14382453e-01,   0.00000000e+00,\n",
       "           1.11709486e-01,   2.17823537e-01,   2.87171987e-01,\n",
       "           1.68912537e-01])],\n",
       " [0.0077899022605285835,\n",
       "  0.051629072684087868,\n",
       "  0.15088208746637899,\n",
       "  0.44401462397093899,\n",
       "  array([  0.00000000e+00,   2.13184452e-01,   1.11932686e-17,\n",
       "           1.10359499e-01,   2.19158665e-01,   2.87542263e-01,\n",
       "           1.69755120e-01])],\n",
       " [0.0078028481078115568,\n",
       "  0.051879699248120505,\n",
       "  0.1504027243969468,\n",
       "  0.4436479891042836,\n",
       "  array([  1.80486703e-17,   2.11988186e-01,   5.29074292e-17,\n",
       "           1.09011415e-01,   2.20491894e-01,   2.87912023e-01,\n",
       "           1.70596482e-01])],\n",
       " [0.0078157756012704471,\n",
       "  0.052130325814537012,\n",
       "  0.14992761850513789,\n",
       "  0.44328171515877135,\n",
       "  array([  6.83935721e-17,   2.10793609e-01,   0.00000000e+00,\n",
       "           1.07665252e-01,   2.21823220e-01,   2.88281251e-01,\n",
       "           1.71436668e-01])],\n",
       " [0.0078286851541103063,\n",
       "  0.052380952380954589,\n",
       "  0.14945671657846318,\n",
       "  0.44291579896129518,\n",
       "  array([  0.00000000e+00,   2.09600689e-01,   1.19003356e-17,\n",
       "           1.06320957e-01,   2.23152698e-01,   2.88649966e-01,\n",
       "           1.72275690e-01])],\n",
       " [0.0078415770965106404,\n",
       "  0.05263157894737433,\n",
       "  0.14898996483368543,\n",
       "  0.4425502370790525,\n",
       "  array([  0.00000000e+00,   2.08409395e-01,   4.56480440e-17,\n",
       "           1.04978497e-01,   2.24480363e-01,   2.89018178e-01,\n",
       "           1.73113566e-01])],\n",
       " [0.007854451749822796,\n",
       "  0.052882205513797423,\n",
       "  0.14852731034021457,\n",
       "  0.44218502622673828,\n",
       "  array([  7.58378344e-17,   2.07219700e-01,   0.00000000e+00,\n",
       "           1.03637838e-01,   2.25806247e-01,   2.89385896e-01,\n",
       "           1.73950319e-01])],\n",
       " [0.0078673094264213959,\n",
       "  0.053132832080221917,\n",
       "  0.14806870099721092,\n",
       "  0.44182016326475443,\n",
       "  array([ 0.        ,  0.20603157,  0.        ,  0.10229895,  0.22713038,\n",
       "          0.28975313,  0.17478597])],\n",
       " [0.0078801504258924921,\n",
       "  0.053383458646636496,\n",
       "  0.14761408544271967,\n",
       "  0.44145564519987862,\n",
       "  array([  1.76641758e-17,   2.04844990e-01,   5.25927482e-17,\n",
       "           1.00961786e-01,   2.28452802e-01,   2.90119888e-01,\n",
       "           1.75620534e-01])],\n",
       " [0.0078929751130208774,\n",
       "  0.05363408522028705,\n",
       "  0.14716341447053088,\n",
       "  0.44109146925000975,\n",
       "  array([  3.16415420e-17,   2.03659908e-01,   2.32479115e-18,\n",
       "           9.96263389e-02,   2.29773547e-01,   2.90486179e-01,\n",
       "           1.76454027e-01])],\n",
       " [0.007905783707759538,\n",
       "  0.053884711780152986,\n",
       "  0.14671663717929406,\n",
       "  0.44072763300486784,\n",
       "  array([  9.85533511e-17,   2.02476338e-01,   8.31369517e-18,\n",
       "           9.82925282e-02,   2.31092644e-01,   2.90852018e-01,\n",
       "           1.77286471e-01])],\n",
       " [0.0079185763738312005,\n",
       "  0.054135338345866098,\n",
       "  0.14627370246104468,\n",
       "  0.4403641322280179,\n",
       "  array([ 0.        ,  0.20129421,  0.        ,  0.09696042,  0.23241007,\n",
       "          0.29121739,  0.17811791])],\n",
       " [0.0079313535878037141,\n",
       "  0.05438596491268026,\n",
       "  0.1458345659682227,\n",
       "  0.4400009675213572,\n",
       "  array([  8.32571826e-18,   2.00113547e-01,   9.72552668e-17,\n",
       "           9.56298935e-02,   2.33725959e-01,   2.91582265e-01,\n",
       "           1.78948335e-01])],\n",
       " [0.0079441154932500292,\n",
       "  0.054636591478808054,\n",
       "  0.14539917806423414,\n",
       "  0.43963813176526434,\n",
       "  array([  2.38110065e-16,   1.98934247e-01,   0.00000000e+00,\n",
       "           9.43009776e-02,   2.35040196e-01,   2.91946813e-01,\n",
       "           1.79777768e-01])],\n",
       " [0.0079568623825504638,\n",
       "  0.054887218045598214,\n",
       "  0.14496749272189757,\n",
       "  0.4392756270833445,\n",
       "  array([  8.88386191e-17,   1.97756374e-01,   0.00000000e+00,\n",
       "           9.29736060e-02,   2.36352931e-01,   2.92310857e-01,\n",
       "           1.80606232e-01])],\n",
       " [0.0079695945964336247,\n",
       "  0.055137844612093062,\n",
       "  0.14453946563383982,\n",
       "  0.43891344934028476,\n",
       "  array([  1.57061184e-17,   1.96579843e-01,   0.00000000e+00,\n",
       "           9.16477759e-02,   2.37664148e-01,   2.92674505e-01,\n",
       "           1.81433728e-01])],\n",
       " [0.0079823123927063831,\n",
       "  0.055388471178114032,\n",
       "  0.14411505179548051,\n",
       "  0.43855159633815094,\n",
       "  array([  4.65559872e-17,   1.95404628e-01,   9.49690146e-17,\n",
       "           9.03234630e-02,   2.38973872e-01,   2.93037769e-01,\n",
       "           1.82260269e-01])],\n",
       " [0.0079950158937166799,\n",
       "  0.055639097744410899,\n",
       "  0.14369420457613014,\n",
       "  0.43819006692453338,\n",
       "  array([  1.03238775e-16,   1.94230750e-01,   0.00000000e+00,\n",
       "           8.90006242e-02,   2.40282134e-01,   2.93400600e-01,\n",
       "           1.83085893e-01])],\n",
       " [0.0080077053856985811,\n",
       "  0.055889724311190693,\n",
       "  0.14327688111525025,\n",
       "  0.43782885955393214,\n",
       "  array([ 0.        ,  0.19305818,  0.        ,  0.08767926,  0.24158898,\n",
       "          0.29376298,  0.18391061])],\n",
       " [0.0080203810945493059,\n",
       "  0.05614035087724864,\n",
       "  0.14286303824651789,\n",
       "  0.43746796986597203,\n",
       "  array([ 0.        ,  0.19188685,  0.        ,  0.08635931,  0.24289435,\n",
       "          0.29412506,  0.18473443])],\n",
       " [0.0080330435653663771,\n",
       "  0.056390977444576232,\n",
       "  0.14245263922338711,\n",
       "  0.4371074014248158,\n",
       "  array([ 0.        ,  0.19071681,  0.        ,  0.08504071,  0.24419846,\n",
       "          0.29448671,  0.18555731])],\n",
       " [0.0080456922176311441,\n",
       "  0.056641604010207493,\n",
       "  0.14204562808957907,\n",
       "  0.43674714445694773,\n",
       "  array([  0.00000000e+00,   1.89547956e-01,   1.97606307e-17,\n",
       "           8.37236151e-02,   2.45501011e-01,   2.94847999e-01,\n",
       "           1.86379419e-01])],\n",
       " [0.0080583278032442859,\n",
       "  0.056892230578126674,\n",
       "  0.14164197327749822,\n",
       "  0.4363872032088309,\n",
       "  array([  7.76928040e-17,   1.88380340e-01,   7.48313242e-17,\n",
       "           8.24078549e-02,   2.46802250e-01,   2.95208890e-01,\n",
       "           1.87200664e-01])],\n",
       " [0.0080709507150496518,\n",
       "  0.057142857145032561,\n",
       "  0.14124163750799187,\n",
       "  0.43602757441303108,\n",
       "  array([ 0.        ,  0.18721378,  0.        ,  0.08109365,  0.24810218,\n",
       "          0.29556934,  0.18802106])],\n",
       " [0.0080835607789655414,\n",
       "  0.05739348370941566,\n",
       "  0.14084457427070934,\n",
       "  0.43566826116149837,\n",
       "  array([  3.26251190e-19,   1.86048684e-01,   2.17876643e-17,\n",
       "           7.97802887e-02,   2.49400871e-01,   2.95929548e-01,\n",
       "           1.88840609e-01])],\n",
       " [0.0080961582804471126,\n",
       "  0.057644110275843478,\n",
       "  0.14045074582129363,\n",
       "  0.43530925472889553,\n",
       "  array([  0.00000000e+00,   1.84884584e-01,   2.27597879e-17,\n",
       "           7.84684858e-02,   2.50698177e-01,   2.96289371e-01,\n",
       "           1.89659381e-01])],\n",
       " [0.0081087436528213784,\n",
       "  0.057894736842324497,\n",
       "  0.14006011763911161,\n",
       "  0.43495055900941221,\n",
       "  array([  0.00000000e+00,   1.83721641e-01,   1.02344936e-16,\n",
       "           7.71579171e-02,   2.51994281e-01,   2.96648833e-01,\n",
       "           1.90477328e-01])],\n",
       " [0.0081213169908269031,\n",
       "  0.058145363408604565,\n",
       "  0.1396726499713489,\n",
       "  0.43459217075804513,\n",
       "  array([  1.99655663e-16,   1.82559779e-01,   4.93946574e-18,\n",
       "           7.58486482e-02,   2.53289135e-01,   2.97007956e-01,\n",
       "           1.91294482e-01])],\n",
       " [0.0081338783516951563,\n",
       "  0.058395989975059036,\n",
       "  0.13928830310384568,\n",
       "  0.43423408948512093,\n",
       "  array([  4.12759229e-17,   1.81399040e-01,   4.36330773e-17,\n",
       "           7.45406035e-02,   2.54582758e-01,   2.97366724e-01,\n",
       "           1.92110875e-01])],\n",
       " [0.0081464280008597904,\n",
       "  0.058646616541499809,\n",
       "  0.13890704155277525,\n",
       "  0.43387631394392934,\n",
       "  array([  1.39463044e-16,   1.80239380e-01,   0.00000000e+00,\n",
       "           7.32337816e-02,   2.55875174e-01,   2.97725159e-01,\n",
       "           1.92926505e-01])],\n",
       " [0.0081589659221418601,\n",
       "  0.058897243108443111,\n",
       "  0.13852882565520705,\n",
       "  0.43351884244869249,\n",
       "  array([ 0.        ,  0.17908077,  0.        ,  0.07192825,  0.25716636,\n",
       "          0.29808319,  0.19374143])],\n",
       " [0.00817149276822122,\n",
       "  0.059147869674797238,\n",
       "  0.13815362773248066,\n",
       "  0.43316167565465585,\n",
       "  array([  0.00000000e+00,   1.77923211e-01,   1.94339055e-17,\n",
       "           7.06238202e-02,   2.58456435e-01,   2.98440977e-01,\n",
       "           1.94555556e-01])],\n",
       " [0.0081840085261510702,\n",
       "  0.059398496240620213,\n",
       "  0.13778140936427208,\n",
       "  0.43280481175065932,\n",
       "  array([  1.02858406e-16,   1.76766684e-01,   8.02593223e-17,\n",
       "           6.93205090e-02,   2.59745364e-01,   2.98798507e-01,\n",
       "           1.95368936e-01])],\n",
       " [0.0081965130902960891,\n",
       "  0.059649122807063845,\n",
       "  0.13741213121956306,\n",
       "  0.43244824991208075,\n",
       "  array([  0.00000000e+00,   1.75611187e-01,   5.39041383e-17,\n",
       "           6.80183913e-02,   2.61033138e-01,   2.99155648e-01,\n",
       "           1.96181636e-01])],\n",
       " [0.0082090066784165951,\n",
       "  0.059899749373762669,\n",
       "  0.13704576002804295,\n",
       "  0.432091989619872,\n",
       "  array([  4.69293478e-18,   1.74456702e-01,   4.92464949e-17,\n",
       "           6.67174458e-02,   2.62319787e-01,   2.99512405e-01,\n",
       "           1.96993660e-01])],\n",
       " [0.0082214897984877189,\n",
       "  0.060150375939880374,\n",
       "  0.13668226789978846,\n",
       "  0.43173602947365425,\n",
       "  array([ 0.        ,  0.17330319,  0.        ,  0.06541752,  0.26360534,\n",
       "          0.29986901,  0.19780494])],\n",
       " [0.0082337534358534002,\n",
       "  0.060401002506863637,\n",
       "  0.13631815854244742,\n",
       "  0.43138196767944287,\n",
       "  array([  0.00000000e+00,   1.72174111e-01,   3.71677250e-18,\n",
       "           6.42358111e-02,   2.64918393e-01,   3.00000000e-01,\n",
       "           1.98671685e-01])],\n",
       " [0.008245884624365209,\n",
       "  0.060651629072758291,\n",
       "  0.13595487459163488,\n",
       "  0.43102912520075709,\n",
       "  array([  0.00000000e+00,   1.71059540e-01,   2.81762299e-17,\n",
       "           6.31234146e-02,   2.66246823e-01,   3.00000000e-01,\n",
       "           1.99570222e-01])],\n",
       " [0.0082580044673941991,\n",
       "  0.060902255639107943,\n",
       "  0.13559439434114132,\n",
       "  0.4306765726630824,\n",
       "  array([  7.52117855e-18,   1.69946044e-01,   0.00000000e+00,\n",
       "           6.20120090e-02,   2.67574021e-01,   3.00000000e-01,\n",
       "           2.00467926e-01])],\n",
       " [0.0082701129487753287,\n",
       "  0.061152882208153007,\n",
       "  0.13523668304995676,\n",
       "  0.43032431056128828,\n",
       "  array([  3.04445885e-17,   1.68833725e-01,   1.89974529e-17,\n",
       "           6.09014302e-02,   2.68900017e-01,   3.00000000e-01,\n",
       "           2.01364827e-01])],\n",
       " [0.0082822106549803251,\n",
       "  0.061403508774054698,\n",
       "  0.13488171637644056,\n",
       "  0.42997233436609472,\n",
       "  array([  0.00000000e+00,   1.67722253e-01,   2.05396567e-17,\n",
       "           5.97920631e-02,   2.70224779e-01,   3.00000000e-01,\n",
       "           2.02260905e-01])],\n",
       " [0.008294297653312542,\n",
       "  0.061654135339238289,\n",
       "  0.13452946193592688,\n",
       "  0.42962064533081801,\n",
       "  array([  2.69512176e-16,   1.66611736e-01,   6.91468970e-17,\n",
       "           5.86837274e-02,   2.71548364e-01,   3.00000000e-01,\n",
       "           2.03156172e-01])],\n",
       " [0.0083063740382699272,\n",
       "  0.061904761904918636,\n",
       "  0.13417988831017449,\n",
       "  0.42926924325392324,\n",
       "  array([  9.12015492e-17,   1.65502200e-01,   2.52748757e-18,\n",
       "           5.75763577e-02,   2.72870795e-01,   3.00000000e-01,\n",
       "           2.04050647e-01])],\n",
       " [0.0083184398200586932,\n",
       "  0.062155388472067481,\n",
       "  0.13383296323209345,\n",
       "  0.42891812835308119,\n",
       "  array([  1.59049786e-16,   1.64393718e-01,   0.00000000e+00,\n",
       "           5.64698360e-02,   2.74192090e-01,   3.00000000e-01,\n",
       "           2.04944356e-01])],\n",
       " [0.0083304952610048534,\n",
       "  0.062406015038147737,\n",
       "  0.13348865900045953,\n",
       "  0.4285672979464647,\n",
       "  array([  1.37489215e-16,   1.63286133e-01,   0.00000000e+00,\n",
       "           5.53643356e-02,   2.75512223e-01,   3.00000000e-01,\n",
       "           2.05837308e-01])],\n",
       " [0.0083425405985348821,\n",
       "  0.062656641604337829,\n",
       "  0.13314694795192011,\n",
       "  0.42821675301512346,\n",
       "  array([  0.00000000e+00,   1.62179479e-01,   4.48766838e-17,\n",
       "           5.42597655e-02,   2.76831261e-01,   3.00000000e-01,\n",
       "           2.06729494e-01])],\n",
       " [0.0083545759196417876,\n",
       "  0.062907268170523375,\n",
       "  0.13280780047537516,\n",
       "  0.42786649272886623,\n",
       "  array([ 0.        ,  0.16107374,  0.        ,  0.05315612,  0.2781492 ,\n",
       "          0.3       ,  0.20762094])],\n",
       " [0.0083666011137198491,\n",
       "  0.063157894739570578,\n",
       "  0.13247118429484142,\n",
       "  0.42751651788418593,\n",
       "  array([  1.94211681e-16,   1.59969050e-01,   3.00866280e-18,\n",
       "           5.20532167e-02,   2.79466065e-01,   3.00000000e-01,\n",
       "           2.08511669e-01])],\n",
       " [0.0083786170821423169,\n",
       "  0.063408521303351478,\n",
       "  0.13213708362726734,\n",
       "  0.42716682504487979,\n",
       "  array([  1.25607028e-16,   1.58864996e-01,   0.00000000e+00,\n",
       "           5.09515078e-02,   2.80781873e-01,   3.00000000e-01,\n",
       "           2.09401623e-01])],\n",
       " [0.0083906230682614519,\n",
       "  0.06365914786970335,\n",
       "  0.13180545685963724,\n",
       "  0.42681741635283266,\n",
       "  array([ 0.        ,  0.15776197,  0.        ,  0.04985051,  0.2820966 ,\n",
       "          0.3       ,  0.21029091])],\n",
       " [0.0084026200796047945,\n",
       "  0.063909774438208194,\n",
       "  0.13147629065298849,\n",
       "  0.42646829329120889,\n",
       "  array([ 0.        ,  0.15665979,  0.        ,  0.04875037,  0.28341042,\n",
       "          0.3       ,  0.21117942])],\n",
       " [0.0084146068843524661,\n",
       "  0.064160401002572476,\n",
       "  0.13114953698645193,\n",
       "  0.42611944862429574,\n",
       "  array([  2.04671448e-17,   1.55558505e-01,   0.00000000e+00,\n",
       "           4.76511405e-02,   2.84722980e-01,   3.00000000e-01,\n",
       "           2.12067374e-01])],\n",
       " [0.008426585100205523,\n",
       "  0.064411027569717963,\n",
       "  0.13082519279924013,\n",
       "  0.42577088989245188,\n",
       "  array([  3.25945448e-17,   1.54458033e-01,   0.00000000e+00,\n",
       "           4.65527173e-02,   2.86034700e-01,   3.00000000e-01,\n",
       "           2.12954549e-01])],\n",
       " [0.0084385537927673792,\n",
       "  0.064661654135352242,\n",
       "  0.13050321563230469,\n",
       "  0.42542261155692879,\n",
       "  array([ 0.        ,  0.15335843,  0.        ,  0.04545514,  0.28734531,\n",
       "          0.3       ,  0.21384112])],\n",
       " [0.0084505137170829327,\n",
       "  0.064912280701831304,\n",
       "  0.13018358969544769,\n",
       "  0.42507461671660607,\n",
       "  array([  9.03882873e-18,   1.52259649e-01,   1.72118572e-17,\n",
       "           4.43583553e-02,   2.88654999e-01,   3.00000000e-01,\n",
       "           2.14726996e-01])],\n",
       " [0.0084624650063502751,\n",
       "  0.065162907268360604,\n",
       "  0.12986628990476559,\n",
       "  0.4247269043715684,\n",
       "  array([  8.03628814e-17,   1.51161632e-01,   1.07462225e-16,\n",
       "           4.32624250e-02,   2.89963751e-01,   3.00000000e-01,\n",
       "           2.15612192e-01])],\n",
       " [0.0084744073512130567,\n",
       "  0.065413533834594265,\n",
       "  0.12955128479439104,\n",
       "  0.42437947344850507,\n",
       "  array([  1.25087868e-17,   1.50064456e-01,   3.42520690e-17,\n",
       "           4.21672661e-02,   2.91271502e-01,   3.00000000e-01,\n",
       "           2.16496776e-01])],\n",
       " [0.0084863415056914675,\n",
       "  0.065664160402227056,\n",
       "  0.1292385595689981,\n",
       "  0.42403232630492338,\n",
       "  array([  1.45123252e-18,   1.48968031e-01,   1.06697051e-16,\n",
       "           4.10728953e-02,   2.92578411e-01,   3.00000000e-01,\n",
       "           2.17380663e-01])],\n",
       " [0.0084982663326546807,\n",
       "  0.065914786969781466,\n",
       "  0.12892807097367542,\n",
       "  0.42368545973587274,\n",
       "  array([  0.00000000e+00,   1.47872589e-01,   7.48737079e-17,\n",
       "           3.99791232e-02,   2.93884251e-01,   3.00000000e-01,\n",
       "           2.18264037e-01])],\n",
       " [0.0085101835393200376,\n",
       "  0.066165413533841783,\n",
       "  0.12861981940107295,\n",
       "  0.42333887343378784,\n",
       "  array([  2.09202373e-17,   1.46777592e-01,   1.01383546e-16,\n",
       "           3.88864844e-02,   2.95189217e-01,   3.00000000e-01,\n",
       "           2.19146707e-01])],\n",
       " [0.0085220922340915294,\n",
       "  0.066416040100651774,\n",
       "  0.12831376608988612,\n",
       "  0.42299257102133259,\n",
       "  array([ 0.        ,  0.14568354,  0.        ,  0.03779437,  0.29649331,\n",
       "          0.3       ,  0.22002879])],\n",
       " [0.0085339929195398182,\n",
       "  0.066666666666671884,\n",
       "  0.12800989379308725,\n",
       "  0.42264654973596055,\n",
       "  array([  6.55195227e-17,   1.44590151e-01,   1.23274395e-18,\n",
       "           3.67031003e-02,   2.97796495e-01,   3.00000000e-01,\n",
       "           2.20910253e-01])],\n",
       " [0.0085458855003089206,\n",
       "  0.066917293233160091,\n",
       "  0.12770817657750247,\n",
       "  0.4223008107488464,\n",
       "  array([ 0.        ,  0.14349754,  0.        ,  0.03561252,  0.29909881,\n",
       "          0.3       ,  0.22179113])],\n",
       " [0.0085565249071870315,\n",
       "  0.067167919799501971,\n",
       "  0.12739005365550229,\n",
       "  0.42194665061535391,\n",
       "  array([  0.00000000e+00,   1.42356318e-01,   8.24182607e-18,\n",
       "           3.47647136e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.22878968e-01])],\n",
       " [0.008564347024364637,\n",
       "  0.067418546366323551,\n",
       "  0.12703250790709189,\n",
       "  0.42157338840840147,\n",
       "  array([  2.11167378e-16,   1.41106271e-01,   0.00000000e+00,\n",
       "           3.44622091e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.24431520e-01])],\n",
       " [0.008572152628867612,\n",
       "  0.067669172932330823,\n",
       "  0.12667736662659917,\n",
       "  0.42120071183808072,\n",
       "  array([ 0.        ,  0.13985859,  0.        ,  0.03416084,  0.3       ,\n",
       "          0.3       ,  0.22598057])],\n",
       " [0.008579940926698915,\n",
       "  0.067919799498746908,\n",
       "  0.12632459150379577,\n",
       "  0.42082861862294263,\n",
       "  array([  4.17690245e-17,   1.38613811e-01,   0.00000000e+00,\n",
       "           3.38598816e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.27526307e-01])],\n",
       " [0.008587712587046015,\n",
       "  0.068170426065162965,\n",
       "  0.12597416625850577,\n",
       "  0.42045710064701919,\n",
       "  array([ 0.        ,  0.13737169,  0.        ,  0.03355957,  0.3       ,\n",
       "          0.3       ,  0.22906874])],\n",
       " [0.0085954678942849749,\n",
       "  0.068421052631578869,\n",
       "  0.12562606922416517,\n",
       "  0.42008615155114459,\n",
       "  array([  3.58079014e-16,   1.36132188e-01,   0.00000000e+00,\n",
       "           3.32598909e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.30607921e-01])],\n",
       " [0.0086032071297443592,\n",
       "  0.068671679202273739,\n",
       "  0.12528027899832547,\n",
       "  0.41971576515162418,\n",
       "  array([  8.93085870e-18,   1.34895252e-01,   0.00000000e+00,\n",
       "           3.29608332e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.32143915e-01])],\n",
       " [0.0086109305631930106,\n",
       "  0.068922305764410996,\n",
       "  0.12493677435323683,\n",
       "  0.41934593549752192,\n",
       "  array([ 0.        ,  0.13366084,  0.        ,  0.03266238,  0.3       ,\n",
       "          0.3       ,  0.23367677])],\n",
       " [0.0086186384647247635,\n",
       "  0.069172932330845524,\n",
       "  0.12459553432696606,\n",
       "  0.41897665675942908,\n",
       "  array([  2.10899434e-17,   1.32428914e-01,   0.00000000e+00,\n",
       "           3.23645372e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.35206549e-01])],\n",
       " [0.0086263310933566966,\n",
       "  0.069423558897385468,\n",
       "  0.12425653813148968,\n",
       "  0.41860792332742602,\n",
       "  array([  1.55858087e-16,   1.31199427e-01,   0.00000000e+00,\n",
       "           3.20672800e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.36733293e-01])],\n",
       " [0.0086340087021671737,\n",
       "  0.069674185463665092,\n",
       "  0.12391976518577008,\n",
       "  0.4182397297569167,\n",
       "  array([  7.35868412e-17,   1.29972341e-01,   1.11717707e-16,\n",
       "           3.17706027e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.38257056e-01])],\n",
       " [0.0086416715404981255,\n",
       "  0.069924812030113151,\n",
       "  0.12358519514899212,\n",
       "  0.41787207075910826,\n",
       "  array([ 0.        ,  0.12874762,  0.        ,  0.0314745 ,  0.3       ,\n",
       "          0.3       ,  0.23977789])],\n",
       " [0.0086493198475855442,\n",
       "  0.070175438597737866,\n",
       "  0.12325280782590448,\n",
       "  0.41750494122132192,\n",
       "  array([  1.55469807e-16,   1.27525212e-01,   8.15653506e-17,\n",
       "           3.11789517e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.41295836e-01])],\n",
       " [0.008656953861721637,\n",
       "  0.070426065163170071,\n",
       "  0.12292258330299088,\n",
       "  0.41713833617323665,\n",
       "  array([  0.00000000e+00,   1.26305094e-01,   5.41549414e-18,\n",
       "           3.08839592e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.42810947e-01])],\n",
       " [0.0086645738129747327,\n",
       "  0.070676691729620822,\n",
       "  0.12259450182136047,\n",
       "  0.41677225079600033,\n",
       "  array([ 0.        ,  0.12508722,  0.        ,  0.03058951,  0.3       ,\n",
       "          0.3       ,  0.24432327])],\n",
       " [0.0086721803974972173,\n",
       "  0.070927318295867611,\n",
       "  0.12226855048039337,\n",
       "  0.41640667862696512,\n",
       "  array([ 0.        ,  0.12387131,  0.        ,  0.0302959 ,  0.3       ,\n",
       "          0.3       ,  0.24583279])],\n",
       " [0.0086797724231926585,\n",
       "  0.071177944862156228,\n",
       "  0.12194469003006443,\n",
       "  0.41604162050937993,\n",
       "  array([  1.13186806e-16,   1.22658080e-01,   2.55813975e-17,\n",
       "           3.00022079e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.47339712e-01])],\n",
       " [0.0086873515046131215,\n",
       "  0.071428571428588605,\n",
       "  0.12162292106455445,\n",
       "  0.41567706671889809,\n",
       "  array([ 0.        ,  0.12144675,  0.        ,  0.02970933,  0.3       ,\n",
       "          0.3       ,  0.24884392])],\n",
       " [0.0086949174836563684,\n",
       "  0.071679197996537769,\n",
       "  0.12130321943719778,\n",
       "  0.41531301439568885,\n",
       "  array([ 0.        ,  0.12023747,  0.        ,  0.02941702,  0.3       ,\n",
       "          0.3       ,  0.25034551])],\n",
       " [0.0087024703331033612,\n",
       "  0.071929824561403483,\n",
       "  0.12098556316753457,\n",
       "  0.41494946027865004,\n",
       "  array([  1.58069025e-16,   1.19030350e-01,   7.49309284e-17,\n",
       "           2.91251187e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.51844532e-01])],\n",
       " [0.008710010461925613,\n",
       "  0.072180451127819609,\n",
       "  0.12066993660792766,\n",
       "  0.41458639956602167,\n",
       "  array([  0.00000000e+00,   1.17825236e-01,   3.77272468e-16,\n",
       "           2.88337542e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.53341009e-01])],\n",
       " [0.0087175380013005972,\n",
       "  0.072431077694235638,\n",
       "  0.12035632050238533,\n",
       "  0.41422382860627727,\n",
       "  array([ 0.        ,  0.11662214,  0.        ,  0.02854288,  0.3       ,\n",
       "          0.3       ,  0.25483499])],\n",
       " [0.0087250531433444509,\n",
       "  0.072681704260686555,\n",
       "  0.12004469669630217,\n",
       "  0.41386174361628375,\n",
       "  array([  4.86147988e-17,   1.15421015e-01,   2.32480784e-17,\n",
       "           2.82524772e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.56326508e-01])],\n",
       " [0.0087325560759818881,\n",
       "  0.072932330827111327,\n",
       "  0.11973504722730885,\n",
       "  0.41350014092413279,\n",
       "  array([ 0.        ,  0.11422185,  0.        ,  0.02796255,  0.3       ,\n",
       "          0.3       ,  0.2578156 ])],\n",
       " [0.0087400469830535843,\n",
       "  0.073182957393549145,\n",
       "  0.11942735432312541,\n",
       "  0.41313901696539479,\n",
       "  array([ 0.        ,  0.1130246 ,  0.        ,  0.02767309,  0.3       ,\n",
       "          0.3       ,  0.25930231])],\n",
       " [0.0087475260444851276,\n",
       "  0.07343358396013791,\n",
       "  0.11912160040062274,\n",
       "  0.4127783682795228,\n",
       "  array([ 0.        ,  0.11182925,  0.        ,  0.02738408,  0.3       ,\n",
       "          0.3       ,  0.26078667])],\n",
       " [0.0087549934362183522,\n",
       "  0.073684210528766184,\n",
       "  0.11881776805901202,\n",
       "  0.41241819150502912,\n",
       "  array([  2.67619939e-16,   1.10635759e-01,   1.83024111e-16,\n",
       "           2.70955288e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.62268712e-01])],\n",
       " [0.0087624493332024104,\n",
       "  0.073934837092731825,\n",
       "  0.11851584013382244,\n",
       "  0.41205848337980211,\n",
       "  array([  7.86796616e-18,   1.09444108e-01,   0.00000000e+00,\n",
       "           2.68074209e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.63748471e-01])],\n",
       " [0.008769893896431501,\n",
       "  0.074185463659147924,\n",
       "  0.11821579948230292,\n",
       "  0.4116992407547489,\n",
       "  array([  9.52317429e-17,   1.08254269e-01,   0.00000000e+00,\n",
       "           2.65197475e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.65225983e-01])],\n",
       " [0.0087773272986842923,\n",
       "  0.074436090225564119,\n",
       "  0.11791762936616239,\n",
       "  0.41134046053074463,\n",
       "  array([  1.68674300e-16,   1.07066214e-01,   0.00000000e+00,\n",
       "           2.62325071e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.66701279e-01])],\n",
       " [0.0087847496991214323,\n",
       "  0.074686716791981758,\n",
       "  0.11762131308554921,\n",
       "  0.41098213973050957,\n",
       "  array([  3.37536287e-16,   1.05879916e-01,   1.51343232e-16,\n",
       "           2.59456918e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.68174392e-01])],\n",
       " [0.0087921612561062887,\n",
       "  0.074937343358408112,\n",
       "  0.11732683415337264,\n",
       "  0.41062427545385688,\n",
       "  array([  6.29124246e-17,   1.04695352e-01,   0.00000000e+00,\n",
       "           2.56592955e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.69645352e-01])],\n",
       " [0.008799562124752849,\n",
       "  0.075187969924854714,\n",
       "  0.11703417625914646,\n",
       "  0.41026686488409142,\n",
       "  array([  0.00000000e+00,   1.03512496e-01,   1.53835985e-16,\n",
       "           2.53733123e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.71114191e-01])],\n",
       " [0.0088069524570074074,\n",
       "  0.075438596491311946,\n",
       "  0.11674332326717769,\n",
       "  0.40990990528550975,\n",
       "  array([  0.00000000e+00,   1.02331325e-01,   2.59837136e-17,\n",
       "           2.50877362e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.72580939e-01])],\n",
       " [0.0088143324017315016,\n",
       "  0.075689223057681457,\n",
       "  0.11645425921487199,\n",
       "  0.40955339400102708,\n",
       "  array([  4.08205724e-16,   1.01151813e-01,   2.27200862e-16,\n",
       "           2.48025615e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.74045626e-01])],\n",
       " [0.0088217021048056458,\n",
       "  0.075939849624064318,\n",
       "  0.11616696831080064,\n",
       "  0.40919732844933976,\n",
       "  array([  4.46660583e-17,   9.99739381e-02,   0.00000000e+00,\n",
       "           2.45177825e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.75508279e-01])],\n",
       " [0.0088290617092654407,\n",
       "  0.076190476190476461,\n",
       "  0.1158814349341085,\n",
       "  0.40884170612280407,\n",
       "  array([  3.52915803e-17,   9.87976774e-02,   0.00000000e+00,\n",
       "           2.42333938e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.76968929e-01])],\n",
       " [0.0088364113551529701,\n",
       "  0.076441102756892393,\n",
       "  0.11559764362970583,\n",
       "  0.40848652458592039,\n",
       "  array([  2.47005582e-17,   9.76230083e-02,   2.82117224e-17,\n",
       "           2.39493899e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.78427602e-01])],\n",
       " [0.0088437511798794919,\n",
       "  0.076691729323845825,\n",
       "  0.1153155791093851,\n",
       "  0.40813178147140938,\n",
       "  array([  7.60998658e-18,   9.64499088e-02,   0.00000000e+00,\n",
       "           2.36657655e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.79884326e-01])],\n",
       " [0.0088510813671018578,\n",
       "  0.076942355891457398,\n",
       "  0.11503522688580112,\n",
       "  0.40777747431749684,\n",
       "  array([  2.20967840e-16,   9.52783311e-02,   0.00000000e+00,\n",
       "           2.33825470e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.81339122e-01])],\n",
       " [0.0088584019211636455,\n",
       "  0.077192982457280013,\n",
       "  0.11475657034065298,\n",
       "  0.40742360131772809,\n",
       "  array([  0.00000000e+00,   9.41083229e-02,   7.79912458e-17,\n",
       "           2.30996470e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.82792030e-01])],\n",
       " [0.0088657130518515741,\n",
       "  0.077443609023373355,\n",
       "  0.11447959571687577,\n",
       "  0.40707016003112018,\n",
       "  array([ 0.        ,  0.09293982,  0.        ,  0.02281711,  0.3       ,\n",
       "          0.3       ,  0.28424307])],\n",
       " [0.0088730149059059685,\n",
       "  0.077694235590152358,\n",
       "  0.11420428862589403,\n",
       "  0.40671714828397909,\n",
       "  array([  1.97055238e-16,   9.17727921e-02,   0.00000000e+00,\n",
       "           2.25349505e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.85692257e-01])],\n",
       " [0.0088803076029320017,\n",
       "  0.077944862157727821,\n",
       "  0.11393063451651209,\n",
       "  0.40636456404426907,\n",
       "  array([  0.00000000e+00,   9.06072213e-02,   1.64000941e-16,\n",
       "           2.22531538e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.87139625e-01])],\n",
       " [0.0088875912414712061,\n",
       "  0.078195488721913328,\n",
       "  0.11365861876096399,\n",
       "  0.40601240540334166,\n",
       "  array([  1.30898190e-16,   8.94431010e-02,   0.00000000e+00,\n",
       "           2.19717023e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.88585197e-01])],\n",
       " [0.0088948659292864465,\n",
       "  0.078446115288464319,\n",
       "  0.11338822702154197,\n",
       "  0.40566067045698334,\n",
       "  array([ 0.        ,  0.08828042,  0.        ,  0.02169058,  0.3       ,\n",
       "          0.3       ,  0.290029  ])],\n",
       " [0.0089021318364660377,\n",
       "  0.078696741854816982,\n",
       "  0.11311944594719131,\n",
       "  0.40530935715994326,\n",
       "  array([  4.07518050e-17,   8.71191270e-02,   0.00000000e+00,\n",
       "           2.14098263e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.91471047e-01])],\n",
       " [0.008909388892796315,\n",
       "  0.078947368421187269,\n",
       "  0.11285225930856087,\n",
       "  0.40495846427379023,\n",
       "  array([  0.00000000e+00,   8.59593082e-02,   1.32901842e-16,\n",
       "           2.11293070e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.92911385e-01])],\n",
       " [0.0089166375382685719,\n",
       "  0.079197994987657352,\n",
       "  0.11258665752407229,\n",
       "  0.40460798898590961,\n",
       "  array([ 0.        ,  0.08480077,  0.        ,  0.02084923,  0.3       ,\n",
       "          0.3       ,  0.29435   ])],\n",
       " [0.0089238776653162485,\n",
       "  0.079448621554183432,\n",
       "  0.11232262424125537,\n",
       "  0.40425793026407492,\n",
       "  array([  1.48080403e-16,   8.36436049e-02,   0.00000000e+00,\n",
       "           2.05694550e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.95786940e-01])],\n",
       " [0.0089311094073134794,\n",
       "  0.079699248120743346,\n",
       "  0.11206014633642418,\n",
       "  0.40390828635277826,\n",
       "  array([  6.32232386e-17,   8.24877905e-02,   6.64266726e-17,\n",
       "           2.02899883e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.97222221e-01])],\n",
       " [0.0089383328779835663,\n",
       "  0.079949874687300873,\n",
       "  0.11179921060468302,\n",
       "  0.40355905559997157,\n",
       "  array([  0.00000000e+00,   8.13333034e-02,   8.50829882e-17,\n",
       "           2.00108317e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.98655865e-01])],\n",
       " [0.0089463943705998961,\n",
       "  0.080200501253140238,\n",
       "  0.11155035480840715,\n",
       "  0.40320764580079749,\n",
       "  array([  0.00000000e+00,   7.97222472e-02,   2.83100577e-17,\n",
       "           2.02777528e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.0089668445240240705,\n",
       "  0.080451127819548857,\n",
       "  0.11145703941076651,\n",
       "  0.40282112221513844,\n",
       "  array([  8.53285360e-17,   7.13352625e-02,   0.00000000e+00,\n",
       "           2.86647375e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.0089863747503970987,\n",
       "  0.080701754385964913,\n",
       "  0.11135290451579014,\n",
       "  0.40244190230146165,\n",
       "  array([  0.00000000e+00,   6.33255569e-02,   3.27198349e-17,\n",
       "           3.66744431e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.0090051060913042928,\n",
       "  0.080952380952380928,\n",
       "  0.11123954583375895,\n",
       "  0.4020690373233573,\n",
       "  array([ 0.        ,  0.05564349,  0.        ,  0.04435651,  0.3       ,\n",
       "          0.3       ,  0.3       ])],\n",
       " [0.0090231354367305439,\n",
       "  0.081203007519436335,\n",
       "  0.11111824195145498,\n",
       "  0.40170176651003536,\n",
       "  array([ 0.        ,  0.04824932,  0.        ,  0.05175068,  0.3       ,\n",
       "          0.3       ,  0.3       ])],\n",
       " [0.0090405417661875136,\n",
       "  0.081453634085214471,\n",
       "  0.11099003583719244,\n",
       "  0.40133946869447923,\n",
       "  array([ 0.        ,  0.04111067,  0.        ,  0.05888933,  0.3       ,\n",
       "          0.3       ,  0.3       ])],\n",
       " [0.0090573904592823884,\n",
       "  0.081704260651727992,\n",
       "  0.11085579120396619,\n",
       "  0.4009816288664107,\n",
       "  array([  5.42311213e-17,   3.42007064e-02,   1.44495316e-16,\n",
       "           6.57992936e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.0090737363576742103,\n",
       "  0.081954887218045322,\n",
       "  0.11071623262116211,\n",
       "  0.40062781439784889,\n",
       "  array([ 0.        ,  0.02749695,  0.        ,  0.07250305,  0.3       ,\n",
       "          0.3       ,  0.3       ])],\n",
       " [0.0090896259949615355,\n",
       "  0.082205513784478351,\n",
       "  0.11057197475575896,\n",
       "  0.4002776577018895,\n",
       "  array([  1.71940409e-16,   2.09803194e-02,   0.00000000e+00,\n",
       "           7.90196806e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.0091050992544006223,\n",
       "  0.0824561403508772,\n",
       "  0.11042354414911391,\n",
       "  0.39993084333136247,\n",
       "  array([ 0.        ,  0.01463445,  0.        ,  0.08536555,  0.3       ,\n",
       "          0.3       ,  0.3       ])],\n",
       " [0.0091201906245810763,\n",
       "  0.082706766917455529,\n",
       "  0.11027139573335482,\n",
       "  0.3995870981938619,\n",
       "  array([  0.00000000e+00,   8.44520175e-03,   1.19514265e-16,\n",
       "           9.15547982e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009134930165980935,\n",
       "  0.082957393484504635,\n",
       "  0.11011592556469631,\n",
       "  0.39924618401243384,\n",
       "  array([ 0.        ,  0.00240024,  0.        ,  0.09759976,  0.3       ,\n",
       "          0.3       ,  0.3       ])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_activeM_pair.sort(key= lambda x: x[0])\n",
    "frontier_activeM_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Construction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean variance opt based over post BL and target peer return \n",
    "\n",
    "benchmark_portfolio= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(), \n",
    "                               asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                               weight= portfolios['Peer'].weight)\n",
    "\n",
    "base_portfolio_w= sorted( [x for x in frontier_BLcons_pair if x[0]>= 7/100], key= lambda x: x[0]) [0]\n",
    "base_portfolio= Portfolio(asset_ret= benchmark_portfolio.asset_return,\n",
    "                         asset_cov= benchmark_portfolio.asset_cov,\n",
    "                         weight= base_portfolio_w[2], benchmark_portfolio= benchmark_portfolio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064955163370140942"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12428132380236374"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13861386,  0.28712871,  0.04950495,  0.23762376,  0.02970297,\n",
       "        0.20792079,  0.04950495])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06587897,  0.3       ,  0.        ,  0.16750796,  0.14351206,\n",
       "        0.19808016,  0.12502085])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_portfolio.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.070036989782269826"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_portfolio.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14634601282081675"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_portfolio.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47857121921060997"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_portfolio.SharpeRatio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07273489,  0.01287129, -0.04950495, -0.0701158 ,  0.11380909,\n",
       "       -0.00984063,  0.0755159 ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_portfolio.active_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1940349642689558"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_portfolio.DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2385642471555851"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47857121921060997"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_portfolio.SharpeRatio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52264621411206391"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.SharpeRatio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base_portfolio achieves similar return as bechmark with smaller vol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For display purpose \n",
    "\n",
    "\n",
    "writter= pd.ExcelWriter('output_wz3.xlsx')\n",
    "tmp_df1= pd.DataFrame(   [[x[0], x[1]]+ x[2].tolist()  for x in frontier_uncons_pair], \n",
    "                      columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name']  )\n",
    "tmp_df2= pd.DataFrame(  [[x[0], x[1]]+ x[2].tolist()  for x in frontier_uncons_NoCorp_pair], \n",
    "                     columns=  ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df3= pd.DataFrame(  [[x[0], x[1]]+ x[2].tolist()  for x in frontier_cons_pair], \n",
    "                     columns=  ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df4= pd.DataFrame(  [[x[0], x[1]]+ x[2].tolist()  for x in frontier_cons_NoCorp_pair], \n",
    "                     columns=  ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df5= pd.DataFrame( [[x[0], x[1]]+ x[2].tolist() for x in frontier_BLuncons_pair], \n",
    "                     columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df6= pd.DataFrame( [[x[0], x[1]]+ x[2].tolist() for x in frontier_BLuncons_NoCorp_pair],\n",
    "                     columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df7= pd.DataFrame( [[x[0], x[1]]+ x[2].tolist() for x in frontier_BLcons_pair], \n",
    "                     columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df8= pd.DataFrame( [[x[0], x[1]]+ x[2].tolist() for x in frontier_BLcons_NoCorp_pair],\n",
    "                     columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "\n",
    "frontier_activeM_pair.sort(key= lambda x: x[0])\n",
    "tmp_df9= pd.DataFrame(  [[x[0], x[1], x[2], x[3]]+ x[4].tolist() for x in frontier_activeM_pair], \n",
    "                     columns= ['active_ExpReturn', 'trackingError', 'IR', 'SR']+ UniverseProperty['asset_name'])\n",
    "\n",
    "tmp_df1.to_excel( writter, 'UNCONS')\n",
    "tmp_df2.to_excel( writter, 'UNCONS_NoCorp')\n",
    "tmp_df3.to_excel( writter, 'CONS')\n",
    "tmp_df4.to_excel( writter, 'CONS_NoCorp')\n",
    "tmp_df5.to_excel( writter, 'BL_UNCONS')\n",
    "tmp_df6.to_excel( writter, 'BL_UNCONS_NoCorp')\n",
    "tmp_df7.to_excel( writter, 'BL_CONS')\n",
    "tmp_df8.to_excel( writter,  'BL_CONS_NoCorp')\n",
    "tmp_df9.to_excel( writter, 'BL_activeOpt')\n",
    "writter.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xc2f1cc0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrHjtrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc3d3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp=pd.read_excel( io= 'Data/cipc data1.xlsx', sheetname= 'Sheet4', index= False)\n",
    "tmp_rollingmax= tmp.rolling(window= tmp.shape[0], min_periods= 1, center= False).max()\n",
    "tmp_rollingmaxdd= -(tmp-tmp_rollingmax)/tmp_rollingmax\n",
    "tmp_rollingmaxdd[tmp_rollingmaxdd<0]=0\n",
    "\n",
    "\n",
    "tmp_rollingmaxdd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peer</th>\n",
       "      <th>IAS MVO</th>\n",
       "      <th>Blended MVO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.049610</td>\n",
       "      <td>0.041823</td>\n",
       "      <td>0.046130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090567</td>\n",
       "      <td>0.083599</td>\n",
       "      <td>0.087714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.059917</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>0.051216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.402530</td>\n",
       "      <td>0.406772</td>\n",
       "      <td>0.413504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Peer     IAS MVO  Blended MVO\n",
       "count  115.000000  115.000000   115.000000\n",
       "mean     0.049610    0.041823     0.046130\n",
       "std      0.090567    0.083599     0.087714\n",
       "min     -0.000000   -0.000000    -0.000000\n",
       "25%     -0.000000   -0.000000    -0.000000\n",
       "50%     -0.000000   -0.000000    -0.000000\n",
       "75%      0.059917    0.028696     0.051216\n",
       "max      0.402530    0.406772     0.413504"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_rollingmaxdd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
