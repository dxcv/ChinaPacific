{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "%pylab\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "import scipy.optimize\n",
    "from pandas import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates portfolio mean return\n",
    "def port_mean(W, R):\n",
    "    return sum(R * W)\n",
    "\n",
    "# Calculates portfolio variance of returns\n",
    "def port_var(W, C):\n",
    "    return dot(dot(W, C), W)\n",
    "\n",
    "# Combination of the two functions above - mean and variance of returns calculation\n",
    "def port_mean_var(W, R, C):\n",
    "    return port_mean(W, R), port_var(W, C)\n",
    "\n",
    "def conv_arithtogeo(R, C):\n",
    "    return R - .5* np.diag(C)\n",
    "\n",
    "def conv_geotoarith(R, C):\n",
    "    return R + .5* np.diag(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given risk-free rate, assets returns and covariances, this function calculates\n",
    "# mean-variance frontier and returns its [x,y] points in two arrays\n",
    "#assumes corp is the 3rd asset\n",
    "def solve_frontier(numPort,R, C, limit, exclcorp, isAnnual):\n",
    "    def fitness(W, R, C, r):\n",
    "        # For given level of return r, find weights which minimizes portfolio variance.\n",
    "        mean, var = port_mean_var(W, R, C)\n",
    "        penalty = 100 * abs(\n",
    "            mean - r)  # Big penalty for not meeting stated portfolio return effectively serves as optimization constraint\n",
    "        return var + penalty\n",
    "\n",
    "    frontier_mean, frontier_var = [], []\n",
    "    frontier_wts = {}\n",
    "    frontier_wts[0] = []\n",
    "    n = len(R)  # Number of assets in the portfolio\n",
    "    if not isAnnual:\n",
    "        R = R * 4\n",
    "        C = C * 4\n",
    " \n",
    "    RGeo = R\n",
    "    R = conv_geotoarith(R, C)\n",
    "    if exclcorp: \n",
    "        Rtemp = np.delete(R, 2, 0)\n",
    "        minR = min(Rtemp)\n",
    "    else:\n",
    "        minR = min(R)\n",
    "    for r in linspace(minR, max(R), numPort):  # Iterate through the range of returns on Y axis\n",
    "        W = ones([n]) / n  # start optimization with equal weights\n",
    "       \n",
    "        #if limit:\n",
    "        if exclcorp:\n",
    "            #b_ = [(0, 1) for i in range(n)]\n",
    "            b_ = [[0,limit],[0,limit],[0,0.0000001]]+[[0, limit]]*(n-3)\n",
    "        else:\n",
    "            b_ = [[0,limit]]*(n)\n",
    "        #else:\n",
    "        #    if exclcorp:\n",
    "        #        b_ = [[0,None],[0,None],[0,0.0000001]]+[[0, None]]*(n-3)\n",
    "        #    else:\n",
    "        #        b_ = [[0, None]]*(n)\n",
    "        c_ = ({'type': 'eq', 'fun': lambda W: sum(W) - 1.})\n",
    "        optimized = scipy.optimize.minimize(fitness, W, (R, C, r), method='SLSQP', constraints=c_, bounds=b_)\n",
    "        #if not optimized.success:\n",
    "        #    raise BaseException(optimized.message)\n",
    "        # add point to the efficient frontier [x,y] = [optimized.x, r]\n",
    "        r = port_mean(optimized.x,RGeo)\n",
    "        frontier_mean.append(r)\n",
    "        frontier_var.append(np.sqrt(port_var(optimized.x, C)))\n",
    "        frontier_wts[0].append(np.array(optimized.x).tolist())\n",
    "    return array(frontier_mean), array(frontier_var), array(frontier_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_CORP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "      <th>Cash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.035495</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.047757</td>\n",
       "      <td>0.070263</td>\n",
       "      <td>0.026435</td>\n",
       "      <td>0.076253</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.091792</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>0.006670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.333429</td>\n",
       "      <td>-0.214401</td>\n",
       "      <td>-0.083766</td>\n",
       "      <td>-0.219432</td>\n",
       "      <td>-0.261180</td>\n",
       "      <td>-0.211290</td>\n",
       "      <td>-0.275584</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.007742</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>-0.030336</td>\n",
       "      <td>-0.016548</td>\n",
       "      <td>-0.043980</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.031222</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>0.038349</td>\n",
       "      <td>0.008214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>0.034229</td>\n",
       "      <td>0.070468</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.066656</td>\n",
       "      <td>0.111489</td>\n",
       "      <td>0.013101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137135</td>\n",
       "      <td>0.264363</td>\n",
       "      <td>0.113356</td>\n",
       "      <td>0.212974</td>\n",
       "      <td>0.297346</td>\n",
       "      <td>0.258489</td>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.023825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            US_RE       US_PE     US_CORP       SP500  Rusell2000        EAFE  \\\n",
       "count  114.000000  114.000000  114.000000  114.000000  114.000000  114.000000   \n",
       "mean     0.018989    0.035495    0.018274    0.027670    0.028452    0.017290   \n",
       "std      0.047757    0.070263    0.026435    0.076253    0.099660    0.091792   \n",
       "min     -0.333429   -0.214401   -0.083766   -0.219432   -0.261180   -0.211290   \n",
       "25%      0.007742    0.004679    0.000719   -0.001749   -0.030336   -0.016548   \n",
       "50%      0.018845    0.037985    0.017305    0.031222    0.037918    0.017968   \n",
       "75%      0.035783    0.069509    0.034229    0.070468    0.088459    0.066656   \n",
       "max      0.137135    0.264363    0.113356    0.212974    0.297346    0.258489   \n",
       "\n",
       "               EM        Cash  \n",
       "count  114.000000  114.000000  \n",
       "mean     0.032061    0.008155  \n",
       "std      0.128686    0.006670  \n",
       "min     -0.275584    0.000000  \n",
       "25%     -0.043980    0.000726  \n",
       "50%      0.038349    0.008214  \n",
       "75%      0.111489    0.013101  \n",
       "max      0.348433    0.023825  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in data\n",
    "ret_df_raw= pd.read_excel( io= 'cipc data1.xlsx', sheetname= 'Data_Input', index_col=0)\n",
    "ret_df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cov2corr(cov, return_std=False):\n",
    "    '''convert covariance matrix to correlation matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cov : array_like, 2d\n",
    "        covariance matrix, see Notes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corr : ndarray (subclass)\n",
    "        correlation matrix\n",
    "    return_std : bool\n",
    "        If this is true then the standard deviation is also returned.\n",
    "        By default only the correlation matrix is returned.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function does not convert subclasses of ndarrays. This requires\n",
    "    that division is defined elementwise. np.ma.array and np.matrix are allowed.\n",
    "\n",
    "    '''\n",
    "    cov = np.asanyarray(cov)\n",
    "    std_ = np.sqrt(np.diag(cov))\n",
    "    corr = cov / np.outer(std_, std_)\n",
    "    if return_std:\n",
    "        return corr, std_\n",
    "    else:\n",
    "        return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_df= ret_df_raw[['US_RE', \n",
    "                   'US_PE',\n",
    "                   'US_CORP',\n",
    "                   'SP500',\n",
    "                   'Rusell2000',\n",
    "                   'EAFE',\n",
    "                   'EM']]\n",
    "                   #'USGOVT10Y']]\n",
    "ret_df_cov= ret_df.cov()\n",
    "ret_df_corr= ret_df.corr()\n",
    "N= ret_df.shape[1]\n",
    "#ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Ledoit Wolf shrunk cov matrix\n",
    "\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "LW= LedoitWolf( ).fit(ret_df)\n",
    "LW_alpha= LW.shrinkage_\n",
    "\n",
    "LW_cov= pd.DataFrame(LW.covariance_)\n",
    "LW_cov.index= ret_df_cov.index\n",
    "LW_cov.columns= ret_df_cov.columns\n",
    "LW_cov\n",
    "\n",
    "LW_corr = pd.DataFrame(cov2corr(LW_cov))\n",
    "LW_corr.index= ret_df_cov.index\n",
    "LW_corr.columns= ret_df_cov.columns\n",
    "LW_corr\n",
    "\n",
    "\n",
    "LW_cov_active = LW_cov + np.diag( np.array([0, 0, 0.0004, 0.0009, 0.0009, 0.0009, 0.0009]))/4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09967199,  0.1412755 ,  0.06296121,  0.15254828,  0.1970037 ,\n",
       "        0.18200475,  0.25263504])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.diagonal(np.matrix(LW_cov.values)))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_eq= np.ones( (7,))*1.0/7\n",
    "weight_peer= np.array( (0.138,0.287,0.046,0.238,0.026,0.211,0.046))\n",
    "weight_peer= weight_peer/ np.sum(weight_peer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 11\n",
      "         Function evaluations: 1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:394: RuntimeWarning: Method Powell cannot handle constraints nor bounds.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "## solve ERC weight \n",
    "\n",
    "def objective_func(w, sigma): \n",
    "    A= np.diag( w)\n",
    "    B= np.diag( np.dot( sigma, w))\n",
    "    C= np.diag( np.dot( A, B))/ np.dot( np.dot( w, sigma), w)- np.ones( w.size )* 1/ w.size\n",
    "    \n",
    "    return np.dot( C, C)\n",
    "\n",
    "\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "opt_res= minimize( objective_func, \n",
    "                 x0= weight_eq,\n",
    "                 args= LW_cov,\n",
    "                 method= 'Powell',\n",
    "                 options= {'disp': True},\n",
    "                 bounds= [[0,None]]*7,\n",
    "                 tol= 1e-16)\n",
    "\n",
    "weight_erc = opt_res.x/ np.sum( opt_res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4589696100701789e-23"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_func( weight_erc, LW_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_CORP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.139113</td>\n",
       "      <td>0.289315</td>\n",
       "      <td>0.046371</td>\n",
       "      <td>0.239919</td>\n",
       "      <td>0.026210</td>\n",
       "      <td>0.212702</td>\n",
       "      <td>0.046371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.206808</td>\n",
       "      <td>0.105522</td>\n",
       "      <td>0.403146</td>\n",
       "      <td>0.085036</td>\n",
       "      <td>0.067863</td>\n",
       "      <td>0.074384</td>\n",
       "      <td>0.057241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                US_RE     US_PE   US_CORP     SP500  Rusell2000      EAFE  \\\n",
       "weight_eq    0.142857  0.142857  0.142857  0.142857    0.142857  0.142857   \n",
       "weight_peer  0.139113  0.289315  0.046371  0.239919    0.026210  0.212702   \n",
       "weight_erc   0.206808  0.105522  0.403146  0.085036    0.067863  0.074384   \n",
       "\n",
       "                   EM  \n",
       "weight_eq    0.142857  \n",
       "weight_peer  0.046371  \n",
       "weight_erc   0.057241  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_1= pd.DataFrame( [weight_eq, weight_peer, weight_erc], \n",
    "                             index=['weight_eq', 'weight_peer', 'weight_erc'], \n",
    "                             columns= LW_cov. columns)\n",
    "portf_weight_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf= 179/10000\n",
    "gamma= [3.5]\n",
    "implied_ExpRet= {}\n",
    "\n",
    "for w_name in portf_weight_1.index: \n",
    "    tmp_dic= {}\n",
    "    for g in gamma:\n",
    "        w= np.array(portf_weight_1.loc[w_name].tolist())\n",
    "        tmp1= np.ones( ( N))* rf/4+ g*  np.dot( LW_cov, w)\n",
    "        tmp2= np.ones( (N))*rf/4+ g* np.dot( ret_df_cov,w) \n",
    "        tmp_dic[str(g)+ '_shrunk']= tmp1\n",
    "        #tmp_dic[str(g)+'_unshrunk']= tmp2\n",
    "    \n",
    "    \n",
    "    tmp= pd.DataFrame( tmp_dic, index= LW_cov.index)\n",
    "    tmp= tmp- .5* np.array([np.diag(LW_cov).tolist()] *tmp.shape[1]).T\n",
    "    implied_ExpRet[w_name]= tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3.5_shrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.007747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.014875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_CORP</th>\n",
       "      <td>0.004943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.016438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.017493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.017475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.016920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            3.5_shrunk\n",
       "US_RE         0.007747\n",
       "US_PE         0.014875\n",
       "US_CORP       0.004943\n",
       "SP500         0.016438\n",
       "Rusell2000    0.017493\n",
       "EAFE          0.017475\n",
       "EM            0.016920"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_peer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## mean variance optimization, constuct efficient fronter \n",
    "\n",
    "CMA_ExpRet_geo= np.array( [700, 880, 325, 821, 906, 807, 903]) /10000 /4 #quarterly expected exponential ret \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[fm, fv, fw] = solve_frontier(100,CMA_ExpRet_geo, LW_cov_active, 1, 1, 0)\n",
    "\n",
    "[fm1, fv1, fw1] = solve_frontier(100,CMA_ExpRet_geo, LW_cov_active, 0.3, 1, 0)\n",
    "\n",
    "[fm2, fv2, fw2] = solve_frontier(100,CMA_ExpRet_geo, LW_cov_active, 1, 0, 0)\n",
    "\n",
    "[fm3, fv3, fw3] = solve_frontier(100,CMA_ExpRet_geo, LW_cov_active, 0.3, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer= pd.ExcelWriter('output_exclcorp_unconst.xlsx') \n",
    "# a = fw.tolist()\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet1')\n",
    "# a = fm\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet2')\n",
    "# a = fv\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet3')\n",
    "# writer.save() \n",
    "\n",
    "# writer= pd.ExcelWriter('output_exclcorp_const.xlsx') \n",
    "# a = fw1.tolist()\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet1')\n",
    "# a = fm1\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet2')\n",
    "# a = fv1\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet3')\n",
    "# writer.save() \n",
    "\n",
    "# writer= pd.ExcelWriter('output_inclcorp_unconst.xlsx') \n",
    "# a = fw2.tolist()\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet1')\n",
    "# a = fm2\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet2')\n",
    "# a = fv2\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet3')\n",
    "# writer.save() \n",
    "\n",
    "# writer= pd.ExcelWriter('output_inclcorp_const.xlsx') \n",
    "# a = fw3.tolist()\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet1')\n",
    "# a = fm3\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet2')\n",
    "# a = fv3\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet3')\n",
    "# writer.save() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Black-Litterman Framework \n",
    "\n",
    "Construct BL framework to incorporate benchmark(prior) and views(observations) and produce a reasonable distribution of expected return (posterior). \n",
    "Apply mean-variance optimization based on posterior to achieve optimal allocation. \n",
    "\n",
    "#### Benckmark/Equilibrium Portfolio\n",
    "\n",
    "Set the benchmark as peer holding `w_peer`, then `iRet_peer_3.5` is the implied equilibrium\\benchmark expected return, given risk aversion factor 3.5.\n",
    "\n",
    "#### The prior confidence  $\\tau$\n",
    "\n",
    "Follow BL's initial setting, $\\tau = 0.05$\n",
    "\n",
    "#### Views\n",
    "\n",
    "`CMA_active` is the subjective view to expected return of each asset. The confidence is proportional to view portfolio (prior) variance with multiplier $\\tau$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### As summary, input: \n",
    "\n",
    "$\\tau$\n",
    "\n",
    "prior expected ret distribution, assuming normal, so the prior mean and variance \n",
    "\n",
    "views, the view portfolio weight, asserted expected ret, and view confidence. \n",
    "\n",
    "#### output: \n",
    "\n",
    "the posterior distribution, mean and variance of post expected return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ExpRet=  implied_ExpRet['weight_peer'][['3.5_shrunk']].T\n",
    "ExpRet.index= ['iRet_peer_3.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## prepare input\n",
    "\n",
    "\n",
    "tau = 5e-2\n",
    "prior_cov= LW_cov* tau\n",
    "prior_cov_inv= np.linalg.inv(prior_cov)\n",
    "prior_mean= ExpRet.loc['iRet_peer_3.5']+ 0.5* np.diag(LW_cov)\n",
    "\n",
    "# CMA_ExpRet_active_arith \n",
    "# is the asserted expected return \n",
    "view_w= np.identity(N)\n",
    "\n",
    "view_ExpRet= conv_geotoarith(CMA_ExpRet_geo,LW_cov_active)\n",
    "view_cov= ( (LW_cov_active)* tau * 2)\n",
    "view_cov_inv= np.linalg.inv( view_cov)\n",
    "\n",
    "##  output: post \n",
    "\n",
    "A= prior_cov_inv\n",
    "B= np.dot( np.dot(view_w.T, view_cov_inv), view_w)\n",
    "C= np.dot(prior_cov_inv, prior_mean)\n",
    "D= np.dot(np.dot(view_w.T, view_cov_inv), view_ExpRet)\n",
    "\n",
    "post_mean_arith= pd.DataFrame( np.dot(np.linalg.inv( A+B), C+D), index=LW_cov.index, columns= ['post_ExpRet']) .T\n",
    "post_cov= pd.DataFrame( np.linalg.inv( prior_cov_inv+ np.dot( np.dot( view_w.T, view_cov_inv), view_w)), index= LW_cov.index, columns= LW_cov.columns)\n",
    "#post_mean_geo= post_mean_arith- .5* np.diag( LW_cov_active)\n",
    "\n",
    "LW_cov_active_bl = LW_cov_active+ post_cov\n",
    "\n",
    "post_mean_geo= post_mean_arith- .5* np.diag(LW_cov_active_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post_mean_geo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-18fa3ae8f8df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpost_mean_geo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'post_mean_geo' is not defined"
     ]
    }
   ],
   "source": [
    "post_mean_geo.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[fm, fv, fw] = solve_frontier(100,post_mean_geo.values[0], LW_cov_active_bl, 1, 1, 0)\n",
    "\n",
    "[fm1, fv1, fw1] = solve_frontier(100,post_mean_geo.values[0], LW_cov_active_bl, 0.3, 1, 0)\n",
    "\n",
    "[fm2, fv2, fw2] = solve_frontier(100,post_mean_geo.values[0], LW_cov_active_bl, 1, 0, 0)\n",
    "\n",
    "[fm3, fv3, fw3] = solve_frontier(100,post_mean_geo.values[0], LW_cov_active_bl, 0.3, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writer= pd.ExcelWriter('output_bl_exclcorp_unconst.xlsx') \n",
    "# a = fw.tolist()\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet1')\n",
    "# a = fm\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet2')\n",
    "# a = fv\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet3')\n",
    "# writer.save() \n",
    "\n",
    "# writer= pd.ExcelWriter('output_bl_exclcorp_const.xlsx') \n",
    "# a = fw1.tolist()\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet1')\n",
    "# a = fm1\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet2')\n",
    "# a = fv1\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet3')\n",
    "# writer.save() \n",
    "\n",
    "# writer= pd.ExcelWriter('output_bl_inclcorp_unconst.xlsx') \n",
    "# a = fw2.tolist()\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet1')\n",
    "# a = fm2\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet2')\n",
    "# a = fv2\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet3')\n",
    "# writer.save() \n",
    "\n",
    "# writer= pd.ExcelWriter('output_bl_inclcorp_const.xlsx') \n",
    "# a = fw3.tolist()\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet1')\n",
    "# a = fm3\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet2')\n",
    "# a = fv3\n",
    "# b = pd.DataFrame(a)\n",
    "# b.to_excel(writer, 'Sheet3')\n",
    "# writer.save() "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
