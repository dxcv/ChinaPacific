{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 11\n",
      "         Function evaluations: 1281\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from portfolio import Portfolio\n",
    "%matplotlib inline \n",
    "\n",
    "## read in data\n",
    "ret_df_raw= pd.read_excel( io= 'Data/cipc data.xlsx', sheetname= 'Data_Input', index_col=0)\n",
    "\n",
    "ret_df= ret_df_raw[['US_RE', \n",
    "                   'US_PE',\n",
    "                   'US_CORP',\n",
    "                   'SP500',\n",
    "                   'Rusell2000',\n",
    "                   'EAFE',\n",
    "                   'EM']]\n",
    "                   #'USGOVT10Y']]\n",
    "ret_df_cov= ret_df.cov()\n",
    "\n",
    "UniverseProperty= {}\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "LW= LedoitWolf( ).fit(ret_df)\n",
    "LW_alpha= LW.shrinkage_\n",
    "\n",
    "LW_cov= pd.DataFrame(LW.covariance_)*4\n",
    "LW_cov.index= ret_df_cov.index\n",
    "LW_cov.columns= ret_df_cov.columns\n",
    "LW_vol= np.sqrt(np.diag(LW_cov))\n",
    "LW_corr= pd.DataFrame( np.dot( np.dot( np.diag(1/ LW_vol), LW_cov), np.diag(1/LW_vol)) , \n",
    "                      index= LW_cov.index, columns= LW_cov.columns)\n",
    "CMA_passive_geo= np.array( [7, 8.8, 2.75, 7.21, 8.06, 7.07, 8.03 ])/100\n",
    "CMA_active_geo= CMA_passive_geo+ np.array( [0,0, 0.5, 1,1,1,1])/100\n",
    "CMA_passive_arith= CMA_passive_geo+ 0.5* LW_vol**2\n",
    "LW_cov_active= LW_cov+ np.diag([0, 0, 4, 9,9,9,9])/10000\n",
    "LW_vol_active= np.sqrt(np.diag(LW_cov_active))\n",
    "CMA_active_arith= CMA_active_geo+ 0.5* LW_vol_active**2\n",
    "\n",
    "# the asset universe properties\n",
    "UniverseProperty['asset_name']= LW_cov.index.tolist()\n",
    "UniverseProperty['asset_count']= LW_cov.shape[0]\n",
    "UniverseProperty['LW_cov']= LW_cov\n",
    "UniverseProperty['LW_vol']= LW_vol\n",
    "UniverseProperty['LW_corr']= LW_corr\n",
    "UniverseProperty['CMA_active_geo']= CMA_active_geo\n",
    "UniverseProperty['CMA_active_arith']= CMA_active_arith\n",
    "UniverseProperty['LW_cov_active']= LW_cov_active\n",
    "UniverseProperty['LW_vol_active']= LW_vol_active\n",
    "\n",
    "\n",
    "# Portfolios\n",
    "\n",
    "portfolios= {}\n",
    "portfolios['EqualWeights']= Portfolio(asset_ret= UniverseProperty['CMA_active_geo'], \n",
    "                                      asset_cov= UniverseProperty['LW_cov_active'], \n",
    "                                      weight= [1/UniverseProperty['asset_count']]* UniverseProperty['asset_count'])\n",
    "\n",
    "tmp= np.array([0.14,0.29,0.05,0.24,0.03,0.21,0.05])\n",
    "tmp= tmp/ np.sum(tmp)\n",
    "portfolios['Peer']= Portfolio( asset_ret= UniverseProperty['CMA_active_geo'],\n",
    "                             asset_cov= UniverseProperty['LW_cov_active'], \n",
    "                             weight= tmp)\n",
    "\n",
    "\n",
    "# solve ERC\n",
    "\n",
    "def temp_ERC_func(w, sigma):\n",
    "    A= np.diag( w)\n",
    "    B= np.diag( np.dot( sigma, w))\n",
    "    C= np.diag( np.dot( A, B))/ np.dot( np.dot( w, sigma), w)- np.ones( w.size )* 1/ w.size\n",
    "    return np.dot( C, C)\n",
    "\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "ERC_opt_res= minimize( temp_ERC_func, \n",
    "                 x0= portfolios['EqualWeights'].weight ,\n",
    "                 args= LW_cov,\n",
    "                 method= 'Powell',\n",
    "                 options= {'disp': True},\n",
    "                 tol= 1e-16)\n",
    "\n",
    "weight_erc = ERC_opt_res.x/ np.sum( ERC_opt_res.x)\n",
    "\n",
    "# ERC portfolio\n",
    "portfolios['ERC']= Portfolio( asset_ret= UniverseProperty['CMA_active_geo'],\n",
    "                            asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                            weight= weight_erc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Frontier Construction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014577770818944482\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014578097207650254\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014589163132461337\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014615953148293514\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014658467255146794\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014716705453021173\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014790667741916646\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014880354121833224\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00149857645927709\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015106899154729674\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015243757948351952\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015396340551710524\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015564647386732593\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001574867831277577\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001594843332984004\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016163912437925409\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016395115740838904\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001664204292715945\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001690469430830812\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017182772817978865\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017475901902151319\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017784080379176774\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001810730824459922\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018445585449816094\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018798912012908692\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019167169418202526\n",
      "            Iterations: 24\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019549823536987834\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001994680887461124\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020358126015505166\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002078377475184426\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002122375547873222\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021678067179232772\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022146711003052937\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002262968581368072\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0023126992669513582\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0023638630986238932\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00241646014060907\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002470490258463262\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025259535788803673\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002582850060928269\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026411797056573824\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002700942518078231\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002762138471641107\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002824767604256372\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0028888298836801498\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0029543253355215487\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0030212539413816226\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003089615708245667\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031594106670049717\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003230638535812508\n",
      "            Iterations: 34\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003303297747266218\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0033773824501618223\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0034528972648267438\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003529841502101294\n",
      "            Iterations: 28\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Current function value: 0.003608214227803333\n",
      "            Iterations: 28\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003688015136397207\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0037692433490048812\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0038519000321678943\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003935984620579595\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004021495793959856\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004108433644148469\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004196798161357849\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004286589336371189\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004377807160029008\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004470451622891747\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004564522629065059\n",
      "            Iterations: 29\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004660015985396029\n",
      "            Iterations: 35\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00475713252384554\n",
      "            Iterations: 33\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004859309329995179\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004967812486484322\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005082644444453851\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005203804390049591\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0053312923483736984\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005465133646127114\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0056058797390712055\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005753835924947908\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0059090022592390695\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006071378723450643\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006240965317582605\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006417762041634979\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006601768895607754\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006792985879500927\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006991412993314512\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007197050237048502\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0074098976107028845\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007629955114277678\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007857222747772863\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008091700511188462\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00833338840452446\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008582286427780863\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008838394580957667\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def frontier_obj(w, sigma):\n",
    "    return (np.dot(  np.dot( w, sigma), w)* .5)\n",
    "\n",
    "def frontier_obj_der( w, sigma): \n",
    "    return (np.dot( w, sigma))\n",
    "\n",
    "\n",
    "frontier_cons0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*w.size)}\n",
    "\n",
    "frontier_uncons={}\n",
    "\n",
    "for target_ret in np.linspace(0.045, 0.1, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['CMA_active_arith'])- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['CMA_active_arith']} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    \n",
    "    # unconstrained opt\n",
    "    MV_opt_1= minimize( frontier_obj, \n",
    "                    x0= portfolios['EqualWeights'].weight, \n",
    "                    args= UniverseProperty['LW_cov_active'], \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter': 1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None]]* UniverseProperty['asset_count'],\n",
    "                    tol= 1e-10)  # long only constrain\n",
    "    \n",
    "    frontier_uncons[target_ret]= Portfolio( asset_ret= UniverseProperty['CMA_active_geo'],\n",
    "                                         asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                                         weight= MV_opt_1.x)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00416077477782325\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0041620369331015475\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004166442358088477\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004174549595130644\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004186264235506788\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0042018178516663686\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004220414836918147\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004242854836497227\n",
      "            Iterations: 23\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004268870199874874\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004298052597064372\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004329496607723859\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004363167989505652\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004399071359981933\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004437206345568815\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004477570578338226\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004520161162530899\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004564984639614273\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004612381979719441\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004661383924715833\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0047127837486159166\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0047662138075351464\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004821581104259152\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004878810410399419\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00493791269645381\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004998804977243388\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0050612956332304546\n",
      "            Iterations: 24\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005126070511686845\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005192642465901125\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005261102327864426\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005331458694896875\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005403716416060382\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005477875348221044\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005553982339187245\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005632277179158973\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0057127718897694935\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005795445333929898\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005880273814585384\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005967250638660538\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006056374020060736\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006147641991161113\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006241052560690411\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006336602929010697\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00643428798074118\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00653419245537094\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006636118974723858\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006740358701184043\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0068466524445141945\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006955084237800826\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007065661023887423\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007178383274046788\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007293251420883877\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007410265832960262\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007529035158530415\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007650317868978875\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00777374574204829\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007899318777738654\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008027036976049952\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008156900336982206\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008288908860535411\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008423062546709551\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008559361395504653\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008697805406920677\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00883839458095767\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n"
     ]
    }
   ],
   "source": [
    "frontier_uncons_NoCorp={}\n",
    "\n",
    "\n",
    "\n",
    "for target_ret in np.linspace(0.07, 0.1, 100): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['CMA_active_arith'])- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['CMA_active_arith']} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    initial_guess= np.ones(UniverseProperty['asset_count'])* 1/UniverseProperty['asset_count']\n",
    "    initial_guess[2]=0\n",
    "    # unconstrained opt\n",
    "    MV_opt_2= minimize( frontier_obj, \n",
    "                    x0= initial_guess, \n",
    "                    args= UniverseProperty['LW_cov_active'], \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter':1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None], [0, None], [0, 1e-15]]+ [[0, None]]* ( UniverseProperty['asset_count']- 3),\n",
    "                    tol= 1e-8)  # long only constrain\n",
    "    \n",
    "    frontier_uncons_NoCorp[target_ret]= Portfolio( asset_ret= UniverseProperty['CMA_active_geo'],\n",
    "                                         asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                                         weight= MV_opt_2.x)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026858324918957958\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002686494013811873\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027039700482175085\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027235192227737567\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027449661244608667\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027680682915364263\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027924139614029534\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00281718899708386\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002842217269023636\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002867497050024062\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0028930276987209945\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0029188092145596973\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002944841597588862\n",
      "            Iterations: 28\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0029711248483355697\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0029976589665295463\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003024443952167144\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0030514798052483617\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0030787665257732007\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031063041137416553\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031340925708529077\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031621318920094263\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003190422082308746\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0032189631400516786\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0032477550652382312\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003276797857876091\n",
      "            Iterations: 27\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0033060915179760836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Iterations: 24\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0033356360454599534\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0033654314404206504\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0033954777028252993\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0034257748326735737\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0034563228299654657\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003487121698100186\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0035181714268801055\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0035494720265028578\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0035810234935692298\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0036128258280792207\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003644879030032832\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003677183099430062\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003709738036270907\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003742543840555377\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0037756005122834666\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0038089080514551745\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0038424664580705018\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n"
     ]
    }
   ],
   "source": [
    "frontier_cons= {}\n",
    "\n",
    "for target_ret in np.linspace(0.06, 0.08, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['CMA_active_arith'])- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['CMA_active_arith']} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    # constrained opt \n",
    "    MV_opt_3= minimize( frontier_obj, \n",
    "                    x0= portfolios['EqualWeights'].weight, \n",
    "                    args= UniverseProperty['LW_cov_active'], \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter':1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.3]]* UniverseProperty['asset_count'],\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "    \n",
    "    frontier_cons[target_ret]=   Portfolio( asset_ret= UniverseProperty['CMA_active_geo'], \n",
    "                                        asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                                        weight= MV_opt_3.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005999742164909799\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006009245101045906\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006045081902177092\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006086341311098281\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006132435835675368\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006182157814984094\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0062348746416162225\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006290586315575836\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006349292836939575\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00641099420546787\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006475690421346831\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006543381484564759\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006614067395099601\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006687748152949647\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006764423758116825\n",
      "            Iterations: 22\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006844094210594406\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006926759510389422\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007012419657499495\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007101074651924606\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00719272449366477\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007287369182719972\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007385008719090219\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007485643102775511\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007589272333775845\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007695896412091239\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007805515337721657\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007918129110844248\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008033737730931929\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008152341198504057\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008276969820931995\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008412351764084027\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00854994268701193\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008689725972184401\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008831701619601449\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008975869629263049\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n"
     ]
    }
   ],
   "source": [
    "frontier_cons_NoCorp= {}\n",
    "\n",
    "for target_ret in np.linspace(0.07, 0.1, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['CMA_active_arith'])- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['CMA_active_arith']} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    # constrained opt \n",
    "    initial_guess= np.ones(UniverseProperty['asset_count'])* 1/UniverseProperty['asset_count']\n",
    "    initial_guess[2]=0\n",
    "    MV_opt_4= minimize( frontier_obj, \n",
    "                    x0= initial_guess, \n",
    "                    args= UniverseProperty['LW_cov_active'], \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter': 1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.3], [0, 0.3], [0, 1e-15]]+ [[0, 0.3]]* ( UniverseProperty['asset_count']-3) ,\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "    \n",
    "    frontier_cons_NoCorp[target_ret]=   Portfolio( asset_ret= UniverseProperty['CMA_active_geo'], \n",
    "                                        asset_cov= UniverseProperty['LW_cov_active'],\n",
    "                                        weight= MV_opt_4.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xc1a5b00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSTEKfhGRFKPgFxFJMf8fXQZQeuX+z7sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc122da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig= plt.figure()\n",
    "\n",
    "frontier_uncons_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_uncons.values()]\n",
    "frontier_uncons_pair.sort(key= lambda x: x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_uncons_pair], y= [x[0] for x in frontier_uncons_pair], \n",
    "            marker='o', c= 'pink', s=10, label= 'long only')\n",
    "\n",
    "frontier_uncons_NoCorp_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_uncons_NoCorp.values()]\n",
    "frontier_uncons_NoCorp_pair.sort(key= lambda x : x[0])\n",
    "plt.scatter( x= [x[1] for x in frontier_uncons_NoCorp_pair], y = [x[0] for x in frontier_uncons_NoCorp_pair], \n",
    "           marker= 'o', c= 'orange', s=10, label= 'long only(No Corp)')\n",
    "\n",
    "\n",
    "frontier_cons_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_cons.values()]\n",
    "frontier_cons_pair.sort(key= lambda x : x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_cons_pair], y= [x[0] for x in frontier_cons_pair], \n",
    "            marker= '*', c= 'blue' , s=10, label= 'long only and constrained')\n",
    "\n",
    "frontier_cons_NoCorp_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_cons_NoCorp.values()]\n",
    "frontier_cons_NoCorp_pair.sort(key= lambda x: x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_cons_NoCorp_pair], y= [x[0] for x in frontier_cons_NoCorp_pair], \n",
    "           marker= '*', c= 'red', s=10, label= 'long only and constrained(No Corp)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peer Implied Return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03096314,  0.05941507,  0.01987301,  0.06643129,  0.07014947,\n",
       "        0.07036907,  0.0680927 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_free= 179/10000\n",
    "gamma= 3.5\n",
    "\n",
    "UniverseProperty['impliedExpectedReturn_peer_arith']= portfolios['Peer'].implied_ExpectedReturn(gamma= gamma, risk_free= risk_free)\n",
    "UniverseProperty['impliedExpectedReturn_peer_geo']= UniverseProperty['impliedExpectedReturn_peer_arith']- .5* np.diag(UniverseProperty['LW_cov'])\n",
    "\n",
    "UniverseProperty['impliedExpectedReturn_peer_geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0359304 ,  0.06939446,  0.02185507,  0.07806678,  0.0895547 ,\n",
       "        0.08693194,  0.10000493])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(UniverseProperty['impliedExpectedReturn_peer_arith'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Return (BL) and Frontier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from blacklitterman import naive_BlackLitterman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply BL to arithmatic expected return \n",
    "\n",
    "prior_ExpectedReturn= UniverseProperty['impliedExpectedReturn_peer_arith']\n",
    "prior_cov= UniverseProperty['LW_cov_active']\n",
    "tau= 0.05\n",
    "prior_risk= UniverseProperty['LW_cov']* tau\n",
    "\n",
    "views_weight= np.identity(UniverseProperty['asset_count'])\n",
    "views_expectedReturn= UniverseProperty['CMA_active_arith']\n",
    "views_risk = UniverseProperty['LW_cov_active']* 2*tau\n",
    "\n",
    "\n",
    "arithBL= naive_BlackLitterman( prior_ExpectedReturn= prior_ExpectedReturn, prior_uncertainty= prior_risk, prior_cov= prior_cov, \n",
    "                         views_weight= views_weight, views_return= views_expectedReturn, views_uncertainty= views_risk)\n",
    "\n",
    "UniverseProperty['arithBL_peer_CMAactive']= arithBL\n",
    "# Note: the prior, view and post are arithmatic \n",
    "# To convert the aithmatic post expected return to geometric, deduct half post return variance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04380985,  0.06861074,  0.02357064,  0.07104906,  0.07605534,\n",
       "        0.07312406,  0.07412406])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arithBL.post_ExpectedReturn- .5* np.diag( arithBL.post_cov) # post geometric expected return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04380985,  0.06861074,  0.02357064,  0.07104906,  0.07605534,\n",
       "        0.07312406,  0.07412406])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arithBL.arith2geo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frontier based on BL post Expected Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018061111084892532\n",
      "            Iterations: 27\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018438935502451395\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018837359702019404\n",
      "            Iterations: 26\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019256384121274677\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019696008111688397\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002015623244475364\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002063681349189862\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021137477987597264\n",
      "            Iterations: 34\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021658260450978578\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002219908868591742\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022759969636436607\n",
      "            Iterations: 31\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002334096624146585\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002394209743778196\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002456324058458726\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025204474703292225\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025865797796155187\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002654720453988199\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027248696891363747\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027970272026150234\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0028711927449626765\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002947367161050373\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0030255561372847122\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031057412158818163\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0031879386963194105\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003272140259817837\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003358345959133922\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0034465558288853523\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0035367698829103763\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0036289881271192085\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003723210559053306\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003819437174400825\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003917667967999779\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004017902934413841\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004120142067939975\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004224385362247124\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0043306328097403235\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004438884401113788\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004549140142109756\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004661399911435902\n",
      "            Iterations: 23\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004775664274811639\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004891932902794121\n",
      "            Iterations: 23\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005010200733230546\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005130476771690298\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005252756932518072\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005377041216749039\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005503329625779399\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005631622160882155\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00576191882319456\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005894219613636917\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006028524532956614\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006164833577161976\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0063031467499416885\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006444219782987739\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006589643003676063\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006739472596338107\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006893698777125272\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007052330740229416\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007215365400173616\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0073828027576228455\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007554642836299498\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007730885593877862\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00791153511782351\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008096581452356921\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008286030786115934\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008479883567169692\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008678140029789342\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008880800018636356\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009087863154355499\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00929933037406016\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009515191679322691\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009735461414541713\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009960133843033772\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010189208919377538\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010422686727507378\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010660567233413288\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01090285043621039\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011149536335841944\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011400624932299824\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011656117730152009\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011919954820885476\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012195778687274486\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012483589329155182\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01278338674656314\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01309517093948635\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013418941909021646\n",
      "            Iterations: 21\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01375469965187866\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014102444171361663\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014462419312675757\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014836279091863955\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015224337788358772\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015626583658323742\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016043027303087962\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016473667020766376\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016918501586634785\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017377530470799502\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017850753491138804\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.018338171181526846\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.018839783525227624\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01936132103593996\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01992240339936224\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n"
     ]
    }
   ],
   "source": [
    "frontier_BLuncons={}\n",
    "\n",
    "for target_ret in np.linspace(0.045, 0.1, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn)- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    \n",
    "    # unconstrained opt\n",
    "    MV_opt_5= minimize( frontier_obj, \n",
    "                    x0= portfolios['EqualWeights'].weight, \n",
    "                    args= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter': 1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None]]* UniverseProperty['asset_count'],\n",
    "                    tol= 1e-10)  # long only constrain\n",
    "    \n",
    "    frontier_BLuncons[target_ret]= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(),\n",
    "                                         asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                                         weight= MV_opt_5.x)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0055505959473478965\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005612169271008836\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005675397476558232\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005739679536866314\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005805445264733835\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005872633694433723\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00594113626214653\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006010949279501955\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006082072752011011\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006154506683846239\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006228251077805078\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006303305935166011\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0063796712553718625\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006457347035412637\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006536333268647495\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00661662994250125\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006698237033717518\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006781154497797813\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006865382242974429\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006950920056910465\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007037767361887608\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0071259222347549965\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007215645917923672\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007306399434298791\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007398264503098989\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00749167151914837\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007586385074839919\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007682409291675241\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007779743649563863\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007878387615791363\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007978341920163307\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008079606626647294\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008182181765501038\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008286067351442727\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008391263390991086\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008497769885438353\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008605586831617001\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008714714220953044\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008825152036294491\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008936900245841267\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009049958809532627\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009164328018422435\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009280010421621647\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00939700032839981\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009515300650489493\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009634913041547134\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009755834292887615\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009878065985594752\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010001608118592673\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010126460689884346\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010252623696941205\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010380097137332994\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010508881009211893\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01063897531144163\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010770380043443792\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01090309520495027\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011037120795796933\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011172456815800605\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01130910326470631\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011447060142177057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011586327447803416\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011726906158378613\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.011871122361014692\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01201889771411862\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012170238858121279\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012325145879220227\n",
      "            Iterations: 14\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01248361950661767\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012645658225271552\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012811262630105506\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.012980432390017234\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01315316684763476\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01332947297431534\n",
      "            Iterations: 16\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01350934160112636\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013692770594188457\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.013879766257505284\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014070339095554527\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014264485593270381\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014462436779829599\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014664599965525507\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.014870982051867793\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015081587305762357\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015296417404878877\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01551547217560223\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01573875126961562\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.015966254316520673\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01619798110682881\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016433931354307985\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.016674104881304705\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01691850157135473\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01716712135894387\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017419964219378557\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017677030155005612\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.017938329409407552\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.018203831409783374\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.018473566813785373\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01874752547851592\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01902571630214931\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.019312355628200134\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.019611253274249132\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.01992240339936225\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n"
     ]
    }
   ],
   "source": [
    "frontier_BLuncons_NoCorp={}\n",
    "\n",
    "\n",
    "for target_ret in np.linspace(0.07, 0.1, 100): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn)- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    initial_guess= np.ones(UniverseProperty['asset_count'])* 1/UniverseProperty['asset_count']\n",
    "    initial_guess[2]=0\n",
    "    # unconstrained opt\n",
    "    MV_opt_6= minimize( frontier_obj, \n",
    "                    x0= initial_guess, \n",
    "                    args= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter':1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None], [0, None], [0, 1e-15]]+ [[0, None]]* ( UniverseProperty['asset_count']- 3),\n",
    "                    tol= 1e-8)  # long only constrain\n",
    "    \n",
    "    frontier_BLuncons_NoCorp[target_ret]= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(),\n",
    "                                         asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                                         weight= MV_opt_6.x)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0035367698829103776\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003570071900208189\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003603638934318933\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003637470985129017\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003671568052474299\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003705930052033874\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0037405571122306365\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0037754491811689\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00381060625884399\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0038460283452520895\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0038817154403933875\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003917667544278451\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003953884657158697\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.003990367427971457\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004027116553540862\n",
      "            Iterations: 26\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0040641320339321555\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0041014138689064355\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00413896205867529\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004176776603115725\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004214857502350102\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004253204756251539\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004291818365083571\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004330698328298293\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004369844646427189\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004409257319284509\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004448936347023843\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0044888817291910375\n",
      "            Iterations: 27\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004529093466265378\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00456957155807048\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0046103160046406\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0046513268057658715\n",
      "            Iterations: 24\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0046926039618411155\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004734147472517622\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004775957337885326\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004818033558007347\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004860376132884377\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004902985062496767\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004945860346849648\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.004989001985990876\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005032409979752123\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00507608432825434\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00512002503167121\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005164233620491127\n",
      "            Iterations: 29\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0052087191230193435\n",
      "            Iterations: 29\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0052534830176491935\n",
      "            Iterations: 28\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005298525304392057\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005343845983248453\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005389445054135525\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0054353225173267615\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005481478372432149\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005527912619666846\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0055746252592253475\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005621616290266231\n",
      "            Iterations: 30\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005668885713793222\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005716433529420294\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005764259737147469\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0058123643369748295\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0058607473289024915\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0059094087129305615\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.005958348489059141\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006007566657287161\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006057063217614684\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006106838170042318\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006156891514567034\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006207223251183351\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006257833379898991\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006308721900714133\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006359888813629459\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006411334118644975\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006463057815759485\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0065150599049863\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006567340386300587\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0066200390681704115\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006674312913175712\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0067293772256847096\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006785030316841777\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006841272186539396\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006898102835007779\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006955522261936778\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0070135304670707705\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0070721274510874696\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00713131321320103\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007191087754178065\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0072514510736562095\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007312403171685916\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007373944048297113\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007436073703401277\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007498792137076438\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007562099349294994\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007625995340177095\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00769048010938856\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007755553657210739\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007821215983602662\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00788746708853794\n",
      "            Iterations: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007954306972016548\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008021735634038504\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008089753074734685\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0081583592937476\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008227554291460817\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008297338067561192\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n"
     ]
    }
   ],
   "source": [
    "frontier_BLcons= {}\n",
    "\n",
    "for target_ret in np.linspace(0.06, 0.08, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn)- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    # constrained opt \n",
    "    MV_opt_7= minimize( frontier_obj, \n",
    "                    x0= portfolios['EqualWeights'].weight, \n",
    "                    args= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter':1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.3]]* UniverseProperty['asset_count'],\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "    \n",
    "    frontier_BLcons[target_ret]=   Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(), \n",
    "                                        asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                                        weight= MV_opt_7.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0061986921585903895\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00620885052733728\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006231036541667296\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006255399383869188\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006281329583466524\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0063088271404593\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006337892054847513\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006368524326631165\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006400723955810257\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006434353546334593\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006469156222268315\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006505126112387326\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006542263216691641\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0065805675351812525\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0066200390678561585\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006660638831653053\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006701771472132177\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006743235307674825\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006785030383456623\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006827156598194595\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006869613913335845\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006912402493651358\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006955522261559798\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.006998973217567717\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007042755361506271\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0070868686933783015\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00713131321317526\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007176088920905703\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007221195816566773\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00726663390015848\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00731240317168081\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007358503631133775\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007404935278517365\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0074516981138366386\n",
      "            Iterations: 23\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007498792137151183\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0075462173484144215\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007593973747417068\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007642061334474903\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007690480109362186\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007739230072260149\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00778831122308878\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007837723561848043\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007887467088537938\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007937541803158463\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.007987947705709616\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008038684796191398\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008089753074603813\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00814115254094686\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008192883195220522\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008244945037424825\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008297338067559763\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008350062285625329\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008403117691621524\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008456504285548347\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008510222067405801\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008564271037193883\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008618651194912596\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00867336254056194\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00872840507414192\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008783778795652524\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008839483705093753\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008895519802465618\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.008951887087768118\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009008585561001233\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00906561522216499\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009122976071259371\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009180668108284388\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00923869133324003\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009297045746126317\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009355731346943213\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009414748135690747\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009474096112368923\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009533775276977715\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009593785629517147\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009654127169987196\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009714799898387883\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009775803814719203\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00983713891898115\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009898805211173723\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.009960802691296919\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010023131359350767\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010085791215335227\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010148782259250326\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.010212104491096052\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n"
     ]
    }
   ],
   "source": [
    "frontier_BLcons_NoCorp= {}\n",
    "\n",
    "for target_ret in np.linspace(0.07, 0.085, 100 ): \n",
    "    frontier_cons1= {'type': 'ineq', \n",
    "                'fun': lambda w: np.dot(w, UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn)- target_ret,\n",
    "                'jac': lambda w: UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn} \n",
    "\n",
    "    cons= (frontier_cons0 # fully invested \n",
    "          , frontier_cons1 # return requirement \n",
    "          )\n",
    "    \n",
    "    # constrained opt \n",
    "    initial_guess= np.ones(UniverseProperty['asset_count'])* 1/UniverseProperty['asset_count']\n",
    "    initial_guess[2]=0\n",
    "    MV_opt_8= minimize( frontier_obj, \n",
    "                    x0= initial_guess, \n",
    "                    args= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                    jac= frontier_obj_der ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True, 'maxiter': 1000},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.3], [0, 0.3], [0, 1e-15]]+ [[0, 0.3]]* ( UniverseProperty['asset_count']-3) ,\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "    \n",
    "    frontier_BLcons_NoCorp[target_ret]=   Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(), \n",
    "                                        asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov,\n",
    "                                        weight= MV_opt_8.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAJCCAYAAABAuEcoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFoskSZIkSZJU9v8D81lR49D7q5YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc2ac978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig= plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.scatter(x= [x[1] for x in frontier_uncons_pair], y= [x[0] for x in frontier_uncons_pair], \n",
    "            marker='o', c= 'pink', s=60, label= 'CMA: long only')\n",
    "plt.scatter( x= [x[1] for x in frontier_uncons_NoCorp_pair], y = [x[0] for x in frontier_uncons_NoCorp_pair], \n",
    "           marker= 'o', c= 'orange', s=60, label= 'CMA: long only(No Corp)')\n",
    "plt.scatter(x= [x[1] for x in frontier_cons_pair], y= [x[0] for x in frontier_cons_pair], \n",
    "            marker= 'o', c= 'blue' , s=60, label= 'CMA: long only and constrained')\n",
    "plt.scatter(x= [x[1] for x in frontier_cons_NoCorp_pair], y= [x[0] for x in frontier_cons_NoCorp_pair], \n",
    "           marker= 'o', c= 'red', s=60, label= 'CMA: long only and constrained(No Corp)')\n",
    "\n",
    "\n",
    "frontier_BLuncons_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_BLuncons.values()]\n",
    "frontier_uncons_pair.sort(key= lambda x: x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_BLuncons_pair], y= [x[0] for x in frontier_BLuncons_pair], \n",
    "            marker='^', c= 'pink', s=60, label= 'BL: long only')\n",
    "\n",
    "frontier_BLuncons_NoCorp_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_BLuncons_NoCorp.values()]\n",
    "frontier_BLuncons_NoCorp_pair.sort(key= lambda x : x[0])\n",
    "plt.scatter( x= [x[1] for x in frontier_BLuncons_NoCorp_pair], y = [x[0] for x in frontier_BLuncons_NoCorp_pair], \n",
    "           marker= '^', c= 'orange', s=60, label= 'BL: long only(No Corp)')\n",
    "\n",
    "\n",
    "frontier_BLcons_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_BLcons.values()]\n",
    "frontier_BLcons_pair.sort(key= lambda x : x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_BLcons_pair], y= [x[0] for x in frontier_BLcons_pair], \n",
    "            marker= '^', c= 'blue' , s=60, label= 'BL: long only and constrained')\n",
    "\n",
    "frontier_BLcons_NoCorp_pair= [[x.expected_return, x.volatility, x.weight] for x in frontier_BLcons_NoCorp.values()]\n",
    "frontier_BLcons_NoCorp_pair.sort(key= lambda x: x[0])\n",
    "plt.scatter(x= [x[1] for x in frontier_BLcons_NoCorp_pair], y= [x[0] for x in frontier_BLcons_NoCorp_pair], \n",
    "           marker= '^', c= 'red', s=60, label= 'BL: long only and constrained(No Corp)')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "1. CMA results are represented by nodes while the BL results are triangles. BL result shifted down relative to CMA since BL post return is lower than CMA active. \n",
    "\n",
    "2. Applying BL slacks the concentration constrain (at 30% level)\n",
    "\n",
    "3. Applying BL makes US Corp less different from other assets, hence insensitive to the NoCorp Constrain. (Kicking out US Corp leads to smooth extension of the frontier and insignificant jump compared to the CMA cases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Management Optimization\n",
    "\n",
    "\n",
    "Treat Peer as bechmark, max the benefit from deviation with limited tracking error budget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -4.8332856665799196e-12\n",
      "            Iterations: 112\n",
      "            Function evaluations: 221\n",
      "            Gradient evaluations: 112\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0003963962185422194\n",
      "            Iterations: 19\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0007927924368546288\n",
      "            Iterations: 16\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.001189188654623979\n",
      "            Iterations: 15\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00158558487283354\n",
      "            Iterations: 13\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.001981981091034121\n",
      "            Iterations: 11\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.002378377309385061\n",
      "            Iterations: 14\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.002774773527502916\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.003157029165813289\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.003502103826874759\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0038256785909380553\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00413595600846056\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.004437282691213485\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0047322326298204955\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005022448863388642\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005309038990191291\n",
      "            Iterations: 15\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.005592781457034781\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00587424176142635\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0061538419247620735\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006431904035415965\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006708678630658174\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.006984363801025094\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007259118411590729\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.007533071471129518\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0078063289101884354\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008078978574914698\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008351093965964708\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00862273707883029\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.008893960589222273\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009164809554442495\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009435322755138174\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.00970553375534217\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.009975384248236132\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010233538823496285\n",
      "            Iterations: 17\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.010475663387739876\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0107059046826518\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01092935192314491\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011147549426530182\n",
      "            Iterations: 17\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011361225704542217\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011570969006331974\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011777261434573603\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.011980503188747545\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012181030199429017\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012379127224079847\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012575037744818055\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012768971564949664\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012961110736480503\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013151614218024677\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01334062160111112\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013528256109858645\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Current function value: -0.013714627038043097\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.013899831751823251\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01408395734082268\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01426708199889836\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014449276174566709\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014630603546219261\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014811121847531262\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.014990883569931246\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015169936568298095\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015348324578265952\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015526082395761441\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01570318912967781\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015879666985945964\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016055552099473475\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016230877780400242\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01640567479415661\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016579971607415624\n",
      "            Iterations: 19\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016753609960317155\n",
      "            Iterations: 20\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01692583338327481\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017096644790422152\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01726613673116574\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0174343932131095\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017601490720370767\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017767499088239783\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017932482245798555\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018096498866209634\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018259602921821938\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018421844170547604\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01858326858259906\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01874391871150039\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01889839647297971\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019031454148625525\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01914946756343311\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019174776313502784\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w_b= portfolios['Peer'].weight\n",
    "expected_return= UniverseProperty['arithBL_peer_CMAactive'].post_ExpectedReturn\n",
    "cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov\n",
    "benchmark_portfolio= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(), \n",
    "                               asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                               weight= portfolios['Peer'].weight)\n",
    "\n",
    "\n",
    "frontier_activeM= {} # key tracking error, value the optmized portfolio \n",
    "\n",
    "\n",
    "\n",
    "def activeMang_obj(w):\n",
    "    return  -1*np.dot((w- w_b), expected_return )\n",
    "\n",
    "def activeMang_obj_der( w): \n",
    "    return -1* expected_return\n",
    "\n",
    "activeMang_cons0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*w.size)}\n",
    "\n",
    "for trackingError in np.linspace(0, .1, 100): \n",
    "    activeMang_cons1= {'type': 'ineq',\n",
    "                      'fun': lambda w: trackingError**2 - np.dot( np.dot( w- w_b, cov), w-w_b),\n",
    "                      'jac': lambda w: -2* np.dot(cov, w- w_b)}\n",
    "    \n",
    "    activeMang_cons= (activeMang_cons0, \n",
    "                     activeMang_cons1)\n",
    "    MV_opt_9= minimize( activeMang_obj, \n",
    "                      x0= w_b,\n",
    "                      jac= activeMang_obj_der,\n",
    "                      method= 'SLSQP', \n",
    "                      options= {'disp': True, 'maxiter': 1000},\n",
    "                      constraints= activeMang_cons,\n",
    "                      bounds= [[0, 0.3]]* UniverseProperty['asset_count'],\n",
    "                      tol= 1e-12)\n",
    "    frontier_activeM[trackingError]= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(),\n",
    "                                               asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                                               weight= MV_opt_9.x, benchmark_portfolio= benchmark_portfolio)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAD8CAYAAABHN8LqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZYHHGGNMoP4/bBKnNSIj1wAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc20e080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frontier_activeM_pair= [[x.active_expectedReturn, \n",
    "                         x.tracking_error, \n",
    "                         x.active_expectedReturn/ x.tracking_error,\n",
    "                         x.SharpeRatio(risk_free= 0) ,\n",
    "                         x.weight] \n",
    "                        for x in frontier_activeM.values()]\n",
    "frontier_activeM_pair.sort(key= lambda x: x[2], reverse= True)\n",
    "max_IR= frontier_activeM_pair[0]\n",
    "frontier_activeM_pair.sort(key= lambda x:x[3], reverse= True)\n",
    "max_SR= frontier_activeM_pair[0]\n",
    "frontier_activeM_pair.sort( key= lambda x: x[0])\n",
    "fig, ax1= plt.subplots()\n",
    "ax2= ax1.twinx()\n",
    "ax1.scatter( x= [ x[1] for x in frontier_activeM_pair ], y= [ x[0] for x in frontier_activeM_pair], marker='^', c= 'm', label= 'Active Return') \n",
    "ax2.scatter(x= [ x[1] for x in frontier_activeM_pair], y= [x[2] for x in frontier_activeM_pair], marker= '*', c= 'y', label= 'IR')\n",
    "ax2.scatter( x= [x[1] for x in frontier_activeM_pair], y= [x[3] for x in frontier_activeM_pair], marker= 'o', c= 'b', label= 'SR')\n",
    "# plt.xlim(- 0.01, 0.035 )\n",
    "ax1.set_ylim(-1e-3, 0.02)\n",
    "#plt.ylim( -1e-3, 0.02)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12428132380236374"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064955163370140942"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.808978230811031e-12,\n",
       "  1.2378057675891136e-11,\n",
       "  0.30772018765349712,\n",
       "  0.52264621409734613,\n",
       "  array([ 0.13861386,  0.28712871,  0.04950495,  0.23762376,  0.02970297,\n",
       "          0.20792079,  0.04950495])],\n",
       " [0.00030761961872589763,\n",
       "  0.0010101010109649314,\n",
       "  0.30454342227816811,\n",
       "  0.5213895318629771,\n",
       "  array([ 0.13928728,  0.2889524 ,  0.04271249,  0.23910143,  0.0301378 ,\n",
       "          0.2095107 ,  0.05029791])],\n",
       " [0.00061523970523041168,\n",
       "  0.0020202020213507914,\n",
       "  0.30454365391587757,\n",
       "  0.5201430872775461,\n",
       "  array([ 0.1399606 ,  0.29077613,  0.03592007,  0.24057911,  0.03057269,\n",
       "          0.21110058,  0.05109083])],\n",
       " [0.00092285931678028413,\n",
       "  0.0030303030303061424,\n",
       "  0.30454357453718101,\n",
       "  0.5189068808824987,\n",
       "  array([ 0.14063408,  0.29259973,  0.02912758,  0.24205676,  0.03100753,\n",
       "          0.21269054,  0.05188377])],\n",
       " [0.0012304791026896515,\n",
       "  0.0040404040404122777,\n",
       "  0.30454357791506786,\n",
       "  0.51768089482128898,\n",
       "  array([ 0.14130749,  0.2944234 ,  0.02233512,  0.24353443,  0.03144238,\n",
       "          0.21428046,  0.05267671])],\n",
       " [0.0015380997557215429,\n",
       "  0.0050505050505534358,\n",
       "  0.30454375162994785,\n",
       "  0.51646511697711062,\n",
       "  array([ 0.14198089,  0.29624703,  0.01554263,  0.24501239,  0.03187708,\n",
       "          0.21587031,  0.05346966])],\n",
       " [0.0018457184655901572,\n",
       "  0.0060606060609677444,\n",
       "  0.30454354680420143,\n",
       "  0.5152595119000325,\n",
       "  array([ 0.14265434,  0.29807072,  0.00875019,  0.24648976,  0.03231205,\n",
       "          0.21746034,  0.05426261])],\n",
       " [0.0021533383096023692,\n",
       "  0.0070707070708417022,\n",
       "  0.30454356092367918,\n",
       "  0.51406406222372192,\n",
       "  array([ 0.14332772,  0.29989439,  0.00195775,  0.24796741,  0.03274691,\n",
       "          0.21905029,  0.05505553])],\n",
       " [0.0024093304351265128,\n",
       "  0.0080808080808143501,\n",
       "  0.29815464134667463,\n",
       "  0.51214484122342152,\n",
       "  array([ 0.13818832,  0.3       ,  0.        ,  0.24848557,  0.03552144,\n",
       "          0.22100843,  0.05679624])],\n",
       " [0.0026268458679569043,\n",
       "  0.0090909090913684227,\n",
       "  0.2889530454606597,\n",
       "  0.51014254466189379,\n",
       "  array([ 0.13116983,  0.3       ,  0.        ,  0.24841729,  0.03884071,\n",
       "          0.22287352,  0.05869865])],\n",
       " [0.0028308086001989177,\n",
       "  0.010101010101043324,\n",
       "  0.28025005141877107,\n",
       "  0.50826918398073573,\n",
       "  array([ 0.12458864,  0.3       ,  0.        ,  0.24835319,  0.04195314,\n",
       "          0.22462248,  0.06048255])],\n",
       " [0.0030263899876410943,\n",
       "  0.011111111111431208,\n",
       "  0.27237509887985173,\n",
       "  0.50647714563768376,\n",
       "  array([ 0.11827787,  0.3       ,  0.        ,  0.24829184,  0.04493766,\n",
       "          0.22629951,  0.06219312])],\n",
       " [0.0032163289003611455,\n",
       "  0.012121212121516045,\n",
       "  0.26534713427314127,\n",
       "  0.50474131062500094,\n",
       "  array([  1.12149175e-01,   3.00000000e-01,   3.08160033e-17,\n",
       "           2.48232212e-01,   4.78360714e-02,   2.27928167e-01,\n",
       "           6.38543744e-02])],\n",
       " [0.0034022471560586861,\n",
       "  0.0131313131317254,\n",
       "  0.25909420649171933,\n",
       "  0.50304690434417287,\n",
       "  array([  1.06150246e-01,   3.00000000e-01,   5.61236090e-17,\n",
       "           2.48173625e-01,   5.06732905e-02,   2.29522337e-01,\n",
       "           6.54805018e-02])],\n",
       " [0.003585183620468173,\n",
       "  0.014141414141771511,\n",
       "  0.25352369886955683,\n",
       "  0.5013845814356177,\n",
       "  array([ 0.10024749,  0.3       ,  0.        ,  0.24811622,  0.05346482,\n",
       "          0.23109105,  0.06708042])],\n",
       " [0.0037658338911822323,\n",
       "  0.01515151515152631,\n",
       "  0.24854503681784429,\n",
       "  0.49974810373020778,\n",
       "  array([  9.44185000e-02,   3.00000000e-01,   1.53361205e-17,\n",
       "           2.48059550e-01,   5.62214723e-02,   2.32640069e-01,\n",
       "           6.86604087e-02])],\n",
       " [0.0039446887961133879,\n",
       "  0.01616161616327454,\n",
       "  0.24407761923447055,\n",
       "  0.49813314907235245,\n",
       "  array([  8.86474721e-02,   3.00000000e-01,   2.40247661e-18,\n",
       "           2.48003261e-01,   5.89509071e-02,   2.34173703e-01,\n",
       "           7.02246574e-02])],\n",
       " [0.0041221053223550741,\n",
       "  0.017171717172170611,\n",
       "  0.24005201582492722,\n",
       "  0.49653662265808751,\n",
       "  array([ 0.08292282,  0.3       ,  0.        ,  0.24794763,  0.06165816,\n",
       "          0.23569499,  0.07177639])],\n",
       " [0.0042983491583840861,\n",
       "  0.018181818182431388,\n",
       "  0.23640920370315152,\n",
       "  0.49495626438801249,\n",
       "  array([ 0.07723603,  0.3       ,  0.        ,  0.24789225,  0.06434765,\n",
       "          0.23720624,  0.07331784])],\n",
       " [0.0044736236238909479,\n",
       "  0.019191919192273942,\n",
       "  0.23309933618790388,\n",
       "  0.4933903825874727,\n",
       "  array([ 0.0715805 ,  0.3       ,  0.        ,  0.24783725,  0.06702227,\n",
       "          0.23870916,  0.07485082])],\n",
       " [0.004648086461452294,\n",
       "  0.020202020202201715,\n",
       "  0.23008027983982129,\n",
       "  0.49183769520014947,\n",
       "  array([  6.59511676e-02,   3.00000000e-01,   2.52463265e-17,\n",
       "           2.47782468e-01,   6.96845325e-02,   2.40205131e-01,\n",
       "           7.63767010e-02])],\n",
       " [0.0048218625408944409,\n",
       "  0.021212121212202381,\n",
       "  0.22731637692701095,\n",
       "  0.49029721580181418,\n",
       "  array([  6.03439938e-02,   3.00000000e-01,   4.95675376e-17,\n",
       "           2.47727901e-01,   7.23363131e-02,   2.41695215e-01,\n",
       "           7.78965777e-02])],\n",
       " [0.0049950520068177528,\n",
       "  0.02222222222222963,\n",
       "  0.22477734030672394,\n",
       "  0.48876817848119664,\n",
       "  array([  5.47557488e-02,   3.00000000e-01,   1.95116202e-17,\n",
       "           2.47673515e-01,   7.49791459e-02,   2.43180263e-01,\n",
       "           7.94113269e-02])],\n",
       " [0.0051677363190856329,\n",
       "  0.023232323232347571,\n",
       "  0.22243734590823552,\n",
       "  0.48724998299973643,\n",
       "  array([ 0.0491838 ,  0.3       ,  0.        ,  0.24761928,  0.07761428,\n",
       "          0.24466098,  0.08092165])],\n",
       " [0.0053399820020123209,\n",
       "  0.024242424242439733,\n",
       "  0.22027425758286748,\n",
       "  0.48574215338239907,\n",
       "  array([ 0.04362601,  0.3       ,  0.        ,  0.24756519,  0.08024272,\n",
       "          0.24613794,  0.08242814])],\n",
       " [0.0055118448121795043,\n",
       "  0.025252525252543085,\n",
       "  0.21826905456215423,\n",
       "  0.48424431361876646,\n",
       "  array([  3.80805761e-02,   3.00000000e-01,   9.40734395e-18,\n",
       "           2.47511216e-01,   8.28653246e-02,   2.47611615e-01,\n",
       "           8.39312681e-02])],\n",
       " [0.0056833706353822174,\n",
       "  0.026262626262632819,\n",
       "  0.21640526650103811,\n",
       "  0.4827561600301235,\n",
       "  array([  3.25460126e-02,   3.00000000e-01,   1.41600781e-17,\n",
       "           2.47457345e-01,   8.54827776e-02,   2.49082398e-01,\n",
       "           8.54314670e-02])],\n",
       " [0.0058545991666921378,\n",
       "  0.027272727273171937,\n",
       "  0.21466863610854503,\n",
       "  0.48127745316377119,\n",
       "  array([  2.70210458e-02,   3.00000000e-01,   2.05673099e-17,\n",
       "           2.47403558e-01,   8.80957470e-02,   2.50550633e-01,\n",
       "           8.69290160e-02])],\n",
       " [0.0060255630124580626,\n",
       "  0.02828282828413204,\n",
       "  0.21304669221637496,\n",
       "  0.47980799469470825,\n",
       "  array([  2.15046222e-02,   3.00000000e-01,   5.07280885e-17,\n",
       "           2.47349840e-01,   9.07046886e-02,   2.52016584e-01,\n",
       "           8.84242645e-02])],\n",
       " [0.0061962904943178177,\n",
       "  0.029292929293222723,\n",
       "  0.21152853756252385,\n",
       "  0.47834762357750904,\n",
       "  array([ 0.01599581,  0.3       ,  0.        ,  0.24729625,  0.09330989,\n",
       "          0.25348054,  0.0899175 ])],\n",
       " [0.0063668067055733871,\n",
       "  0.030303030304775831,\n",
       "  0.21010462127181923,\n",
       "  0.47689621816024069,\n",
       "  array([  1.04938353e-02,   3.00000000e-01,   3.33879212e-17,\n",
       "           2.47242651e-01,   9.59120429e-02,   2.54942655e-01,\n",
       "           9.14088153e-02])],\n",
       " [0.0065371318072272814,\n",
       "  0.031313131313148071,\n",
       "  0.20876646739198532,\n",
       "  0.47545366383225773,\n",
       "  array([  4.99799977e-03,   3.00000000e-01,   8.32797276e-17,\n",
       "           2.47189219e-01,   9.85110440e-02,   2.56403162e-01,\n",
       "           9.28985747e-02])],\n",
       " [0.0066979135784457512,\n",
       "  0.032323232323381183,\n",
       "  0.20721670133221112,\n",
       "  0.47399180256270451,\n",
       "  array([  0.00000000e+00,   3.00000000e-01,   3.02833296e-17,\n",
       "           2.45693251e-01,   1.01674788e-01,   2.57841991e-01,\n",
       "           9.47899703e-02])],\n",
       " [0.006760910544223897,\n",
       "  0.033333333333336886,\n",
       "  0.20282731632669529,\n",
       "  0.47229331444067718,\n",
       "  array([ 0.        ,  0.3       ,  0.        ,  0.23020016,  0.11023903,\n",
       "          0.25902634,  0.10053448])],\n",
       " [0.0068199955594940055,\n",
       "  0.03434343434424212,\n",
       "  0.19858222363941941,\n",
       "  0.47066009962895161,\n",
       "  array([  2.12287177e-17,   3.00000000e-01,   0.00000000e+00,\n",
       "           2.15669132e-01,   1.18271421e-01,   2.60137122e-01,\n",
       "           1.05922325e-01])],\n",
       " [0.0068802928548804152,\n",
       "  0.035353535353638305,\n",
       "  0.19461399789462216,\n",
       "  0.4690220880459865,\n",
       "  array([  0.00000000e+00,   2.97237817e-01,   1.48826412e-17,\n",
       "           2.05078751e-01,   1.25483378e-01,   2.61562448e-01,\n",
       "           1.10637606e-01])],\n",
       " [0.0069435169579261623,\n",
       "  0.036363636364861195,\n",
       "  0.19094671633653784,\n",
       "  0.46735514353466956,\n",
       "  array([  1.70270906e-18,   2.91395591e-01,   3.38205632e-17,\n",
       "           1.98495104e-01,   1.31994531e-01,   2.63368062e-01,\n",
       "           1.14746712e-01])],\n",
       " [0.007005255892890784,\n",
       "  0.037373737373841406,\n",
       "  0.18743792794439382,\n",
       "  0.46571378753680726,\n",
       "  array([ 0.        ,  0.28569047,  0.        ,  0.19206613,  0.13835256,\n",
       "          0.26513164,  0.11875921])],\n",
       " [0.0070657153466977618,\n",
       "  0.038383838383899312,\n",
       "  0.18408047876893896,\n",
       "  0.4640942487776602,\n",
       "  array([  5.40326996e-17,   2.80103669e-01,   1.34497504e-17,\n",
       "           1.85770351e-01,   1.44578930e-01,   2.66858431e-01,\n",
       "           1.22688619e-01])],\n",
       " [0.0071250618617791613,\n",
       "  0.039393939394775195,\n",
       "  0.18086695494901828,\n",
       "  0.46249351529449079,\n",
       "  array([  8.80218556e-17,   2.74619748e-01,   3.44621381e-17,\n",
       "           1.79590447e-01,   1.50690713e-01,   2.68553373e-01,\n",
       "           1.26545719e-01])],\n",
       " [0.0071834322594079751,\n",
       "  0.040404040404171025,\n",
       "  0.17778994841977261,\n",
       "  0.46090916061494325,\n",
       "  array([  1.99196941e-16,   2.69225931e-01,   3.21554468e-17,\n",
       "           1.73512266e-01,   1.56701904e-01,   2.70220593e-01,\n",
       "           1.30339306e-01])],\n",
       " [0.0072409394425797628,\n",
       "  0.041414141414439908,\n",
       "  0.174842196295178,\n",
       "  0.45933922090446411,\n",
       "  array([ 0.        ,  0.26391195,  0.        ,  0.16752391,  0.16262426,\n",
       "          0.27186307,  0.1340768 ])],\n",
       " [0.0072976783622880079,\n",
       "  0.042424242424329642,\n",
       "  0.17201670425357798,\n",
       "  0.45778207348789379,\n",
       "  array([  5.63057704e-17,   2.58668884e-01,   6.42164794e-18,\n",
       "           1.61615648e-01,   1.68467430e-01,   2.73483645e-01,\n",
       "           1.37764392e-01])],\n",
       " [0.007353730269796039,\n",
       "  0.043434343434984125,\n",
       "  0.16930681318582999,\n",
       "  0.45623638815553741,\n",
       "  array([  3.53443991e-17,   2.53489316e-01,   6.99600503e-18,\n",
       "           1.55778969e-01,   1.74239942e-01,   2.75084554e-01,\n",
       "           1.41407218e-01])],\n",
       " [0.0074091624536651987,\n",
       "  0.044444444449863688,\n",
       "  0.16670615518713999,\n",
       "  0.45470104749105422,\n",
       "  array([ 0.        ,  0.24836709,  0.        ,  0.15000661,  0.17994852,\n",
       "          0.27666778,  0.14500999])],\n",
       " [0.0074640357065298641,\n",
       "  0.045454545454947849,\n",
       "  0.16420878554220333,\n",
       "  0.45317512745237493,\n",
       "  array([  4.35040379e-17,   2.43296489e-01,   7.36880843e-17,\n",
       "           1.44292547e-01,   1.85599599e-01,   2.78235008e-01,\n",
       "           1.48576357e-01])],\n",
       " [0.0075184012594631594,\n",
       "  0.04646464646506418,\n",
       "  0.16180907058264377,\n",
       "  0.4516578471462393,\n",
       "  array([ 0.        ,  0.23827278,  0.        ,  0.13863138,  0.19119838,\n",
       "          0.27978776,  0.15210971])],\n",
       " [0.007572304139103459,\n",
       "  0.047474747475922174,\n",
       "  0.15950172547929642,\n",
       "  0.45014855309094376,\n",
       "  array([  0.00000000e+00,   2.33291888e-01,   3.35066971e-17,\n",
       "           1.33018253e-01,   1.96749533e-01,   2.81327386e-01,\n",
       "           1.55612940e-01])],\n",
       " [0.0076257836766798369,\n",
       "  0.048484848485280944,\n",
       "  0.15728178833011877,\n",
       "  0.44864669193272366,\n",
       "  array([  0.00000000e+00,   2.28350036e-01,   2.32160791e-17,\n",
       "           1.27449404e-01,   2.02257093e-01,   2.82854780e-01,\n",
       "           1.59088687e-01])],\n",
       " [0.0076788747370002929,\n",
       "  0.049494949496117817,\n",
       "  0.15514461202960905,\n",
       "  0.44715179590644866,\n",
       "  array([  2.90144057e-17,   2.23444034e-01,   7.79373972e-17,\n",
       "           1.21921040e-01,   2.07724593e-01,   2.84371143e-01,\n",
       "           1.62539189e-01])],\n",
       " [0.0077316082373343554,\n",
       "  0.050505050505777832,\n",
       "  0.15308584309701564,\n",
       "  0.44566347584955462,\n",
       "  array([  1.00025493e-16,   2.18571175e-01,   1.06964116e-17,\n",
       "           1.16429751e-01,   2.13155318e-01,   2.85877308e-01,\n",
       "           1.65966448e-01])],\n",
       " [0.0077840116822561105,\n",
       "  0.051515151517417417,\n",
       "  0.15110140323714888,\n",
       "  0.44418139688637009,\n",
       "  array([  0.00000000e+00,   2.13728780e-01,   1.27966457e-17,\n",
       "           1.10972889e-01,   2.18552031e-01,   2.87374022e-01,\n",
       "           1.69372278e-01])],\n",
       " [0.0078361099175673736,\n",
       "  0.052525252525256493,\n",
       "  0.14918747727675219,\n",
       "  0.44270528087959543,\n",
       "  array([  1.35858024e-16,   2.08914596e-01,   0.00000000e+00,\n",
       "           1.05547804e-01,   2.23917331e-01,   2.88862028e-01,\n",
       "           1.72758242e-01])],\n",
       " [0.0078879248530163548,\n",
       "  0.053535353535360403,\n",
       "  0.14734048310349415,\n",
       "  0.4412348917730084,\n",
       "  array([  3.87585813e-17,   2.04126590e-01,   1.78171202e-17,\n",
       "           1.00152214e-01,   2.29253444e-01,   2.90341938e-01,\n",
       "           1.76125813e-01])],\n",
       " [0.0079394765614632171,\n",
       "  0.054545454545479315,\n",
       "  0.14555707029342621,\n",
       "  0.43977003321941305,\n",
       "  array([  1.68505835e-16,   1.99362905e-01,   0.00000000e+00,\n",
       "           9.47840449e-02,   2.34562457e-01,   2.91814327e-01,\n",
       "           1.79476266e-01])],\n",
       " [0.0079907829834891652,\n",
       "  0.055555555555588949,\n",
       "  0.14383409370271852,\n",
       "  0.43831054073432718,\n",
       "  array([ 0.        ,  0.19462189,  0.        ,  0.08944141,  0.2398462 ,\n",
       "          0.29327971,  0.18281078])],\n",
       " [0.0080418609600274946,\n",
       "  0.056565656567422767,\n",
       "  0.142168613396047,\n",
       "  0.43685628277152611,\n",
       "  array([  6.94457722e-17,   1.89902051e-01,   0.00000000e+00,\n",
       "           8.41225391e-02,   2.45106552e-01,   2.94738513e-01,\n",
       "           1.86130345e-01])],\n",
       " [0.0080927238874471986,\n",
       "  0.057575757576466463,\n",
       "  0.14055783593814181,\n",
       "  0.43540713601494008,\n",
       "  array([  1.44290867e-17,   1.85201988e-01,   4.03033814e-17,\n",
       "           7.88260634e-02,   2.50344531e-01,   2.96191273e-01,\n",
       "           1.89436145e-01])],\n",
       " [0.0081433867187936833,\n",
       "  0.058585858586034614,\n",
       "  0.13899918709623316,\n",
       "  0.43396301945281152,\n",
       "  array([  2.84382830e-16,   1.80520417e-01,   3.29980555e-17,\n",
       "           7.35504703e-02,   2.55561971e-01,   2.97638295e-01,\n",
       "           1.92728847e-01])],\n",
       " [0.0081938615124728803,\n",
       "  0.059595959596018981,\n",
       "  0.13749021859898422,\n",
       "  0.43252385902222751,\n",
       "  array([  0.00000000e+00,   1.75856206e-01,   1.87441572e-18,\n",
       "           6.82945086e-02,   2.60760067e-01,   2.99079912e-01,\n",
       "           1.96009306e-01])],\n",
       " [0.0082436798025571391,\n",
       "  0.060606060606175176,\n",
       "  0.13602071674193567,\n",
       "  0.43109325677068649,\n",
       "  array([  6.12042430e-17,   1.71262108e-01,   3.11759751e-17,\n",
       "           6.33255956e-02,   2.66005382e-01,   3.00000000e-01,\n",
       "           1.99406914e-01])],\n",
       " [0.0082924669772552941,\n",
       "  0.061616161617194506,\n",
       "  0.13458266077614955,\n",
       "  0.42967391308132796,\n",
       "  array([ 0.        ,  0.16677993,  0.        ,  0.0588516 ,  0.2713479 ,\n",
       "          0.3       ,  0.20302058])],\n",
       " [0.0083410810953410408,\n",
       "  0.06262626262661225,\n",
       "  0.13318823039260533,\n",
       "  0.42825922814123923,\n",
       "  array([ 0.        ,  0.16231357,  0.        ,  0.0543936 ,  0.27667144,\n",
       "          0.3       ,  0.20662139])],\n",
       " [0.008389531996668741,\n",
       "  0.063636363636380019,\n",
       "  0.13183550280476056,\n",
       "  0.42684916901592146,\n",
       "  array([  2.30801307e-17,   1.57862214e-01,   1.39643707e-16,\n",
       "           4.99505686e-02,   2.81977119e-01,   3.00000000e-01,\n",
       "           2.10210098e-01])],\n",
       " [0.0084378287768694365,\n",
       "  0.064646464646753651,\n",
       "  0.1305226638916156,\n",
       "  0.42544371183839563,\n",
       "  array([  0.00000000e+00,   1.53425044e-01,   8.46031194e-17,\n",
       "           4.55216281e-02,   2.87265937e-01,   3.00000000e-01,\n",
       "           2.13787391e-01])],\n",
       " [0.008485979977309795,\n",
       "  0.065656565657644939,\n",
       "  0.12924800272920919,\n",
       "  0.42404284172411716,\n",
       "  array([  1.33502027e-16,   1.49001246e-01,   0.00000000e+00,\n",
       "           4.11060461e-02,   2.92538819e-01,   3.00000000e-01,\n",
       "           2.17353889e-01])],\n",
       " [0.0085339929195398182,\n",
       "  0.066666666666671884,\n",
       "  0.12800989379308725,\n",
       "  0.42264654973596055,\n",
       "  array([  6.55195227e-17,   1.44590151e-01,   1.23274395e-18,\n",
       "           3.67031003e-02,   2.97796495e-01,   3.00000000e-01,\n",
       "           2.20910253e-01])],\n",
       " [0.0085723888872723947,\n",
       "  0.067676767676767682,\n",
       "  0.12666664176715925,\n",
       "  0.42118942776292301,\n",
       "  array([ 0.        ,  0.13982083,  0.        ,  0.03415171,  0.3       ,\n",
       "          0.3       ,  0.22602746])],\n",
       " [0.008603675662583618,\n",
       "  0.068686868686868643,\n",
       "  0.12525939567584982,\n",
       "  0.41969333545421383,\n",
       "  array([  1.11707038e-16,   1.34820368e-01,   2.44197754e-17,\n",
       "           3.29427275e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.32236904e-01])],\n",
       " [0.0086347059305337884,\n",
       "  0.069696969697056355,\n",
       "  0.12388925900315684,\n",
       "  0.41820628419975631,\n",
       "  array([  8.46483073e-17,   1.29860905e-01,   0.00000000e+00,\n",
       "           3.17436606e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.38395434e-01])],\n",
       " [0.0086654964988895061,\n",
       "  0.070707070707244232,\n",
       "  0.12255487905542224,\n",
       "  0.41672791189727326,\n",
       "  array([  3.14958396e-16,   1.24939753e-01,   0.00000000e+00,\n",
       "           3.05538560e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.44506391e-01])],\n",
       " [0.0086960626677910057,\n",
       "  0.071717171719273637,\n",
       "  0.12125495832198276,\n",
       "  0.41525789861122769,\n",
       "  array([  2.22539928e-16,   1.20054451e-01,   0.00000000e+00,\n",
       "           2.93727491e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.50572800e-01])],\n",
       " [0.0087264182156124061,\n",
       "  0.072727272727334188,\n",
       "  0.11998825046456918,\n",
       "  0.41379596190468526,\n",
       "  array([  1.26722235e-16,   1.15202840e-01,   0.00000000e+00,\n",
       "           2.81997282e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.56597431e-01])],\n",
       " [0.0087565759442563996,\n",
       "  0.073737373739652973,\n",
       "  0.11875356417186129,\n",
       "  0.41234185073052088,\n",
       "  array([  3.19470848e-17,   1.10382833e-01,   0.00000000e+00,\n",
       "           2.70343775e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.62582790e-01])],\n",
       " [0.0087865474299817243,\n",
       "  0.074747474747477838,\n",
       "  0.11754975615785875,\n",
       "  0.41089534294148738,\n",
       "  array([  7.73118887e-17,   1.05592591e-01,   1.39643256e-16,\n",
       "           2.58762242e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.68531185e-01])],\n",
       " [0.008816343330394558,\n",
       "  0.075757575757580159,\n",
       "  0.11637573196120141,\n",
       "  0.40945624111611262,\n",
       "  array([ 0.        ,  0.10083041,  0.        ,  0.02472486,  0.3       ,\n",
       "          0.3       ,  0.27444473])],\n",
       " [0.0088459735123101041,\n",
       "  0.076767676769996768,\n",
       "  0.11523044443318871,\n",
       "  0.40802436955766558,\n",
       "  array([  1.70569124e-16,   9.60946975e-02,   3.69188442e-17,\n",
       "           2.35799325e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.80325370e-01])],\n",
       " [0.0088754468202482169,\n",
       "  0.077777777779350479,\n",
       "  0.11411288768659823,\n",
       "  0.40659957278967757,\n",
       "  array([  3.31312895e-16,   9.13841054e-02,   0.00000000e+00,\n",
       "           2.24409805e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.86174914e-01])],\n",
       " [0.0089047717376813697,\n",
       "  0.078787878788028523,\n",
       "  0.11302210282420259,\n",
       "  0.40518171134665182,\n",
       "  array([  2.44222226e-16,   8.66972304e-02,   6.99496387e-17,\n",
       "           2.13077621e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.91995008e-01])],\n",
       " [0.0089339559983259379,\n",
       "  0.07979797979848062,\n",
       "  0.11195717010490087,\n",
       "  0.40377066137009843,\n",
       "  array([  5.47918914e-17,   8.20328351e-02,   3.49935384e-18,\n",
       "           2.01799806e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           2.97787184e-01])],\n",
       " [0.0089944128591160789,\n",
       "  0.080808080808080829,\n",
       "  0.11130585913156145,\n",
       "  0.40228298880865271,\n",
       "  array([ 0.        ,  0.06002898,  0.        ,  0.03997102,  0.3       ,\n",
       "          0.3       ,  0.3       ])],\n",
       " [0.0090648797743556036,\n",
       "  0.081818181818192365,\n",
       "  0.11079297501988754,\n",
       "  0.40082032853603211,\n",
       "  array([ 0.       ,  0.0311292,  0.       ,  0.0688708,  0.3      ,\n",
       "          0.3      ,  0.3      ])],\n",
       " [0.0091273792976488445,\n",
       "  0.082828282828282751,\n",
       "  0.11019640859356541,\n",
       "  0.39942146648386961,\n",
       "  array([  3.26456231e-16,   5.49699450e-03,   7.89711845e-18,\n",
       "           9.45030055e-02,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])],\n",
       " [0.009140782729937293,\n",
       "  0.083058498498133085,\n",
       "  0.11005234738432879,\n",
       "  0.39910940918990734,\n",
       "  array([  6.53281554e-17,   0.00000000e+00,   0.00000000e+00,\n",
       "           1.00000000e-01,   3.00000000e-01,   3.00000000e-01,\n",
       "           3.00000000e-01])]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_activeM_pair.sort(key= lambda x: x[0])\n",
    "frontier_activeM_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Construction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean variance opt based over post BL and target peer return \n",
    "\n",
    "benchmark_portfolio= Portfolio( asset_ret= UniverseProperty['arithBL_peer_CMAactive'].arith2geo(), \n",
    "                               asset_cov= UniverseProperty['arithBL_peer_CMAactive'].post_cov, \n",
    "                               weight= portfolios['Peer'].weight)\n",
    "\n",
    "base_portfolio_w= sorted( [x for x in frontier_BLcons_pair if x[0]>= benchmark_portfolio.expected_return], key= lambda x: x[0]) [0]\n",
    "base_portfolio= Portfolio(asset_ret= benchmark_portfolio.asset_return,\n",
    "                         asset_cov= benchmark_portfolio.asset_cov,\n",
    "                         weight= base_portfolio_w[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064955163370140942"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.expected_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12428132380236374"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13861386,  0.28712871,  0.04950495,  0.23762376,  0.02970297,\n",
       "        0.20792079,  0.04950495])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_portfolio.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22818002,  0.3       ,  0.        ,  0.16908807,  0.06675601,\n",
       "        0.1549494 ,  0.0810265 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_portfolio.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base_portfolio achieves similar return as bechmark with smaller vol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For display purpose \n",
    "\n",
    "\n",
    "writter= pd.ExcelWriter('output_wz3.xlsx')\n",
    "tmp_df1= pd.DataFrame(   [[x[0], x[1]]+ x[2].tolist()  for x in frontier_uncons_pair], \n",
    "                      columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name']  )\n",
    "tmp_df2= pd.DataFrame(  [[x[0], x[1]]+ x[2].tolist()  for x in frontier_uncons_NoCorp_pair], \n",
    "                     columns=  ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df3= pd.DataFrame(  [[x[0], x[1]]+ x[2].tolist()  for x in frontier_cons_pair], \n",
    "                     columns=  ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df4= pd.DataFrame(  [[x[0], x[1]]+ x[2].tolist()  for x in frontier_cons_NoCorp_pair], \n",
    "                     columns=  ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df5= pd.DataFrame( [[x[0], x[1]]+ x[2].tolist() for x in frontier_BLuncons_pair], \n",
    "                     columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df6= pd.DataFrame( [[x[0], x[1]]+ x[2].tolist() for x in frontier_BLuncons_NoCorp_pair],\n",
    "                     columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df7= pd.DataFrame( [[x[0], x[1]]+ x[2].tolist() for x in frontier_BLcons_pair], \n",
    "                     columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "tmp_df8= pd.DataFrame( [[x[0], x[1]]+ x[2].tolist() for x in frontier_BLcons_NoCorp_pair],\n",
    "                     columns= ['ExpectedRet', 'vol']+ UniverseProperty['asset_name'])\n",
    "\n",
    "frontier_activeM_pair.sort(key= lambda x: x[0])\n",
    "tmp_df9= pd.DataFrame(  [[x[0], x[1], x[2], x[3]]+ x[4].tolist() for x in frontier_activeM_pair], \n",
    "                     columns= ['active_ExpReturn', 'trackingError', 'IR', 'SR']+ UniverseProperty['asset_name'])\n",
    "\n",
    "tmp_df1.to_excel( writter, 'UNCONS')\n",
    "tmp_df2.to_excel( writter, 'UNCONS_NoCorp')\n",
    "tmp_df3.to_excel( writter, 'CONS')\n",
    "tmp_df4.to_excel( writter, 'CONS_NoCorp')\n",
    "tmp_df5.to_excel( writter, 'BL_UNCONS')\n",
    "tmp_df6.to_excel( writter, 'BL_UNCONS_NoCorp')\n",
    "tmp_df7.to_excel( writter, 'BL_CONS')\n",
    "tmp_df8.to_excel( writter,  'BL_CONS_NoCorp')\n",
    "tmp_df9.to_excel( writter, 'BL_activeOpt')\n",
    "writter.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
