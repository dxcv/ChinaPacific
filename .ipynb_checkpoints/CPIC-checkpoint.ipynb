{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US NCREIF: FUND INDEX OPEN-END DIVERSIFIED CORE RETURNS NADJ</th>\n",
       "      <th>US Private Equity</th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "      <th>Cash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018311</td>\n",
       "      <td>0.034503</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.035495</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029578</td>\n",
       "      <td>0.047497</td>\n",
       "      <td>0.047757</td>\n",
       "      <td>0.070263</td>\n",
       "      <td>0.064625</td>\n",
       "      <td>0.076253</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.091792</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>0.006670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.136900</td>\n",
       "      <td>-0.159500</td>\n",
       "      <td>-0.333429</td>\n",
       "      <td>-0.214401</td>\n",
       "      <td>-0.215870</td>\n",
       "      <td>-0.219432</td>\n",
       "      <td>-0.261180</td>\n",
       "      <td>-0.211290</td>\n",
       "      <td>-0.275584</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.012925</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.007742</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>-0.030336</td>\n",
       "      <td>-0.016548</td>\n",
       "      <td>-0.043980</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024050</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>0.026129</td>\n",
       "      <td>0.031222</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>0.038349</td>\n",
       "      <td>0.008214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035350</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>0.049455</td>\n",
       "      <td>0.070468</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.066656</td>\n",
       "      <td>0.111489</td>\n",
       "      <td>0.013101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.137135</td>\n",
       "      <td>0.264363</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>0.212974</td>\n",
       "      <td>0.297346</td>\n",
       "      <td>0.258489</td>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.023825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       US NCREIF: FUND INDEX OPEN-END DIVERSIFIED CORE RETURNS NADJ  \\\n",
       "count                                         114.000000              \n",
       "mean                                            0.018311              \n",
       "std                                             0.029578              \n",
       "min                                            -0.136900              \n",
       "25%                                             0.012925              \n",
       "50%                                             0.024050              \n",
       "75%                                             0.035350              \n",
       "max                                             0.054500              \n",
       "\n",
       "       US Private Equity       US_RE       US_PE       US_HY       SP500  \\\n",
       "count         114.000000  114.000000  114.000000  114.000000  114.000000   \n",
       "mean            0.034503    0.018989    0.035495    0.024647    0.027670   \n",
       "std             0.047497    0.047757    0.070263    0.064625    0.076253   \n",
       "min            -0.159500   -0.333429   -0.214401   -0.215870   -0.219432   \n",
       "25%             0.011300    0.007742    0.004679   -0.002124   -0.001749   \n",
       "50%             0.037200    0.018845    0.037985    0.026129    0.031222   \n",
       "75%             0.059000    0.035783    0.069509    0.049455    0.070468   \n",
       "max             0.178000    0.137135    0.264363    0.427906    0.212974   \n",
       "\n",
       "       Rusell2000        EAFE          EM        Cash  \n",
       "count  114.000000  114.000000  114.000000  114.000000  \n",
       "mean     0.028452    0.017290    0.032061    0.008155  \n",
       "std      0.099660    0.091792    0.128686    0.006670  \n",
       "min     -0.261180   -0.211290   -0.275584    0.000000  \n",
       "25%     -0.030336   -0.016548   -0.043980    0.000726  \n",
       "50%      0.037918    0.017968    0.038349    0.008214  \n",
       "75%      0.088459    0.066656    0.111489    0.013101  \n",
       "max      0.297346    0.258489    0.348433    0.023825  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in data\n",
    "ret_df_raw= pd.read_excel( io= 'Data/cipc data_20170907.xlsx', sheetname= 'Data_Input', index_col=0)\n",
    "ret_df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_df= ret_df_raw[['US_RE', \n",
    "                   'US_PE',\n",
    "                   'US_HY',\n",
    "                   'SP500',\n",
    "                   'Rusell2000',\n",
    "                   'EAFE',\n",
    "                   'EM']]\n",
    "ret_df_cov= ret_df.cov()\n",
    "ret_df_corr= ret_df.corr()\n",
    "N= ret_df.shape[1]\n",
    "#ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# period1_start= '1987-01-01'\n",
    "# period1_end= '1999-07-01'\n",
    "# period2_start= '2002-01-01'\n",
    "# period2_end= '2008-01-01'\n",
    "# period3_start= '2009-12-31'\n",
    "# period3_end= '2017-12-31'\n",
    "\n",
    "# ret_df1= ret_df[ np.logical_and( ret_df.index>= period1_start, ret_df.index<= period1_end) ]\n",
    "# ret_df2= ret_df[ np.logical_and( ret_df.index>= period2_start, ret_df.index<= period2_end) ]\n",
    "# ret_df3= ret_df[ np.logical_and( ret_df.index>= period3_start, ret_df.index<= period3_end) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.006220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.008594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.007698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.015923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       0.002540  0.001038  0.000806  0.001162    0.001527  0.001175   \n",
       "US_PE       0.001038  0.005029  0.001758  0.003705    0.004692  0.003906   \n",
       "US_HY       0.000806  0.001758  0.004316  0.002500    0.003166  0.002726   \n",
       "SP500       0.001162  0.003705  0.002500  0.005852    0.006276  0.005322   \n",
       "Rusell2000  0.001527  0.004692  0.003166  0.006276    0.009711  0.006270   \n",
       "EAFE        0.001175  0.003906  0.002726  0.005322    0.006270  0.008299   \n",
       "EM          0.001462  0.005121  0.003805  0.006220    0.008594  0.007698   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.001462  \n",
       "US_PE       0.005121  \n",
       "US_HY       0.003805  \n",
       "SP500       0.006220  \n",
       "Rusell2000  0.008594  \n",
       "EAFE        0.007698  \n",
       "EM          0.015923  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ledoit Wolf shrunk cov matrix\n",
    "\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "LW= LedoitWolf( ).fit(ret_df)\n",
    "LW_alpha= LW.shrinkage_\n",
    "\n",
    "LW_cov= pd.DataFrame(LW.covariance_)\n",
    "LW_cov.index= ret_df_cov.index\n",
    "LW_cov.columns= ret_df_cov.columns\n",
    "LW_cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## arithmatic avg ret to exponential avg ret \n",
    "\n",
    "ret_cov= np.diagonal(np.matrix(LW_cov.values))\n",
    "coverter= np.array([ret_cov.tolist()]*ret_df.shape[0])* .5\n",
    "ret_df_exp= ret_df- coverter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_eq= np.ones( (7,))*1.0/7\n",
    "weight_peer= np.array( (0.14,0.29,0.05,0.24,0.03,0.21,0.05))\n",
    "weight_peer= weight_peer/ np.sum(weight_peer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 11\n",
      "         Function evaluations: 1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:394: RuntimeWarning: Method Powell cannot handle constraints nor bounds.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "## solve ERC weight \n",
    "\n",
    "def objective_func(w, sigma): \n",
    "    A= np.diag( w)\n",
    "    B= np.diag( np.dot( sigma, w))\n",
    "    C= np.diag( np.dot( A, B))/ np.dot( np.dot( w, sigma), w)- np.ones( w.size )* 1/ w.size\n",
    "    \n",
    "    return np.dot( C, C)\n",
    "\n",
    "\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "opt_res= minimize( objective_func, \n",
    "                 x0= weight_eq,\n",
    "                 args= LW_cov,\n",
    "                 method= 'Powell',\n",
    "                 options= {'disp': True},\n",
    "                 bounds= [[0,None]]*7,\n",
    "                 tol= 1e-16)\n",
    "\n",
    "weight_erc = opt_res.x/ np.sum( opt_res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7842763342203468e-23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_func( weight_erc, LW_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>0.177851</td>\n",
       "      <td>0.118734</td>\n",
       "      <td>0.092724</td>\n",
       "      <td>0.105874</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "weight_eq    0.142857  0.142857  0.142857  0.142857    0.142857  0.142857   \n",
       "weight_peer  0.138614  0.287129  0.049505  0.237624    0.029703  0.207921   \n",
       "weight_erc   0.282415  0.142979  0.177851  0.118734    0.092724  0.105874   \n",
       "\n",
       "                   EM  \n",
       "weight_eq    0.142857  \n",
       "weight_peer  0.049505  \n",
       "weight_erc   0.079423  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "portf_weight_1= pd.DataFrame( [weight_eq, weight_peer, weight_erc], \n",
    "                             index=['weight_eq', 'weight_peer', 'weight_erc'], \n",
    "                             columns= LW_cov. columns)\n",
    "portf_weight_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## recover the implied expected ret based on shirinked cov matrix\n",
    "\n",
    "rf= 179/10000\n",
    "gamma= [ 1.5, 2, 2.5, 3, 3.5,4]\n",
    "implied_ExpRet= {}\n",
    "\n",
    "for w_name in portf_weight_1.index: \n",
    "    tmp_dic= {}\n",
    "    for g in gamma:\n",
    "        w= np.array(portf_weight_1.loc[w_name].tolist())\n",
    "        tmp1= np.ones( ( N))* rf/4+ g*  np.dot( LW_cov, w)\n",
    "        tmp2= np.ones( (N))*rf/4+ g* np.dot( ret_df_cov,w) \n",
    "        tmp_dic[str(g)+ '_shrunk']= tmp1\n",
    "        tmp_dic[str(g)+'_unshrunk']= tmp2\n",
    "    \n",
    "    \n",
    "    tmp= pd.DataFrame( tmp_dic, index= LW_cov.index)\n",
    "    tmp= tmp- .5* np.array([np.diag(LW_cov).tolist()] *tmp.shape[1]).T\n",
    "    implied_ExpRet[w_name]= tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5_shrunk</th>\n",
       "      <th>1.5_unshrunk</th>\n",
       "      <th>2.5_shrunk</th>\n",
       "      <th>2.5_unshrunk</th>\n",
       "      <th>2_shrunk</th>\n",
       "      <th>2_unshrunk</th>\n",
       "      <th>3.5_shrunk</th>\n",
       "      <th>3.5_unshrunk</th>\n",
       "      <th>3_shrunk</th>\n",
       "      <th>3_unshrunk</th>\n",
       "      <th>4_shrunk</th>\n",
       "      <th>4_unshrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>2.114289</td>\n",
       "      <td>2.133245</td>\n",
       "      <td>2.669094</td>\n",
       "      <td>2.700688</td>\n",
       "      <td>2.391691</td>\n",
       "      <td>2.416967</td>\n",
       "      <td>3.223899</td>\n",
       "      <td>3.268131</td>\n",
       "      <td>2.946497</td>\n",
       "      <td>2.984409</td>\n",
       "      <td>3.501302</td>\n",
       "      <td>3.551852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>2.948458</td>\n",
       "      <td>3.056591</td>\n",
       "      <td>4.391306</td>\n",
       "      <td>4.571528</td>\n",
       "      <td>3.669882</td>\n",
       "      <td>3.814060</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>6.086466</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>5.328997</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>6.843935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>2.562022</td>\n",
       "      <td>2.634741</td>\n",
       "      <td>3.652207</td>\n",
       "      <td>3.773405</td>\n",
       "      <td>3.107114</td>\n",
       "      <td>3.204073</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>4.912069</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>4.342737</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>5.481402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>3.279979</td>\n",
       "      <td>3.421321</td>\n",
       "      <td>5.053519</td>\n",
       "      <td>5.289088</td>\n",
       "      <td>4.166749</td>\n",
       "      <td>4.355205</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.156855</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.222972</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>8.090739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>3.296555</td>\n",
       "      <td>3.490678</td>\n",
       "      <td>5.595700</td>\n",
       "      <td>5.919238</td>\n",
       "      <td>4.446127</td>\n",
       "      <td>4.704958</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>8.347797</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>7.133518</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>9.562077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>3.164197</td>\n",
       "      <td>3.330556</td>\n",
       "      <td>5.186866</td>\n",
       "      <td>5.464131</td>\n",
       "      <td>4.175532</td>\n",
       "      <td>4.397344</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>7.597706</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.530919</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>8.664494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>2.790269</td>\n",
       "      <td>3.033674</td>\n",
       "      <td>5.580172</td>\n",
       "      <td>5.985847</td>\n",
       "      <td>4.185221</td>\n",
       "      <td>4.509760</td>\n",
       "      <td>8.370075</td>\n",
       "      <td>8.938019</td>\n",
       "      <td>6.975123</td>\n",
       "      <td>7.461933</td>\n",
       "      <td>9.765026</td>\n",
       "      <td>10.414105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1.5_shrunk  1.5_unshrunk  2.5_shrunk  2.5_unshrunk  2_shrunk  \\\n",
       "US_RE         2.114289      2.133245    2.669094      2.700688  2.391691   \n",
       "US_PE         2.948458      3.056591    4.391306      4.571528  3.669882   \n",
       "US_HY         2.562022      2.634741    3.652207      3.773405  3.107114   \n",
       "SP500         3.279979      3.421321    5.053519      5.289088  4.166749   \n",
       "Rusell2000    3.296555      3.490678    5.595700      5.919238  4.446127   \n",
       "EAFE          3.164197      3.330556    5.186866      5.464131  4.175532   \n",
       "EM            2.790269      3.033674    5.580172      5.985847  4.185221   \n",
       "\n",
       "            2_unshrunk  3.5_shrunk  3.5_unshrunk  3_shrunk  3_unshrunk  \\\n",
       "US_RE         2.416967    3.223899      3.268131  2.946497    2.984409   \n",
       "US_PE         3.814060    5.834154      6.086466  5.112730    5.328997   \n",
       "US_HY         3.204073    4.742391      4.912069  4.197299    4.342737   \n",
       "SP500         4.355205    6.827058      7.156855  5.940288    6.222972   \n",
       "Rusell2000    4.704958    7.894844      8.347797  6.745272    7.133518   \n",
       "EAFE          4.397344    7.209535      7.597706  6.198200    6.530919   \n",
       "EM            4.509760    8.370075      8.938019  6.975123    7.461933   \n",
       "\n",
       "            4_shrunk  4_unshrunk  \n",
       "US_RE       3.501302    3.551852  \n",
       "US_PE       6.555578    6.843935  \n",
       "US_HY       5.287484    5.481402  \n",
       "SP500       7.713828    8.090739  \n",
       "Rusell2000  9.044416    9.562077  \n",
       "EAFE        8.220869    8.664494  \n",
       "EM          9.765026   10.414105  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_eq']*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5_shrunk</th>\n",
       "      <th>1.5_unshrunk</th>\n",
       "      <th>2.5_shrunk</th>\n",
       "      <th>2.5_unshrunk</th>\n",
       "      <th>2_shrunk</th>\n",
       "      <th>2_unshrunk</th>\n",
       "      <th>3.5_shrunk</th>\n",
       "      <th>3.5_unshrunk</th>\n",
       "      <th>3_shrunk</th>\n",
       "      <th>3_unshrunk</th>\n",
       "      <th>4_shrunk</th>\n",
       "      <th>4_unshrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>2.199490</td>\n",
       "      <td>2.188242</td>\n",
       "      <td>2.811095</td>\n",
       "      <td>2.792348</td>\n",
       "      <td>2.505292</td>\n",
       "      <td>2.490295</td>\n",
       "      <td>3.422701</td>\n",
       "      <td>3.396455</td>\n",
       "      <td>3.116898</td>\n",
       "      <td>3.094402</td>\n",
       "      <td>3.728504</td>\n",
       "      <td>3.698509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>2.596270</td>\n",
       "      <td>2.680794</td>\n",
       "      <td>3.804326</td>\n",
       "      <td>3.945200</td>\n",
       "      <td>3.200298</td>\n",
       "      <td>3.312997</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>5.209607</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>4.577403</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>5.841810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>2.383524</td>\n",
       "      <td>2.435290</td>\n",
       "      <td>3.354711</td>\n",
       "      <td>3.440986</td>\n",
       "      <td>2.869117</td>\n",
       "      <td>2.938138</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>4.446683</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>3.943835</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>4.949532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>2.801773</td>\n",
       "      <td>2.917307</td>\n",
       "      <td>4.256508</td>\n",
       "      <td>4.449065</td>\n",
       "      <td>3.529140</td>\n",
       "      <td>3.683186</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>5.980822</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.214944</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>6.746701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>2.642041</td>\n",
       "      <td>2.805246</td>\n",
       "      <td>4.504843</td>\n",
       "      <td>4.776850</td>\n",
       "      <td>3.573442</td>\n",
       "      <td>3.791048</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>6.748455</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.762653</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>7.734257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>2.577358</td>\n",
       "      <td>2.713946</td>\n",
       "      <td>4.208801</td>\n",
       "      <td>4.436448</td>\n",
       "      <td>3.393080</td>\n",
       "      <td>3.575197</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.158950</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.297699</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>1.867548</td>\n",
       "      <td>2.065501</td>\n",
       "      <td>4.042303</td>\n",
       "      <td>4.372225</td>\n",
       "      <td>2.954925</td>\n",
       "      <td>3.218863</td>\n",
       "      <td>6.217058</td>\n",
       "      <td>6.678948</td>\n",
       "      <td>5.129680</td>\n",
       "      <td>5.525587</td>\n",
       "      <td>7.304435</td>\n",
       "      <td>7.832310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1.5_shrunk  1.5_unshrunk  2.5_shrunk  2.5_unshrunk  2_shrunk  \\\n",
       "US_RE         2.199490      2.188242    2.811095      2.792348  2.505292   \n",
       "US_PE         2.596270      2.680794    3.804326      3.945200  3.200298   \n",
       "US_HY         2.383524      2.435290    3.354711      3.440986  2.869117   \n",
       "SP500         2.801773      2.917307    4.256508      4.449065  3.529140   \n",
       "Rusell2000    2.642041      2.805246    4.504843      4.776850  3.573442   \n",
       "EAFE          2.577358      2.713946    4.208801      4.436448  3.393080   \n",
       "EM            1.867548      2.065501    4.042303      4.372225  2.954925   \n",
       "\n",
       "            2_unshrunk  3.5_shrunk  3.5_unshrunk  3_shrunk  3_unshrunk  \\\n",
       "US_RE         2.490295    3.422701      3.396455  3.116898    3.094402   \n",
       "US_PE         3.312997    5.012383      5.209607  4.408355    4.577403   \n",
       "US_HY         2.938138    4.325897      4.446683  3.840304    3.943835   \n",
       "SP500         3.683186    5.711243      5.980822  4.983875    5.214944   \n",
       "Rusell2000    3.791048    6.367644      6.748455  5.436244    5.762653   \n",
       "EAFE          3.575197    5.840244      6.158950  5.024522    5.297699   \n",
       "EM            3.218863    6.217058      6.678948  5.129680    5.525587   \n",
       "\n",
       "            4_shrunk  4_unshrunk  \n",
       "US_RE       3.728504    3.698509  \n",
       "US_PE       5.616411    5.841810  \n",
       "US_HY       4.811491    4.949532  \n",
       "SP500       6.438610    6.746701  \n",
       "Rusell2000  7.299045    7.734257  \n",
       "EAFE        6.655965    7.020200  \n",
       "EM          7.304435    7.832310  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_erc']*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5_shrunk</th>\n",
       "      <th>1.5_unshrunk</th>\n",
       "      <th>2.5_shrunk</th>\n",
       "      <th>2.5_unshrunk</th>\n",
       "      <th>2_shrunk</th>\n",
       "      <th>2_unshrunk</th>\n",
       "      <th>3.5_shrunk</th>\n",
       "      <th>3.5_unshrunk</th>\n",
       "      <th>3_shrunk</th>\n",
       "      <th>3_unshrunk</th>\n",
       "      <th>4_shrunk</th>\n",
       "      <th>4_unshrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>2.078958</td>\n",
       "      <td>2.096641</td>\n",
       "      <td>2.610209</td>\n",
       "      <td>2.639680</td>\n",
       "      <td>2.344583</td>\n",
       "      <td>2.368160</td>\n",
       "      <td>3.141460</td>\n",
       "      <td>3.182720</td>\n",
       "      <td>2.875835</td>\n",
       "      <td>2.911200</td>\n",
       "      <td>3.407086</td>\n",
       "      <td>3.454240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>3.040413</td>\n",
       "      <td>3.117582</td>\n",
       "      <td>4.544566</td>\n",
       "      <td>4.673180</td>\n",
       "      <td>3.792489</td>\n",
       "      <td>3.895381</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>6.228778</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>5.450979</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>7.006577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>2.290933</td>\n",
       "      <td>2.369524</td>\n",
       "      <td>3.200393</td>\n",
       "      <td>3.331376</td>\n",
       "      <td>2.745663</td>\n",
       "      <td>2.850450</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>4.293229</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>3.812303</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>4.774156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>3.223711</td>\n",
       "      <td>3.336902</td>\n",
       "      <td>4.959738</td>\n",
       "      <td>5.148390</td>\n",
       "      <td>4.091725</td>\n",
       "      <td>4.242646</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>6.959878</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.054134</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>7.865622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>2.982469</td>\n",
       "      <td>3.184680</td>\n",
       "      <td>5.072223</td>\n",
       "      <td>5.409241</td>\n",
       "      <td>4.027346</td>\n",
       "      <td>4.296960</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.633801</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.521521</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.746082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>3.116358</td>\n",
       "      <td>3.262773</td>\n",
       "      <td>5.107134</td>\n",
       "      <td>5.351160</td>\n",
       "      <td>4.111746</td>\n",
       "      <td>4.306967</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>7.439546</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>6.395353</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.483739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>2.195580</td>\n",
       "      <td>2.423192</td>\n",
       "      <td>4.589023</td>\n",
       "      <td>4.968376</td>\n",
       "      <td>3.392301</td>\n",
       "      <td>3.695784</td>\n",
       "      <td>6.982466</td>\n",
       "      <td>7.513560</td>\n",
       "      <td>5.785744</td>\n",
       "      <td>6.240968</td>\n",
       "      <td>8.179187</td>\n",
       "      <td>8.786152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1.5_shrunk  1.5_unshrunk  2.5_shrunk  2.5_unshrunk  2_shrunk  \\\n",
       "US_RE         2.078958      2.096641    2.610209      2.639680  2.344583   \n",
       "US_PE         3.040413      3.117582    4.544566      4.673180  3.792489   \n",
       "US_HY         2.290933      2.369524    3.200393      3.331376  2.745663   \n",
       "SP500         3.223711      3.336902    4.959738      5.148390  4.091725   \n",
       "Rusell2000    2.982469      3.184680    5.072223      5.409241  4.027346   \n",
       "EAFE          3.116358      3.262773    5.107134      5.351160  4.111746   \n",
       "EM            2.195580      2.423192    4.589023      4.968376  3.392301   \n",
       "\n",
       "            2_unshrunk  3.5_shrunk  3.5_unshrunk  3_shrunk  3_unshrunk  \\\n",
       "US_RE         2.368160    3.141460      3.182720  2.875835    2.911200   \n",
       "US_PE         3.895381    6.048718      6.228778  5.296642    5.450979   \n",
       "US_HY         2.850450    4.109852      4.293229  3.655122    3.812303   \n",
       "SP500         4.242646    6.695766      6.959878  5.827752    6.054134   \n",
       "Rusell2000    4.296960    7.161977      7.633801  6.117100    6.521521   \n",
       "EAFE          4.306967    7.097910      7.439546  6.102522    6.395353   \n",
       "EM            3.695784    6.982466      7.513560  5.785744    6.240968   \n",
       "\n",
       "            4_shrunk  4_unshrunk  \n",
       "US_RE       3.407086    3.454240  \n",
       "US_PE       6.800794    7.006577  \n",
       "US_HY       4.564582    4.774156  \n",
       "SP500       7.563779    7.865622  \n",
       "Rusell2000  8.206854    8.746082  \n",
       "EAFE        8.093298    8.483739  \n",
       "EM          8.179187    8.786152  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_peer']*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## mean variance optimization, constuct efficient fronter \n",
    "\n",
    "CMA_ExpRet_geo= np.array( [700, 880, 377, 721, 806, 707, 803]) /10000 /4 #quarterly expected exponential ret \n",
    "LW_cov.index\n",
    "CMA_ExpRet_arith= CMA_ExpRet_geo+ .5* np.diag(LW_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017529819935662469\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017529819935662469\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001703873088778188\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001703873088778188\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00165638280356643\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00165638280356643\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016105111379309748\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016105111379309748\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015662580918718197\n",
      "            Iterations: 4\n",
      "            Function evaluations: 4\n",
      "            Gradient evaluations: 4\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015662580918718197\n",
      "            Iterations: 4\n",
      "            Function evaluations: 4\n",
      "            Gradient evaluations: 4\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015236236653889698\n",
      "            Iterations: 5\n",
      "            Function evaluations: 5\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015236236653889698\n",
      "            Iterations: 5\n",
      "            Function evaluations: 5\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014826078584824205\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014826078584824205\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014438642996744612\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014432106711521737\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014259938880249083\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014054321033982286\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014086791508231917\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001369272155220585\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013919200880693095\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013347308266192454\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013757166997632629\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013018081175942063\n",
      "            Iterations: 8\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013600689859050515\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012705040281454705\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013449769464946764\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012408185582730362\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001330440581532137\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012127517079769036\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013164598910174318\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011863034772570738\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013030348749505634\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011614738661135464\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012901655333315298\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011382628745463196\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012778518661603316\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011166705025553957\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012660938734369688\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010966967501407745\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001254891555161442\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010783416173024544\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012442449113337498\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001061605104040437\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012341539419538938\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010464872103547217\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012246186470218734\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010329879362453085\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012156384896980794\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001021107281712197\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001207208127802242\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001010842316962102\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011993261891321732\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001001585882784514\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011919926736878722\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000992880233847368\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011852075814693412\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009847253701506628\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011789709124765781\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009771212916943992\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011732826667095833\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009700679984785765\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011681428441683572\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009635654905031956\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011635514448528994\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009576137677682559\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011595084687632102\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009522128302737575\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011560139158992898\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009473626780197007\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001153067786261138\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009430633110060851\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011506700798487545\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009393147292329112\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011488207966621397\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000936116932700178\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011475199367012938\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009334699214078865\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011467674999662164\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009313736953560365\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011465634864569062\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009298282545446275\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011469078961733657\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009288335989736605\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001147800729115594\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009283897286431347\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011492419852835909\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009284966435530498\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011512316646773556\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009291543437034066\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001153769767296889\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009303628290942043\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011568562931421915\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009321220997254438\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001160491242213262\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009344321555971248\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011646746145101017\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009372929967092472\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011694064100327098\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009407046230618106\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011746866287810859\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009446670346548156\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011805152707552306\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009491802314882617\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001187002449731427\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009542442136634697\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011944163886471763\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009598589808764837\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00120276918781802\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009660245334312507\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012120608472439588\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009727408712264607\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012222913669249914\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000980006669857634\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012334472308648254\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000987817633656742\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012454726084376807\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009961734332501622\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001258361426181617\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001005074068637895\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012721136840966347\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010145195398199415\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012867293821827355\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010245098467963005\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013022085204399164\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010350449895669715\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013185510988681798\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010461249681319555\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013357346180999502\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001057747125584778\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013535819782451136\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010699059316258694\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013720553207223491\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010826009747748199\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013911546455524792\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010957820381609583\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014108799527286788\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011098974494952799\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014312312422553014\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001125739620467417\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001452208514142076\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011437285124079506\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014738117683613058\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011638695045448585\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014960410049241703\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00118616259687814\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015188962238549622\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012106077894077955\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015423714967057124\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012372050821338246\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015664219737462684\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001265954475056227\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015910383859547206\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012968559681750035\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001616220733277473\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013299095614901547\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016419690157145259\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001365115255001679\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016685802801246817\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014024730487095774\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016970723718630423\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014419829426138495\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001727530332930347\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001483644936714496\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017599541637879175\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015274590310115155\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017943438642819838\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015734252255049093\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018306994344125431\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001621543520194677\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018690208741795936\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016718139150808187\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019093081835831382\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001724236410163333\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019515613629879412\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001778811005442223\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00199578041129971\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018355377009174848\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002041966011027766\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018944164965891217\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020960513683565864\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019554473924571344\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021647825680858952\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002018630388521518\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022430882065789175\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020839654847822782\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002324127190818221\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002151452681239409\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024078629803257106\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022210919778929148\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002494295575101376\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022928833747427936\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002583424975145225\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0023668268717890483\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026752511804572572\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0024429224690316774\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027697741910374693\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025211701664706763\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002866994006885861\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026015699641060513\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def obj_func(w, sigma):\n",
    "    return (np.dot(  np.dot( w, sigma), w)* .5)\n",
    "\n",
    "def obj_func_derivative( w, sigma): \n",
    "    return (np.dot( w, sigma))\n",
    "\n",
    "\n",
    "cons_eq0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "# cons_ineq0= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[0]-w[1]+ 0.5, \n",
    "#              'jac': lambda w: np.array([-1]*2+ [0]*10)}\n",
    "# cons_ineq1= {'type': 'ineq',\n",
    "#              'fun': lambda w: -w[2]-w[3]-w[4]-w[5]-w[6]+ 0.5,\n",
    "#              'jac': lambda w: np.array([0]*2+ [-1]*5+ [0]*5)}\n",
    "# cons_ineq2= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[7]-w[8]-w[9]-w[10]+ 0.5, \n",
    "#              'jac': lambda w: np.array([0]*7+ [-1]*4+ [0])}\n",
    "# cons_ineq3= {'type': 'ineq', \n",
    "#             'fun': lambda w: -w[11]+ 0.5,\n",
    "#             'jac': lambda w: np.array( [0]*11+ [-1])}\n",
    "\n",
    "\n",
    "\n",
    "fronter1_w= {}\n",
    "fronter1_vol= {}\n",
    "fronter2_w= {}\n",
    "fronter2_vol= {}\n",
    "\n",
    "for target_ret in np.linspace(0.05, 0.1, 100 ): \n",
    "    cons_ineq4= {'type': 'eq', \n",
    "                'fun': lambda w: -np.dot(w, CMA_ExpRet_arith*4)+ target_ret,\n",
    "                'jac': lambda w: -CMA_ExpRet_arith*4}\n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          , cons_ineq4\n",
    "          )\n",
    "\n",
    "    MV_opt_2= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.25]]+[[0, 0.4]]+[[0,None]]* (N-2),\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "\n",
    "    MV_opt_1= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None]]* N,\n",
    "                    tol= 1e-12)  # long only constrain\n",
    "    \n",
    "    fronter1_w[target_ret]= MV_opt_1.x\n",
    "    fronter1_vol[target_ret]= np.sqrt(MV_opt_1.fun*2) \n",
    "    \n",
    "    fronter2_w[target_ret]= MV_opt_2.x\n",
    "    fronter2_vol[target_ret]= np.sqrt(MV_opt_2.fun*2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.084848484848484854, 0.047449754909112372)\n",
      "[  5.85466949e-01   3.97230246e-01   0.00000000e+00   0.00000000e+00\n",
      "   8.13151629e-19   2.20906193e-18   1.73028058e-02]\n",
      "(0.085858585858585856, 0.054292020930543854)\n",
      "[ 0.25        0.4         0.0685198   0.20937833  0.          0.0378983\n",
      "  0.03420357]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJsL8P1gQxSYbAv3+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbfe27b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fronter_1= list( fronter1_vol.items())\n",
    "fronter_1.sort( key=lambda x: x[1])\n",
    "minvar_portf1= fronter_1[0]\n",
    "minvar_portf1_w= fronter1_w[minvar_portf1[0]]\n",
    "fronter_1.sort( key= lambda x: (x[0]- rf)/ x[1], reverse=True)\n",
    "efficient_portf1= fronter_1[0]\n",
    "efficient_portf1_w= fronter1_w[efficient_portf1[0]]\n",
    "\n",
    "fronter_2= list(fronter2_vol.items())\n",
    "fronter_2.sort(key= lambda x: x[1])\n",
    "minvar_portf2= fronter_2[0]\n",
    "minvar_portf2_w= fronter2_w[minvar_portf2[0]]\n",
    "fronter_2.sort(key= lambda x: (x[0]-rf)/x[1], reverse= True)\n",
    "efficient_portf2= fronter_2[0]\n",
    "efficient_portf2_w= fronter2_w[efficient_portf2[0]]\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip( * list( fronter1_vol.items())) \n",
    "fig= plt.figure( )\n",
    "plt.scatter(x= tmp_vol, y= tmp_ret, marker=\".\", c= 'pink' , label= 'long only')\n",
    "plt.scatter(x= minvar_portf1[1], y= minvar_portf1[0], marker= 'o', c='purple', s= 100 )\n",
    "plt.scatter(x= efficient_portf1[1], y = efficient_portf1[0], marker= '*', c='m', s=200)\n",
    "plt.plot( [0.04, efficient_portf1[1]], [ (efficient_portf1[0]-rf)/efficient_portf1[1]* 0.04+rf, efficient_portf1[0]], 'k-')\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip(* list(fronter2_vol.items()))\n",
    "plt.scatter( x= tmp_vol, y= tmp_ret, marker= '.', c='blue', label= 'long only+ concentration constrain')\n",
    "plt.scatter( x= minvar_portf2[1], y=minvar_portf2[0], marker= 'o', c= 'y', s=100)\n",
    "plt.scatter(x= efficient_portf2[1], y = efficient_portf2[0], marker= '*', c='r', s=200)\n",
    "plt.plot( [0.04, efficient_portf2[1]], [ (efficient_portf2[0]-rf)/efficient_portf2[1]* 0.04+rf, efficient_portf2[0]], 'k-')\n",
    "plt.legend()\n",
    "plt.title('Efficient Fronter')\n",
    "\n",
    "print(efficient_portf1)\n",
    "print(efficient_portf1_w)\n",
    "print(efficient_portf2)\n",
    "print(efficient_portf2_w)\n",
    "\n",
    "weight_longonly= efficient_portf1_w\n",
    "weight_longonly_conc= efficient_portf2_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>2.079208e-01</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>0.177851</td>\n",
       "      <td>0.118734</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>1.058735e-01</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly</th>\n",
       "      <td>0.585467</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.131516e-19</td>\n",
       "      <td>2.209062e-18</td>\n",
       "      <td>0.017303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly_conc</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.068520</td>\n",
       "      <td>0.209378</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.789830e-02</td>\n",
       "      <td>0.034204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             US_RE     US_PE     US_HY     SP500  \\\n",
       "weight_eq                 0.142857  0.142857  0.142857  0.142857   \n",
       "weight_peer               0.138614  0.287129  0.049505  0.237624   \n",
       "weight_erc                0.282415  0.142979  0.177851  0.118734   \n",
       "CMA_weight_longonly       0.585467  0.397230  0.000000  0.000000   \n",
       "CMA_weight_longonly_conc  0.250000  0.400000  0.068520  0.209378   \n",
       "\n",
       "                            Rusell2000          EAFE        EM  \n",
       "weight_eq                 1.428571e-01  1.428571e-01  0.142857  \n",
       "weight_peer               2.970297e-02  2.079208e-01  0.049505  \n",
       "weight_erc                9.272408e-02  1.058735e-01  0.079423  \n",
       "CMA_weight_longonly       8.131516e-19  2.209062e-18  0.017303  \n",
       "CMA_weight_longonly_conc  0.000000e+00  3.789830e-02  0.034204  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_2= pd.DataFrame([efficient_portf1_w, efficient_portf2_w], \n",
    "                             index=['CMA_weight_longonly', 'CMA_weight_longonly_conc'], columns=LW_cov.columns)\n",
    "pd.concat([portf_weight_1, portf_weight_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019671737334283113\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01863363861784658\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017631170987462922\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016700033645660244\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.015817167230974653\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    }
   ],
   "source": [
    "## risk adj return optimal long only portfolio with CMA expected ret\n",
    "\n",
    "\n",
    "def obj_func_CMA(w, ARGS):  # ARGS= [sigma, ExpRet, gamma]\n",
    "    return (np.dot(  np.dot( w, ARGS[0]), w)* .5* ARGS[2]- np.dot( ARGS[1], w))\n",
    "\n",
    "def obj_func_derivative_CMA( w, ARGS): \n",
    "    return (np.dot( w, ARGS[0])* ARGS[2]- ARGS[1])\n",
    "\n",
    "\n",
    "cons_eq0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "# cons_ineq0= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[0]-w[1]+ 0.5, \n",
    "#              'jac': lambda w: np.array([-1]*2+ [0]*10)}\n",
    "# cons_ineq1= {'type': 'ineq',\n",
    "#              'fun': lambda w: -w[2]-w[3]-w[4]-w[5]-w[6]+ 0.5,\n",
    "#              'jac': lambda w: np.array([0]*2+ [-1]*5+ [0]*5)}\n",
    "# cons_ineq2= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[7]-w[8]-w[9]-w[10]+ 0.5, \n",
    "#              'jac': lambda w: np.array([0]*7+ [-1]*4+ [0])}\n",
    "# cons_ineq3= {'type': 'ineq', \n",
    "#             'fun': lambda w: -w[11]+ 0.5,\n",
    "#             'jac': lambda w: np.array( [0]*11+ [-1])}\n",
    "\n",
    "\n",
    "CMA_riskAdj_opt={}\n",
    "\n",
    "for g in [2,2.5,3,3.5,4]: \n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          )\n",
    "\n",
    "    MV_opt= minimize( obj_func_CMA, \n",
    "                    x0= weight_eq, \n",
    "                    args= [LW_cov, CMA_ExpRet_arith, g], \n",
    "                    jac= obj_func_derivative_CMA ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, 0.25]]+[[0, .4]]+[[0,None]]* (N-2),\n",
    "                    tol= 1e-12)\n",
    "    \n",
    "    CMA_riskAdj_opt[g]= MV_opt.x\n",
    "    \n",
    "CMA_riskAdj_portf_w= pd.DataFrame( CMA_riskAdj_opt, index=LW_cov.columns).T\n",
    "CMA_riskAdj_portf_w.index= ['weight_CMA_MVO_gamma_'+str(x) for x in CMA_riskAdj_portf_w.index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_2.0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.142691</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.207309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_2.5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.290668e-16</td>\n",
       "      <td>0.178579</td>\n",
       "      <td>5.468188e-17</td>\n",
       "      <td>0.171421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_3.0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.393563e-02</td>\n",
       "      <td>0.147340</td>\n",
       "      <td>1.145913e-02</td>\n",
       "      <td>0.137265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_3.5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.119546e-20</td>\n",
       "      <td>1.185313e-01</td>\n",
       "      <td>0.099783</td>\n",
       "      <td>2.314831e-02</td>\n",
       "      <td>0.108537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_4.0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.669781e-01</td>\n",
       "      <td>0.064116</td>\n",
       "      <td>3.191520e-02</td>\n",
       "      <td>0.086991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          US_RE  US_PE         US_HY         SP500  \\\n",
       "weight_CMA_MVO_gamma_2.0   0.25    0.4  0.000000e+00  0.000000e+00   \n",
       "weight_CMA_MVO_gamma_2.5   0.25    0.4  0.000000e+00  1.290668e-16   \n",
       "weight_CMA_MVO_gamma_3.0   0.25    0.4  0.000000e+00  5.393563e-02   \n",
       "weight_CMA_MVO_gamma_3.5   0.25    0.4  6.119546e-20  1.185313e-01   \n",
       "weight_CMA_MVO_gamma_4.0   0.25    0.4  0.000000e+00  1.669781e-01   \n",
       "\n",
       "                          Rusell2000          EAFE        EM  \n",
       "weight_CMA_MVO_gamma_2.0    0.142691  0.000000e+00  0.207309  \n",
       "weight_CMA_MVO_gamma_2.5    0.178579  5.468188e-17  0.171421  \n",
       "weight_CMA_MVO_gamma_3.0    0.147340  1.145913e-02  0.137265  \n",
       "weight_CMA_MVO_gamma_3.5    0.099783  2.314831e-02  0.108537  \n",
       "weight_CMA_MVO_gamma_4.0    0.064116  3.191520e-02  0.086991  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMA_riskAdj_portf_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Introducing active management\n",
    "# Apply active management to Equity (SP500, Rusell2000, EAFE and EM), \n",
    "# assuming IR of 1/3 and active alpha 1% and hence tracking error 3%, both annualized \n",
    "\n",
    "\n",
    "LW_vol= np.sqrt(np.diag(LW_cov))\n",
    "LW_corr= pd.DataFrame(np.dot(np.dot(np.diag(1/LW_vol), LW_cov), np.diag(1/LW_vol)), columns= LW_cov.columns, index=LW_cov.index)\n",
    "LW_cov_active= pd.DataFrame(LW_cov+ np.diag( np.array([0, 0, 0, 0.0009/4, 0.0009/4, 0.0009/4, 0.0009/4])),\n",
    "                           index= LW_cov.index,\n",
    "                           columns= LW_cov.columns)\n",
    "LW_vol_active= np.sqrt(np.diag(LW_cov_active))\n",
    "\n",
    "CMA_ExpRet_active_geo= CMA_ExpRet_geo+ np.array([0,0,0, 0.01/4, 0.01/4, 0.01/4, 0.01/4])\n",
    "CMA_ExpRet_active_arith= CMA_ExpRet_arith+ np.array( [0,0,0, 0.01/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4 ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017529819935662477\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017529819935662477\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017038730887781871\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001703873088778188\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016563828035664311\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016563828035664314\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016105111379309761\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016105111379309753\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015662580918718223\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015662580918718218\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015236236653889703\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015236236653889703\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014826078584824222\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001482607858482422\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014438642996744604\n",
      "            Iterations: 4\n",
      "            Function evaluations: 4\n",
      "            Gradient evaluations: 4\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014432106711521745\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014259938880249083\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014054321033982295\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014086791508231915\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013692721552205872\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013919200880693097\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001334730826619245\n",
      "            Iterations: 5\n",
      "            Function evaluations: 5\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001375716699763263\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013018081175942067\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013600689859050517\n",
      "            Iterations: 8\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00127050402814547\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013449769464946768\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001240818558273036\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013304405815321365\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012127517079769043\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013164598910174322\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011863034772570736\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013030348749505634\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011614738661135458\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012901655333315291\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011382628745463196\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012778518661603316\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011166705025553957\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012660938734369688\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010966967501407745\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012548915551614422\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010783416173024553\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012442449113337505\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001061605104040437\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012341539419538938\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010464872103547213\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012246186470218736\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010329879362453087\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012156390265376884\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010211072817121968\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012072150805013384\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010108423169621025\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011993468089128248\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010015858827845145\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011920342117721456\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000992880233847368\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001185277289079302\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009847253701506633\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011790760408342945\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009771212916943992\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011734304670371221\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009700679984785766\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011683405676877852\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009635654905031956\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011638063427862836\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009576137677682563\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011598277923326183\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009522128302737575\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011564049163267877\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000947362678019701\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011535377147687928\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000943063311006085\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011511996691765454\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000939314729232911\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001149343594456625\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000936116932700178\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011479685715219386\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009334699214078865\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011470746003724868\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009313736953560365\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011466616810082693\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009298282545446277\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001146729813429286\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009288335989736606\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001147278997635537\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009283897286431347\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011483092336270224\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009284966435530498\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011498205214037422\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009291543437034064\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011518128609656966\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009303628290942046\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011542862523128848\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009321191295927855\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001157240695445308\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009343732547547175\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011606761903629648\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009371073296626181\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011645927370658566\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009403213543164873\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011689903355539826\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009440153287163255\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011738689858273427\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009481892528621327\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001179228687885937\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009528431267539082\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001185069441729766\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009579769503916529\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011913912473588291\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009635907237753659\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011981941047731269\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009696844469050482\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001205478013972659\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009762581148950208\n",
      "            Iterations: 27\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012132429749574251\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009833027027562292\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012214889650619953\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009908099920996078\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012302394666231528\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009987799829940713\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012395375959521862\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001007212675581831\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012493839261442643\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010161080691295195\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001259778457199387\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010254661644443822\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001270721242425033\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010352869612490249\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001282212121898768\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010455704600653975\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012942512555430257\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010563166594031378\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013068385900503285\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001067525560651818\n",
      "            Iterations: 31\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013199741254206767\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010791970158284256\n",
      "            Iterations: 34\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001333657861654068\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010916196175688388\n",
      "            Iterations: 35\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013478897987505057\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011055746919549825\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013626699367099888\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001121099825969997\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013779982755325157\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001138195019600661\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013938748152180886\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011568602728469744\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014102726726324805\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011770955779363138\n",
      "            Iterations: 34\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014271103236739105\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001198778297763702\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014443821756753598\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012217897518179129\n",
      "            Iterations: 34\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001462088227717545\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012461299398074353\n",
      "            Iterations: 38\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014802284807239495\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012717988618236526\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014988029347388562\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001298796517449383\n",
      "            Iterations: 33\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015178115887621404\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013271229071602027\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015372544436590718\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013567780310337297\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015571314993904192\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013877621018906603\n",
      "            Iterations: 35\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015774427555675604\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014201138727258904\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015981882124813163\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001453960118677818\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016194723462454143\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001489313283953068\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016425337806321434\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015261733685473086\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016677317141630637\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015645403724605363\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016950661472200437\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016044142956927491\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017245370796578716\n",
      "            Iterations: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016457951382439487\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017561445114765452\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016886829001141327\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017898884426760658\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017330775813033065\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001825768873256438\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017789791818114643\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001863785803217652\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018263877016386084\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019039392325597149\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018753031407847392\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001946229161282626\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019257254992498573\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019906555893910213\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00197765477703396\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002037218516875247\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002031090974137049\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020884295477828036\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020860340905591245\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021452861214768114\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021424841263001865\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022036814621456866\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022004410813602363\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n"
     ]
    }
   ],
   "source": [
    "## Fronter Construction with active management\n",
    "\n",
    "\n",
    "\n",
    "fronter1_active_w= {}\n",
    "fronter1_active_vol= {}\n",
    "fronter2_active_w= {}\n",
    "fronter2_active_vol= {}\n",
    "\n",
    "for target_ret in np.linspace(0.05, 0.1, 100 ): \n",
    "    cons_ineq4_active= {'type': 'eq', \n",
    "                'fun': lambda w: -np.dot(w, CMA_ExpRet_active_arith*4)+ target_ret,\n",
    "                'jac': lambda w: -CMA_ExpRet_active_arith*4}\n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          , cons_ineq4_active\n",
    "          )\n",
    "\n",
    "    MV_active_opt_2= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov_active, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,0.25]]+[[0, 0.4]]+[[0,None]]* (N-2),\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "\n",
    "    MV_active_opt_1= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov_active, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None]]* N,\n",
    "                    tol= 1e-12)  # long only constrain\n",
    "    \n",
    "    fronter1_active_w[target_ret]= MV_active_opt_1.x\n",
    "    fronter1_active_vol[target_ret]= np.sqrt(MV_active_opt_1.fun*2) \n",
    "    \n",
    "    fronter2_active_w[target_ret]= MV_active_opt_2.x\n",
    "    fronter2_active_vol[target_ret]= np.sqrt(MV_active_opt_2.fun*2)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.084848484848484854, 0.047449754909112372)\n",
      "[  5.85466949e-01   3.97230246e-01   0.00000000e+00   0.00000000e+00\n",
      "   8.13151629e-19   2.20906193e-18   1.73028058e-02]\n",
      "(0.085858585858585856, 0.054292020930543854)\n",
      "[ 0.25        0.4         0.0685198   0.20937833  0.          0.0378983\n",
      "  0.03420357]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAJOCAYAAAA3eodTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEzT4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1560f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fronter_1= list( fronter1_vol.items())\n",
    "fronter_1.sort( key=lambda x: x[1])\n",
    "minvar_portf1= fronter_1[0]\n",
    "minvar_portf1_w= fronter1_w[minvar_portf1[0]]\n",
    "fronter_1.sort( key= lambda x: (x[0]- rf)/ x[1], reverse=True)\n",
    "efficient_portf1= fronter_1[0]\n",
    "efficient_portf1_w= fronter1_w[efficient_portf1[0]]\n",
    "\n",
    "fronter_2= list(fronter2_vol.items())\n",
    "fronter_2.sort(key= lambda x: x[1])\n",
    "minvar_portf2= fronter_2[0]\n",
    "minvar_portf2_w= fronter2_w[minvar_portf2[0]]\n",
    "fronter_2.sort(key= lambda x: (x[0]-rf)/x[1], reverse= True)\n",
    "efficient_portf2= fronter_2[0]\n",
    "efficient_portf2_w= fronter2_w[efficient_portf2[0]]\n",
    "\n",
    "fronter_active_1= list( fronter1_active_vol.items())\n",
    "fronter_active_1.sort(key= lambda x: x[1])\n",
    "minvar_active_portf1= fronter_active_1[0]\n",
    "minvar_active_portf1_w= fronter1_active_w[minvar_active_portf1[0]]\n",
    "fronter_active_1.sort(key= lambda x: (x[0]-rf)/x[1], reverse =True)\n",
    "efficient_portf1_active= fronter_active_1[0]\n",
    "efficient_active_portf1_w= fronter1_active_w[efficient_portf1_active[0]]\n",
    "\n",
    "\n",
    "fronter_active_2= list( fronter2_active_vol.items())\n",
    "fronter_active_2.sort( key= lambda x: x[1])\n",
    "minvar_active_portf2= fronter_active_2[0]\n",
    "minvar_active_portf2_w= fronter2_active_w[ minvar_active_portf2[0]]\n",
    "fronter_active_2.sort(key= lambda x: (x[0]-rf)/x[1], reverse= True)\n",
    "efficient_portf2_active= fronter_active_2[0]\n",
    "efficient_portf2_active_w= fronter2_active_w[efficient_portf2_active[0]]\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize= (20,10))\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip( * list( fronter1_vol.items())) \n",
    "plt.scatter(x= tmp_vol, y= tmp_ret, marker=\".\", c= 'pink' , label= 'CMA:long only')\n",
    "plt.scatter(x= minvar_portf1[1], y= minvar_portf1[0], marker= 'o', c='pink', s= 100 )\n",
    "plt.scatter(x= efficient_portf1[1], y = efficient_portf1[0], marker= '*', c='pink', s=200)\n",
    "# plt.plot( [0.04, efficient_portf1[1]], [ (efficient_portf1[0]-rf)/efficient_portf1[1]* 0.04+rf, efficient_portf1[0]], \n",
    "#          linestyle='-', c='pink')\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip(* list(fronter2_vol.items()))\n",
    "plt.scatter( x= tmp_vol, y= tmp_ret, marker= '.', c='blue', label= 'CMA:long only+ concentration constrain')\n",
    "plt.scatter( x= minvar_portf2[1], y=minvar_portf2[0], marker= 'o', c= 'blue', s=100)\n",
    "plt.scatter(x= efficient_portf2[1], y = efficient_portf2[0], marker= '*', c='blue', s=200)\n",
    "# plt.plot( [0.04, efficient_portf2[1]], [ (efficient_portf2[0]-rf)/efficient_portf2[1]* 0.04+rf, efficient_portf2[0]], \n",
    "#          linestyle= '-', c= 'blue')\n",
    "\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip( * list( fronter1_active_vol.items())) \n",
    "plt.scatter(x= tmp_vol, y= tmp_ret, marker=\".\", c= 'orange' , label= 'CMA_active:long only')\n",
    "plt.scatter(x= minvar_active_portf1[1], y= minvar_active_portf1[0], marker= 'o', c='orange', s= 100 )\n",
    "plt.scatter(x= efficient_portf1_active[1], y = efficient_portf1_active[0], marker= '*', c='orange', s=200)\n",
    "# plt.plot( [0.04, efficient_portf1_active[1]], [ (efficient_portf1_active[0]-rf)/efficient_portf1_active[1]* 0.04+rf, efficient_portf1_active[0]], \n",
    "#          linestyle='-', c='orange')\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip(* list(fronter2_active_vol.items()))\n",
    "plt.scatter( x= tmp_vol, y= tmp_ret, marker= '.', c='red', label= 'CMA_active:long only+ concentration constrain')\n",
    "plt.scatter( x= minvar_active_portf2[1], y=minvar_active_portf2[0], marker= 'o', c= 'red', s=100)\n",
    "plt.scatter(x= efficient_portf2_active[1], y = efficient_portf2_active[0], marker= '*', c='red', s=200)\n",
    "# plt.plot( [0.04, efficient_portf2_active[1]], [ (efficient_portf2_active[0]-rf)/efficient_portf2_active[1]* 0.04+rf, efficient_portf2_active[0]], \n",
    "#          linestyle= '-', c='red')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Efficient Fronter')\n",
    "\n",
    "print(efficient_portf1)\n",
    "print(efficient_portf1_w)\n",
    "print(efficient_portf2)\n",
    "print(efficient_portf2_w)\n",
    "\n",
    "weight_longonly= efficient_portf1_w\n",
    "weight_longonly_conc= efficient_portf2_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>4.950495e-02</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>2.079208e-01</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>1.778511e-01</td>\n",
       "      <td>0.118734</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>1.058735e-01</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly</th>\n",
       "      <td>0.585467</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.131516e-19</td>\n",
       "      <td>2.209062e-18</td>\n",
       "      <td>0.017303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly_conc</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.851980e-02</td>\n",
       "      <td>0.209378</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.789830e-02</td>\n",
       "      <td>0.034204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active_weight_longonly</th>\n",
       "      <td>0.566429</td>\n",
       "      <td>0.317327</td>\n",
       "      <td>2.331035e-18</td>\n",
       "      <td>0.072942</td>\n",
       "      <td>1.138412e-18</td>\n",
       "      <td>1.906249e-02</td>\n",
       "      <td>0.024239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active_weight_longonly_conc</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.244178</td>\n",
       "      <td>5.003051e-03</td>\n",
       "      <td>6.020933e-02</td>\n",
       "      <td>0.040609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    US_RE     US_PE         US_HY     SP500  \\\n",
       "weight_eq                        0.142857  0.142857  1.428571e-01  0.142857   \n",
       "weight_peer                      0.138614  0.287129  4.950495e-02  0.237624   \n",
       "weight_erc                       0.282415  0.142979  1.778511e-01  0.118734   \n",
       "CMA_weight_longonly              0.585467  0.397230  0.000000e+00  0.000000   \n",
       "CMA_weight_longonly_conc         0.250000  0.400000  6.851980e-02  0.209378   \n",
       "CMA_active_weight_longonly       0.566429  0.317327  2.331035e-18  0.072942   \n",
       "CMA_active_weight_longonly_conc  0.250000  0.400000  0.000000e+00  0.244178   \n",
       "\n",
       "                                   Rusell2000          EAFE        EM  \n",
       "weight_eq                        1.428571e-01  1.428571e-01  0.142857  \n",
       "weight_peer                      2.970297e-02  2.079208e-01  0.049505  \n",
       "weight_erc                       9.272408e-02  1.058735e-01  0.079423  \n",
       "CMA_weight_longonly              8.131516e-19  2.209062e-18  0.017303  \n",
       "CMA_weight_longonly_conc         0.000000e+00  3.789830e-02  0.034204  \n",
       "CMA_active_weight_longonly       1.138412e-18  1.906249e-02  0.024239  \n",
       "CMA_active_weight_longonly_conc  5.003051e-03  6.020933e-02  0.040609  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_3= pd.DataFrame( [efficient_active_portf1_w, efficient_portf2_active_w],\n",
    "                            index= ['CMA_active_weight_longonly', 'CMA_active_weight_longonly_conc'], \n",
    "                            columns= LW_cov.columns)\n",
    "\n",
    "pd.concat([portf_weight_1, portf_weight_2, portf_weight_3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018531132909627348\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0186737278727682\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01760033310853517\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01789346527097745\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0167139491253233\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01717623503768577\n",
      "            Iterations: 34\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_CMAactive_MVO_gamma_weight_CMAactive_MVO_gamma_3.0uncons</th>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.410369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.815891e-17</td>\n",
       "      <td>0.103296</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.131823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMAactive_MVO_gamma_weight_CMAactive_MVO_gamma_3.5uncons</th>\n",
       "      <td>0.408587</td>\n",
       "      <td>0.397580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.083450</td>\n",
       "      <td>2.763720e-17</td>\n",
       "      <td>0.110382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMAactive_MVO_gamma_weight_CMAactive_MVO_gamma_4.0uncons</th>\n",
       "      <td>0.448396</td>\n",
       "      <td>0.386824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.910660e-03</td>\n",
       "      <td>0.066791</td>\n",
       "      <td>1.832683e-17</td>\n",
       "      <td>0.094078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       US_RE     US_PE  US_HY  \\\n",
       "weight_CMAactive_MVO_gamma_weight_CMAactive_MVO...  0.354512  0.410369    0.0   \n",
       "weight_CMAactive_MVO_gamma_weight_CMAactive_MVO...  0.408587  0.397580    0.0   \n",
       "weight_CMAactive_MVO_gamma_weight_CMAactive_MVO...  0.448396  0.386824    0.0   \n",
       "\n",
       "                                                           SP500  Rusell2000  \\\n",
       "weight_CMAactive_MVO_gamma_weight_CMAactive_MVO...  4.815891e-17    0.103296   \n",
       "weight_CMAactive_MVO_gamma_weight_CMAactive_MVO...  0.000000e+00    0.083450   \n",
       "weight_CMAactive_MVO_gamma_weight_CMAactive_MVO...  3.910660e-03    0.066791   \n",
       "\n",
       "                                                            EAFE        EM  \n",
       "weight_CMAactive_MVO_gamma_weight_CMAactive_MVO...  0.000000e+00  0.131823  \n",
       "weight_CMAactive_MVO_gamma_weight_CMAactive_MVO...  2.763720e-17  0.110382  \n",
       "weight_CMAactive_MVO_gamma_weight_CMAactive_MVO...  1.832683e-17  0.094078  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Risk adj return utility constrained optimal with active management \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def obj_func_CMAactive(w, ARGS):  # ARGS= [sigma, ExpRet, gamma]\n",
    "    return (np.dot(  np.dot( w, ARGS[0]), w)* .5* ARGS[2]- np.dot( ARGS[1], w))\n",
    "\n",
    "def obj_func_derivative_CMAactive( w, ARGS): \n",
    "    return (np.dot( w, ARGS[0])* ARGS[2]- ARGS[1])\n",
    "\n",
    "\n",
    "cons_eq0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "# cons_ineq0= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[0]-w[1]+ 0.5, \n",
    "#              'jac': lambda w: np.array([-1]*2+ [0]*10)}\n",
    "# cons_ineq1= {'type': 'ineq',\n",
    "#              'fun': lambda w: -w[2]-w[3]-w[4]-w[5]-w[6]+ 0.5,\n",
    "#              'jac': lambda w: np.array([0]*2+ [-1]*5+ [0]*5)}\n",
    "# cons_ineq2= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[7]-w[8]-w[9]-w[10]+ 0.5, \n",
    "#              'jac': lambda w: np.array([0]*7+ [-1]*4+ [0])}\n",
    "# cons_ineq3= {'type': 'ineq', \n",
    "#             'fun': lambda w: -w[11]+ 0.5,\n",
    "#             'jac': lambda w: np.array( [0]*11+ [-1])}\n",
    "\n",
    "\n",
    "CMAactive_riskAdj_opt={}\n",
    "CMAactive_riskAdj_opt2={}\n",
    "for g in [3,3.5,4]: \n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          )\n",
    "\n",
    "    MV_opt= minimize( obj_func_CMAactive, \n",
    "                    x0= weight_eq, \n",
    "                    args= [LW_cov_active, CMA_ExpRet_active_arith, g], \n",
    "                    jac= obj_func_derivative_CMAactive ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, 0.25]]+[[0, .4]]+[[0,None]]* (N-2),\n",
    "                    tol= 1e-12)\n",
    "\n",
    "    MV_opt2= minimize( obj_func_CMAactive, \n",
    "                    x0= weight_eq, \n",
    "                    args= [LW_cov_active, CMA_ExpRet_active_arith, g], \n",
    "                    jac= obj_func_derivative_CMAactive ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,None]]* N,\n",
    "                    tol= 1e-12)\n",
    "    \n",
    "    CMAactive_riskAdj_opt[g]= MV_opt.x\n",
    "    CMAactive_riskAdj_opt2[g]= MV_opt2.x\n",
    "    \n",
    "CMAactive_riskAdj_portf_w= pd.DataFrame( CMAactive_riskAdj_opt, index=LW_cov_active.columns).T\n",
    "CMAactive_riskAdj_portf_w.index= ['weight_CMAactive_MVO_gamma_'+str(x) for x in CMAactive_riskAdj_portf_w.index]\n",
    "CMAactive_riskAdj_portf_w2= pd.DataFrame( CMAactive_riskAdj_opt2, index= LW_cov_active.columns).T\n",
    "CMAactive_riskAdj_portf_w2.index= ['weight_CMAactive_MVO_gamma_'+str(x)+'uncons' for x in CMAactive_riskAdj_portf_w.index]\n",
    "CMAactive_riskAdj_portf_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>4.950495e-02</td>\n",
       "      <td>2.376238e-01</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>2.079208e-01</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>1.778511e-01</td>\n",
       "      <td>1.187341e-01</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>1.058735e-01</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_1</th>\n",
       "      <td>0.585467</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.131516e-19</td>\n",
       "      <td>2.209062e-18</td>\n",
       "      <td>0.017303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.851980e-02</td>\n",
       "      <td>2.093783e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.789830e-02</td>\n",
       "      <td>0.034204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.393563e-02</td>\n",
       "      <td>1.473398e-01</td>\n",
       "      <td>1.145913e-02</td>\n",
       "      <td>0.137265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3.5</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.119546e-20</td>\n",
       "      <td>1.185313e-01</td>\n",
       "      <td>9.978316e-02</td>\n",
       "      <td>2.314831e-02</td>\n",
       "      <td>0.108537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_4</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.669781e-01</td>\n",
       "      <td>6.411567e-02</td>\n",
       "      <td>3.191520e-02</td>\n",
       "      <td>0.086991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_1</th>\n",
       "      <td>0.566429</td>\n",
       "      <td>0.317327</td>\n",
       "      <td>2.331035e-18</td>\n",
       "      <td>7.294239e-02</td>\n",
       "      <td>1.138412e-18</td>\n",
       "      <td>1.906249e-02</td>\n",
       "      <td>0.024239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.441783e-01</td>\n",
       "      <td>5.003051e-03</td>\n",
       "      <td>6.020933e-02</td>\n",
       "      <td>0.040609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.278645e-17</td>\n",
       "      <td>5.710772e-02</td>\n",
       "      <td>1.413027e-01</td>\n",
       "      <td>1.591524e-02</td>\n",
       "      <td>0.135674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.130489e-01</td>\n",
       "      <td>1.005411e-01</td>\n",
       "      <td>2.918463e-02</td>\n",
       "      <td>0.107225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.550615e-01</td>\n",
       "      <td>6.993241e-02</td>\n",
       "      <td>3.911039e-02</td>\n",
       "      <td>0.085896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3unc</th>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.410369</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.815891e-17</td>\n",
       "      <td>1.032960e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.131823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5unc</th>\n",
       "      <td>0.408587</td>\n",
       "      <td>0.397580</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.345012e-02</td>\n",
       "      <td>2.763720e-17</td>\n",
       "      <td>0.110382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4unc</th>\n",
       "      <td>0.448396</td>\n",
       "      <td>0.386824</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.910660e-03</td>\n",
       "      <td>6.679136e-02</td>\n",
       "      <td>1.832683e-17</td>\n",
       "      <td>0.094078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE         US_HY         SP500    Rusell2000  \\\n",
       "w_eq           0.142857  0.142857  1.428571e-01  1.428571e-01  1.428571e-01   \n",
       "w_peer         0.138614  0.287129  4.950495e-02  2.376238e-01  2.970297e-02   \n",
       "w_erc          0.282415  0.142979  1.778511e-01  1.187341e-01  9.272408e-02   \n",
       "w_MVO_1        0.585467  0.397230  0.000000e+00  0.000000e+00  8.131516e-19   \n",
       "w_MVO_2        0.250000  0.400000  6.851980e-02  2.093783e-01  0.000000e+00   \n",
       "w_RUO_3        0.250000  0.400000  0.000000e+00  5.393563e-02  1.473398e-01   \n",
       "w_RUO_3.5      0.250000  0.400000  6.119546e-20  1.185313e-01  9.978316e-02   \n",
       "w_RUO_4        0.250000  0.400000  0.000000e+00  1.669781e-01  6.411567e-02   \n",
       "w_aMVO_1       0.566429  0.317327  2.331035e-18  7.294239e-02  1.138412e-18   \n",
       "w_aMVO_2       0.250000  0.400000  0.000000e+00  2.441783e-01  5.003051e-03   \n",
       "w_aRUO_3       0.250000  0.400000  4.278645e-17  5.710772e-02  1.413027e-01   \n",
       "w_aRUO_3.5     0.250000  0.400000  0.000000e+00  1.130489e-01  1.005411e-01   \n",
       "w_aRUO_4       0.250000  0.400000  0.000000e+00  1.550615e-01  6.993241e-02   \n",
       "w_aRUO_3unc    0.354512  0.410369  0.000000e+00  4.815891e-17  1.032960e-01   \n",
       "w_aRUO_3.5unc  0.408587  0.397580  0.000000e+00  0.000000e+00  8.345012e-02   \n",
       "w_aRUO_4unc    0.448396  0.386824  0.000000e+00  3.910660e-03  6.679136e-02   \n",
       "\n",
       "                       EAFE        EM  \n",
       "w_eq           1.428571e-01  0.142857  \n",
       "w_peer         2.079208e-01  0.049505  \n",
       "w_erc          1.058735e-01  0.079423  \n",
       "w_MVO_1        2.209062e-18  0.017303  \n",
       "w_MVO_2        3.789830e-02  0.034204  \n",
       "w_RUO_3        1.145913e-02  0.137265  \n",
       "w_RUO_3.5      2.314831e-02  0.108537  \n",
       "w_RUO_4        3.191520e-02  0.086991  \n",
       "w_aMVO_1       1.906249e-02  0.024239  \n",
       "w_aMVO_2       6.020933e-02  0.040609  \n",
       "w_aRUO_3       1.591524e-02  0.135674  \n",
       "w_aRUO_3.5     2.918463e-02  0.107225  \n",
       "w_aRUO_4       3.911039e-02  0.085896  \n",
       "w_aRUO_3unc    0.000000e+00  0.131823  \n",
       "w_aRUO_3.5unc  2.763720e-17  0.110382  \n",
       "w_aRUO_4unc    1.832683e-17  0.094078  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight= pd.concat( [portf_weight_1, \n",
    "                          portf_weight_2, \n",
    "                          CMA_riskAdj_portf_w.iloc[ -3:] ,\n",
    "                          portf_weight_3, \n",
    "                          CMAactive_riskAdj_portf_w,\n",
    "                         CMAactive_riskAdj_portf_w2], axis= 0 )\n",
    "portf_weight.index= ['w_eq', # equal weight \n",
    "                    'w_peer', # peer weight\n",
    "                    'w_erc', # equal risk contribution weight \n",
    "                    'w_MVO_1', # mean-variance optimal weight with long only constrain\n",
    "                    'w_MVO_2', # mean-variance optimal weight with long only+ concentration constrain\n",
    "                    'w_RUO_3', # risk adj utility optimal weight with long only+ concentration constrain, give risk aversion 3 \n",
    "                    'w_RUO_3.5', # risk adj utility optimal weight with long only+ concentration constrain, given risk aversion 3.5\n",
    "                    'w_RUO_4', # risk adj utility optimal weight with long only+ concentration constrain, give risk aversion 4\n",
    "                    'w_aMVO_1', # mean-variance optimal weight with long only constrain, and active management \n",
    "                    'w_aMVO_2', # mean-variance optimal weight with long only+ concentration constrain, and active management \n",
    "                    'w_aRUO_3', # risk adj utility optimal weight with long only+ concentration constrain, and active management, give risk aversion 3 \n",
    "                    'w_aRUO_3.5', # risk adj utility optimal weight with long only+ concentration constrain, and active management, give risk aversion 3.5 \n",
    "                    'w_aRUO_4', # risk adj utility optimal weight with long only+ concentration constrain, and active management, give risk aversion 4\n",
    "                    'w_aRUO_3unc',\n",
    "                    'w_aRUO_3.5unc',\n",
    "                    'w_aRUO_4unc'] \n",
    "portf_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3</th>\n",
       "      <td>2.946497</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.975123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3.5</th>\n",
       "      <td>3.223899</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>8.370075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_4</th>\n",
       "      <td>3.501302</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>9.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3</th>\n",
       "      <td>2.875835</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>5.785744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.141460</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3</th>\n",
       "      <td>3.116898</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.129680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3.5</th>\n",
       "      <td>3.422701</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.217058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_4</th>\n",
       "      <td>3.728504</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>8.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_eq_3      2.946497  5.112730  4.197299  5.940288    6.745272  6.198200   \n",
       "iRet_eq_3.5    3.223899  5.834154  4.742391  6.827058    7.894844  7.209535   \n",
       "iRet_eq_4      3.501302  6.555578  5.287484  7.713828    9.044416  8.220869   \n",
       "iRet_peer_3    2.875835  5.296642  3.655122  5.827752    6.117100  6.102522   \n",
       "iRet_peer_3.5  3.141460  6.048718  4.109852  6.695766    7.161977  7.097910   \n",
       "iRet_peer_4    3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "iRet_erc_3     3.116898  4.408355  3.840304  4.983875    5.436244  5.024522   \n",
       "iRet_erc_3.5   3.422701  5.012383  4.325897  5.711243    6.367644  5.840244   \n",
       "iRet_erc_4     3.728504  5.616411  4.811491  6.438610    7.299045  6.655965   \n",
       "CMA            7.000000  8.800000  3.770000  7.210000    8.060000  7.070000   \n",
       "CMA_active     7.000000  8.800000  3.770000  8.210000    9.060000  8.070000   \n",
       "\n",
       "                     EM  \n",
       "iRet_eq_3      6.975123  \n",
       "iRet_eq_3.5    8.370075  \n",
       "iRet_eq_4      9.765026  \n",
       "iRet_peer_3    5.785744  \n",
       "iRet_peer_3.5  6.982466  \n",
       "iRet_peer_4    8.179187  \n",
       "iRet_erc_3     5.129680  \n",
       "iRet_erc_3.5   6.217058  \n",
       "iRet_erc_4     7.304435  \n",
       "CMA            8.030000  \n",
       "CMA_active     9.030000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpRet=  pd.concat([implied_ExpRet['weight_eq'][['3_shrunk', '3.5_shrunk', '4_shrunk']].T, \n",
    "                   implied_ExpRet['weight_peer'][['3_shrunk', '3.5_shrunk', '4_shrunk']].T,\n",
    "                   implied_ExpRet['weight_erc'][['3_shrunk', '3.5_shrunk', '4_shrunk']].T,\n",
    "                   pd.DataFrame([CMA_ExpRet_geo,CMA_ExpRet_active_geo], columns= LW_cov.columns)], \n",
    "                   axis=0)* 400\n",
    "ExpRet.index= ['iRet_eq_3', # implied expected return from equal weight with risk aversion 3\n",
    "               'iRet_eq_3.5', # implied expected return from equal weight with risk aversion 3.5\n",
    "               'iRet_eq_4',\n",
    "               'iRet_peer_3', # implied expected return from peer weight with risk aversion 3\n",
    "               'iRet_peer_3.5', # implied expected return from peer weight with risk aversion 3.5\n",
    "               'iRet_peer_4',\n",
    "               'iRet_erc_3', # implied expected return from equal risk contribution weight with risk aversion 3\n",
    "               'iRet_erc_3.5',# implied expected return from equal risk contribution weight with risk aversion 3.5\n",
    "               'iRet_erc_4',\n",
    "               'CMA', # CMA expected return \n",
    "               'CMA_active' # CMA expected return, and active management\n",
    "              ]\n",
    "\n",
    "ExpRet # annualized expected ret in percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Black-Litterman Framework \n",
    "\n",
    "Construct BL framework to incorporate benchmark(prior) and views(observations) and produce a reasonable distribution of expected return (posterior). \n",
    "Apply mean-variance optimization based on posterior to achieve optimal allocation. \n",
    "\n",
    "#### Benckmark/Equilibrium Portfolio\n",
    "\n",
    "Set the benchmark as peer holding `w_peer`, then `iRet_peer_4` is the implied equilibrium\\benchmark expected return, given risk aversion factor 4.\n",
    "\n",
    "#### The prior confidence  $\\tau$\n",
    "\n",
    "Follow BL's initial setting, $\\tau = 0.05$\n",
    "\n",
    "#### Views\n",
    "\n",
    "`CMA_active` is the subjective view to expected return of each asset. The confidence is proportional to view portfolio (prior) variance with multiplier $\\tau$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### As summary, input: \n",
    "\n",
    "$\\tau$\n",
    "\n",
    "prior expected ret distribution, assuming normal, so the prior mean and variance \n",
    "\n",
    "views, the view portfolio weight, asserted expected ret, and view confidence. \n",
    "\n",
    "#### output: \n",
    "\n",
    "the posterior distribution, mean and variance of post expected return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## prepare input\n",
    "\n",
    "tau = 5e-2\n",
    "prior_cov= LW_cov* tau\n",
    "prior_cov_inv= np.linalg.inv(prior_cov)\n",
    "prior_mean= np.array(ExpRet.loc['iRet_peer_4'].tolist())/100/4+ 0.5* np.diag(LW_cov)\n",
    "\n",
    "\n",
    "\n",
    "# CMA_ExpRet_active_arith \n",
    "# is the asserted expected return \n",
    "view_w= np.identity(N)\n",
    "view_ExpRet= CMA_ExpRet_active_arith\n",
    "view_cov= ( (LW_cov_active)* tau)\n",
    "view_cov_inv= np.linalg.inv( view_cov)\n",
    "\n",
    "##  output: post \n",
    "\n",
    "A= prior_cov_inv\n",
    "B= np.dot( np.dot(view_w.T, view_cov_inv), view_w)\n",
    "C= np.dot(prior_cov_inv, prior_mean)\n",
    "D= np.dot(np.dot(view_w.T, view_cov_inv), view_ExpRet)\n",
    "\n",
    "post_mean_arith= pd.DataFrame( np.dot(np.linalg.inv( A+B), C+D), index=LW_cov.index, columns= ['post_ExpRet']) .T\n",
    "post_cov= pd.DataFrame( np.linalg.inv( prior_cov_inv+ np.dot( np.dot( view_w.T, view_cov_inv), view_w)), index= LW_cov.index, columns= LW_cov.columns)\n",
    "post_mean_geo= post_mean_arith- .5* np.diag( LW_cov_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_ExpRet</th>\n",
       "      <td>5.203543</td>\n",
       "      <td>7.800397</td>\n",
       "      <td>4.167291</td>\n",
       "      <td>7.864592</td>\n",
       "      <td>8.617483</td>\n",
       "      <td>8.073044</td>\n",
       "      <td>8.579113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_peer_4  3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "CMA_active   7.000000  8.800000  3.770000  8.210000    9.060000  8.070000   \n",
       "post_ExpRet  5.203543  7.800397  4.167291  7.864592    8.617483  8.073044   \n",
       "\n",
       "                   EM  \n",
       "iRet_peer_4  8.179187  \n",
       "CMA_active   9.030000  \n",
       "post_ExpRet  8.579113  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([ ExpRet.loc[['iRet_peer_4', 'CMA_active']], \n",
    "          post_mean_geo*400], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       0.000063  0.000026  0.000020  0.000029    0.000038  0.000029   \n",
       "US_PE       0.000026  0.000126  0.000044  0.000093    0.000117  0.000098   \n",
       "US_HY       0.000020  0.000044  0.000108  0.000063    0.000079  0.000068   \n",
       "SP500       0.000029  0.000093  0.000063  0.000149    0.000157  0.000133   \n",
       "Rusell2000  0.000038  0.000117  0.000079  0.000157    0.000245  0.000157   \n",
       "EAFE        0.000029  0.000098  0.000068  0.000133    0.000157  0.000210   \n",
       "EM          0.000037  0.000128  0.000095  0.000156    0.000215  0.000192   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.000037  \n",
       "US_PE       0.000128  \n",
       "US_HY       0.000095  \n",
       "SP500       0.000156  \n",
       "Rusell2000  0.000215  \n",
       "EAFE        0.000192  \n",
       "EM          0.000401  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01415042876456362\n",
      "            Iterations: 31\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.25      ,  0.38310451,  0.        ,  0.1433533 ,  0.04641799,\n",
       "        0.11128261,  0.06584159])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MVO based over post expected mean and variance\n",
    "\n",
    "\n",
    "MV_opt= minimize( obj_func_CMA, \n",
    "                x0= weight_eq, \n",
    "                args= [LW_cov_active+ post_cov, post_mean_arith, 4], \n",
    "                jac= obj_func_derivative_CMA ,\n",
    "                method= 'SLSQP',\n",
    "                options= {'disp': True},\n",
    "                constraints= cons, \n",
    "                bounds= [[0, 0.25]]+[[0, .4]]+[[0,None]]* (N-2),\n",
    "                tol= 1e-120)\n",
    "\n",
    "MV_opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>4.950495e-02</td>\n",
       "      <td>2.376238e-01</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>2.079208e-01</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>1.778511e-01</td>\n",
       "      <td>1.187341e-01</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>1.058735e-01</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_1</th>\n",
       "      <td>0.585467</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.131516e-19</td>\n",
       "      <td>2.209062e-18</td>\n",
       "      <td>0.017303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.851980e-02</td>\n",
       "      <td>2.093783e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.789830e-02</td>\n",
       "      <td>0.034204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.393563e-02</td>\n",
       "      <td>1.473398e-01</td>\n",
       "      <td>1.145913e-02</td>\n",
       "      <td>0.137265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3.5</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.119546e-20</td>\n",
       "      <td>1.185313e-01</td>\n",
       "      <td>9.978316e-02</td>\n",
       "      <td>2.314831e-02</td>\n",
       "      <td>0.108537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_4</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.669781e-01</td>\n",
       "      <td>6.411567e-02</td>\n",
       "      <td>3.191520e-02</td>\n",
       "      <td>0.086991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_1</th>\n",
       "      <td>0.566429</td>\n",
       "      <td>0.317327</td>\n",
       "      <td>2.331035e-18</td>\n",
       "      <td>7.294239e-02</td>\n",
       "      <td>1.138412e-18</td>\n",
       "      <td>1.906249e-02</td>\n",
       "      <td>0.024239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.441783e-01</td>\n",
       "      <td>5.003051e-03</td>\n",
       "      <td>6.020933e-02</td>\n",
       "      <td>0.040609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.278645e-17</td>\n",
       "      <td>5.710772e-02</td>\n",
       "      <td>1.413027e-01</td>\n",
       "      <td>1.591524e-02</td>\n",
       "      <td>0.135674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.130489e-01</td>\n",
       "      <td>1.005411e-01</td>\n",
       "      <td>2.918463e-02</td>\n",
       "      <td>0.107225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.550615e-01</td>\n",
       "      <td>6.993241e-02</td>\n",
       "      <td>3.911039e-02</td>\n",
       "      <td>0.085896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3unc</th>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.410369</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.815891e-17</td>\n",
       "      <td>1.032960e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.131823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5unc</th>\n",
       "      <td>0.408587</td>\n",
       "      <td>0.397580</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.345012e-02</td>\n",
       "      <td>2.763720e-17</td>\n",
       "      <td>0.110382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4unc</th>\n",
       "      <td>0.448396</td>\n",
       "      <td>0.386824</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.910660e-03</td>\n",
       "      <td>6.679136e-02</td>\n",
       "      <td>1.832683e-17</td>\n",
       "      <td>0.094078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.383105</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.433533e-01</td>\n",
       "      <td>4.641799e-02</td>\n",
       "      <td>1.112826e-01</td>\n",
       "      <td>0.065842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE         US_HY         SP500    Rusell2000  \\\n",
       "w_eq           0.142857  0.142857  1.428571e-01  1.428571e-01  1.428571e-01   \n",
       "w_peer         0.138614  0.287129  4.950495e-02  2.376238e-01  2.970297e-02   \n",
       "w_erc          0.282415  0.142979  1.778511e-01  1.187341e-01  9.272408e-02   \n",
       "w_MVO_1        0.585467  0.397230  0.000000e+00  0.000000e+00  8.131516e-19   \n",
       "w_MVO_2        0.250000  0.400000  6.851980e-02  2.093783e-01  0.000000e+00   \n",
       "w_RUO_3        0.250000  0.400000  0.000000e+00  5.393563e-02  1.473398e-01   \n",
       "w_RUO_3.5      0.250000  0.400000  6.119546e-20  1.185313e-01  9.978316e-02   \n",
       "w_RUO_4        0.250000  0.400000  0.000000e+00  1.669781e-01  6.411567e-02   \n",
       "w_aMVO_1       0.566429  0.317327  2.331035e-18  7.294239e-02  1.138412e-18   \n",
       "w_aMVO_2       0.250000  0.400000  0.000000e+00  2.441783e-01  5.003051e-03   \n",
       "w_aRUO_3       0.250000  0.400000  4.278645e-17  5.710772e-02  1.413027e-01   \n",
       "w_aRUO_3.5     0.250000  0.400000  0.000000e+00  1.130489e-01  1.005411e-01   \n",
       "w_aRUO_4       0.250000  0.400000  0.000000e+00  1.550615e-01  6.993241e-02   \n",
       "w_aRUO_3unc    0.354512  0.410369  0.000000e+00  4.815891e-17  1.032960e-01   \n",
       "w_aRUO_3.5unc  0.408587  0.397580  0.000000e+00  0.000000e+00  8.345012e-02   \n",
       "w_aRUO_4unc    0.448396  0.386824  0.000000e+00  3.910660e-03  6.679136e-02   \n",
       "w_BL           0.250000  0.383105  0.000000e+00  1.433533e-01  4.641799e-02   \n",
       "\n",
       "                       EAFE        EM  \n",
       "w_eq           1.428571e-01  0.142857  \n",
       "w_peer         2.079208e-01  0.049505  \n",
       "w_erc          1.058735e-01  0.079423  \n",
       "w_MVO_1        2.209062e-18  0.017303  \n",
       "w_MVO_2        3.789830e-02  0.034204  \n",
       "w_RUO_3        1.145913e-02  0.137265  \n",
       "w_RUO_3.5      2.314831e-02  0.108537  \n",
       "w_RUO_4        3.191520e-02  0.086991  \n",
       "w_aMVO_1       1.906249e-02  0.024239  \n",
       "w_aMVO_2       6.020933e-02  0.040609  \n",
       "w_aRUO_3       1.591524e-02  0.135674  \n",
       "w_aRUO_3.5     2.918463e-02  0.107225  \n",
       "w_aRUO_4       3.911039e-02  0.085896  \n",
       "w_aRUO_3unc    0.000000e+00  0.131823  \n",
       "w_aRUO_3.5unc  2.763720e-17  0.110382  \n",
       "w_aRUO_4unc    1.832683e-17  0.094078  \n",
       "w_BL           1.112826e-01  0.065842  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_final= pd.concat( [portf_weight,\n",
    "                         pd.DataFrame( MV_opt.x, index= portf_weight.columns, columns= ['w_BL']).T], axis=0)\n",
    "portf_weight_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155061</td>\n",
       "      <td>0.069932</td>\n",
       "      <td>0.039110</td>\n",
       "      <td>0.085896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.383105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143353</td>\n",
       "      <td>0.046418</td>\n",
       "      <td>0.111283</td>\n",
       "      <td>0.065842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "w_peer    0.138614  0.287129  0.049505  0.237624    0.029703  0.207921   \n",
       "w_aRUO_4  0.250000  0.400000  0.000000  0.155061    0.069932  0.039110   \n",
       "w_BL      0.250000  0.383105  0.000000  0.143353    0.046418  0.111283   \n",
       "\n",
       "                EM  \n",
       "w_peer    0.049505  \n",
       "w_aRUO_4  0.085896  \n",
       "w_BL      0.065842  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_final.loc[['w_peer', 'w_aRUO_4', 'w_BL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3</th>\n",
       "      <td>2.946497</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.975123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3.5</th>\n",
       "      <td>3.223899</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>8.370075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_4</th>\n",
       "      <td>3.501302</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>9.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3</th>\n",
       "      <td>2.875835</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>5.785744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.141460</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3</th>\n",
       "      <td>3.116898</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.129680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3.5</th>\n",
       "      <td>3.422701</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.217058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_4</th>\n",
       "      <td>3.728504</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>8.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_ExpRet</th>\n",
       "      <td>5.203543</td>\n",
       "      <td>7.800397</td>\n",
       "      <td>4.167291</td>\n",
       "      <td>7.864592</td>\n",
       "      <td>8.617483</td>\n",
       "      <td>8.073044</td>\n",
       "      <td>8.579113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_eq_3      2.946497  5.112730  4.197299  5.940288    6.745272  6.198200   \n",
       "iRet_eq_3.5    3.223899  5.834154  4.742391  6.827058    7.894844  7.209535   \n",
       "iRet_eq_4      3.501302  6.555578  5.287484  7.713828    9.044416  8.220869   \n",
       "iRet_peer_3    2.875835  5.296642  3.655122  5.827752    6.117100  6.102522   \n",
       "iRet_peer_3.5  3.141460  6.048718  4.109852  6.695766    7.161977  7.097910   \n",
       "iRet_peer_4    3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "iRet_erc_3     3.116898  4.408355  3.840304  4.983875    5.436244  5.024522   \n",
       "iRet_erc_3.5   3.422701  5.012383  4.325897  5.711243    6.367644  5.840244   \n",
       "iRet_erc_4     3.728504  5.616411  4.811491  6.438610    7.299045  6.655965   \n",
       "CMA            7.000000  8.800000  3.770000  7.210000    8.060000  7.070000   \n",
       "CMA_active     7.000000  8.800000  3.770000  8.210000    9.060000  8.070000   \n",
       "post_ExpRet    5.203543  7.800397  4.167291  7.864592    8.617483  8.073044   \n",
       "\n",
       "                     EM  \n",
       "iRet_eq_3      6.975123  \n",
       "iRet_eq_3.5    8.370075  \n",
       "iRet_eq_4      9.765026  \n",
       "iRet_peer_3    5.785744  \n",
       "iRet_peer_3.5  6.982466  \n",
       "iRet_peer_4    8.179187  \n",
       "iRet_erc_3     5.129680  \n",
       "iRet_erc_3.5   6.217058  \n",
       "iRet_erc_4     7.304435  \n",
       "CMA            8.030000  \n",
       "CMA_active     9.030000  \n",
       "post_ExpRet    8.579113  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpRet_final= pd.concat([ExpRet, \n",
    "                        post_mean_geo*400], axis=0)\n",
    "ExpRet_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050394</td>\n",
       "      <td>0.070916</td>\n",
       "      <td>0.065698</td>\n",
       "      <td>0.076496</td>\n",
       "      <td>0.098543</td>\n",
       "      <td>0.091099</td>\n",
       "      <td>0.126186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  0.050394  0.070916  0.065698  0.076496  0.098543  0.091099  0.126186"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.sqrt(np.diag( LW_cov))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290357</td>\n",
       "      <td>0.243449</td>\n",
       "      <td>0.301545</td>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.255969</td>\n",
       "      <td>0.229836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.290357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>0.682977</td>\n",
       "      <td>0.671396</td>\n",
       "      <td>0.604658</td>\n",
       "      <td>0.572320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.243449</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.459033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.301545</td>\n",
       "      <td>0.682977</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832526</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>0.644399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.671396</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.832526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698464</td>\n",
       "      <td>0.691124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.255969</td>\n",
       "      <td>0.604658</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>0.698464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.229836</td>\n",
       "      <td>0.572320</td>\n",
       "      <td>0.459033</td>\n",
       "      <td>0.644399</td>\n",
       "      <td>0.691124</td>\n",
       "      <td>0.669628</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       1.000000  0.290357  0.243449  0.301545    0.307428  0.255969   \n",
       "US_PE       0.290357  1.000000  0.377413  0.682977    0.671396  0.604658   \n",
       "US_HY       0.243449  0.377413  1.000000  0.497447    0.488964  0.455539   \n",
       "SP500       0.301545  0.682977  0.497447  1.000000    0.832526  0.763682   \n",
       "Rusell2000  0.307428  0.671396  0.488964  0.832526    1.000000  0.698464   \n",
       "EAFE        0.255969  0.604658  0.455539  0.763682    0.698464  1.000000   \n",
       "EM          0.229836  0.572320  0.459033  0.644399    0.691124  0.669628   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.229836  \n",
       "US_PE       0.572320  \n",
       "US_HY       0.459033  \n",
       "SP500       0.644399  \n",
       "Rusell2000  0.691124  \n",
       "EAFE        0.669628  \n",
       "EM          1.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130784</td>\n",
       "      <td>0.124802</td>\n",
       "      <td>0.109958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.130784  0.124802  0.109958"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.sqrt(np.diag(np.dot(np.dot(portf_weight.iloc[0:3], LW_cov), portf_weight.iloc[0:3].T)))*2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3</th>\n",
       "      <td>2.946497</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.975123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3.5</th>\n",
       "      <td>3.223899</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>8.370075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_4</th>\n",
       "      <td>3.501302</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>9.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3</th>\n",
       "      <td>2.875835</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>5.785744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.141460</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3</th>\n",
       "      <td>3.116898</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.129680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3.5</th>\n",
       "      <td>3.422701</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.217058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_4</th>\n",
       "      <td>3.728504</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>8.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_ExpRet</th>\n",
       "      <td>5.203543</td>\n",
       "      <td>7.800397</td>\n",
       "      <td>4.167291</td>\n",
       "      <td>7.864592</td>\n",
       "      <td>8.617483</td>\n",
       "      <td>8.073044</td>\n",
       "      <td>8.579113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_eq_3      2.946497  5.112730  4.197299  5.940288    6.745272  6.198200   \n",
       "iRet_eq_3.5    3.223899  5.834154  4.742391  6.827058    7.894844  7.209535   \n",
       "iRet_eq_4      3.501302  6.555578  5.287484  7.713828    9.044416  8.220869   \n",
       "iRet_peer_3    2.875835  5.296642  3.655122  5.827752    6.117100  6.102522   \n",
       "iRet_peer_3.5  3.141460  6.048718  4.109852  6.695766    7.161977  7.097910   \n",
       "iRet_peer_4    3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "iRet_erc_3     3.116898  4.408355  3.840304  4.983875    5.436244  5.024522   \n",
       "iRet_erc_3.5   3.422701  5.012383  4.325897  5.711243    6.367644  5.840244   \n",
       "iRet_erc_4     3.728504  5.616411  4.811491  6.438610    7.299045  6.655965   \n",
       "CMA            7.000000  8.800000  3.770000  7.210000    8.060000  7.070000   \n",
       "CMA_active     7.000000  8.800000  3.770000  8.210000    9.060000  8.070000   \n",
       "post_ExpRet    5.203543  7.800397  4.167291  7.864592    8.617483  8.073044   \n",
       "\n",
       "                     EM  \n",
       "iRet_eq_3      6.975123  \n",
       "iRet_eq_3.5    8.370075  \n",
       "iRet_eq_4      9.765026  \n",
       "iRet_peer_3    5.785744  \n",
       "iRet_peer_3.5  6.982466  \n",
       "iRet_peer_4    8.179187  \n",
       "iRet_erc_3     5.129680  \n",
       "iRet_erc_3.5   6.217058  \n",
       "iRet_erc_4     7.304435  \n",
       "CMA            8.030000  \n",
       "CMA_active     9.030000  \n",
       "post_ExpRet    8.579113  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpRet_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ew</th>\n",
       "      <th>peer</th>\n",
       "      <th>erc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.006116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.014428</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>0.012081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.009712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.017735</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.014547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.020898</td>\n",
       "      <td>0.018628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>0.016314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.023934</td>\n",
       "      <td>0.021748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ew      peer       erc\n",
       "US_RE       0.005548  0.005313  0.006116\n",
       "US_PE       0.014428  0.015042  0.012081\n",
       "US_HY       0.010902  0.009095  0.009712\n",
       "SP500       0.017735  0.017360  0.014547\n",
       "Rusell2000  0.022991  0.020898  0.018628\n",
       "EAFE        0.020227  0.019908  0.016314\n",
       "EM          0.027899  0.023934  0.021748"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.dot(LW_cov, portf_weight.loc[['w_eq', 'w_peer', 'w_erc']].T), index=LW_cov.index, columns= ['ew', 'peer', 'erc'])*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080296</td>\n",
       "      <td>0.082679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.080296  0.082679"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_w= portf_weight_final.loc[[ 'w_aRUO_4unc', 'w_aRUO_4']]\n",
    "\n",
    "tmp_ret= np.dot(tmp_w, ExpRet_final.loc['CMA_active'])/100\n",
    "tmp_vol= np.sqrt(np.diag(np.dot(np.dot(tmp_w, LW_cov_active), tmp_w.T)))*2\n",
    "pd.DataFrame(tmp_ret).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105291</td>\n",
       "      <td>0.117965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.105291  0.117965"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tmp_vol).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05812362,  0.05484773])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_ret- 4/2* tmp_vol**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(view_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CMA_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>9.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CMA_active\n",
       "US_RE             7.00\n",
       "US_PE             8.80\n",
       "US_HY             3.77\n",
       "SP500             8.21\n",
       "Rusell2000        9.06\n",
       "EAFE              8.07\n",
       "EM                9.03"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ExpRet_final.loc['CMA_active'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl_w= portf_weight_final.loc['w_BL'].values\n",
    "bl_ret= ExpRet_final.loc['post_ExpRet'].values/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.072799263232308981"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(bl_w, bl_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11834028601999896"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.dot(np.dot(bl_w, LW_cov_active+ post_cov), bl_w))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
