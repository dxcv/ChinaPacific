{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "%pylab\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "import scipy.optimize\n",
    "from pandas import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates portfolio mean return\n",
    "def port_mean(W, R):\n",
    "    return sum(R * W)\n",
    "\n",
    "# Calculates portfolio variance of returns\n",
    "def port_var(W, C):\n",
    "    return dot(dot(W, C), W)\n",
    "\n",
    "# Combination of the two functions above - mean and variance of returns calculation\n",
    "def port_mean_var(W, R, C):\n",
    "    return port_mean(W, R), port_var(W, C)\n",
    "\n",
    "def conv_arithtogeo(R, C):\n",
    "    return R - .5* np.diag(C)\n",
    "\n",
    "def conv_geotoarith(R, C):\n",
    "    return R + .5* np.diag(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given risk-free rate, assets returns and covariances, this function calculates\n",
    "# mean-variance frontier and returns its [x,y] points in two arrays\n",
    "#assumes corp is the 3rd asset\n",
    "def solve_frontier(numPort,R, C, limit, exclcorp, isAnnual):\n",
    "    def fitness(W, R, C, r):\n",
    "        # For given level of return r, find weights which minimizes portfolio variance.\n",
    "        mean, var = port_mean_var(W, R, C)\n",
    "        penalty = 100 * abs(\n",
    "            mean - r)  # Big penalty for not meeting stated portfolio return effectively serves as optimization constraint\n",
    "        return var + penalty\n",
    "\n",
    "    frontier_mean, frontier_var = [], []\n",
    "    frontier_wts = {}\n",
    "    frontier_wts[0] = []\n",
    "    n = len(R)  # Number of assets in the portfolio\n",
    "    if not isAnnual:\n",
    "        R = R * 4\n",
    "        C = C * 4\n",
    " \n",
    "    RGeo = R\n",
    "    R = conv_geotoarith(R, C)\n",
    "    if exclcorp: \n",
    "        Rtemp = np.delete(R, 2, 0)\n",
    "        minR = min(Rtemp)\n",
    "    else:\n",
    "        minR = min(R)\n",
    "    for r in linspace(minR, max(R), numPort):  # Iterate through the range of returns on Y axis\n",
    "        W = ones([n]) / n  # start optimization with equal weights\n",
    "       \n",
    "        #if limit:\n",
    "        if exclcorp:\n",
    "            #b_ = [(0, 1) for i in range(n)]\n",
    "            b_ = [[0,limit],[0,limit],[0,0.0000001]]+[[0, limit]]*(n-3)\n",
    "        else:\n",
    "            b_ = [[0,limit]]*(n)\n",
    "        #else:\n",
    "        #    if exclcorp:\n",
    "        #        b_ = [[0,None],[0,None],[0,0.0000001]]+[[0, None]]*(n-3)\n",
    "        #    else:\n",
    "        #        b_ = [[0, None]]*(n)\n",
    "        c_ = ({'type': 'eq', 'fun': lambda W: sum(W) - 1.})\n",
    "        optimized = scipy.optimize.minimize(fitness, W, (R, C, r), method='SLSQP', constraints=c_, bounds=b_)\n",
    "        #if not optimized.success:\n",
    "        #    raise BaseException(optimized.message)\n",
    "        # add point to the efficient frontier [x,y] = [optimized.x, r]\n",
    "        r = port_mean(optimized.x,RGeo)\n",
    "        frontier_mean.append(r)\n",
    "        frontier_var.append(np.sqrt(port_var(optimized.x, C)))\n",
    "        frontier_wts[0].append(np.array(optimized.x).tolist())\n",
    "    return array(frontier_mean), array(frontier_var), array(frontier_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in data\n",
    "ret_df_raw= pd.read_excel( io= 'cipc data1.xlsx', sheetname= 'Data_Input', index_col=0)\n",
    "ret_df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cov2corr(cov, return_std=False):\n",
    "    '''convert covariance matrix to correlation matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cov : array_like, 2d\n",
    "        covariance matrix, see Notes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corr : ndarray (subclass)\n",
    "        correlation matrix\n",
    "    return_std : bool\n",
    "        If this is true then the standard deviation is also returned.\n",
    "        By default only the correlation matrix is returned.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function does not convert subclasses of ndarrays. This requires\n",
    "    that division is defined elementwise. np.ma.array and np.matrix are allowed.\n",
    "\n",
    "    '''\n",
    "    cov = np.asanyarray(cov)\n",
    "    std_ = np.sqrt(np.diag(cov))\n",
    "    corr = cov / np.outer(std_, std_)\n",
    "    if return_std:\n",
    "        return corr, std_\n",
    "    else:\n",
    "        return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_df= ret_df_raw[['US_RE', \n",
    "                   'US_PE',\n",
    "                   'US_CORP',\n",
    "                   'SP500',\n",
    "                   'Rusell2000',\n",
    "                   'EAFE',\n",
    "                   'EM']]\n",
    "                   #'USGOVT10Y']]\n",
    "ret_df_cov= ret_df.cov()\n",
    "ret_df_corr= ret_df.corr()\n",
    "N= ret_df.shape[1]\n",
    "#ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Ledoit Wolf shrunk cov matrix\n",
    "\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "LW= LedoitWolf( ).fit(ret_df)\n",
    "LW_alpha= LW.shrinkage_\n",
    "\n",
    "LW_cov= pd.DataFrame(LW.covariance_)\n",
    "LW_cov.index= ret_df_cov.index\n",
    "LW_cov.columns= ret_df_cov.columns\n",
    "LW_cov\n",
    "\n",
    "LW_corr = pd.DataFrame(cov2corr(LW_cov))\n",
    "LW_corr.index= ret_df_cov.index\n",
    "LW_corr.columns= ret_df_cov.columns\n",
    "LW_corr\n",
    "\n",
    "\n",
    "LW_cov_active = LW_cov + np.diag( np.array([0, 0, 0.0004, 0.0009, 0.0009, 0.0009, 0.0009]))/4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.diagonal(np.matrix(LW_cov.values)))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_eq= np.ones( (7,))*1.0/7\n",
    "weight_peer= np.array( (0.138,0.287,0.046,0.238,0.026,0.211,0.046))\n",
    "weight_peer= weight_peer/ np.sum(weight_peer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## solve ERC weight \n",
    "\n",
    "def objective_func(w, sigma): \n",
    "    A= np.diag( w)\n",
    "    B= np.diag( np.dot( sigma, w))\n",
    "    C= np.diag( np.dot( A, B))/ np.dot( np.dot( w, sigma), w)- np.ones( w.size )* 1/ w.size\n",
    "    \n",
    "    return np.dot( C, C)\n",
    "\n",
    "\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "opt_res= minimize( objective_func, \n",
    "                 x0= weight_eq,\n",
    "                 args= LW_cov,\n",
    "                 method= 'Powell',\n",
    "                 options= {'disp': True},\n",
    "                 bounds= [[0,None]]*7,\n",
    "                 tol= 1e-16)\n",
    "\n",
    "weight_erc = opt_res.x/ np.sum( opt_res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func( weight_erc, LW_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portf_weight_1= pd.DataFrame( [weight_eq, weight_peer, weight_erc], \n",
    "                             index=['weight_eq', 'weight_peer', 'weight_erc'], \n",
    "                             columns= LW_cov. columns)\n",
    "portf_weight_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf= 179/10000\n",
    "gamma= [3.5]\n",
    "implied_ExpRet= {}\n",
    "\n",
    "for w_name in portf_weight_1.index: \n",
    "    tmp_dic= {}\n",
    "    for g in gamma:\n",
    "        w= np.array(portf_weight_1.loc[w_name].tolist())\n",
    "        tmp1= np.ones( ( N))* rf/4+ g*  np.dot( LW_cov, w)\n",
    "        tmp2= np.ones( (N))*rf/4+ g* np.dot( ret_df_cov,w) \n",
    "        tmp_dic[str(g)+ '_shrunk']= tmp1\n",
    "        #tmp_dic[str(g)+'_unshrunk']= tmp2\n",
    "    \n",
    "    \n",
    "    tmp= pd.DataFrame( tmp_dic, index= LW_cov.index)\n",
    "    tmp= tmp- .5* np.array([np.diag(LW_cov).tolist()] *tmp.shape[1]).T\n",
    "    implied_ExpRet[w_name]= tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implied_ExpRet['weight_peer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## mean variance optimization, constuct efficient fronter \n",
    "\n",
    "CMA_ExpRet_geo= np.array( [700, 880, 325, 821, 906, 807, 903]) /10000 /4 #quarterly expected exponential ret \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[fm, fv, fw] = solve_frontier(100,CMA_ExpRet_geo, LW_cov_active, 1, 1, 0)\n",
    "\n",
    "[fm1, fv1, fw1] = solve_frontier(100,CMA_ExpRet_geo, LW_cov_active, 0.3, 1, 0)\n",
    "\n",
    "[fm2, fv2, fw2] = solve_frontier(100,CMA_ExpRet_geo, LW_cov_active, 1, 0, 0)\n",
    "\n",
    "[fm3, fv3, fw3] = solve_frontier(100,CMA_ExpRet_geo, LW_cov_active, 0.3, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer= pd.ExcelWriter('output_exclcorp_unconst.xlsx') \n",
    "a = fw.tolist()\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet1')\n",
    "a = fm\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet2')\n",
    "a = fv\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet3')\n",
    "writer.save() \n",
    "\n",
    "writer= pd.ExcelWriter('output_exclcorp_const.xlsx') \n",
    "a = fw1.tolist()\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet1')\n",
    "a = fm1\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet2')\n",
    "a = fv1\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet3')\n",
    "writer.save() \n",
    "\n",
    "writer= pd.ExcelWriter('output_inclcorp_unconst.xlsx') \n",
    "a = fw2.tolist()\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet1')\n",
    "a = fm2\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet2')\n",
    "a = fv2\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet3')\n",
    "writer.save() \n",
    "\n",
    "writer= pd.ExcelWriter('output_inclcorp_const.xlsx') \n",
    "a = fw3.tolist()\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet1')\n",
    "a = fm3\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet2')\n",
    "a = fv3\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet3')\n",
    "writer.save() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Black-Litterman Framework \n",
    "\n",
    "Construct BL framework to incorporate benchmark(prior) and views(observations) and produce a reasonable distribution of expected return (posterior). \n",
    "Apply mean-variance optimization based on posterior to achieve optimal allocation. \n",
    "\n",
    "#### Benckmark/Equilibrium Portfolio\n",
    "\n",
    "Set the benchmark as peer holding `w_peer`, then `iRet_peer_3.5` is the implied equilibrium\\benchmark expected return, given risk aversion factor 3.5.\n",
    "\n",
    "#### The prior confidence  $\\tau$\n",
    "\n",
    "Follow BL's initial setting, $\\tau = 0.05$\n",
    "\n",
    "#### Views\n",
    "\n",
    "`CMA_active` is the subjective view to expected return of each asset. The confidence is proportional to view portfolio (prior) variance with multiplier $\\tau$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### As summary, input: \n",
    "\n",
    "$\\tau$\n",
    "\n",
    "prior expected ret distribution, assuming normal, so the prior mean and variance \n",
    "\n",
    "views, the view portfolio weight, asserted expected ret, and view confidence. \n",
    "\n",
    "#### output: \n",
    "\n",
    "the posterior distribution, mean and variance of post expected return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ExpRet=  implied_ExpRet['weight_peer'][['3.5_shrunk']].T\n",
    "ExpRet.index= ['iRet_peer_3.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## prepare input\n",
    "\n",
    "\n",
    "tau = 5e-2\n",
    "prior_cov= LW_cov* tau\n",
    "prior_cov_inv= np.linalg.inv(prior_cov)\n",
    "prior_mean= ExpRet.loc['iRet_peer_3.5']+ 0.5* np.diag(LW_cov)\n",
    "\n",
    "# CMA_ExpRet_active_arith \n",
    "# is the asserted expected return \n",
    "view_w= np.identity(N)\n",
    "\n",
    "view_ExpRet= conv_geotoarith(CMA_ExpRet_geo,LW_cov_active)\n",
    "view_cov= ( (LW_cov_active)* tau * 2)\n",
    "view_cov_inv= np.linalg.inv( view_cov)\n",
    "\n",
    "##  output: post \n",
    "\n",
    "A= prior_cov_inv\n",
    "B= np.dot( np.dot(view_w.T, view_cov_inv), view_w)\n",
    "C= np.dot(prior_cov_inv, prior_mean)\n",
    "D= np.dot(np.dot(view_w.T, view_cov_inv), view_ExpRet)\n",
    "\n",
    "post_mean_arith= pd.DataFrame( np.dot(np.linalg.inv( A+B), C+D), index=LW_cov.index, columns= ['post_ExpRet']) .T\n",
    "post_cov= pd.DataFrame( np.linalg.inv( prior_cov_inv+ np.dot( np.dot( view_w.T, view_cov_inv), view_w)), index= LW_cov.index, columns= LW_cov.columns)\n",
    "#post_mean_geo= post_mean_arith- .5* np.diag( LW_cov_active)\n",
    "\n",
    "LW_cov_active_bl = LW_cov_active+ post_cov\n",
    "\n",
    "post_mean_geo= post_mean_arith- .5* np.diag(LW_cov_active_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[fm, fv, fw] = solve_frontier(100,post_mean_geo.values[0], LW_cov_active_bl, 1, 1, 0)\n",
    "\n",
    "[fm1, fv1, fw1] = solve_frontier(100,post_mean_geo.values[0], LW_cov_active_bl, 0.3, 1, 0)\n",
    "\n",
    "[fm2, fv2, fw2] = solve_frontier(100,post_mean_geo.values[0], LW_cov_active_bl, 1, 0, 0)\n",
    "\n",
    "[fm3, fv3, fw3] = solve_frontier(100,post_mean_geo.values[0], LW_cov_active_bl, 0.3, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer= pd.ExcelWriter('output_bl_exclcorp_unconst.xlsx') \n",
    "a = fw.tolist()\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet1')\n",
    "a = fm\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet2')\n",
    "a = fv\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet3')\n",
    "writer.save() \n",
    "\n",
    "writer= pd.ExcelWriter('output_bl_exclcorp_const.xlsx') \n",
    "a = fw1.tolist()\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet1')\n",
    "a = fm1\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet2')\n",
    "a = fv1\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet3')\n",
    "writer.save() \n",
    "\n",
    "writer= pd.ExcelWriter('output_bl_inclcorp_unconst.xlsx') \n",
    "a = fw2.tolist()\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet1')\n",
    "a = fm2\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet2')\n",
    "a = fv2\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet3')\n",
    "writer.save() \n",
    "\n",
    "writer= pd.ExcelWriter('output_bl_inclcorp_const.xlsx') \n",
    "a = fw3.tolist()\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet1')\n",
    "a = fm3\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet2')\n",
    "a = fv3\n",
    "b = pd.DataFrame(a)\n",
    "b.to_excel(writer, 'Sheet3')\n",
    "writer.save() "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
