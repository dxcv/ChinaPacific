{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US NCREIF: FUND INDEX OPEN-END DIVERSIFIED CORE RETURNS NADJ</th>\n",
       "      <th>US Private Equity</th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "      <th>USGOVT10Y</th>\n",
       "      <th>Cash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018311</td>\n",
       "      <td>0.034503</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.035495</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029578</td>\n",
       "      <td>0.047497</td>\n",
       "      <td>0.047757</td>\n",
       "      <td>0.070263</td>\n",
       "      <td>0.064625</td>\n",
       "      <td>0.076253</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.091792</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>0.040278</td>\n",
       "      <td>0.006670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.136900</td>\n",
       "      <td>-0.159500</td>\n",
       "      <td>-0.333429</td>\n",
       "      <td>-0.214401</td>\n",
       "      <td>-0.215870</td>\n",
       "      <td>-0.219432</td>\n",
       "      <td>-0.261180</td>\n",
       "      <td>-0.211290</td>\n",
       "      <td>-0.275584</td>\n",
       "      <td>-0.060971</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.012925</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.007742</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>-0.030336</td>\n",
       "      <td>-0.016548</td>\n",
       "      <td>-0.043980</td>\n",
       "      <td>-0.013117</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024050</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>0.026129</td>\n",
       "      <td>0.031222</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>0.038349</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.008214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035350</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>0.049455</td>\n",
       "      <td>0.070468</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.066656</td>\n",
       "      <td>0.111489</td>\n",
       "      <td>0.042543</td>\n",
       "      <td>0.013101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.137135</td>\n",
       "      <td>0.264363</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>0.212974</td>\n",
       "      <td>0.297346</td>\n",
       "      <td>0.258489</td>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.159175</td>\n",
       "      <td>0.023825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       US NCREIF: FUND INDEX OPEN-END DIVERSIFIED CORE RETURNS NADJ  \\\n",
       "count                                         114.000000              \n",
       "mean                                            0.018311              \n",
       "std                                             0.029578              \n",
       "min                                            -0.136900              \n",
       "25%                                             0.012925              \n",
       "50%                                             0.024050              \n",
       "75%                                             0.035350              \n",
       "max                                             0.054500              \n",
       "\n",
       "       US Private Equity       US_RE       US_PE       US_HY       SP500  \\\n",
       "count         114.000000  114.000000  114.000000  114.000000  114.000000   \n",
       "mean            0.034503    0.018989    0.035495    0.024647    0.027670   \n",
       "std             0.047497    0.047757    0.070263    0.064625    0.076253   \n",
       "min            -0.159500   -0.333429   -0.214401   -0.215870   -0.219432   \n",
       "25%             0.011300    0.007742    0.004679   -0.002124   -0.001749   \n",
       "50%             0.037200    0.018845    0.037985    0.026129    0.031222   \n",
       "75%             0.059000    0.035783    0.069509    0.049455    0.070468   \n",
       "max             0.178000    0.137135    0.264363    0.427906    0.212974   \n",
       "\n",
       "       Rusell2000        EAFE          EM   USGOVT10Y        Cash  \n",
       "count  114.000000  114.000000  114.000000  114.000000  114.000000  \n",
       "mean     0.028452    0.017290    0.032061    0.017342    0.008155  \n",
       "std      0.099660    0.091792    0.128686    0.040278    0.006670  \n",
       "min     -0.261180   -0.211290   -0.275584   -0.060971    0.000000  \n",
       "25%     -0.030336   -0.016548   -0.043980   -0.013117    0.000726  \n",
       "50%      0.037918    0.017968    0.038349    0.014060    0.008214  \n",
       "75%      0.088459    0.066656    0.111489    0.042543    0.013101  \n",
       "max      0.297346    0.258489    0.348433    0.159175    0.023825  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in data\n",
    "ret_df_raw= pd.read_excel( io= 'Data/cipc data.xlsx', sheetname= 'Data_Input', index_col=0)\n",
    "ret_df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cov2corr(cov, return_std=False):\n",
    "    '''convert covariance matrix to correlation matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cov : array_like, 2d\n",
    "        covariance matrix, see Notes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corr : ndarray (subclass)\n",
    "        correlation matrix\n",
    "    return_std : bool\n",
    "        If this is true then the standard deviation is also returned.\n",
    "        By default only the correlation matrix is returned.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function does not convert subclasses of ndarrays. This requires\n",
    "    that division is defined elementwise. np.ma.array and np.matrix are allowed.\n",
    "\n",
    "    '''\n",
    "    cov = np.asanyarray(cov)\n",
    "    std_ = np.sqrt(np.diag(cov))\n",
    "    corr = cov / np.outer(std_, std_)\n",
    "    if return_std:\n",
    "        return corr, std_\n",
    "    else:\n",
    "        return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_df= ret_df_raw[['US_RE', \n",
    "                   'US_PE',\n",
    "                   'US_HY',\n",
    "                   'SP500',\n",
    "                   'Rusell2000',\n",
    "                   'EAFE',\n",
    "                   'EM']]\n",
    "                   #'USGOVT10Y']]\n",
    "ret_df_cov= ret_df.cov()\n",
    "ret_df_corr= ret_df.corr()\n",
    "N= ret_df.shape[1]\n",
    "#ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# period1_start= '1987-01-01'\n",
    "# period1_end= '1999-07-01'\n",
    "# period2_start= '2002-01-01'\n",
    "# period2_end= '2008-01-01'\n",
    "# period3_start= '2009-12-31'\n",
    "# period3_end= '2017-12-31'\n",
    "\n",
    "# ret_df1= ret_df[ np.logical_and( ret_df.index>= period1_start, ret_df.index<= period1_end) ]\n",
    "# ret_df2= ret_df[ np.logical_and( ret_df.index>= period2_start, ret_df.index<= period2_end) ]\n",
    "# ret_df3= ret_df[ np.logical_and( ret_df.index>= period3_start, ret_df.index<= period3_end) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290357</td>\n",
       "      <td>0.243449</td>\n",
       "      <td>0.301545</td>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.255969</td>\n",
       "      <td>0.229836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.290357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>0.682977</td>\n",
       "      <td>0.671396</td>\n",
       "      <td>0.604658</td>\n",
       "      <td>0.572320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.243449</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.459033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.301545</td>\n",
       "      <td>0.682977</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832526</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>0.644399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.671396</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.832526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698464</td>\n",
       "      <td>0.691124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.255969</td>\n",
       "      <td>0.604658</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>0.698464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.229836</td>\n",
       "      <td>0.572320</td>\n",
       "      <td>0.459033</td>\n",
       "      <td>0.644399</td>\n",
       "      <td>0.691124</td>\n",
       "      <td>0.669628</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       1.000000  0.290357  0.243449  0.301545    0.307428  0.255969   \n",
       "US_PE       0.290357  1.000000  0.377413  0.682977    0.671396  0.604658   \n",
       "US_HY       0.243449  0.377413  1.000000  0.497447    0.488964  0.455539   \n",
       "SP500       0.301545  0.682977  0.497447  1.000000    0.832526  0.763682   \n",
       "Rusell2000  0.307428  0.671396  0.488964  0.832526    1.000000  0.698464   \n",
       "EAFE        0.255969  0.604658  0.455539  0.763682    0.698464  1.000000   \n",
       "EM          0.229836  0.572320  0.459033  0.644399    0.691124  0.669628   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.229836  \n",
       "US_PE       0.572320  \n",
       "US_HY       0.459033  \n",
       "SP500       0.644399  \n",
       "Rusell2000  0.691124  \n",
       "EAFE        0.669628  \n",
       "EM          1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ledoit Wolf shrunk cov matrix\n",
    "\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "LW= LedoitWolf( ).fit(ret_df)\n",
    "LW_alpha= LW.shrinkage_\n",
    "\n",
    "LW_cov= pd.DataFrame(LW.covariance_)\n",
    "LW_cov.index= ret_df_cov.index\n",
    "LW_cov.columns= ret_df_cov.columns\n",
    "LW_cov\n",
    "\n",
    "LW_corr = pd.DataFrame(cov2corr(LW_cov))\n",
    "LW_corr.index= ret_df_cov.index\n",
    "LW_corr.columns= ret_df_cov.columns\n",
    "LW_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10078878,  0.14183195,  0.13139679,  0.15299213,  0.19708686,\n",
       "        0.18219804,  0.25237214])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.diagonal(np.matrix(LW_cov.values)))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## arithmatic avg ret to exponential avg ret \n",
    "\n",
    "ret_cov= np.diagonal(np.matrix(LW_cov.values))\n",
    "coverter= np.array([ret_cov.tolist()]*ret_df.shape[0])* .5\n",
    "ret_df_exp= ret_df- coverter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_eq= np.ones( (7,))*1.0/7\n",
    "weight_peer= np.array( (0.14,0.29,0.05,0.24,0.03,0.21,0.05))\n",
    "weight_peer= weight_peer/ np.sum(weight_peer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:394: RuntimeWarning: Method Powell cannot handle constraints nor bounds.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 11\n",
      "         Function evaluations: 1304\n"
     ]
    }
   ],
   "source": [
    "## solve ERC weight \n",
    "\n",
    "def objective_func(w, sigma): \n",
    "    A= np.diag( w)\n",
    "    B= np.diag( np.dot( sigma, w))\n",
    "    C= np.diag( np.dot( A, B))/ np.dot( np.dot( w, sigma), w)- np.ones( w.size )* 1/ w.size\n",
    "    \n",
    "    return np.dot( C, C)\n",
    "\n",
    "\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "opt_res= minimize( objective_func, \n",
    "                 x0= weight_eq,\n",
    "                 args= LW_cov,\n",
    "                 method= 'Powell',\n",
    "                 options= {'disp': True},\n",
    "                 bounds= [[0,None]]*7,\n",
    "                 tol= 1e-16)\n",
    "\n",
    "weight_erc = opt_res.x/ np.sum( opt_res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7842763342203468e-23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_func( weight_erc, LW_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>0.177851</td>\n",
       "      <td>0.118734</td>\n",
       "      <td>0.092724</td>\n",
       "      <td>0.105874</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "weight_eq    0.142857  0.142857  0.142857  0.142857    0.142857  0.142857   \n",
       "weight_peer  0.138614  0.287129  0.049505  0.237624    0.029703  0.207921   \n",
       "weight_erc   0.282415  0.142979  0.177851  0.118734    0.092724  0.105874   \n",
       "\n",
       "                   EM  \n",
       "weight_eq    0.142857  \n",
       "weight_peer  0.049505  \n",
       "weight_erc   0.079423  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "portf_weight_1= pd.DataFrame( [weight_eq, weight_peer, weight_erc], \n",
    "                             index=['weight_eq', 'weight_peer', 'weight_erc'], \n",
    "                             columns= LW_cov. columns)\n",
    "portf_weight_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## recover the implied expected ret based on shirinked cov matrix\n",
    "\n",
    "rf= 179/10000\n",
    "gamma= [ 1.5, 2, 2.5, 3, 3.5,4]\n",
    "implied_ExpRet= {}\n",
    "\n",
    "for w_name in portf_weight_1.index: \n",
    "    tmp_dic= {}\n",
    "    for g in gamma:\n",
    "        w= np.array(portf_weight_1.loc[w_name].tolist())\n",
    "        tmp1= np.ones( ( N))* rf/4+ g*  np.dot( LW_cov, w)\n",
    "        tmp2= np.ones( (N))*rf/4+ g* np.dot( ret_df_cov,w) \n",
    "        tmp_dic[str(g)+ '_shrunk']= tmp1\n",
    "        tmp_dic[str(g)+'_unshrunk']= tmp2\n",
    "    \n",
    "    \n",
    "    tmp= pd.DataFrame( tmp_dic, index= LW_cov.index)\n",
    "    tmp= tmp- .5* np.array([np.diag(LW_cov).tolist()] *tmp.shape[1]).T\n",
    "    implied_ExpRet[w_name]= tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5_shrunk</th>\n",
       "      <th>1.5_unshrunk</th>\n",
       "      <th>2.5_shrunk</th>\n",
       "      <th>2.5_unshrunk</th>\n",
       "      <th>2_shrunk</th>\n",
       "      <th>2_unshrunk</th>\n",
       "      <th>3.5_shrunk</th>\n",
       "      <th>3.5_unshrunk</th>\n",
       "      <th>3_shrunk</th>\n",
       "      <th>3_unshrunk</th>\n",
       "      <th>4_shrunk</th>\n",
       "      <th>4_unshrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>2.114289</td>\n",
       "      <td>2.133245</td>\n",
       "      <td>2.669094</td>\n",
       "      <td>2.700688</td>\n",
       "      <td>2.391691</td>\n",
       "      <td>2.416967</td>\n",
       "      <td>3.223899</td>\n",
       "      <td>3.268131</td>\n",
       "      <td>2.946497</td>\n",
       "      <td>2.984409</td>\n",
       "      <td>3.501302</td>\n",
       "      <td>3.551852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>2.948458</td>\n",
       "      <td>3.056591</td>\n",
       "      <td>4.391306</td>\n",
       "      <td>4.571528</td>\n",
       "      <td>3.669882</td>\n",
       "      <td>3.814060</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>6.086466</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>5.328997</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>6.843935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>2.562022</td>\n",
       "      <td>2.634741</td>\n",
       "      <td>3.652207</td>\n",
       "      <td>3.773405</td>\n",
       "      <td>3.107114</td>\n",
       "      <td>3.204073</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>4.912069</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>4.342737</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>5.481402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>3.279979</td>\n",
       "      <td>3.421321</td>\n",
       "      <td>5.053519</td>\n",
       "      <td>5.289088</td>\n",
       "      <td>4.166749</td>\n",
       "      <td>4.355205</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.156855</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.222972</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>8.090739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>3.296555</td>\n",
       "      <td>3.490678</td>\n",
       "      <td>5.595700</td>\n",
       "      <td>5.919238</td>\n",
       "      <td>4.446127</td>\n",
       "      <td>4.704958</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>8.347797</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>7.133518</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>9.562077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>3.164197</td>\n",
       "      <td>3.330556</td>\n",
       "      <td>5.186866</td>\n",
       "      <td>5.464131</td>\n",
       "      <td>4.175532</td>\n",
       "      <td>4.397344</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>7.597706</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.530919</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>8.664494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>2.790269</td>\n",
       "      <td>3.033674</td>\n",
       "      <td>5.580172</td>\n",
       "      <td>5.985847</td>\n",
       "      <td>4.185221</td>\n",
       "      <td>4.509760</td>\n",
       "      <td>8.370075</td>\n",
       "      <td>8.938019</td>\n",
       "      <td>6.975123</td>\n",
       "      <td>7.461933</td>\n",
       "      <td>9.765026</td>\n",
       "      <td>10.414105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1.5_shrunk  1.5_unshrunk  2.5_shrunk  2.5_unshrunk  2_shrunk  \\\n",
       "US_RE         2.114289      2.133245    2.669094      2.700688  2.391691   \n",
       "US_PE         2.948458      3.056591    4.391306      4.571528  3.669882   \n",
       "US_HY         2.562022      2.634741    3.652207      3.773405  3.107114   \n",
       "SP500         3.279979      3.421321    5.053519      5.289088  4.166749   \n",
       "Rusell2000    3.296555      3.490678    5.595700      5.919238  4.446127   \n",
       "EAFE          3.164197      3.330556    5.186866      5.464131  4.175532   \n",
       "EM            2.790269      3.033674    5.580172      5.985847  4.185221   \n",
       "\n",
       "            2_unshrunk  3.5_shrunk  3.5_unshrunk  3_shrunk  3_unshrunk  \\\n",
       "US_RE         2.416967    3.223899      3.268131  2.946497    2.984409   \n",
       "US_PE         3.814060    5.834154      6.086466  5.112730    5.328997   \n",
       "US_HY         3.204073    4.742391      4.912069  4.197299    4.342737   \n",
       "SP500         4.355205    6.827058      7.156855  5.940288    6.222972   \n",
       "Rusell2000    4.704958    7.894844      8.347797  6.745272    7.133518   \n",
       "EAFE          4.397344    7.209535      7.597706  6.198200    6.530919   \n",
       "EM            4.509760    8.370075      8.938019  6.975123    7.461933   \n",
       "\n",
       "            4_shrunk  4_unshrunk  \n",
       "US_RE       3.501302    3.551852  \n",
       "US_PE       6.555578    6.843935  \n",
       "US_HY       5.287484    5.481402  \n",
       "SP500       7.713828    8.090739  \n",
       "Rusell2000  9.044416    9.562077  \n",
       "EAFE        8.220869    8.664494  \n",
       "EM          9.765026   10.414105  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_eq']*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5_shrunk</th>\n",
       "      <th>1.5_unshrunk</th>\n",
       "      <th>2.5_shrunk</th>\n",
       "      <th>2.5_unshrunk</th>\n",
       "      <th>2_shrunk</th>\n",
       "      <th>2_unshrunk</th>\n",
       "      <th>3.5_shrunk</th>\n",
       "      <th>3.5_unshrunk</th>\n",
       "      <th>3_shrunk</th>\n",
       "      <th>3_unshrunk</th>\n",
       "      <th>4_shrunk</th>\n",
       "      <th>4_unshrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>2.199490</td>\n",
       "      <td>2.188242</td>\n",
       "      <td>2.811095</td>\n",
       "      <td>2.792348</td>\n",
       "      <td>2.505292</td>\n",
       "      <td>2.490295</td>\n",
       "      <td>3.422701</td>\n",
       "      <td>3.396455</td>\n",
       "      <td>3.116898</td>\n",
       "      <td>3.094402</td>\n",
       "      <td>3.728504</td>\n",
       "      <td>3.698509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>2.596270</td>\n",
       "      <td>2.680794</td>\n",
       "      <td>3.804326</td>\n",
       "      <td>3.945200</td>\n",
       "      <td>3.200298</td>\n",
       "      <td>3.312997</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>5.209607</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>4.577403</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>5.841810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>2.383524</td>\n",
       "      <td>2.435290</td>\n",
       "      <td>3.354711</td>\n",
       "      <td>3.440986</td>\n",
       "      <td>2.869117</td>\n",
       "      <td>2.938138</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>4.446683</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>3.943835</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>4.949532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>2.801773</td>\n",
       "      <td>2.917307</td>\n",
       "      <td>4.256508</td>\n",
       "      <td>4.449065</td>\n",
       "      <td>3.529140</td>\n",
       "      <td>3.683186</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>5.980822</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.214944</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>6.746701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>2.642041</td>\n",
       "      <td>2.805246</td>\n",
       "      <td>4.504843</td>\n",
       "      <td>4.776850</td>\n",
       "      <td>3.573442</td>\n",
       "      <td>3.791048</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>6.748455</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.762653</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>7.734257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>2.577358</td>\n",
       "      <td>2.713946</td>\n",
       "      <td>4.208801</td>\n",
       "      <td>4.436448</td>\n",
       "      <td>3.393080</td>\n",
       "      <td>3.575197</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.158950</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.297699</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>1.867548</td>\n",
       "      <td>2.065501</td>\n",
       "      <td>4.042303</td>\n",
       "      <td>4.372225</td>\n",
       "      <td>2.954925</td>\n",
       "      <td>3.218863</td>\n",
       "      <td>6.217058</td>\n",
       "      <td>6.678948</td>\n",
       "      <td>5.129680</td>\n",
       "      <td>5.525587</td>\n",
       "      <td>7.304435</td>\n",
       "      <td>7.832310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1.5_shrunk  1.5_unshrunk  2.5_shrunk  2.5_unshrunk  2_shrunk  \\\n",
       "US_RE         2.199490      2.188242    2.811095      2.792348  2.505292   \n",
       "US_PE         2.596270      2.680794    3.804326      3.945200  3.200298   \n",
       "US_HY         2.383524      2.435290    3.354711      3.440986  2.869117   \n",
       "SP500         2.801773      2.917307    4.256508      4.449065  3.529140   \n",
       "Rusell2000    2.642041      2.805246    4.504843      4.776850  3.573442   \n",
       "EAFE          2.577358      2.713946    4.208801      4.436448  3.393080   \n",
       "EM            1.867548      2.065501    4.042303      4.372225  2.954925   \n",
       "\n",
       "            2_unshrunk  3.5_shrunk  3.5_unshrunk  3_shrunk  3_unshrunk  \\\n",
       "US_RE         2.490295    3.422701      3.396455  3.116898    3.094402   \n",
       "US_PE         3.312997    5.012383      5.209607  4.408355    4.577403   \n",
       "US_HY         2.938138    4.325897      4.446683  3.840304    3.943835   \n",
       "SP500         3.683186    5.711243      5.980822  4.983875    5.214944   \n",
       "Rusell2000    3.791048    6.367644      6.748455  5.436244    5.762653   \n",
       "EAFE          3.575197    5.840244      6.158950  5.024522    5.297699   \n",
       "EM            3.218863    6.217058      6.678948  5.129680    5.525587   \n",
       "\n",
       "            4_shrunk  4_unshrunk  \n",
       "US_RE       3.728504    3.698509  \n",
       "US_PE       5.616411    5.841810  \n",
       "US_HY       4.811491    4.949532  \n",
       "SP500       6.438610    6.746701  \n",
       "Rusell2000  7.299045    7.734257  \n",
       "EAFE        6.655965    7.020200  \n",
       "EM          7.304435    7.832310  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_erc']*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5_shrunk</th>\n",
       "      <th>1.5_unshrunk</th>\n",
       "      <th>2.5_shrunk</th>\n",
       "      <th>2.5_unshrunk</th>\n",
       "      <th>2_shrunk</th>\n",
       "      <th>2_unshrunk</th>\n",
       "      <th>3.5_shrunk</th>\n",
       "      <th>3.5_unshrunk</th>\n",
       "      <th>3_shrunk</th>\n",
       "      <th>3_unshrunk</th>\n",
       "      <th>4_shrunk</th>\n",
       "      <th>4_unshrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>2.078958</td>\n",
       "      <td>2.096641</td>\n",
       "      <td>2.610209</td>\n",
       "      <td>2.639680</td>\n",
       "      <td>2.344583</td>\n",
       "      <td>2.368160</td>\n",
       "      <td>3.141460</td>\n",
       "      <td>3.182720</td>\n",
       "      <td>2.875835</td>\n",
       "      <td>2.911200</td>\n",
       "      <td>3.407086</td>\n",
       "      <td>3.454240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>3.040413</td>\n",
       "      <td>3.117582</td>\n",
       "      <td>4.544566</td>\n",
       "      <td>4.673180</td>\n",
       "      <td>3.792489</td>\n",
       "      <td>3.895381</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>6.228778</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>5.450979</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>7.006577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>2.290933</td>\n",
       "      <td>2.369524</td>\n",
       "      <td>3.200393</td>\n",
       "      <td>3.331376</td>\n",
       "      <td>2.745663</td>\n",
       "      <td>2.850450</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>4.293229</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>3.812303</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>4.774156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>3.223711</td>\n",
       "      <td>3.336902</td>\n",
       "      <td>4.959738</td>\n",
       "      <td>5.148390</td>\n",
       "      <td>4.091725</td>\n",
       "      <td>4.242646</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>6.959878</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.054134</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>7.865622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>2.982469</td>\n",
       "      <td>3.184680</td>\n",
       "      <td>5.072223</td>\n",
       "      <td>5.409241</td>\n",
       "      <td>4.027346</td>\n",
       "      <td>4.296960</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.633801</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.521521</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.746082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>3.116358</td>\n",
       "      <td>3.262773</td>\n",
       "      <td>5.107134</td>\n",
       "      <td>5.351160</td>\n",
       "      <td>4.111746</td>\n",
       "      <td>4.306967</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>7.439546</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>6.395353</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.483739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>2.195580</td>\n",
       "      <td>2.423192</td>\n",
       "      <td>4.589023</td>\n",
       "      <td>4.968376</td>\n",
       "      <td>3.392301</td>\n",
       "      <td>3.695784</td>\n",
       "      <td>6.982466</td>\n",
       "      <td>7.513560</td>\n",
       "      <td>5.785744</td>\n",
       "      <td>6.240968</td>\n",
       "      <td>8.179187</td>\n",
       "      <td>8.786152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1.5_shrunk  1.5_unshrunk  2.5_shrunk  2.5_unshrunk  2_shrunk  \\\n",
       "US_RE         2.078958      2.096641    2.610209      2.639680  2.344583   \n",
       "US_PE         3.040413      3.117582    4.544566      4.673180  3.792489   \n",
       "US_HY         2.290933      2.369524    3.200393      3.331376  2.745663   \n",
       "SP500         3.223711      3.336902    4.959738      5.148390  4.091725   \n",
       "Rusell2000    2.982469      3.184680    5.072223      5.409241  4.027346   \n",
       "EAFE          3.116358      3.262773    5.107134      5.351160  4.111746   \n",
       "EM            2.195580      2.423192    4.589023      4.968376  3.392301   \n",
       "\n",
       "            2_unshrunk  3.5_shrunk  3.5_unshrunk  3_shrunk  3_unshrunk  \\\n",
       "US_RE         2.368160    3.141460      3.182720  2.875835    2.911200   \n",
       "US_PE         3.895381    6.048718      6.228778  5.296642    5.450979   \n",
       "US_HY         2.850450    4.109852      4.293229  3.655122    3.812303   \n",
       "SP500         4.242646    6.695766      6.959878  5.827752    6.054134   \n",
       "Rusell2000    4.296960    7.161977      7.633801  6.117100    6.521521   \n",
       "EAFE          4.306967    7.097910      7.439546  6.102522    6.395353   \n",
       "EM            3.695784    6.982466      7.513560  5.785744    6.240968   \n",
       "\n",
       "            4_shrunk  4_unshrunk  \n",
       "US_RE       3.407086    3.454240  \n",
       "US_PE       6.800794    7.006577  \n",
       "US_HY       4.564582    4.774156  \n",
       "SP500       7.563779    7.865622  \n",
       "Rusell2000  8.206854    8.746082  \n",
       "EAFE        8.093298    8.483739  \n",
       "EM          8.179187    8.786152  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_peer']*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## mean variance optimization, constuct efficient fronter \n",
    "\n",
    "CMA_ExpRet_geo= np.array( [700, 880, 477, 721, 806, 707, 803]) /10000 /4 #quarterly expected exponential ret \n",
    "LW_cov.index\n",
    "CMA_ExpRet_arith= CMA_ExpRet_geo+ .5* np.diag(LW_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491855912\n",
      "            Iterations: 7\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 3\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021581396224591392\n",
      "            Iterations: 7\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 3\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491804853\n",
      "            Iterations: 36\n",
      "            Function evaluations: 300\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002158139622459017\n",
      "            Iterations: 15\n",
      "            Function evaluations: 76\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491846623\n",
      "            Iterations: 11\n",
      "            Function evaluations: 52\n",
      "            Gradient evaluations: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021581396224603657\n",
      "            Iterations: 37\n",
      "            Function evaluations: 343\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491833482\n",
      "            Iterations: 6\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021581396224585165\n",
      "            Iterations: 37\n",
      "            Function evaluations: 303\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00129219884918221\n",
      "            Iterations: 15\n",
      "            Function evaluations: 95\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002158139622458854\n",
      "            Iterations: 37\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491798138\n",
      "            Iterations: 15\n",
      "            Function evaluations: 86\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00215813962246014\n",
      "            Iterations: 12\n",
      "            Function evaluations: 68\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491813277\n",
      "            Iterations: 25\n",
      "            Function evaluations: 196\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021581396224593266\n",
      "            Iterations: 56\n",
      "            Function evaluations: 552\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491846814\n",
      "            Iterations: 28\n",
      "            Function evaluations: 228\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002158139622458252\n",
      "            Iterations: 18\n",
      "            Function evaluations: 134\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001292198849180484\n",
      "            Iterations: 46\n",
      "            Function evaluations: 400\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002158139622458291\n",
      "            Iterations: 12\n",
      "            Function evaluations: 64\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001292198849178019\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021581396224588643\n",
      "            Iterations: 23\n",
      "            Function evaluations: 189\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491816732\n",
      "            Iterations: 20\n",
      "            Function evaluations: 150\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021581396224585286\n",
      "            Iterations: 37\n",
      "            Function evaluations: 343\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491823675\n",
      "            Iterations: 24\n",
      "            Function evaluations: 197\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002158139622458028\n",
      "            Iterations: 15\n",
      "            Function evaluations: 88\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001292198849183265\n",
      "            Iterations: 21\n",
      "            Function evaluations: 158\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002158139622458304\n",
      "            Iterations: 31\n",
      "            Function evaluations: 277\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491809598\n",
      "            Iterations: 32\n",
      "            Function evaluations: 266\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002114897954342651\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491838665\n",
      "            Iterations: 8\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 4\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020239881280283076\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491789195\n",
      "            Iterations: 25\n",
      "            Function evaluations: 170\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019368843319882856\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491810458\n",
      "            Iterations: 81\n",
      "            Function evaluations: 738\n",
      "            Gradient evaluations: 77\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018535865662225879\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491773977\n",
      "            Iterations: 60\n",
      "            Function evaluations: 567\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017740948307312131\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491841944\n",
      "            Iterations: 62\n",
      "            Function evaluations: 591\n",
      "            Gradient evaluations: 58\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016984091255141586\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491735187\n",
      "            Iterations: 74\n",
      "            Function evaluations: 690\n",
      "            Gradient evaluations: 70\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001626529450571429\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491825668\n",
      "            Iterations: 30\n",
      "            Function evaluations: 256\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001558455805903023\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491842314\n",
      "            Iterations: 33\n",
      "            Function evaluations: 279\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014941881915089366\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491833383\n",
      "            Iterations: 22\n",
      "            Function evaluations: 161\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014337266073891717\n",
      "            Iterations: 5\n",
      "            Function evaluations: 5\n",
      "            Gradient evaluations: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491850997\n",
      "            Iterations: 93\n",
      "            Function evaluations: 919\n",
      "            Gradient evaluations: 89\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013770710535437336\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00129219884918391\n",
      "            Iterations: 31\n",
      "            Function evaluations: 267\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013242215299726192\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491852534\n",
      "            Iterations: 87\n",
      "            Function evaluations: 857\n",
      "            Gradient evaluations: 83\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012751780366758256\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491816168\n",
      "            Iterations: 25\n",
      "            Function evaluations: 203\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012299405736533524\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491824854\n",
      "            Iterations: 17\n",
      "            Function evaluations: 105\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011885091409052054\n",
      "            Iterations: 8\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 8\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0012921988491864601\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1019\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00115088373843138\n",
      "            Iterations: 10\n",
      "            Function evaluations: 10\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491826726\n",
      "            Iterations: 29\n",
      "            Function evaluations: 244\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011170643662318774\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491823794\n",
      "            Iterations: 14\n",
      "            Function evaluations: 90\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010870510243066974\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491825453\n",
      "            Iterations: 39\n",
      "            Function evaluations: 361\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010608437126558403\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491833875\n",
      "            Iterations: 18\n",
      "            Function evaluations: 126\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010384424312793053\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491832674\n",
      "            Iterations: 62\n",
      "            Function evaluations: 610\n",
      "            Gradient evaluations: 58\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010198471801770943\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491816627\n",
      "            Iterations: 24\n",
      "            Function evaluations: 195\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010050579593492048\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0012921988491827571\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1029\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009937054544209933\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491840675\n",
      "            Iterations: 36\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009835747766845514\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491823085\n",
      "            Iterations: 43\n",
      "            Function evaluations: 392\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009742969442286464\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0012921988491836798\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1031\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009658719570532792\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491843292\n",
      "            Iterations: 11\n",
      "            Function evaluations: 52\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009582998151584513\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491830353\n",
      "            Iterations: 18\n",
      "            Function evaluations: 124\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009515805185441603\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491827723\n",
      "            Iterations: 11\n",
      "            Function evaluations: 52\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009457140672104087\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001292198849183135\n",
      "            Iterations: 9\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009407004611571945\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491827253\n",
      "            Iterations: 37\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009365397003845188\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491830334\n",
      "            Iterations: 62\n",
      "            Function evaluations: 607\n",
      "            Gradient evaluations: 58\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009332317848923811\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0012921988491644944\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1027\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009307767146807815\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012921988491831871\n",
      "            Iterations: 41\n",
      "            Function evaluations: 376\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009291744897497202\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012451584987509029\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009284251100991973\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001202941312723272\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009285285757292124\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011749809492170766\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009294848866397654\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001153078379016844\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009312940428308565\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011355325494062892\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009339560443024862\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011223434603854078\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000937470891054654\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001113511111954204\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009418385830873598\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001110201919955471\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009470591204006035\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011200848212329787\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009531325029943857\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011315668471246455\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009600587308687061\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011446171222105552\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009678378040235648\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011592356464907101\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009764697224589614\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011753825959154938\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009859544861748962\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011926093421039104\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009962920951713695\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012107901388245254\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010074825494483805\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012299249875458243\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010195258490059294\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012500138872372415\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010324219938440174\n",
      "            Iterations: 20\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012710569037112467\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010461709839629785\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012930310097678565\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001060702033527263\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013158387134180828\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010759101735518515\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013394688291990299\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010917944302568801\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001363921357087954\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011083548036541495\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013891962970848518\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011255912937397194\n",
      "            Iterations: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001415293649189726\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011437285124079508\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001442213413402579\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001163869504544858\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001469955589723405\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011861625968781395\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001498520178152208\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012106077894077948\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015279071786889861\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001237205082133824\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015581165913337515\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012659544750562276\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001589148416102412\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001296855968175003\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016210026530140585\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013299095614901564\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016536793019300898\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013651152550016778\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016871783629925175\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001402473048709577\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017215221700528198\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014419829426138482\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00175746378304593\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014836449367144967\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017953712657329903\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015274590310115164\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018352446180565434\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001573425225504911\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018770838400165909\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001621543520194679\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019208889316131282\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016718139150808183\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001966659892846163\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017242364101633335\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020143967237156936\n",
      "            Iterations: 25\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017788110054422221\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00206642820037022\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018355377009174857\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002132088481421969\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018944164965891217\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002209149523834903\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019554473924571327\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022893184961587914\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020186303885215196\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0023721842737508556\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002083965484782276\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002457746856611102\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021514526812394068\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0025460920736244757\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022210919778929156\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026380146679059135\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022928833747427923\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0027337081085088543\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002366826871789046\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00283317239543329\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002442922469031673\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002936407528679225\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002521170166470674\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0030434135082466557\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0026015699641060526\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def obj_func(w, sigma):\n",
    "    return (np.dot(  np.dot( w, sigma), w)* .5)\n",
    "\n",
    "def obj_func_derivative( w, sigma): \n",
    "    return (np.dot( w, sigma))\n",
    "\n",
    "\n",
    "cons_eq0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "# cons_ineq0= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[0]-w[1]+ 0.5, \n",
    "#              'jac': lambda w: np.array([-1]*2+ [0]*10)}\n",
    "# cons_ineq1= {'type': 'ineq',\n",
    "#              'fun': lambda w: -w[2]-w[3]-w[4]-w[5]-w[6]+ 0.5,\n",
    "#              'jac': lambda w: np.array([0]*2+ [-1]*5+ [0]*5)}\n",
    "# cons_ineq2= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[7]-w[8]-w[9]-w[10]+ 0.5, \n",
    "#              'jac': lambda w: np.array([0]*7+ [-1]*4+ [0])}\n",
    "# cons_ineq3= {'type': 'ineq', \n",
    "#             'fun': lambda w: -w[11]+ 0.5,\n",
    "#             'jac': lambda w: np.array( [0]*11+ [-1])}\n",
    "\n",
    "\n",
    "\n",
    "fronter1_w= {}\n",
    "fronter1_vol= {}\n",
    "fronter2_w= {}\n",
    "fronter2_vol= {}\n",
    "\n",
    "for target_ret in np.linspace(0.05, 0.1, 100 ): \n",
    "    cons_ineq4= {'type': 'eq', \n",
    "                'fun': lambda w: -np.dot(w, CMA_ExpRet_arith*4)+ target_ret,\n",
    "                'jac': lambda w: -CMA_ExpRet_arith*4}\n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          , cons_ineq4\n",
    "          )\n",
    "\n",
    "    MV_opt_2= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    #bounds= [[0,0.25]]+[[0, 0.4]]+[[0,None]]* (N-2),\n",
    "                    bounds= [[0,0.3]]* (N),\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "\n",
    "    MV_opt_1= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None]]* N,\n",
    "                    tol= 1e-12)  # long only constrain\n",
    "    \n",
    "    fronter1_w[target_ret]= MV_opt_1.x\n",
    "    fronter1_vol[target_ret]= np.sqrt(MV_opt_1.fun*2) \n",
    "    \n",
    "    fronter2_w[target_ret]= MV_opt_2.x\n",
    "    fronter2_vol[target_ret]= np.sqrt(MV_opt_2.fun*2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.084343434343434345, 0.047081945661880828)\n",
      "[  5.76958650e-01   3.92525584e-01   1.58869429e-02   3.55245618e-18\n",
      "   0.00000000e+00   0.00000000e+00   1.46288226e-02]\n",
      "(0.081313131313131309, 0.049596874650441922)\n",
      "[  3.00000000e-01   3.00000000e-01   1.78278771e-01   1.69614120e-01\n",
      "   3.21016288e-17   2.93300999e-02   2.27770094e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOBhjjKnm/wN5yL0lu/RKIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb15eda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fronter_1= list( fronter1_vol.items())\n",
    "fronter_1.sort( key=lambda x: x[1])\n",
    "minvar_portf1= fronter_1[0]\n",
    "minvar_portf1_w= fronter1_w[minvar_portf1[0]]\n",
    "fronter_1.sort( key= lambda x: (x[0]- rf)/ x[1], reverse=True)\n",
    "efficient_portf1= fronter_1[0]\n",
    "efficient_portf1_w= fronter1_w[efficient_portf1[0]]\n",
    "\n",
    "fronter_2= list(fronter2_vol.items())\n",
    "fronter_2.sort(key= lambda x: x[1])\n",
    "minvar_portf2= fronter_2[0]\n",
    "minvar_portf2_w= fronter2_w[minvar_portf2[0]]\n",
    "fronter_2.sort(key= lambda x: (x[0]-rf)/x[1], reverse= True)\n",
    "efficient_portf2= fronter_2[0]\n",
    "efficient_portf2_w= fronter2_w[efficient_portf2[0]]\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip( * list( fronter1_vol.items())) \n",
    "fig= plt.figure( )\n",
    "plt.scatter(x= tmp_vol, y= tmp_ret, marker=\".\", c= 'pink' , label= 'long only')\n",
    "plt.scatter(x= minvar_portf1[1], y= minvar_portf1[0], marker= 'o', c='purple', s= 100 )\n",
    "plt.scatter(x= efficient_portf1[1], y = efficient_portf1[0], marker= '*', c='m', s=200)\n",
    "plt.plot( [0.04, efficient_portf1[1]], [ (efficient_portf1[0]-rf)/efficient_portf1[1]* 0.04+rf, efficient_portf1[0]], 'k-')\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip(* list(fronter2_vol.items()))\n",
    "plt.scatter( x= tmp_vol, y= tmp_ret, marker= '.', c='blue', label= 'long only+ concentration constrain')\n",
    "plt.scatter( x= minvar_portf2[1], y=minvar_portf2[0], marker= 'o', c= 'y', s=100)\n",
    "plt.scatter(x= efficient_portf2[1], y = efficient_portf2[0], marker= '*', c='r', s=200)\n",
    "plt.plot( [0.04, efficient_portf2[1]], [ (efficient_portf2[0]-rf)/efficient_portf2[1]* 0.04+rf, efficient_portf2[0]], 'k-')\n",
    "plt.legend()\n",
    "plt.title('Efficient Fronter')\n",
    "\n",
    "print(efficient_portf1)\n",
    "print(efficient_portf1_w)\n",
    "print(efficient_portf2)\n",
    "print(efficient_portf2_w)\n",
    "\n",
    "weight_longonly= efficient_portf1_w\n",
    "weight_longonly_conc= efficient_portf2_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>2.376238e-01</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>0.177851</td>\n",
       "      <td>1.187341e-01</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>0.105874</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly</th>\n",
       "      <td>0.576959</td>\n",
       "      <td>0.392526</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>3.552456e-18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly_conc</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.178279</td>\n",
       "      <td>1.696141e-01</td>\n",
       "      <td>3.210163e-17</td>\n",
       "      <td>0.029330</td>\n",
       "      <td>0.022777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             US_RE     US_PE     US_HY         SP500  \\\n",
       "weight_eq                 0.142857  0.142857  0.142857  1.428571e-01   \n",
       "weight_peer               0.138614  0.287129  0.049505  2.376238e-01   \n",
       "weight_erc                0.282415  0.142979  0.177851  1.187341e-01   \n",
       "CMA_weight_longonly       0.576959  0.392526  0.015887  3.552456e-18   \n",
       "CMA_weight_longonly_conc  0.300000  0.300000  0.178279  1.696141e-01   \n",
       "\n",
       "                            Rusell2000      EAFE        EM  \n",
       "weight_eq                 1.428571e-01  0.142857  0.142857  \n",
       "weight_peer               2.970297e-02  0.207921  0.049505  \n",
       "weight_erc                9.272408e-02  0.105874  0.079423  \n",
       "CMA_weight_longonly       0.000000e+00  0.000000  0.014629  \n",
       "CMA_weight_longonly_conc  3.210163e-17  0.029330  0.022777  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_2= pd.DataFrame([efficient_portf1_w, efficient_portf2_w], \n",
    "                             index=['CMA_weight_longonly', 'CMA_weight_longonly_conc'], columns=LW_cov.columns)\n",
    "pd.concat([portf_weight_1, portf_weight_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.019479826007340877\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018450266469870222\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01747522085701578\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016576791911206225\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.01573940249981361\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n"
     ]
    }
   ],
   "source": [
    "## risk adj return optimal long only portfolio with CMA expected ret\n",
    "\n",
    "\n",
    "def obj_func_CMA(w, ARGS):  # ARGS= [sigma, ExpRet, gamma]\n",
    "    return (np.dot(  np.dot( w, ARGS[0]), w)* .5* ARGS[2]- np.dot( ARGS[1], w))\n",
    "\n",
    "def obj_func_derivative_CMA( w, ARGS): \n",
    "    return (np.dot( w, ARGS[0])* ARGS[2]- ARGS[1])\n",
    "\n",
    "\n",
    "cons_eq0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "# cons_ineq0= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[0]-w[1]+ 0.5, \n",
    "#              'jac': lambda w: np.array([-1]*2+ [0]*10)}\n",
    "# cons_ineq1= {'type': 'ineq',\n",
    "#              'fun': lambda w: -w[2]-w[3]-w[4]-w[5]-w[6]+ 0.5,\n",
    "#              'jac': lambda w: np.array([0]*2+ [-1]*5+ [0]*5)}\n",
    "# cons_ineq2= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[7]-w[8]-w[9]-w[10]+ 0.5, \n",
    "#              'jac': lambda w: np.array([0]*7+ [-1]*4+ [0])}\n",
    "# cons_ineq3= {'type': 'ineq', \n",
    "#             'fun': lambda w: -w[11]+ 0.5,\n",
    "#             'jac': lambda w: np.array( [0]*11+ [-1])}\n",
    "\n",
    "\n",
    "CMA_riskAdj_opt={}\n",
    "\n",
    "for g in [2,2.5,3,3.5,4]: \n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          )\n",
    "\n",
    "    MV_opt= minimize( obj_func_CMA, \n",
    "                    x0= weight_eq, \n",
    "                    args= [LW_cov, CMA_ExpRet_arith, g], \n",
    "                    jac= obj_func_derivative_CMA ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    #bounds= [[0, 0.25]]+[[0, .4]]+[[0,None]]* (N-2),\n",
    "                    bounds= [[0,0.3]]* (N),\n",
    "                    tol= 1e-12)\n",
    "    \n",
    "    CMA_riskAdj_opt[g]= MV_opt.x\n",
    "    \n",
    "CMA_riskAdj_portf_w= pd.DataFrame( CMA_riskAdj_opt, index=LW_cov.columns).T\n",
    "CMA_riskAdj_portf_w.index= ['weight_CMA_MVO_gamma_'+str(x) for x in CMA_riskAdj_portf_w.index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_2.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180607</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.219393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_2.5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.140117e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>3.856257e-17</td>\n",
       "      <td>0.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_3.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.075994</td>\n",
       "      <td>0.161141</td>\n",
       "      <td>1.837060e-02</td>\n",
       "      <td>0.144495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_3.5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.898587e-17</td>\n",
       "      <td>0.140589</td>\n",
       "      <td>0.113584</td>\n",
       "      <td>3.005979e-02</td>\n",
       "      <td>0.115767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_4.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.582843e-02</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.077544</td>\n",
       "      <td>3.237553e-02</td>\n",
       "      <td>0.092089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          US_RE  US_PE         US_HY     SP500  Rusell2000  \\\n",
       "weight_CMA_MVO_gamma_2.0    0.3    0.3  0.000000e+00  0.000000    0.180607   \n",
       "weight_CMA_MVO_gamma_2.5    0.3    0.3  9.140117e-17  0.000000    0.216500   \n",
       "weight_CMA_MVO_gamma_3.0    0.3    0.3  0.000000e+00  0.075994    0.161141   \n",
       "weight_CMA_MVO_gamma_3.5    0.3    0.3  6.898587e-17  0.140589    0.113584   \n",
       "weight_CMA_MVO_gamma_4.0    0.3    0.3  3.582843e-02  0.162162    0.077544   \n",
       "\n",
       "                                  EAFE        EM  \n",
       "weight_CMA_MVO_gamma_2.0  0.000000e+00  0.219393  \n",
       "weight_CMA_MVO_gamma_2.5  3.856257e-17  0.183500  \n",
       "weight_CMA_MVO_gamma_3.0  1.837060e-02  0.144495  \n",
       "weight_CMA_MVO_gamma_3.5  3.005979e-02  0.115767  \n",
       "weight_CMA_MVO_gamma_4.0  3.237553e-02  0.092089  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMA_riskAdj_portf_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Introducing active management\n",
    "# Apply active management to Equity (SP500, Rusell2000, EAFE and EM), \n",
    "# assuming IR of 1/3 and active alpha 1% and hence tracking error 3%, both annualized \n",
    "\n",
    "\n",
    "LW_vol= np.sqrt(np.diag(LW_cov))\n",
    "LW_corr= pd.DataFrame(np.dot(np.dot(np.diag(1/LW_vol), LW_cov), np.diag(1/LW_vol)), columns= LW_cov.columns, index=LW_cov.index)\n",
    "LW_cov_active= pd.DataFrame(LW_cov+ np.diag( np.array([0, 0, 0.0009/4, 0.0009/4, 0.0009/4, 0.0009/4, 0.0009/4])),\n",
    "                           index= LW_cov.index,\n",
    "                           columns= LW_cov.columns)\n",
    "LW_vol_active= np.sqrt(np.diag(LW_cov_active))\n",
    "\n",
    "CMA_ExpRet_active_geo= CMA_ExpRet_geo+ np.array([0,0,0.0075/4, 0.01/4, 0.01/4, 0.01/4, 0.01/4])\n",
    "CMA_ExpRet_active_arith= CMA_ExpRet_arith+ np.array( [0,0,0.0075/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4 ])\n",
    "\n",
    "LW_corr_active= pd.DataFrame(np.dot(np.dot(np.diag(1/LW_vol_active), LW_cov_active), np.diag(1/LW_vol_active)), \n",
    "                            index= LW_cov_active.index,\n",
    "                            columns= LW_cov_active.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0013135738490619268\n",
      "            Iterations: 101\n",
      "            Function evaluations: 887\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00203450400479991\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491830916\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019270247034073812\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491836975\n",
      "            Iterations: 34\n",
      "            Function evaluations: 244\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001825409268465486\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491829797\n",
      "            Iterations: 34\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017296576999742193\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491848808\n",
      "            Iterations: 39\n",
      "            Function evaluations: 287\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016397699979335825\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491820723\n",
      "            Iterations: 17\n",
      "            Function evaluations: 123\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015557461623435674\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491840327\n",
      "            Iterations: 53\n",
      "            Function evaluations: 363\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001477586193204187\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.0013135738491804054\n",
      "            Iterations: 77\n",
      "            Function evaluations: 771\n",
      "            Gradient evaluations: 73\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001405290090515434\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0013135738491045947\n",
      "            Iterations: 101\n",
      "            Function evaluations: 977\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013388578542773118\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491828637\n",
      "            Iterations: 31\n",
      "            Function evaluations: 190\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012782894844898182\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001313573849181895\n",
      "            Iterations: 33\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012235849811529573\n",
      "            Iterations: 4\n",
      "            Function evaluations: 4\n",
      "            Gradient evaluations: 4\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.0013135738491805715\n",
      "            Iterations: 91\n",
      "            Function evaluations: 865\n",
      "            Gradient evaluations: 87\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011747443442667227\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491827694\n",
      "            Iterations: 18\n",
      "            Function evaluations: 120\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001131767573831116\n",
      "            Iterations: 8\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 8\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491818468\n",
      "            Iterations: 51\n",
      "            Function evaluations: 394\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00109465466984614\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491827941\n",
      "            Iterations: 72\n",
      "            Function evaluations: 543\n",
      "            Gradient evaluations: 68\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010634056323117933\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491837673\n",
      "            Iterations: 22\n",
      "            Function evaluations: 117\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010380204612280759\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0013135738491839937\n",
      "            Iterations: 101\n",
      "            Function evaluations: 885\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001018499156594987\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491832738\n",
      "            Iterations: 51\n",
      "            Function evaluations: 492\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010048417184125278\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.0013135738491809015\n",
      "            Iterations: 72\n",
      "            Function evaluations: 653\n",
      "            Gradient evaluations: 71\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009956175273665249\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001313573849183454\n",
      "            Iterations: 96\n",
      "            Function evaluations: 946\n",
      "            Gradient evaluations: 92\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009872033104458002\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0013135738491824658\n",
      "            Iterations: 101\n",
      "            Function evaluations: 917\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009794216461944283\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491838794\n",
      "            Iterations: 26\n",
      "            Function evaluations: 198\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00097227253461241\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0013135738491825912\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1006\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009657559756997469\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.0013135738491839488\n",
      "            Iterations: 65\n",
      "            Function evaluations: 545\n",
      "            Gradient evaluations: 61\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009598719694564365\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491821167\n",
      "            Iterations: 91\n",
      "            Function evaluations: 829\n",
      "            Gradient evaluations: 87\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009546205158824798\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001313573849182644\n",
      "            Iterations: 68\n",
      "            Function evaluations: 594\n",
      "            Gradient evaluations: 64\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009500016149778766\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491835893\n",
      "            Iterations: 97\n",
      "            Function evaluations: 961\n",
      "            Gradient evaluations: 93\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000946015266742628\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0013135738491198243\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1020\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009426614711767328\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491828611\n",
      "            Iterations: 60\n",
      "            Function evaluations: 455\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000939940228280191\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491821993\n",
      "            Iterations: 78\n",
      "            Function evaluations: 691\n",
      "            Gradient evaluations: 74\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009378515380530034\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.001313573849172421\n",
      "            Iterations: 101\n",
      "            Function evaluations: 944\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009363954004951694\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.0013135738491819881\n",
      "            Iterations: 66\n",
      "            Function evaluations: 638\n",
      "            Gradient evaluations: 62\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009355718156066891\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491833822\n",
      "            Iterations: 49\n",
      "            Function evaluations: 458\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009353807833875627\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491835093\n",
      "            Iterations: 7\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 3\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009358223038377897\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.001313573849182632\n",
      "            Iterations: 101\n",
      "            Function evaluations: 902\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009368963769573709\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001313573849182695\n",
      "            Iterations: 48\n",
      "            Function evaluations: 450\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009385815753450033\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001313573849182847\n",
      "            Iterations: 48\n",
      "            Function evaluations: 375\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009408331707666472\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491826766\n",
      "            Iterations: 38\n",
      "            Function evaluations: 303\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009436497640688626\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0013135738483257007\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1027\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009470313552516489\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0013135738490757222\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1010\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009509779443150061\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013135738491830665\n",
      "            Iterations: 10\n",
      "            Function evaluations: 42\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000955489531258935\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.001313573848817096\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1032\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009605661160834349\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0013135738490027244\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1065\n",
      "            Gradient evaluations: 100\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009662076987885058\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011580981138310062\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009724131337879411\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011242249076671251\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000979165192282414\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011244936773335365\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009864580903579045\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011305186505035656\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009942918270056259\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011372379258151814\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010026664033539064\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011446515032683849\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010115818187027424\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011527593828631773\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010209813183700163\n",
      "            Iterations: 35\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011615615645995563\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010307774933364215\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011710580484775232\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010409693727997619\n",
      "            Iterations: 35\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011812488344970773\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010515569567509464\n",
      "            Iterations: 34\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001192130858801228\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010625402452725838\n",
      "            Iterations: 37\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012035423667905599\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010739192383272319\n",
      "            Iterations: 37\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012153916997401657\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001085693935915883\n",
      "            Iterations: 39\n",
      "            Function evaluations: 39\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012276788572523557\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010978643380564956\n",
      "            Iterations: 39\n",
      "            Function evaluations: 39\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Current function value: 0.0012404038396816404\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011104304447761314\n",
      "            Iterations: 38\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012535666469616282\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011233922560539874\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001267167279062318\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011367497715666568\n",
      "            Iterations: 29\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012812056499326933\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011505029917916816\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001295650959046059\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011646519165622613\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013104783532232934\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011792040566660689\n",
      "            Iterations: 35\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001325687832185648\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011943354549772058\n",
      "            Iterations: 39\n",
      "            Function evaluations: 39\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001341279395933122\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012101180270822204\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013572530444657138\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012265514906779137\n",
      "            Iterations: 39\n",
      "            Function evaluations: 39\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013736088971321105\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012436361279606343\n",
      "            Iterations: 37\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013903466258121276\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012613718448378644\n",
      "            Iterations: 36\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014074664987744848\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012797586417448515\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014249685170614975\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012987965174511475\n",
      "            Iterations: 34\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014428526815591512\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013184854737463179\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014611187161487754\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001338825508508012\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014797669581772038\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013598166234599798\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014987972849907498\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0013814588180257811\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001518209696589417\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014037558444904652\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015380041929732029\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014267625683672797\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015581807741421078\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014505076827128315\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001578739440096133\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014749911875246889\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015996801908352758\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015002130828028477\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016210030263595387\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015261733685473086\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016427079467017387\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015528720447580747\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016647949517678748\n",
      "            Iterations: 33\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015803091114351432\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001687264041643044\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016084845685785142\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017104131509129738\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016373984161881902\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00173460820192825\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001667050654264168\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017598501376401422\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001697441282806449\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00178613895804865\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017285703018150344\n",
      "            Iterations: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001813474663153773\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001760437711289922\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018418572529555095\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017930435112311156\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.001871286727453861\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018263877016386112\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019017630866488304\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018604702825124066\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019332863305404143\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0018952912538525092\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019658564591286103\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019308506156589145\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019994734724134797\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019671483679316194\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020341373703948525\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020041845106706325\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020709441958156704\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020419590438759475\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021104160512741147\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020804719675475624\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021506419027444946\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002119723281685484\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021916217500325586\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002159712986289708\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002233355593138307\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.002200441081360236\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n"
     ]
    }
   ],
   "source": [
    "## Fronter Construction with active management\n",
    "\n",
    "\n",
    "\n",
    "fronter1_active_w= {}\n",
    "fronter1_active_vol= {}\n",
    "fronter2_active_w= {}\n",
    "fronter2_active_vol= {}\n",
    "\n",
    "for target_ret in np.linspace(0.065, 0.1, 100 ): \n",
    "    cons_ineq4_active= {'type': 'eq', \n",
    "                'fun': lambda w: -np.dot(w, CMA_ExpRet_active_arith*4)+ target_ret,\n",
    "                'jac': lambda w: -CMA_ExpRet_active_arith*4}\n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          , cons_ineq4_active\n",
    "          )\n",
    "\n",
    "    MV_active_opt_2= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov_active, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    #bounds= [[0,0.25]]+[[0, 0.4]]+[[0,None]]* (N-2),\n",
    "                    bounds= [[0,0.3]]* (N),\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "\n",
    "    MV_active_opt_1= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov_active, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None]]* N,\n",
    "                    tol= 1e-12)  # long only constrain\n",
    "    \n",
    "    fronter1_active_w[target_ret]= MV_active_opt_1.x\n",
    "    fronter1_active_vol[target_ret]= np.sqrt(MV_active_opt_1.fun*2) \n",
    "    \n",
    "    fronter2_active_w[target_ret]= MV_active_opt_2.x\n",
    "    fronter2_active_vol[target_ret]= np.sqrt(MV_active_opt_2.fun*2)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.084343434343434345, 0.047081945661880828)\n",
      "[  5.76958650e-01   3.92525584e-01   1.58869429e-02   3.55245618e-18\n",
      "   0.00000000e+00   0.00000000e+00   1.46288226e-02]\n",
      "(0.081313131313131309, 0.049596874650441922)\n",
      "[  3.00000000e-01   3.00000000e-01   1.78278771e-01   1.69614120e-01\n",
      "   3.21016288e-17   2.93300999e-02   2.27770094e-02]\n",
      "(0.084090909090909091, 0.046344778310554724)\n",
      "[  5.39163618e-01   3.12269699e-01   5.54793646e-02   5.79459741e-02\n",
      "   1.00669866e-18   1.39161193e-02   2.12252243e-02]\n",
      "(0.085151515151515159, 0.049807707027761085)\n",
      "[  3.00000000e-01   3.00000000e-01   1.71646197e-01   1.70585862e-01\n",
      "   9.28253620e-18   3.95984112e-02   1.81695300e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAAJOCAYAAAA3eodTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niwAAAADYYlgEAAAAwBbDIgAAAAC2/P+4TebypR+8jQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc2afe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fronter_1= list( fronter1_vol.items())\n",
    "fronter_1.sort( key=lambda x: x[1])\n",
    "minvar_portf1= fronter_1[0]\n",
    "minvar_portf1_w= fronter1_w[minvar_portf1[0]]\n",
    "fronter_1.sort( key= lambda x: (x[0]- rf)/ x[1], reverse=True)\n",
    "efficient_portf1= fronter_1[0]\n",
    "efficient_portf1_w= fronter1_w[efficient_portf1[0]]\n",
    "\n",
    "fronter_2= list(fronter2_vol.items())\n",
    "fronter_2.sort(key= lambda x: x[1])\n",
    "minvar_portf2= fronter_2[0]\n",
    "minvar_portf2_w= fronter2_w[minvar_portf2[0]]\n",
    "fronter_2.sort(key= lambda x: (x[0]-rf)/x[1], reverse= True)\n",
    "efficient_portf2= fronter_2[0]\n",
    "efficient_portf2_w= fronter2_w[efficient_portf2[0]]\n",
    "\n",
    "fronter_active_1= list( fronter1_active_vol.items())\n",
    "fronter_active_1.sort(key= lambda x: x[1])\n",
    "minvar_active_portf1= fronter_active_1[0]\n",
    "minvar_active_portf1_w= fronter1_active_w[minvar_active_portf1[0]]\n",
    "fronter_active_1.sort(key= lambda x: (x[0]-rf)/x[1], reverse =True)\n",
    "efficient_portf1_active= fronter_active_1[0]\n",
    "efficient_portf1_active_w= fronter1_active_w[efficient_portf1_active[0]]\n",
    "\n",
    "\n",
    "fronter_active_2= list( fronter2_active_vol.items())\n",
    "fronter_active_2.sort( key= lambda x: x[1])\n",
    "minvar_active_portf2= fronter_active_2[0]\n",
    "minvar_active_portf2_w= fronter2_active_w[ minvar_active_portf2[0]]\n",
    "fronter_active_2.sort(key= lambda x: (x[0]-rf)/x[1], reverse= True)\n",
    "efficient_portf2_active= fronter_active_2[0]\n",
    "efficient_portf2_active_w= fronter2_active_w[efficient_portf2_active[0]]\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize= (20,10))\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip( * list( fronter1_vol.items())) \n",
    "plt.scatter(x= tmp_vol, y= tmp_ret, marker=\".\", c= 'pink' , label= 'CMA:long only')\n",
    "plt.scatter(x= minvar_portf1[1], y= minvar_portf1[0], marker= 'o', c='pink', s= 100 )\n",
    "plt.scatter(x= efficient_portf1[1], y = efficient_portf1[0], marker= '*', c='pink', s=200)\n",
    "# plt.plot( [0.04, efficient_portf1[1]], [ (efficient_portf1[0]-rf)/efficient_portf1[1]* 0.04+rf, efficient_portf1[0]], \n",
    "#          linestyle='-', c='pink')\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip(* list(fronter2_vol.items()))\n",
    "plt.scatter( x= tmp_vol, y= tmp_ret, marker= '.', c='blue', label= 'CMA:long only+ concentration constrain')\n",
    "plt.scatter( x= minvar_portf2[1], y=minvar_portf2[0], marker= 'o', c= 'blue', s=100)\n",
    "plt.scatter(x= efficient_portf2[1], y = efficient_portf2[0], marker= '*', c='blue', s=200)\n",
    "# plt.plot( [0.04, efficient_portf2[1]], [ (efficient_portf2[0]-rf)/efficient_portf2[1]* 0.04+rf, efficient_portf2[0]], \n",
    "#          linestyle= '-', c= 'blue')\n",
    "\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip( * list( fronter1_active_vol.items())) \n",
    "plt.scatter(x= tmp_vol, y= tmp_ret, marker=\".\", c= 'orange' , label= 'CMA_active:long only')\n",
    "plt.scatter(x= minvar_active_portf1[1], y= minvar_active_portf1[0], marker= 'o', c='orange', s= 100 )\n",
    "plt.scatter(x= efficient_portf1_active[1], y = efficient_portf1_active[0], marker= '*', c='orange', s=200)\n",
    "# plt.plot( [0.04, efficient_portf1_active[1]], [ (efficient_portf1_active[0]-rf)/efficient_portf1_active[1]* 0.04+rf, efficient_portf1_active[0]], \n",
    "#          linestyle='-', c='orange')\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip(* list(fronter2_active_vol.items()))\n",
    "plt.scatter( x= tmp_vol, y= tmp_ret, marker= '.', c='red', label= 'CMA_active:long only+ concentration constrain')\n",
    "plt.scatter( x= minvar_active_portf2[1], y=minvar_active_portf2[0], marker= 'o', c= 'red', s=100)\n",
    "plt.scatter(x= efficient_portf2_active[1], y = efficient_portf2_active[0], marker= '*', c='red', s=200)\n",
    "# plt.plot( [0.04, efficient_portf2_active[1]], [ (efficient_portf2_active[0]-rf)/efficient_portf2_active[1]* 0.04+rf, efficient_portf2_active[0]], \n",
    "#          linestyle= '-', c='red')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Efficient Fronter')\n",
    "\n",
    "print(efficient_portf1)\n",
    "print(efficient_portf1_w)\n",
    "print(efficient_portf2)\n",
    "print(efficient_portf2_w)\n",
    "print(efficient_portf1_active)\n",
    "print(efficient_portf1_active_w)\n",
    "print(efficient_portf2_active)\n",
    "print(efficient_portf2_active_w)\n",
    "\n",
    "weight_longonly= efficient_portf1_w\n",
    "weight_longonly_conc= efficient_portf2_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>2.376238e-01</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>0.177851</td>\n",
       "      <td>1.187341e-01</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>0.105874</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly</th>\n",
       "      <td>0.576959</td>\n",
       "      <td>0.392526</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>3.552456e-18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly_conc</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.178279</td>\n",
       "      <td>1.696141e-01</td>\n",
       "      <td>3.210163e-17</td>\n",
       "      <td>0.029330</td>\n",
       "      <td>0.022777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active_weight_longonly</th>\n",
       "      <td>0.539164</td>\n",
       "      <td>0.312270</td>\n",
       "      <td>0.055479</td>\n",
       "      <td>5.794597e-02</td>\n",
       "      <td>1.006699e-18</td>\n",
       "      <td>0.013916</td>\n",
       "      <td>0.021225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active_weight_longonly_conc</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.171646</td>\n",
       "      <td>1.705859e-01</td>\n",
       "      <td>9.282536e-18</td>\n",
       "      <td>0.039598</td>\n",
       "      <td>0.018170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    US_RE     US_PE     US_HY         SP500  \\\n",
       "weight_eq                        0.142857  0.142857  0.142857  1.428571e-01   \n",
       "weight_peer                      0.138614  0.287129  0.049505  2.376238e-01   \n",
       "weight_erc                       0.282415  0.142979  0.177851  1.187341e-01   \n",
       "CMA_weight_longonly              0.576959  0.392526  0.015887  3.552456e-18   \n",
       "CMA_weight_longonly_conc         0.300000  0.300000  0.178279  1.696141e-01   \n",
       "CMA_active_weight_longonly       0.539164  0.312270  0.055479  5.794597e-02   \n",
       "CMA_active_weight_longonly_conc  0.300000  0.300000  0.171646  1.705859e-01   \n",
       "\n",
       "                                   Rusell2000      EAFE        EM  \n",
       "weight_eq                        1.428571e-01  0.142857  0.142857  \n",
       "weight_peer                      2.970297e-02  0.207921  0.049505  \n",
       "weight_erc                       9.272408e-02  0.105874  0.079423  \n",
       "CMA_weight_longonly              0.000000e+00  0.000000  0.014629  \n",
       "CMA_weight_longonly_conc         3.210163e-17  0.029330  0.022777  \n",
       "CMA_active_weight_longonly       1.006699e-18  0.013916  0.021225  \n",
       "CMA_active_weight_longonly_conc  9.282536e-18  0.039598  0.018170  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_3= pd.DataFrame( [efficient_portf1_active_w, efficient_portf2_active_w],\n",
    "                            index= ['CMA_active_weight_longonly', 'CMA_active_weight_longonly_conc'], \n",
    "                            columns= LW_cov.columns)\n",
    "\n",
    "pd.concat([portf_weight_1, portf_weight_2, portf_weight_3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018502647757496642\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.018673727872844652\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017603590448697876\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017893465271042158\n",
      "            Iterations: 36\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016750084655004403\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017176235037675097\n",
      "            Iterations: 38\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_CMAactive_MVO_gamma_3.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078008</td>\n",
       "      <td>0.155415</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>0.143006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMAactive_MVO_gamma_3.5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133980</td>\n",
       "      <td>0.114633</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>0.114561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMAactive_MVO_gamma_4.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.168906</td>\n",
       "      <td>0.083499</td>\n",
       "      <td>0.044666</td>\n",
       "      <td>0.092601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                US_RE  US_PE     US_HY     SP500  Rusell2000  \\\n",
       "weight_CMAactive_MVO_gamma_3.0    0.3    0.3  0.000000  0.078008    0.155415   \n",
       "weight_CMAactive_MVO_gamma_3.5    0.3    0.3  0.000000  0.133980    0.114633   \n",
       "weight_CMAactive_MVO_gamma_4.0    0.3    0.3  0.010328  0.168906    0.083499   \n",
       "\n",
       "                                    EAFE        EM  \n",
       "weight_CMAactive_MVO_gamma_3.0  0.023572  0.143006  \n",
       "weight_CMAactive_MVO_gamma_3.5  0.036827  0.114561  \n",
       "weight_CMAactive_MVO_gamma_4.0  0.044666  0.092601  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Risk adj return utility constrained optimal with active management \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def obj_func_CMAactive(w, ARGS):  # ARGS= [sigma, ExpRet, gamma]\n",
    "    return (np.dot(  np.dot( w, ARGS[0]), w)* .5* ARGS[2]- np.dot( ARGS[1], w))\n",
    "\n",
    "def obj_func_derivative_CMAactive( w, ARGS): \n",
    "    return (np.dot( w, ARGS[0])* ARGS[2]- ARGS[1])\n",
    "\n",
    "\n",
    "cons_eq0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "# cons_ineq0= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[0]-w[1]+ 0.5, \n",
    "#              'jac': lambda w: np.array([-1]*2+ [0]*10)}\n",
    "# cons_ineq1= {'type': 'ineq',\n",
    "#              'fun': lambda w: -w[2]-w[3]-w[4]-w[5]-w[6]+ 0.5,\n",
    "#              'jac': lambda w: np.array([0]*2+ [-1]*5+ [0]*5)}\n",
    "# cons_ineq2= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[7]-w[8]-w[9]-w[10]+ 0.5, \n",
    "#              'jac': lambda w: np.array([0]*7+ [-1]*4+ [0])}\n",
    "# cons_ineq3= {'type': 'ineq', \n",
    "#             'fun': lambda w: -w[11]+ 0.5,\n",
    "#             'jac': lambda w: np.array( [0]*11+ [-1])}\n",
    "\n",
    "\n",
    "CMAactive_riskAdj_opt={}\n",
    "CMAactive_riskAdj_opt2={}\n",
    "for g in [3,3.5,4]: \n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          )\n",
    "\n",
    "    MV_opt= minimize( obj_func_CMAactive, \n",
    "                    x0= weight_eq, \n",
    "                    args= [LW_cov_active, CMA_ExpRet_active_arith, g], \n",
    "                    jac= obj_func_derivative_CMAactive ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    #bounds= [[0, 0.25]]+[[0, .4]]+[[0,None]]* (N-2),\n",
    "                    bounds= [[0,0.3]]* (N),\n",
    "                    tol= 1e-12)\n",
    "\n",
    "    MV_opt2= minimize( obj_func_CMAactive, \n",
    "                    x0= weight_eq, \n",
    "                    args= [LW_cov_active, CMA_ExpRet_active_arith, g], \n",
    "                    jac= obj_func_derivative_CMAactive ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,None]]* N,\n",
    "                    tol= 1e-12)\n",
    "    \n",
    "    CMAactive_riskAdj_opt[g]= MV_opt.x\n",
    "    CMAactive_riskAdj_opt2[g]= MV_opt2.x\n",
    "    \n",
    "CMAactive_riskAdj_portf_w= pd.DataFrame( CMAactive_riskAdj_opt, index=LW_cov_active.columns).T\n",
    "CMAactive_riskAdj_portf_w.index= ['weight_CMAactive_MVO_gamma_'+str(x) for x in CMAactive_riskAdj_portf_w.index]\n",
    "CMAactive_riskAdj_portf_w2= pd.DataFrame( CMAactive_riskAdj_opt2, index= LW_cov_active.columns).T\n",
    "CMAactive_riskAdj_portf_w2.index= ['weight_CMAactive_MVO_gamma_'+str(x)+'uncons' for x in CMAactive_riskAdj_portf_w.index]\n",
    "CMAactive_riskAdj_portf_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  #pd.DataFrame(CMAactive_riskAdj_opt[2],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>4.950495e-02</td>\n",
       "      <td>2.376238e-01</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>2.079208e-01</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>1.778511e-01</td>\n",
       "      <td>1.187341e-01</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>1.058735e-01</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_1</th>\n",
       "      <td>0.576959</td>\n",
       "      <td>0.392526</td>\n",
       "      <td>1.588694e-02</td>\n",
       "      <td>3.552456e-18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_2</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.782788e-01</td>\n",
       "      <td>1.696141e-01</td>\n",
       "      <td>3.210163e-17</td>\n",
       "      <td>2.933010e-02</td>\n",
       "      <td>0.022777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.599354e-02</td>\n",
       "      <td>1.611408e-01</td>\n",
       "      <td>1.837060e-02</td>\n",
       "      <td>0.144495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>6.898587e-17</td>\n",
       "      <td>1.405892e-01</td>\n",
       "      <td>1.135842e-01</td>\n",
       "      <td>3.005979e-02</td>\n",
       "      <td>0.115767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_4</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3.582843e-02</td>\n",
       "      <td>1.621623e-01</td>\n",
       "      <td>7.754428e-02</td>\n",
       "      <td>3.237553e-02</td>\n",
       "      <td>0.092089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_1</th>\n",
       "      <td>0.539164</td>\n",
       "      <td>0.312270</td>\n",
       "      <td>5.547936e-02</td>\n",
       "      <td>5.794597e-02</td>\n",
       "      <td>1.006699e-18</td>\n",
       "      <td>1.391612e-02</td>\n",
       "      <td>0.021225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_2</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.716462e-01</td>\n",
       "      <td>1.705859e-01</td>\n",
       "      <td>9.282536e-18</td>\n",
       "      <td>3.959841e-02</td>\n",
       "      <td>0.018170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.800752e-02</td>\n",
       "      <td>1.554151e-01</td>\n",
       "      <td>2.357154e-02</td>\n",
       "      <td>0.143006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.339801e-01</td>\n",
       "      <td>1.146326e-01</td>\n",
       "      <td>3.682659e-02</td>\n",
       "      <td>0.114561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.032750e-02</td>\n",
       "      <td>1.689064e-01</td>\n",
       "      <td>8.349900e-02</td>\n",
       "      <td>4.466580e-02</td>\n",
       "      <td>0.092601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3unc</th>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.410367</td>\n",
       "      <td>1.991798e-17</td>\n",
       "      <td>1.677506e-17</td>\n",
       "      <td>1.032986e-01</td>\n",
       "      <td>1.629310e-17</td>\n",
       "      <td>0.131823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5unc</th>\n",
       "      <td>0.408589</td>\n",
       "      <td>0.397578</td>\n",
       "      <td>2.015557e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.344910e-02</td>\n",
       "      <td>1.848988e-17</td>\n",
       "      <td>0.110384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4unc</th>\n",
       "      <td>0.448397</td>\n",
       "      <td>0.386824</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.910225e-03</td>\n",
       "      <td>6.679204e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.094077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE         US_HY         SP500    Rusell2000  \\\n",
       "w_eq           0.142857  0.142857  1.428571e-01  1.428571e-01  1.428571e-01   \n",
       "w_peer         0.138614  0.287129  4.950495e-02  2.376238e-01  2.970297e-02   \n",
       "w_erc          0.282415  0.142979  1.778511e-01  1.187341e-01  9.272408e-02   \n",
       "w_MVO_1        0.576959  0.392526  1.588694e-02  3.552456e-18  0.000000e+00   \n",
       "w_MVO_2        0.300000  0.300000  1.782788e-01  1.696141e-01  3.210163e-17   \n",
       "w_RUO_3        0.300000  0.300000  0.000000e+00  7.599354e-02  1.611408e-01   \n",
       "w_RUO_3.5      0.300000  0.300000  6.898587e-17  1.405892e-01  1.135842e-01   \n",
       "w_RUO_4        0.300000  0.300000  3.582843e-02  1.621623e-01  7.754428e-02   \n",
       "w_aMVO_1       0.539164  0.312270  5.547936e-02  5.794597e-02  1.006699e-18   \n",
       "w_aMVO_2       0.300000  0.300000  1.716462e-01  1.705859e-01  9.282536e-18   \n",
       "w_aRUO_3       0.300000  0.300000  0.000000e+00  7.800752e-02  1.554151e-01   \n",
       "w_aRUO_3.5     0.300000  0.300000  0.000000e+00  1.339801e-01  1.146326e-01   \n",
       "w_aRUO_4       0.300000  0.300000  1.032750e-02  1.689064e-01  8.349900e-02   \n",
       "w_aRUO_3unc    0.354512  0.410367  1.991798e-17  1.677506e-17  1.032986e-01   \n",
       "w_aRUO_3.5unc  0.408589  0.397578  2.015557e-17  0.000000e+00  8.344910e-02   \n",
       "w_aRUO_4unc    0.448397  0.386824  0.000000e+00  3.910225e-03  6.679204e-02   \n",
       "\n",
       "                       EAFE        EM  \n",
       "w_eq           1.428571e-01  0.142857  \n",
       "w_peer         2.079208e-01  0.049505  \n",
       "w_erc          1.058735e-01  0.079423  \n",
       "w_MVO_1        0.000000e+00  0.014629  \n",
       "w_MVO_2        2.933010e-02  0.022777  \n",
       "w_RUO_3        1.837060e-02  0.144495  \n",
       "w_RUO_3.5      3.005979e-02  0.115767  \n",
       "w_RUO_4        3.237553e-02  0.092089  \n",
       "w_aMVO_1       1.391612e-02  0.021225  \n",
       "w_aMVO_2       3.959841e-02  0.018170  \n",
       "w_aRUO_3       2.357154e-02  0.143006  \n",
       "w_aRUO_3.5     3.682659e-02  0.114561  \n",
       "w_aRUO_4       4.466580e-02  0.092601  \n",
       "w_aRUO_3unc    1.629310e-17  0.131823  \n",
       "w_aRUO_3.5unc  1.848988e-17  0.110384  \n",
       "w_aRUO_4unc    0.000000e+00  0.094077  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight= pd.concat( [portf_weight_1, \n",
    "                          portf_weight_2, \n",
    "                          CMA_riskAdj_portf_w.iloc[ -3:] ,\n",
    "                          portf_weight_3, \n",
    "                          CMAactive_riskAdj_portf_w,\n",
    "                         CMAactive_riskAdj_portf_w2], axis= 0 )\n",
    "portf_weight.index= ['w_eq', # equal weight \n",
    "                    'w_peer', # peer weight\n",
    "                    'w_erc', # equal risk contribution weight \n",
    "                    'w_MVO_1', # mean-variance optimal weight with long only constrain\n",
    "                    'w_MVO_2', # mean-variance optimal weight with long only+ concentration constrain\n",
    "                    'w_RUO_3', # risk adj utility optimal weight with long only+ concentration constrain, give risk aversion 3 \n",
    "                    'w_RUO_3.5', # risk adj utility optimal weight with long only+ concentration constrain, given risk aversion 3.5\n",
    "                    'w_RUO_4', # risk adj utility optimal weight with long only+ concentration constrain, give risk aversion 4\n",
    "                    'w_aMVO_1', # mean-variance optimal weight with long only constrain, and active management \n",
    "                    'w_aMVO_2', # mean-variance optimal weight with long only+ concentration constrain, and active management \n",
    "                    'w_aRUO_3', # risk adj utility optimal weight with long only+ concentration constrain, and active management, give risk aversion 3 \n",
    "                    'w_aRUO_3.5', # risk adj utility optimal weight with long only+ concentration constrain, and active management, give risk aversion 3.5 \n",
    "                    'w_aRUO_4', # risk adj utility optimal weight with long only+ concentration constrain, and active management, give risk aversion 4\n",
    "                    'w_aRUO_3unc',\n",
    "                    'w_aRUO_3.5unc',\n",
    "                    'w_aRUO_4unc'] \n",
    "portf_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3</th>\n",
       "      <td>2.946497</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.975123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3.5</th>\n",
       "      <td>3.223899</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>8.370075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_4</th>\n",
       "      <td>3.501302</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>9.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3</th>\n",
       "      <td>2.875835</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>5.785744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.141460</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3</th>\n",
       "      <td>3.116898</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.129680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3.5</th>\n",
       "      <td>3.422701</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.217058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_4</th>\n",
       "      <td>3.728504</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>4.770000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>8.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_eq_3      2.946497  5.112730  4.197299  5.940288    6.745272  6.198200   \n",
       "iRet_eq_3.5    3.223899  5.834154  4.742391  6.827058    7.894844  7.209535   \n",
       "iRet_eq_4      3.501302  6.555578  5.287484  7.713828    9.044416  8.220869   \n",
       "iRet_peer_3    2.875835  5.296642  3.655122  5.827752    6.117100  6.102522   \n",
       "iRet_peer_3.5  3.141460  6.048718  4.109852  6.695766    7.161977  7.097910   \n",
       "iRet_peer_4    3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "iRet_erc_3     3.116898  4.408355  3.840304  4.983875    5.436244  5.024522   \n",
       "iRet_erc_3.5   3.422701  5.012383  4.325897  5.711243    6.367644  5.840244   \n",
       "iRet_erc_4     3.728504  5.616411  4.811491  6.438610    7.299045  6.655965   \n",
       "CMA            7.000000  8.800000  4.770000  7.210000    8.060000  7.070000   \n",
       "CMA_active     7.000000  8.800000  5.520000  8.210000    9.060000  8.070000   \n",
       "\n",
       "                     EM  \n",
       "iRet_eq_3      6.975123  \n",
       "iRet_eq_3.5    8.370075  \n",
       "iRet_eq_4      9.765026  \n",
       "iRet_peer_3    5.785744  \n",
       "iRet_peer_3.5  6.982466  \n",
       "iRet_peer_4    8.179187  \n",
       "iRet_erc_3     5.129680  \n",
       "iRet_erc_3.5   6.217058  \n",
       "iRet_erc_4     7.304435  \n",
       "CMA            8.030000  \n",
       "CMA_active     9.030000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpRet=  pd.concat([implied_ExpRet['weight_eq'][['3_shrunk', '3.5_shrunk', '4_shrunk']].T, \n",
    "                   implied_ExpRet['weight_peer'][['3_shrunk', '3.5_shrunk', '4_shrunk']].T,\n",
    "                   implied_ExpRet['weight_erc'][['3_shrunk', '3.5_shrunk', '4_shrunk']].T,\n",
    "                   pd.DataFrame([CMA_ExpRet_geo,CMA_ExpRet_active_geo], columns= LW_cov.columns)], \n",
    "                   axis=0)* 400\n",
    "ExpRet.index= ['iRet_eq_3', # implied expected return from equal weight with risk aversion 3\n",
    "               'iRet_eq_3.5', # implied expected return from equal weight with risk aversion 3.5\n",
    "               'iRet_eq_4',\n",
    "               'iRet_peer_3', # implied expected return from peer weight with risk aversion 3\n",
    "               'iRet_peer_3.5', # implied expected return from peer weight with risk aversion 3.5\n",
    "               'iRet_peer_4',\n",
    "               'iRet_erc_3', # implied expected return from equal risk contribution weight with risk aversion 3\n",
    "               'iRet_erc_3.5',# implied expected return from equal risk contribution weight with risk aversion 3.5\n",
    "               'iRet_erc_4',\n",
    "               'CMA', # CMA expected return \n",
    "               'CMA_active' # CMA expected return, and active management\n",
    "              ]\n",
    "\n",
    "ExpRet # annualized expected ret in percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Black-Litterman Framework \n",
    "\n",
    "Construct BL framework to incorporate benchmark(prior) and views(observations) and produce a reasonable distribution of expected return (posterior). \n",
    "Apply mean-variance optimization based on posterior to achieve optimal allocation. \n",
    "\n",
    "#### Benckmark/Equilibrium Portfolio\n",
    "\n",
    "Set the benchmark as peer holding `w_peer`, then `iRet_peer_3.5` is the implied equilibrium\\benchmark expected return, given risk aversion factor 3.5.\n",
    "\n",
    "#### The prior confidence  $\\tau$\n",
    "\n",
    "Follow BL's initial setting, $\\tau = 0.05$\n",
    "\n",
    "#### Views\n",
    "\n",
    "`CMA_active` is the subjective view to expected return of each asset. The confidence is proportional to view portfolio (prior) variance with multiplier $\\tau$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### As summary, input: \n",
    "\n",
    "$\\tau$\n",
    "\n",
    "prior expected ret distribution, assuming normal, so the prior mean and variance \n",
    "\n",
    "views, the view portfolio weight, asserted expected ret, and view confidence. \n",
    "\n",
    "#### output: \n",
    "\n",
    "the posterior distribution, mean and variance of post expected return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## prepare input\n",
    "\n",
    "tau = 5e-2\n",
    "prior_cov= LW_cov* tau\n",
    "prior_cov_inv= np.linalg.inv(prior_cov)\n",
    "prior_mean= np.array(ExpRet.loc['iRet_peer_3.5'].tolist())/100/4+ 0.5* np.diag(LW_cov)\n",
    "\n",
    "\n",
    "\n",
    "# CMA_ExpRet_active_arith \n",
    "# is the asserted expected return \n",
    "view_w= np.identity(N)\n",
    "view_ExpRet= CMA_ExpRet_active_arith\n",
    "view_cov= ( (LW_cov_active)* tau * 2)\n",
    "view_cov_inv= np.linalg.inv( view_cov)\n",
    "\n",
    "##  output: post \n",
    "\n",
    "A= prior_cov_inv\n",
    "B= np.dot( np.dot(view_w.T, view_cov_inv), view_w)\n",
    "C= np.dot(prior_cov_inv, prior_mean)\n",
    "D= np.dot(np.dot(view_w.T, view_cov_inv), view_ExpRet)\n",
    "\n",
    "post_mean_arith= pd.DataFrame( np.dot(np.linalg.inv( A+B), C+D), index=LW_cov.index, columns= ['post_ExpRet']) .T\n",
    "post_cov= pd.DataFrame( np.linalg.inv( prior_cov_inv+ np.dot( np.dot( view_w.T, view_cov_inv), view_w)), index= LW_cov.index, columns= LW_cov.columns)\n",
    "post_mean_geo= post_mean_arith- .5* np.diag( LW_cov_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.14146</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.09791</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.00000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.07000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_ExpRet</th>\n",
       "      <td>4.42764</td>\n",
       "      <td>6.965812</td>\n",
       "      <td>4.543940</td>\n",
       "      <td>7.173288</td>\n",
       "      <td>7.772621</td>\n",
       "      <td>7.40399</td>\n",
       "      <td>7.634548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 US_RE     US_PE     US_HY     SP500  Rusell2000     EAFE  \\\n",
       "iRet_peer_3.5  3.14146  6.048718  4.109852  6.695766    7.161977  7.09791   \n",
       "CMA_active     7.00000  8.800000  5.520000  8.210000    9.060000  8.07000   \n",
       "post_ExpRet    4.42764  6.965812  4.543940  7.173288    7.772621  7.40399   \n",
       "\n",
       "                     EM  \n",
       "iRet_peer_3.5  6.982466  \n",
       "CMA_active     9.030000  \n",
       "post_ExpRet    7.634548  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([ ExpRet.loc[['iRet_peer_3.5', 'CMA_active']], \n",
    "          post_mean_geo*400], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       0.000085  0.000035  0.000027  0.000039    0.000051  0.000039   \n",
       "US_PE       0.000035  0.000168  0.000059  0.000124    0.000156  0.000130   \n",
       "US_HY       0.000027  0.000059  0.000146  0.000083    0.000106  0.000091   \n",
       "SP500       0.000039  0.000124  0.000083  0.000197    0.000209  0.000177   \n",
       "Rusell2000  0.000051  0.000156  0.000106  0.000209    0.000326  0.000209   \n",
       "EAFE        0.000039  0.000130  0.000091  0.000177    0.000209  0.000279   \n",
       "EM          0.000049  0.000171  0.000127  0.000207    0.000286  0.000257   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.000049  \n",
       "US_PE       0.000171  \n",
       "US_HY       0.000127  \n",
       "SP500       0.000207  \n",
       "Rusell2000  0.000286  \n",
       "EAFE        0.000257  \n",
       "EM          0.000533  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012175617663712581\n",
      "            Iterations: 36\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.3       ,  0.3       ,  0.0250876 ,  0.15948793,  0.03391084,\n",
       "        0.12635039,  0.05516323])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MVO based over post expected mean and variance\n",
    "\n",
    "\n",
    "MV_opt= minimize( obj_func_CMA, \n",
    "                x0= weight_eq, \n",
    "                args= [LW_cov_active+ post_cov, post_mean_arith, 4], \n",
    "                jac= obj_func_derivative_CMA ,\n",
    "                method= 'SLSQP',\n",
    "                options= {'disp': True},\n",
    "                constraints= cons, \n",
    "                #bounds= [[0, 0.25]]+[[0, .4]]+[[0,None]]* (N-2),\n",
    "                bounds= [[0,0.3]]* (N),\n",
    "                tol= 1e-120)\n",
    "\n",
    "MV_opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.012180486978360865\n",
      "            Iterations: 44\n",
      "            Function evaluations: 55\n",
      "            Gradient evaluations: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.30986589,  0.32137822,  0.01415427,  0.14598856,  0.03094773,\n",
       "        0.12262675,  0.05503858])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MV_unc_opt= minimize( obj_func_CMA, \n",
    "                x0= weight_eq, \n",
    "                args= [LW_cov_active+ post_cov, post_mean_arith, 4], \n",
    "                jac= obj_func_derivative_CMA ,\n",
    "                method= 'SLSQP',\n",
    "                options= {'disp': True},\n",
    "                constraints= cons, \n",
    "                bounds= [[0,None]]* N,\n",
    "                tol= 1e-120)\n",
    "\n",
    "MV_unc_opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>4.950495e-02</td>\n",
       "      <td>2.376238e-01</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>2.079208e-01</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>1.778511e-01</td>\n",
       "      <td>1.187341e-01</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>1.058735e-01</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_1</th>\n",
       "      <td>0.576959</td>\n",
       "      <td>0.392526</td>\n",
       "      <td>1.588694e-02</td>\n",
       "      <td>3.552456e-18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_2</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.782788e-01</td>\n",
       "      <td>1.696141e-01</td>\n",
       "      <td>3.210163e-17</td>\n",
       "      <td>2.933010e-02</td>\n",
       "      <td>0.022777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.599354e-02</td>\n",
       "      <td>1.611408e-01</td>\n",
       "      <td>1.837060e-02</td>\n",
       "      <td>0.144495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>6.898587e-17</td>\n",
       "      <td>1.405892e-01</td>\n",
       "      <td>1.135842e-01</td>\n",
       "      <td>3.005979e-02</td>\n",
       "      <td>0.115767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_4</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3.582843e-02</td>\n",
       "      <td>1.621623e-01</td>\n",
       "      <td>7.754428e-02</td>\n",
       "      <td>3.237553e-02</td>\n",
       "      <td>0.092089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_1</th>\n",
       "      <td>0.539164</td>\n",
       "      <td>0.312270</td>\n",
       "      <td>5.547936e-02</td>\n",
       "      <td>5.794597e-02</td>\n",
       "      <td>1.006699e-18</td>\n",
       "      <td>1.391612e-02</td>\n",
       "      <td>0.021225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_2</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.716462e-01</td>\n",
       "      <td>1.705859e-01</td>\n",
       "      <td>9.282536e-18</td>\n",
       "      <td>3.959841e-02</td>\n",
       "      <td>0.018170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.800752e-02</td>\n",
       "      <td>1.554151e-01</td>\n",
       "      <td>2.357154e-02</td>\n",
       "      <td>0.143006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.339801e-01</td>\n",
       "      <td>1.146326e-01</td>\n",
       "      <td>3.682659e-02</td>\n",
       "      <td>0.114561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.032750e-02</td>\n",
       "      <td>1.689064e-01</td>\n",
       "      <td>8.349900e-02</td>\n",
       "      <td>4.466580e-02</td>\n",
       "      <td>0.092601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3unc</th>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.410367</td>\n",
       "      <td>1.991798e-17</td>\n",
       "      <td>1.677506e-17</td>\n",
       "      <td>1.032986e-01</td>\n",
       "      <td>1.629310e-17</td>\n",
       "      <td>0.131823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5unc</th>\n",
       "      <td>0.408589</td>\n",
       "      <td>0.397578</td>\n",
       "      <td>2.015557e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.344910e-02</td>\n",
       "      <td>1.848988e-17</td>\n",
       "      <td>0.110384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4unc</th>\n",
       "      <td>0.448397</td>\n",
       "      <td>0.386824</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.910225e-03</td>\n",
       "      <td>6.679204e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.094077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.508760e-02</td>\n",
       "      <td>1.594879e-01</td>\n",
       "      <td>3.391084e-02</td>\n",
       "      <td>1.263504e-01</td>\n",
       "      <td>0.055163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL_unc</th>\n",
       "      <td>0.309866</td>\n",
       "      <td>0.321378</td>\n",
       "      <td>1.415427e-02</td>\n",
       "      <td>1.459886e-01</td>\n",
       "      <td>3.094773e-02</td>\n",
       "      <td>1.226267e-01</td>\n",
       "      <td>0.055039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE         US_HY         SP500    Rusell2000  \\\n",
       "w_eq           0.142857  0.142857  1.428571e-01  1.428571e-01  1.428571e-01   \n",
       "w_peer         0.138614  0.287129  4.950495e-02  2.376238e-01  2.970297e-02   \n",
       "w_erc          0.282415  0.142979  1.778511e-01  1.187341e-01  9.272408e-02   \n",
       "w_MVO_1        0.576959  0.392526  1.588694e-02  3.552456e-18  0.000000e+00   \n",
       "w_MVO_2        0.300000  0.300000  1.782788e-01  1.696141e-01  3.210163e-17   \n",
       "w_RUO_3        0.300000  0.300000  0.000000e+00  7.599354e-02  1.611408e-01   \n",
       "w_RUO_3.5      0.300000  0.300000  6.898587e-17  1.405892e-01  1.135842e-01   \n",
       "w_RUO_4        0.300000  0.300000  3.582843e-02  1.621623e-01  7.754428e-02   \n",
       "w_aMVO_1       0.539164  0.312270  5.547936e-02  5.794597e-02  1.006699e-18   \n",
       "w_aMVO_2       0.300000  0.300000  1.716462e-01  1.705859e-01  9.282536e-18   \n",
       "w_aRUO_3       0.300000  0.300000  0.000000e+00  7.800752e-02  1.554151e-01   \n",
       "w_aRUO_3.5     0.300000  0.300000  0.000000e+00  1.339801e-01  1.146326e-01   \n",
       "w_aRUO_4       0.300000  0.300000  1.032750e-02  1.689064e-01  8.349900e-02   \n",
       "w_aRUO_3unc    0.354512  0.410367  1.991798e-17  1.677506e-17  1.032986e-01   \n",
       "w_aRUO_3.5unc  0.408589  0.397578  2.015557e-17  0.000000e+00  8.344910e-02   \n",
       "w_aRUO_4unc    0.448397  0.386824  0.000000e+00  3.910225e-03  6.679204e-02   \n",
       "w_BL           0.300000  0.300000  2.508760e-02  1.594879e-01  3.391084e-02   \n",
       "w_BL_unc       0.309866  0.321378  1.415427e-02  1.459886e-01  3.094773e-02   \n",
       "\n",
       "                       EAFE        EM  \n",
       "w_eq           1.428571e-01  0.142857  \n",
       "w_peer         2.079208e-01  0.049505  \n",
       "w_erc          1.058735e-01  0.079423  \n",
       "w_MVO_1        0.000000e+00  0.014629  \n",
       "w_MVO_2        2.933010e-02  0.022777  \n",
       "w_RUO_3        1.837060e-02  0.144495  \n",
       "w_RUO_3.5      3.005979e-02  0.115767  \n",
       "w_RUO_4        3.237553e-02  0.092089  \n",
       "w_aMVO_1       1.391612e-02  0.021225  \n",
       "w_aMVO_2       3.959841e-02  0.018170  \n",
       "w_aRUO_3       2.357154e-02  0.143006  \n",
       "w_aRUO_3.5     3.682659e-02  0.114561  \n",
       "w_aRUO_4       4.466580e-02  0.092601  \n",
       "w_aRUO_3unc    1.629310e-17  0.131823  \n",
       "w_aRUO_3.5unc  1.848988e-17  0.110384  \n",
       "w_aRUO_4unc    0.000000e+00  0.094077  \n",
       "w_BL           1.263504e-01  0.055163  \n",
       "w_BL_unc       1.226267e-01  0.055039  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_final= pd.concat( [portf_weight,\n",
    "                         pd.DataFrame( [MV_opt.x, MV_unc_opt.x], columns= portf_weight.columns, index= ['w_BL', 'w_BL_unc'])], axis=0)\n",
    "portf_weight_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133980</td>\n",
       "      <td>0.114633</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>0.114561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.025088</td>\n",
       "      <td>0.159488</td>\n",
       "      <td>0.033911</td>\n",
       "      <td>0.126350</td>\n",
       "      <td>0.055163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL_unc</th>\n",
       "      <td>0.309866</td>\n",
       "      <td>0.321378</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.145989</td>\n",
       "      <td>0.030948</td>\n",
       "      <td>0.122627</td>\n",
       "      <td>0.055039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "w_peer      0.138614  0.287129  0.049505  0.237624    0.029703  0.207921   \n",
       "w_aRUO_3.5  0.300000  0.300000  0.000000  0.133980    0.114633  0.036827   \n",
       "w_BL        0.300000  0.300000  0.025088  0.159488    0.033911  0.126350   \n",
       "w_BL_unc    0.309866  0.321378  0.014154  0.145989    0.030948  0.122627   \n",
       "\n",
       "                  EM  \n",
       "w_peer      0.049505  \n",
       "w_aRUO_3.5  0.114561  \n",
       "w_BL        0.055163  \n",
       "w_BL_unc    0.055039  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_final.loc[['w_peer', 'w_aRUO_3.5', 'w_BL', 'w_BL_unc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3</th>\n",
       "      <td>2.946497</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.975123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3.5</th>\n",
       "      <td>3.223899</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>8.370075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_4</th>\n",
       "      <td>3.501302</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>9.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3</th>\n",
       "      <td>2.875835</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>5.785744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.141460</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3</th>\n",
       "      <td>3.116898</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.129680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3.5</th>\n",
       "      <td>3.422701</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.217058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_4</th>\n",
       "      <td>3.728504</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>4.770000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>8.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_ExpRet</th>\n",
       "      <td>4.427640</td>\n",
       "      <td>6.965812</td>\n",
       "      <td>4.543940</td>\n",
       "      <td>7.173288</td>\n",
       "      <td>7.772621</td>\n",
       "      <td>7.403990</td>\n",
       "      <td>7.634548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_eq_3      2.946497  5.112730  4.197299  5.940288    6.745272  6.198200   \n",
       "iRet_eq_3.5    3.223899  5.834154  4.742391  6.827058    7.894844  7.209535   \n",
       "iRet_eq_4      3.501302  6.555578  5.287484  7.713828    9.044416  8.220869   \n",
       "iRet_peer_3    2.875835  5.296642  3.655122  5.827752    6.117100  6.102522   \n",
       "iRet_peer_3.5  3.141460  6.048718  4.109852  6.695766    7.161977  7.097910   \n",
       "iRet_peer_4    3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "iRet_erc_3     3.116898  4.408355  3.840304  4.983875    5.436244  5.024522   \n",
       "iRet_erc_3.5   3.422701  5.012383  4.325897  5.711243    6.367644  5.840244   \n",
       "iRet_erc_4     3.728504  5.616411  4.811491  6.438610    7.299045  6.655965   \n",
       "CMA            7.000000  8.800000  4.770000  7.210000    8.060000  7.070000   \n",
       "CMA_active     7.000000  8.800000  5.520000  8.210000    9.060000  8.070000   \n",
       "post_ExpRet    4.427640  6.965812  4.543940  7.173288    7.772621  7.403990   \n",
       "\n",
       "                     EM  \n",
       "iRet_eq_3      6.975123  \n",
       "iRet_eq_3.5    8.370075  \n",
       "iRet_eq_4      9.765026  \n",
       "iRet_peer_3    5.785744  \n",
       "iRet_peer_3.5  6.982466  \n",
       "iRet_peer_4    8.179187  \n",
       "iRet_erc_3     5.129680  \n",
       "iRet_erc_3.5   6.217058  \n",
       "iRet_erc_4     7.304435  \n",
       "CMA            8.030000  \n",
       "CMA_active     9.030000  \n",
       "post_ExpRet    7.634548  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpRet_final= pd.concat([ExpRet, \n",
    "                        post_mean_geo*400], axis=0)\n",
    "ExpRet_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100789</td>\n",
       "      <td>0.141832</td>\n",
       "      <td>0.131397</td>\n",
       "      <td>0.152992</td>\n",
       "      <td>0.197087</td>\n",
       "      <td>0.182198</td>\n",
       "      <td>0.252372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  0.100789  0.141832  0.131397  0.152992  0.197087  0.182198  0.252372"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.sqrt(np.diag( LW_cov))).T*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290357</td>\n",
       "      <td>0.243449</td>\n",
       "      <td>0.301545</td>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.255969</td>\n",
       "      <td>0.229836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.290357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>0.682977</td>\n",
       "      <td>0.671396</td>\n",
       "      <td>0.604658</td>\n",
       "      <td>0.572320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.243449</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.459033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.301545</td>\n",
       "      <td>0.682977</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832526</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>0.644399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.671396</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.832526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698464</td>\n",
       "      <td>0.691124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.255969</td>\n",
       "      <td>0.604658</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>0.698464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.229836</td>\n",
       "      <td>0.572320</td>\n",
       "      <td>0.459033</td>\n",
       "      <td>0.644399</td>\n",
       "      <td>0.691124</td>\n",
       "      <td>0.669628</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       1.000000  0.290357  0.243449  0.301545    0.307428  0.255969   \n",
       "US_PE       0.290357  1.000000  0.377413  0.682977    0.671396  0.604658   \n",
       "US_HY       0.243449  0.377413  1.000000  0.497447    0.488964  0.455539   \n",
       "SP500       0.301545  0.682977  0.497447  1.000000    0.832526  0.763682   \n",
       "Rusell2000  0.307428  0.671396  0.488964  0.832526    1.000000  0.698464   \n",
       "EAFE        0.255969  0.604658  0.455539  0.763682    0.698464  1.000000   \n",
       "EM          0.229836  0.572320  0.459033  0.644399    0.691124  0.669628   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.229836  \n",
       "US_PE       0.572320  \n",
       "US_HY       0.459033  \n",
       "SP500       0.644399  \n",
       "Rusell2000  0.691124  \n",
       "EAFE        0.669628  \n",
       "EM          1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290357</td>\n",
       "      <td>0.237342</td>\n",
       "      <td>0.295909</td>\n",
       "      <td>0.303927</td>\n",
       "      <td>0.252569</td>\n",
       "      <td>0.228229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.290357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367945</td>\n",
       "      <td>0.670214</td>\n",
       "      <td>0.663750</td>\n",
       "      <td>0.596624</td>\n",
       "      <td>0.568319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.237342</td>\n",
       "      <td>0.367945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.471268</td>\n",
       "      <td>0.438210</td>\n",
       "      <td>0.444389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.295909</td>\n",
       "      <td>0.670214</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807664</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>0.627936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.303927</td>\n",
       "      <td>0.663750</td>\n",
       "      <td>0.471268</td>\n",
       "      <td>0.807664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>0.678477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.252569</td>\n",
       "      <td>0.596624</td>\n",
       "      <td>0.438210</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.228229</td>\n",
       "      <td>0.568319</td>\n",
       "      <td>0.444389</td>\n",
       "      <td>0.627936</td>\n",
       "      <td>0.678477</td>\n",
       "      <td>0.656112</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       1.000000  0.290357  0.237342  0.295909    0.303927  0.252569   \n",
       "US_PE       0.290357  1.000000  0.367945  0.670214    0.663750  0.596624   \n",
       "US_HY       0.237342  0.367945  1.000000  0.475904    0.471268  0.438210   \n",
       "SP500       0.295909  0.670214  0.475904  1.000000    0.807664  0.739453   \n",
       "Rusell2000  0.303927  0.663750  0.471268  0.807664    1.000000  0.681336   \n",
       "EAFE        0.252569  0.596624  0.438210  0.739453    0.681336  1.000000   \n",
       "EM          0.228229  0.568319  0.444389  0.627936    0.678477  0.656112   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.228229  \n",
       "US_PE       0.568319  \n",
       "US_HY       0.444389  \n",
       "SP500       0.627936  \n",
       "Rusell2000  0.678477  \n",
       "EAFE        0.656112  \n",
       "EM          1.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_corr_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130784</td>\n",
       "      <td>0.124802</td>\n",
       "      <td>0.109958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.130784  0.124802  0.109958"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.sqrt(np.diag(np.dot(np.dot(portf_weight.iloc[0:3], LW_cov), portf_weight.iloc[0:3].T)))*2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3</th>\n",
       "      <td>2.946497</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.975123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3.5</th>\n",
       "      <td>3.223899</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>8.370075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_4</th>\n",
       "      <td>3.501302</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>9.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3</th>\n",
       "      <td>2.875835</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>5.785744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.141460</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3</th>\n",
       "      <td>3.116898</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.129680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3.5</th>\n",
       "      <td>3.422701</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.217058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_4</th>\n",
       "      <td>3.728504</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>4.770000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>8.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_ExpRet</th>\n",
       "      <td>4.427640</td>\n",
       "      <td>6.965812</td>\n",
       "      <td>4.543940</td>\n",
       "      <td>7.173288</td>\n",
       "      <td>7.772621</td>\n",
       "      <td>7.403990</td>\n",
       "      <td>7.634548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_eq_3      2.946497  5.112730  4.197299  5.940288    6.745272  6.198200   \n",
       "iRet_eq_3.5    3.223899  5.834154  4.742391  6.827058    7.894844  7.209535   \n",
       "iRet_eq_4      3.501302  6.555578  5.287484  7.713828    9.044416  8.220869   \n",
       "iRet_peer_3    2.875835  5.296642  3.655122  5.827752    6.117100  6.102522   \n",
       "iRet_peer_3.5  3.141460  6.048718  4.109852  6.695766    7.161977  7.097910   \n",
       "iRet_peer_4    3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "iRet_erc_3     3.116898  4.408355  3.840304  4.983875    5.436244  5.024522   \n",
       "iRet_erc_3.5   3.422701  5.012383  4.325897  5.711243    6.367644  5.840244   \n",
       "iRet_erc_4     3.728504  5.616411  4.811491  6.438610    7.299045  6.655965   \n",
       "CMA            7.000000  8.800000  4.770000  7.210000    8.060000  7.070000   \n",
       "CMA_active     7.000000  8.800000  5.520000  8.210000    9.060000  8.070000   \n",
       "post_ExpRet    4.427640  6.965812  4.543940  7.173288    7.772621  7.403990   \n",
       "\n",
       "                     EM  \n",
       "iRet_eq_3      6.975123  \n",
       "iRet_eq_3.5    8.370075  \n",
       "iRet_eq_4      9.765026  \n",
       "iRet_peer_3    5.785744  \n",
       "iRet_peer_3.5  6.982466  \n",
       "iRet_peer_4    8.179187  \n",
       "iRet_erc_3     5.129680  \n",
       "iRet_erc_3.5   6.217058  \n",
       "iRet_erc_4     7.304435  \n",
       "CMA            8.030000  \n",
       "CMA_active     9.030000  \n",
       "post_ExpRet    7.634548  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpRet_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ew</th>\n",
       "      <th>peer</th>\n",
       "      <th>erc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.006116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.014428</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>0.012081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.009712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.017735</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.014547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.020898</td>\n",
       "      <td>0.018628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>0.016314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.023934</td>\n",
       "      <td>0.021748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ew      peer       erc\n",
       "US_RE       0.005548  0.005313  0.006116\n",
       "US_PE       0.014428  0.015042  0.012081\n",
       "US_HY       0.010902  0.009095  0.009712\n",
       "SP500       0.017735  0.017360  0.014547\n",
       "Rusell2000  0.022991  0.020898  0.018628\n",
       "EAFE        0.020227  0.019908  0.016314\n",
       "EM          0.027899  0.023934  0.021748"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.dot(LW_cov, portf_weight.loc[['w_eq', 'w_peer', 'w_erc']].T), index=LW_cov.index, columns= ['ew', 'peer', 'erc'])*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081116</td>\n",
       "      <td>0.082102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.081116  0.082102"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_w= portf_weight_final.loc[[ 'w_aRUO_3.5unc', 'w_aRUO_3.5']]\n",
    "\n",
    "tmp_ret= np.dot(tmp_w, ExpRet_final.loc['CMA_active'])/100\n",
    "tmp_vol= np.sqrt(np.diag(np.dot(np.dot(tmp_w, LW_cov_active), tmp_w.T)))*2\n",
    "\n",
    "pd.DataFrame(tmp_ret).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109126</td>\n",
       "      <td>0.118232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.109126  0.118232"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tmp_vol).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(view_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CMA_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>9.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CMA_active\n",
       "US_RE             7.00\n",
       "US_PE             8.80\n",
       "US_HY             5.52\n",
       "SP500             8.21\n",
       "Rusell2000        9.06\n",
       "EAFE              8.07\n",
       "EM                9.03"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ExpRet_final.loc['CMA_active'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_BL_unc</th>\n",
       "      <th>w_BL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.309866</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.321378</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.025088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.145989</td>\n",
       "      <td>0.159488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.030948</td>\n",
       "      <td>0.033911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.122627</td>\n",
       "      <td>0.126350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.055039</td>\n",
       "      <td>0.055163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            w_BL_unc      w_BL\n",
       "US_RE       0.309866  0.300000\n",
       "US_PE       0.321378  0.300000\n",
       "US_HY       0.014154  0.025088\n",
       "SP500       0.145989  0.159488\n",
       "Rusell2000  0.030948  0.033911\n",
       "EAFE        0.122627  0.126350\n",
       "EM          0.055039  0.055163"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl_w= portf_weight_final.loc[['w_BL_unc', 'w_BL']]\n",
    "bl_ret= ExpRet_final.loc['post_ExpRet'].values/100\n",
    "bl_w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062908</td>\n",
       "      <td>0.062963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112647</td>\n",
       "      <td>0.113087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.062908  0.062963\n",
       "0  0.112647  0.113087"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_ret_BL=pd.DataFrame(np.dot(bl_w, bl_ret)).T\n",
    "tmp_vol_BL= pd.DataFrame(np.sqrt(np.diag(np.dot(np.dot(bl_w, LW_cov_active+ post_cov), bl_w.T)))*2).T\n",
    "\n",
    "pd.concat( [tmp_ret_BL, tmp_vol_BL], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.006220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.008594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.007698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.016148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       0.002540  0.001038  0.000806  0.001162    0.001527  0.001175   \n",
       "US_PE       0.001038  0.005029  0.001758  0.003705    0.004692  0.003906   \n",
       "US_HY       0.000806  0.001758  0.004541  0.002500    0.003166  0.002726   \n",
       "SP500       0.001162  0.003705  0.002500  0.006077    0.006276  0.005322   \n",
       "Rusell2000  0.001527  0.004692  0.003166  0.006276    0.009936  0.006270   \n",
       "EAFE        0.001175  0.003906  0.002726  0.005322    0.006270  0.008524   \n",
       "EM          0.001462  0.005121  0.003805  0.006220    0.008594  0.007698   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.001462  \n",
       "US_PE       0.005121  \n",
       "US_HY       0.003805  \n",
       "SP500       0.006220  \n",
       "Rusell2000  0.008594  \n",
       "EAFE        0.007698  \n",
       "EM          0.016148  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_cov_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.005292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.003932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.006428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.010262</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.008880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.007954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>0.016681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       0.002624  0.001072  0.000833  0.001201    0.001578  0.001214   \n",
       "US_PE       0.001072  0.005197  0.001817  0.003829    0.004848  0.004037   \n",
       "US_HY       0.000833  0.001817  0.004688  0.002583    0.003271  0.002817   \n",
       "SP500       0.001201  0.003829  0.002583  0.006274    0.006485  0.005499   \n",
       "Rusell2000  0.001578  0.004848  0.003271  0.006485    0.010262  0.006479   \n",
       "EAFE        0.001214  0.004037  0.002817  0.005499    0.006479  0.008803   \n",
       "EM          0.001510  0.005292  0.003932  0.006428    0.008880  0.007954   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.001510  \n",
       "US_PE       0.005292  \n",
       "US_HY       0.003932  \n",
       "SP500       0.006428  \n",
       "Rusell2000  0.008880  \n",
       "EAFE        0.007954  \n",
       "EM          0.016681  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_cov_active+ post_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.082102</td>\n",
       "      <td>0.082102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.082102  0.082102"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tmp_w= portf_weight_final.loc[[ 'w_aRUO_3.5', 'w_aRUO_3.5']]\n",
    "\n",
    "tmp_ret= np.dot(tmp_w, ExpRet_final.loc['CMA_active'])/100\n",
    "\n",
    "\n",
    "tmp_vol= pd.DataFrame(np.sqrt(np.diag(np.dot(np.dot(tmp_w, LW_cov_active), tmp_w.T)))*2).T\n",
    "\n",
    "pd.DataFrame(tmp_ret).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.118232\n",
       "1  0.118232"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tmp_vol).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bechmark+ active \n",
    "\n",
    "Benchmark = Peer\n",
    "\n",
    "Active= Max (risk adj return) with const dollar neutral \n",
    "\n",
    "\n",
    "What is the corr of Benchmark and Active? \n",
    "\n",
    "How to combine to max SR? with const that final portfolio is long only. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13861386138613863,\n",
       " 0.2871287128712871,\n",
       " 0.04950495049504951,\n",
       " 0.2376237623762376,\n",
       " 0.0297029702970297,\n",
       " 0.2079207920792079,\n",
       " 0.04950495049504951]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_w= portf_weight_final.loc['w_peer'].tolist()\n",
    "benchmark_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExpRet_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0187698 ,  0.02451454,  0.01607064,  0.02356332,  0.0276179 ,\n",
       "        0.02443702,  0.03064896])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMA_ExpRet_active_arith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.006220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.008594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.007698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.016148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       0.002540  0.001038  0.000806  0.001162    0.001527  0.001175   \n",
       "US_PE       0.001038  0.005029  0.001758  0.003705    0.004692  0.003906   \n",
       "US_HY       0.000806  0.001758  0.004541  0.002500    0.003166  0.002726   \n",
       "SP500       0.001162  0.003705  0.002500  0.006077    0.006276  0.005322   \n",
       "Rusell2000  0.001527  0.004692  0.003166  0.006276    0.009936  0.006270   \n",
       "EAFE        0.001175  0.003906  0.002726  0.005322    0.006270  0.008524   \n",
       "EM          0.001462  0.005121  0.003805  0.006220    0.008594  0.007698   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.001462  \n",
       "US_PE       0.005121  \n",
       "US_HY       0.003805  \n",
       "SP500       0.006220  \n",
       "Rusell2000  0.008594  \n",
       "EAFE        0.007698  \n",
       "EM          0.016148  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_cov_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.04975089682802483\n",
      "            Iterations: 39\n",
      "            Function evaluations: 56\n",
      "            Gradient evaluations: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\slsqp.py:341: RuntimeWarning: invalid value encountered in greater\n",
      "  bnderr = bnds[:, 0] > bnds[:, 1]\n"
     ]
    }
   ],
   "source": [
    "## active \n",
    "\n",
    "\n",
    "cons_dollarNeutral= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "\n",
    "cons= (cons_dollarNeutral)\n",
    "MV_active_opt= minimize( obj_func_CMA, \n",
    "                x0= weight_eq, \n",
    "                args= [LW_cov_active, CMA_ExpRet_active_arith*4, 3.5], \n",
    "                jac= obj_func_derivative_CMA ,\n",
    "                method= 'SLSQP',\n",
    "                options= {'disp': True},\n",
    "                constraints= cons, \n",
    "                bounds= [[None,None]]* N,\n",
    "                tol= 1e-120)\n",
    "\n",
    "active_w= MV_active_opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_vol= np.sqrt( np.dot( np.dot( active_w, LW_cov_active), active_w)) *2\n",
    "actuve_ExpRet= np.dot( active_w, CMA_ExpRet_active_geo*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33721852789112011"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.071617352936821435"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuve_ExpRet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13861386138613863,\n",
       " 0.2871287128712871,\n",
       " 0.04950495049504951,\n",
       " 0.2376237623762376,\n",
       " 0.0297029702970297,\n",
       " 0.2079207920792079,\n",
       " 0.04950495049504951]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "benchmark_vol= np.sqrt(np.dot( np.dot(benchmark_w, LW_cov_active), benchmark_w))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "benchmark_ExpRet= np.dot(benchmark_w, CMA_ExpRet_active_geo*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.081152475247524752"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_ExpRet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "\n",
    "ba_corr= np.dot( np.dot(benchmark_w, LW_cov_active), active_w)/ (benchmark_vol/2 * active_vol /2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SR_ba( lam):\n",
    "    return (benchmark_ExpRet+ lam* actuve_ExpRet)/ np.sqrt( benchmark_vol**2+ lam**2 *  active_vol**2+ 2*lam* benchmark_vol * active_vol* ba_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJDX+Dzd7Jv6ajfm4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc18d4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x= np.linspace(0,1,100), y=  SR_ba(np.linspace(0,1,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64827779,  0.64374515,  0.63906297,  0.63425792,  0.62935445,\n",
       "        0.6243748 ,  0.61933912,  0.61426559,  0.60917048,  0.60406833,\n",
       "        0.59897201,  0.5938929 ,  0.588841  ,  0.583825  ,  0.57885247,\n",
       "        0.57392992,  0.5690629 ,  0.56425613,  0.55951352,  0.55483835,\n",
       "        0.55023325,  0.54570032,  0.54124118,  0.53685702,  0.53254865,\n",
       "        0.52831657,  0.52416096,  0.52008179,  0.51607877,  0.51215146,\n",
       "        0.50829923,  0.50452133,  0.50081687,  0.49718489,  0.49362432,\n",
       "        0.49013404,  0.48671287,  0.48335958,  0.48007293,  0.47685161,\n",
       "        0.47369434,  0.47059979,  0.46756666,  0.46459362,  0.46167937,\n",
       "        0.45882259,  0.45602199,  0.4532763 ,  0.45058424,  0.44794457,\n",
       "        0.44535606,  0.44281752,  0.44032775,  0.43788559,  0.43548991,\n",
       "        0.4331396 ,  0.43083356,  0.42857073,  0.42635007,  0.42417057,\n",
       "        0.42203123,  0.4199311 ,  0.41786922,  0.41584468,  0.41385658,\n",
       "        0.41190405,  0.40998625,  0.40810234,  0.40625152,  0.40443301,\n",
       "        0.40264604,  0.40088987,  0.39916378,  0.39746707,  0.39579905,\n",
       "        0.39415906,  0.39254645,  0.39096059,  0.38940086,  0.38786668,\n",
       "        0.38635746,  0.38487264,  0.38341166,  0.381974  ,  0.38055914,\n",
       "        0.37916656,  0.37779579,  0.37644633,  0.37511773,  0.37380953,\n",
       "        0.37252128,  0.37125257,  0.37000297,  0.36877207,  0.36755948,\n",
       "        0.36636481,  0.36518768,  0.36402774,  0.36288462,  0.36175797])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SR_ba(np.linspace(0,1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
