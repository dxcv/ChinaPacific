{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cvxopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2958689410bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mcvxopt\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcvxopt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mblas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolvers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'cvxopt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import cvxopt as opt\n",
    "from cvxopt import blas, solvers\n",
    "\n",
    "import mpld3\n",
    "from mpld3 import plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_CORP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "      <th>Cash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.035495</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.047757</td>\n",
       "      <td>0.070263</td>\n",
       "      <td>0.026435</td>\n",
       "      <td>0.076253</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.091792</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>0.006670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.333429</td>\n",
       "      <td>-0.214401</td>\n",
       "      <td>-0.083766</td>\n",
       "      <td>-0.219432</td>\n",
       "      <td>-0.261180</td>\n",
       "      <td>-0.211290</td>\n",
       "      <td>-0.275584</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.007742</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>-0.030336</td>\n",
       "      <td>-0.016548</td>\n",
       "      <td>-0.043980</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.031222</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>0.038349</td>\n",
       "      <td>0.008214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035783</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>0.034229</td>\n",
       "      <td>0.070468</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.066656</td>\n",
       "      <td>0.111489</td>\n",
       "      <td>0.013101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137135</td>\n",
       "      <td>0.264363</td>\n",
       "      <td>0.113356</td>\n",
       "      <td>0.212974</td>\n",
       "      <td>0.297346</td>\n",
       "      <td>0.258489</td>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.023825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            US_RE       US_PE     US_CORP       SP500  Rusell2000        EAFE  \\\n",
       "count  114.000000  114.000000  114.000000  114.000000  114.000000  114.000000   \n",
       "mean     0.018989    0.035495    0.018274    0.027670    0.028452    0.017290   \n",
       "std      0.047757    0.070263    0.026435    0.076253    0.099660    0.091792   \n",
       "min     -0.333429   -0.214401   -0.083766   -0.219432   -0.261180   -0.211290   \n",
       "25%      0.007742    0.004679    0.000719   -0.001749   -0.030336   -0.016548   \n",
       "50%      0.018845    0.037985    0.017305    0.031222    0.037918    0.017968   \n",
       "75%      0.035783    0.069509    0.034229    0.070468    0.088459    0.066656   \n",
       "max      0.137135    0.264363    0.113356    0.212974    0.297346    0.258489   \n",
       "\n",
       "               EM        Cash  \n",
       "count  114.000000  114.000000  \n",
       "mean     0.032061    0.008155  \n",
       "std      0.128686    0.006670  \n",
       "min     -0.275584    0.000000  \n",
       "25%     -0.043980    0.000726  \n",
       "50%      0.038349    0.008214  \n",
       "75%      0.111489    0.013101  \n",
       "max      0.348433    0.023825  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in data\n",
    "ret_df_raw= pd.read_excel( io= 'Data/cipc data.xlsx', sheetname= 'Data_Input', index_col=0)\n",
    "ret_df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cov2corr(cov, return_std=False):\n",
    "    '''convert covariance matrix to correlation matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cov : array_like, 2d\n",
    "        covariance matrix, see Notes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corr : ndarray (subclass)\n",
    "        correlation matrix\n",
    "    return_std : bool\n",
    "        If this is true then the standard deviation is also returned.\n",
    "        By default only the correlation matrix is returned.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function does not convert subclasses of ndarrays. This requires\n",
    "    that division is defined elementwise. np.ma.array and np.matrix are allowed.\n",
    "\n",
    "    '''\n",
    "    cov = np.asanyarray(cov)\n",
    "    std_ = np.sqrt(np.diag(cov))\n",
    "    corr = cov / np.outer(std_, std_)\n",
    "    if return_std:\n",
    "        return corr, std_\n",
    "    else:\n",
    "        return corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_df= ret_df_raw[['US_RE', \n",
    "                   'US_PE',\n",
    "                   'US_CORP',\n",
    "                   'SP500',\n",
    "                   'Rusell2000',\n",
    "                   'EAFE',\n",
    "                   'EM']]\n",
    "                   #'USGOVT10Y']]\n",
    "ret_df_cov= ret_df.cov()\n",
    "ret_df_corr= ret_df.corr()\n",
    "N= ret_df.shape[1]\n",
    "#ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_CORP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.296730</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.307848</td>\n",
       "      <td>0.313075</td>\n",
       "      <td>0.260839</td>\n",
       "      <td>0.233716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.296730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011812</td>\n",
       "      <td>0.692243</td>\n",
       "      <td>0.678817</td>\n",
       "      <td>0.611732</td>\n",
       "      <td>0.577800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_CORP</th>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.011812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143748</td>\n",
       "      <td>0.079756</td>\n",
       "      <td>0.176276</td>\n",
       "      <td>0.118270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.307848</td>\n",
       "      <td>0.692243</td>\n",
       "      <td>0.143748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840865</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.649903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.313075</td>\n",
       "      <td>0.678817</td>\n",
       "      <td>0.079756</td>\n",
       "      <td>0.840865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704161</td>\n",
       "      <td>0.695298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.260839</td>\n",
       "      <td>0.611732</td>\n",
       "      <td>0.176276</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.704161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.674103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.233716</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.118270</td>\n",
       "      <td>0.649903</td>\n",
       "      <td>0.695298</td>\n",
       "      <td>0.674103</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE   US_CORP     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       1.000000  0.296730  0.015200  0.307848    0.313075  0.260839   \n",
       "US_PE       0.296730  1.000000  0.011812  0.692243    0.678817  0.611732   \n",
       "US_CORP     0.015200  0.011812  1.000000  0.143748    0.079756  0.176276   \n",
       "SP500       0.307848  0.692243  0.143748  1.000000    0.840865  0.771825   \n",
       "Rusell2000  0.313075  0.678817  0.079756  0.840865    1.000000  0.704161   \n",
       "EAFE        0.260839  0.611732  0.176276  0.771825    0.704161  1.000000   \n",
       "EM          0.233716  0.577800  0.118270  0.649903    0.695298  0.674103   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.233716  \n",
       "US_PE       0.577800  \n",
       "US_CORP     0.118270  \n",
       "SP500       0.649903  \n",
       "Rusell2000  0.695298  \n",
       "EAFE        0.674103  \n",
       "EM          1.000000  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ledoit Wolf shrunk cov matrix\n",
    "\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "LW= LedoitWolf( ).fit(ret_df)\n",
    "LW_alpha= LW.shrinkage_\n",
    "\n",
    "LW_cov= pd.DataFrame(LW.covariance_)\n",
    "LW_cov.index= ret_df_cov.index\n",
    "LW_cov.columns= ret_df_cov.columns\n",
    "LW_cov\n",
    "\n",
    "LW_corr = pd.DataFrame(cov2corr(LW_cov))\n",
    "LW_corr.index= ret_df_cov.index\n",
    "LW_corr.columns= ret_df_cov.columns\n",
    "LW_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09967199,  0.1412755 ,  0.06296121,  0.15254828,  0.1970037 ,\n",
       "        0.18200475,  0.25263504])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.diagonal(np.matrix(LW_cov.values)))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## arithmatic avg ret to exponential avg ret \n",
    "\n",
    "ret_cov= np.diagonal(np.matrix(LW_cov.values))\n",
    "coverter= np.array([ret_cov.tolist()]*ret_df.shape[0])* .5\n",
    "ret_df_exp= ret_df- coverter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_eq= np.ones( (7,))*1.0/7\n",
    "weight_peer= np.array( (0.138,0.287,0.046,0.238,0.026,0.211,0.046))\n",
    "weight_peer= weight_peer/ np.sum(weight_peer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 11\n",
      "         Function evaluations: 1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\X197066\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:394: RuntimeWarning: Method Powell cannot handle constraints nor bounds.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "## solve ERC weight \n",
    "\n",
    "def objective_func(w, sigma): \n",
    "    A= np.diag( w)\n",
    "    B= np.diag( np.dot( sigma, w))\n",
    "    C= np.diag( np.dot( A, B))/ np.dot( np.dot( w, sigma), w)- np.ones( w.size )* 1/ w.size\n",
    "    \n",
    "    return np.dot( C, C)\n",
    "\n",
    "\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "opt_res= minimize( objective_func, \n",
    "                 x0= weight_eq,\n",
    "                 args= LW_cov,\n",
    "                 method= 'Powell',\n",
    "                 options= {'disp': True},\n",
    "                 bounds= [[0,None]]*7,\n",
    "                 tol= 1e-16)\n",
    "\n",
    "weight_erc = opt_res.x/ np.sum( opt_res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4589696100701789e-23"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_func( weight_erc, LW_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_CORP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.139113</td>\n",
       "      <td>0.289315</td>\n",
       "      <td>0.046371</td>\n",
       "      <td>0.239919</td>\n",
       "      <td>0.026210</td>\n",
       "      <td>0.212702</td>\n",
       "      <td>0.046371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.206808</td>\n",
       "      <td>0.105522</td>\n",
       "      <td>0.403146</td>\n",
       "      <td>0.085036</td>\n",
       "      <td>0.067863</td>\n",
       "      <td>0.074384</td>\n",
       "      <td>0.057241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                US_RE     US_PE   US_CORP     SP500  Rusell2000      EAFE  \\\n",
       "weight_eq    0.142857  0.142857  0.142857  0.142857    0.142857  0.142857   \n",
       "weight_peer  0.139113  0.289315  0.046371  0.239919    0.026210  0.212702   \n",
       "weight_erc   0.206808  0.105522  0.403146  0.085036    0.067863  0.074384   \n",
       "\n",
       "                   EM  \n",
       "weight_eq    0.142857  \n",
       "weight_peer  0.046371  \n",
       "weight_erc   0.057241  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_1= pd.DataFrame( [weight_eq, weight_peer, weight_erc], \n",
    "                             index=['weight_eq', 'weight_peer', 'weight_erc'], \n",
    "                             columns= LW_cov. columns)\n",
    "portf_weight_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## recover the implied expected ret based on shirinked cov matrix\n",
    "\n",
    "rf= 179/10000\n",
    "gamma= [ 1.5, 2, 2.5, 3, 3.5,4]\n",
    "implied_ExpRet= {}\n",
    "\n",
    "for w_name in portf_weight_1.index: \n",
    "    tmp_dic= {}\n",
    "    for g in gamma:\n",
    "        w= np.array(portf_weight_1.loc[w_name].tolist())\n",
    "        tmp1= np.ones( ( N))* rf/4+ g*  np.dot( LW_cov, w)\n",
    "        tmp2= np.ones( (N))*rf/4+ g* np.dot( ret_df_cov,w) \n",
    "        tmp_dic[str(g)+ '_shrunk']= tmp1\n",
    "        tmp_dic[str(g)+'_unshrunk']= tmp2\n",
    "    \n",
    "    \n",
    "    tmp= pd.DataFrame( tmp_dic, index= LW_cov.index)\n",
    "    tmp= tmp- .5* np.array([np.diag(LW_cov).tolist()] *tmp.shape[1]).T\n",
    "    implied_ExpRet[w_name]= tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5_shrunk</th>\n",
       "      <th>1.5_unshrunk</th>\n",
       "      <th>2.5_shrunk</th>\n",
       "      <th>2.5_unshrunk</th>\n",
       "      <th>2_shrunk</th>\n",
       "      <th>2_unshrunk</th>\n",
       "      <th>3.5_shrunk</th>\n",
       "      <th>3.5_unshrunk</th>\n",
       "      <th>3_shrunk</th>\n",
       "      <th>3_unshrunk</th>\n",
       "      <th>4_shrunk</th>\n",
       "      <th>4_unshrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>2.057276</td>\n",
       "      <td>2.072893</td>\n",
       "      <td>2.566609</td>\n",
       "      <td>2.592638</td>\n",
       "      <td>2.311942</td>\n",
       "      <td>2.332765</td>\n",
       "      <td>3.075943</td>\n",
       "      <td>3.112383</td>\n",
       "      <td>2.821276</td>\n",
       "      <td>2.852511</td>\n",
       "      <td>3.330610</td>\n",
       "      <td>3.372256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>2.815033</td>\n",
       "      <td>2.906044</td>\n",
       "      <td>4.163680</td>\n",
       "      <td>4.315366</td>\n",
       "      <td>3.489357</td>\n",
       "      <td>3.610705</td>\n",
       "      <td>5.512328</td>\n",
       "      <td>5.724688</td>\n",
       "      <td>4.838004</td>\n",
       "      <td>5.020027</td>\n",
       "      <td>6.186652</td>\n",
       "      <td>6.429349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_CORP</th>\n",
       "      <td>1.815416</td>\n",
       "      <td>1.798672</td>\n",
       "      <td>1.964498</td>\n",
       "      <td>1.936591</td>\n",
       "      <td>1.889957</td>\n",
       "      <td>1.867632</td>\n",
       "      <td>2.113579</td>\n",
       "      <td>2.074510</td>\n",
       "      <td>2.039038</td>\n",
       "      <td>2.005550</td>\n",
       "      <td>2.188120</td>\n",
       "      <td>2.143469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>3.112107</td>\n",
       "      <td>3.230827</td>\n",
       "      <td>4.769211</td>\n",
       "      <td>4.967078</td>\n",
       "      <td>3.940659</td>\n",
       "      <td>4.098952</td>\n",
       "      <td>6.426316</td>\n",
       "      <td>6.703328</td>\n",
       "      <td>5.597764</td>\n",
       "      <td>5.835203</td>\n",
       "      <td>7.254868</td>\n",
       "      <td>7.571453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>3.062974</td>\n",
       "      <td>3.225280</td>\n",
       "      <td>5.205305</td>\n",
       "      <td>5.475816</td>\n",
       "      <td>4.134139</td>\n",
       "      <td>4.350548</td>\n",
       "      <td>7.347636</td>\n",
       "      <td>7.726352</td>\n",
       "      <td>6.276470</td>\n",
       "      <td>6.601084</td>\n",
       "      <td>8.418801</td>\n",
       "      <td>8.851619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>2.989717</td>\n",
       "      <td>3.130615</td>\n",
       "      <td>4.893718</td>\n",
       "      <td>5.128549</td>\n",
       "      <td>3.941717</td>\n",
       "      <td>4.129582</td>\n",
       "      <td>6.797720</td>\n",
       "      <td>7.126483</td>\n",
       "      <td>5.845719</td>\n",
       "      <td>6.127516</td>\n",
       "      <td>7.749721</td>\n",
       "      <td>8.125450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>2.517217</td>\n",
       "      <td>2.721740</td>\n",
       "      <td>5.129511</td>\n",
       "      <td>5.470382</td>\n",
       "      <td>3.823364</td>\n",
       "      <td>4.096061</td>\n",
       "      <td>7.741804</td>\n",
       "      <td>8.219024</td>\n",
       "      <td>6.435658</td>\n",
       "      <td>6.844703</td>\n",
       "      <td>9.047951</td>\n",
       "      <td>9.593346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1.5_shrunk  1.5_unshrunk  2.5_shrunk  2.5_unshrunk  2_shrunk  \\\n",
       "US_RE         2.057276      2.072893    2.566609      2.592638  2.311942   \n",
       "US_PE         2.815033      2.906044    4.163680      4.315366  3.489357   \n",
       "US_CORP       1.815416      1.798672    1.964498      1.936591  1.889957   \n",
       "SP500         3.112107      3.230827    4.769211      4.967078  3.940659   \n",
       "Rusell2000    3.062974      3.225280    5.205305      5.475816  4.134139   \n",
       "EAFE          2.989717      3.130615    4.893718      5.128549  3.941717   \n",
       "EM            2.517217      2.721740    5.129511      5.470382  3.823364   \n",
       "\n",
       "            2_unshrunk  3.5_shrunk  3.5_unshrunk  3_shrunk  3_unshrunk  \\\n",
       "US_RE         2.332765    3.075943      3.112383  2.821276    2.852511   \n",
       "US_PE         3.610705    5.512328      5.724688  4.838004    5.020027   \n",
       "US_CORP       1.867632    2.113579      2.074510  2.039038    2.005550   \n",
       "SP500         4.098952    6.426316      6.703328  5.597764    5.835203   \n",
       "Rusell2000    4.350548    7.347636      7.726352  6.276470    6.601084   \n",
       "EAFE          4.129582    6.797720      7.126483  5.845719    6.127516   \n",
       "EM            4.096061    7.741804      8.219024  6.435658    6.844703   \n",
       "\n",
       "            4_shrunk  4_unshrunk  \n",
       "US_RE       3.330610    3.372256  \n",
       "US_PE       6.186652    6.429349  \n",
       "US_CORP     2.188120    2.143469  \n",
       "SP500       7.254868    7.571453  \n",
       "Rusell2000  8.418801    8.851619  \n",
       "EAFE        7.749721    8.125450  \n",
       "EM          9.047951    9.593346  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_eq']*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5_shrunk</th>\n",
       "      <th>1.5_unshrunk</th>\n",
       "      <th>2.5_shrunk</th>\n",
       "      <th>2.5_unshrunk</th>\n",
       "      <th>2_shrunk</th>\n",
       "      <th>2_unshrunk</th>\n",
       "      <th>3.5_shrunk</th>\n",
       "      <th>3.5_unshrunk</th>\n",
       "      <th>3_shrunk</th>\n",
       "      <th>3_unshrunk</th>\n",
       "      <th>4_shrunk</th>\n",
       "      <th>4_unshrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>1.898968</td>\n",
       "      <td>1.891614</td>\n",
       "      <td>2.302763</td>\n",
       "      <td>2.290507</td>\n",
       "      <td>2.100865</td>\n",
       "      <td>2.091060</td>\n",
       "      <td>2.706558</td>\n",
       "      <td>2.689400</td>\n",
       "      <td>2.504660</td>\n",
       "      <td>2.489953</td>\n",
       "      <td>2.908456</td>\n",
       "      <td>2.888846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>1.979126</td>\n",
       "      <td>2.027954</td>\n",
       "      <td>2.770502</td>\n",
       "      <td>2.851883</td>\n",
       "      <td>2.374814</td>\n",
       "      <td>2.439919</td>\n",
       "      <td>3.561879</td>\n",
       "      <td>3.675812</td>\n",
       "      <td>3.166191</td>\n",
       "      <td>3.263847</td>\n",
       "      <td>3.957567</td>\n",
       "      <td>4.087776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_CORP</th>\n",
       "      <td>1.902505</td>\n",
       "      <td>1.836069</td>\n",
       "      <td>2.109646</td>\n",
       "      <td>1.998919</td>\n",
       "      <td>2.006076</td>\n",
       "      <td>1.917494</td>\n",
       "      <td>2.316787</td>\n",
       "      <td>2.161769</td>\n",
       "      <td>2.213216</td>\n",
       "      <td>2.080344</td>\n",
       "      <td>2.420357</td>\n",
       "      <td>2.243193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>2.099504</td>\n",
       "      <td>2.169781</td>\n",
       "      <td>3.081539</td>\n",
       "      <td>3.198667</td>\n",
       "      <td>2.590522</td>\n",
       "      <td>2.684224</td>\n",
       "      <td>4.063575</td>\n",
       "      <td>4.227553</td>\n",
       "      <td>3.572557</td>\n",
       "      <td>3.713110</td>\n",
       "      <td>4.554592</td>\n",
       "      <td>4.741997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>1.695274</td>\n",
       "      <td>1.791495</td>\n",
       "      <td>2.925805</td>\n",
       "      <td>3.086174</td>\n",
       "      <td>2.310539</td>\n",
       "      <td>2.438834</td>\n",
       "      <td>4.156336</td>\n",
       "      <td>4.380852</td>\n",
       "      <td>3.541071</td>\n",
       "      <td>3.733513</td>\n",
       "      <td>4.771602</td>\n",
       "      <td>5.028191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>1.817711</td>\n",
       "      <td>1.902867</td>\n",
       "      <td>2.940376</td>\n",
       "      <td>3.082303</td>\n",
       "      <td>2.379043</td>\n",
       "      <td>2.492585</td>\n",
       "      <td>4.063041</td>\n",
       "      <td>4.261739</td>\n",
       "      <td>3.501708</td>\n",
       "      <td>3.672021</td>\n",
       "      <td>4.624373</td>\n",
       "      <td>4.851456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.787103</td>\n",
       "      <td>0.906078</td>\n",
       "      <td>2.245987</td>\n",
       "      <td>2.444278</td>\n",
       "      <td>1.516545</td>\n",
       "      <td>1.675178</td>\n",
       "      <td>3.704871</td>\n",
       "      <td>3.982478</td>\n",
       "      <td>2.975429</td>\n",
       "      <td>3.213378</td>\n",
       "      <td>4.434313</td>\n",
       "      <td>4.751579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1.5_shrunk  1.5_unshrunk  2.5_shrunk  2.5_unshrunk  2_shrunk  \\\n",
       "US_RE         1.898968      1.891614    2.302763      2.290507  2.100865   \n",
       "US_PE         1.979126      2.027954    2.770502      2.851883  2.374814   \n",
       "US_CORP       1.902505      1.836069    2.109646      1.998919  2.006076   \n",
       "SP500         2.099504      2.169781    3.081539      3.198667  2.590522   \n",
       "Rusell2000    1.695274      1.791495    2.925805      3.086174  2.310539   \n",
       "EAFE          1.817711      1.902867    2.940376      3.082303  2.379043   \n",
       "EM            0.787103      0.906078    2.245987      2.444278  1.516545   \n",
       "\n",
       "            2_unshrunk  3.5_shrunk  3.5_unshrunk  3_shrunk  3_unshrunk  \\\n",
       "US_RE         2.091060    2.706558      2.689400  2.504660    2.489953   \n",
       "US_PE         2.439919    3.561879      3.675812  3.166191    3.263847   \n",
       "US_CORP       1.917494    2.316787      2.161769  2.213216    2.080344   \n",
       "SP500         2.684224    4.063575      4.227553  3.572557    3.713110   \n",
       "Rusell2000    2.438834    4.156336      4.380852  3.541071    3.733513   \n",
       "EAFE          2.492585    4.063041      4.261739  3.501708    3.672021   \n",
       "EM            1.675178    3.704871      3.982478  2.975429    3.213378   \n",
       "\n",
       "            4_shrunk  4_unshrunk  \n",
       "US_RE       2.908456    2.888846  \n",
       "US_PE       3.957567    4.087776  \n",
       "US_CORP     2.420357    2.243193  \n",
       "SP500       4.554592    4.741997  \n",
       "Rusell2000  4.771602    5.028191  \n",
       "EAFE        4.624373    4.851456  \n",
       "EM          4.434313    4.751579  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_erc']*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.5_shrunk</th>\n",
       "      <th>1.5_unshrunk</th>\n",
       "      <th>2.5_shrunk</th>\n",
       "      <th>2.5_unshrunk</th>\n",
       "      <th>2_shrunk</th>\n",
       "      <th>2_unshrunk</th>\n",
       "      <th>3.5_shrunk</th>\n",
       "      <th>3.5_unshrunk</th>\n",
       "      <th>3_shrunk</th>\n",
       "      <th>3_unshrunk</th>\n",
       "      <th>4_shrunk</th>\n",
       "      <th>4_unshrunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>2.067092</td>\n",
       "      <td>2.084087</td>\n",
       "      <td>2.582970</td>\n",
       "      <td>2.611295</td>\n",
       "      <td>2.325031</td>\n",
       "      <td>2.347691</td>\n",
       "      <td>3.098848</td>\n",
       "      <td>3.138503</td>\n",
       "      <td>2.840909</td>\n",
       "      <td>2.874899</td>\n",
       "      <td>3.356788</td>\n",
       "      <td>3.402107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>3.002597</td>\n",
       "      <td>3.073946</td>\n",
       "      <td>4.476287</td>\n",
       "      <td>4.595202</td>\n",
       "      <td>3.739442</td>\n",
       "      <td>3.834574</td>\n",
       "      <td>5.949978</td>\n",
       "      <td>6.116458</td>\n",
       "      <td>5.213132</td>\n",
       "      <td>5.355830</td>\n",
       "      <td>6.686823</td>\n",
       "      <td>6.877086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_CORP</th>\n",
       "      <td>1.757026</td>\n",
       "      <td>1.757139</td>\n",
       "      <td>1.867181</td>\n",
       "      <td>1.867369</td>\n",
       "      <td>1.812104</td>\n",
       "      <td>1.812254</td>\n",
       "      <td>1.977336</td>\n",
       "      <td>1.977599</td>\n",
       "      <td>1.922258</td>\n",
       "      <td>1.922484</td>\n",
       "      <td>2.032413</td>\n",
       "      <td>2.032714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>3.175906</td>\n",
       "      <td>3.277971</td>\n",
       "      <td>4.875542</td>\n",
       "      <td>5.045651</td>\n",
       "      <td>4.025724</td>\n",
       "      <td>4.161811</td>\n",
       "      <td>6.575179</td>\n",
       "      <td>6.813331</td>\n",
       "      <td>5.725361</td>\n",
       "      <td>5.929491</td>\n",
       "      <td>7.424997</td>\n",
       "      <td>7.697171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>2.912776</td>\n",
       "      <td>3.090695</td>\n",
       "      <td>4.954975</td>\n",
       "      <td>5.251507</td>\n",
       "      <td>3.933876</td>\n",
       "      <td>4.171101</td>\n",
       "      <td>6.997174</td>\n",
       "      <td>7.412318</td>\n",
       "      <td>5.976075</td>\n",
       "      <td>6.331913</td>\n",
       "      <td>8.018274</td>\n",
       "      <td>8.492724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>3.072051</td>\n",
       "      <td>3.203146</td>\n",
       "      <td>5.030943</td>\n",
       "      <td>5.249435</td>\n",
       "      <td>4.051497</td>\n",
       "      <td>4.226290</td>\n",
       "      <td>6.989834</td>\n",
       "      <td>7.295723</td>\n",
       "      <td>6.010388</td>\n",
       "      <td>6.272579</td>\n",
       "      <td>7.969280</td>\n",
       "      <td>8.318867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>2.099910</td>\n",
       "      <td>2.299796</td>\n",
       "      <td>4.433998</td>\n",
       "      <td>4.767141</td>\n",
       "      <td>3.266954</td>\n",
       "      <td>3.533468</td>\n",
       "      <td>6.768087</td>\n",
       "      <td>7.234487</td>\n",
       "      <td>5.601043</td>\n",
       "      <td>6.000814</td>\n",
       "      <td>7.935131</td>\n",
       "      <td>8.468160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1.5_shrunk  1.5_unshrunk  2.5_shrunk  2.5_unshrunk  2_shrunk  \\\n",
       "US_RE         2.067092      2.084087    2.582970      2.611295  2.325031   \n",
       "US_PE         3.002597      3.073946    4.476287      4.595202  3.739442   \n",
       "US_CORP       1.757026      1.757139    1.867181      1.867369  1.812104   \n",
       "SP500         3.175906      3.277971    4.875542      5.045651  4.025724   \n",
       "Rusell2000    2.912776      3.090695    4.954975      5.251507  3.933876   \n",
       "EAFE          3.072051      3.203146    5.030943      5.249435  4.051497   \n",
       "EM            2.099910      2.299796    4.433998      4.767141  3.266954   \n",
       "\n",
       "            2_unshrunk  3.5_shrunk  3.5_unshrunk  3_shrunk  3_unshrunk  \\\n",
       "US_RE         2.347691    3.098848      3.138503  2.840909    2.874899   \n",
       "US_PE         3.834574    5.949978      6.116458  5.213132    5.355830   \n",
       "US_CORP       1.812254    1.977336      1.977599  1.922258    1.922484   \n",
       "SP500         4.161811    6.575179      6.813331  5.725361    5.929491   \n",
       "Rusell2000    4.171101    6.997174      7.412318  5.976075    6.331913   \n",
       "EAFE          4.226290    6.989834      7.295723  6.010388    6.272579   \n",
       "EM            3.533468    6.768087      7.234487  5.601043    6.000814   \n",
       "\n",
       "            4_shrunk  4_unshrunk  \n",
       "US_RE       3.356788    3.402107  \n",
       "US_PE       6.686823    6.877086  \n",
       "US_CORP     2.032413    2.032714  \n",
       "SP500       7.424997    7.697171  \n",
       "Rusell2000  8.018274    8.492724  \n",
       "EAFE        7.969280    8.318867  \n",
       "EM          7.935131    8.468160  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implied_ExpRet['weight_peer']*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## mean variance optimization, constuct efficient fronter \n",
    "\n",
    "CMA_ExpRet_geo= np.array( [700, 880, 325, 821, 906, 807, 903]) /10000 /4 #quarterly expected exponential ret \n",
    "LW_cov.index\n",
    "CMA_ExpRet_arith= CMA_ExpRet_geo+ .5* np.diag(LW_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 49\n",
      "            Function evaluations: 461\n",
      "            Gradient evaluations: 45\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1012\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 52\n",
      "            Function evaluations: 473\n",
      "            Gradient evaluations: 48\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 94\n",
      "            Function evaluations: 942\n",
      "            Gradient evaluations: 90\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 83\n",
      "            Function evaluations: 811\n",
      "            Gradient evaluations: 79\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1025\n",
      "            Gradient evaluations: 98\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 979\n",
      "            Gradient evaluations: 98\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306485\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1039\n",
      "            Gradient evaluations: 97\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511297\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1006\n",
      "            Gradient evaluations: 97\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1021\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 74\n",
      "            Function evaluations: 701\n",
      "            Gradient evaluations: 70\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1035\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 99\n",
      "            Function evaluations: 985\n",
      "            Gradient evaluations: 95\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 992\n",
      "            Gradient evaluations: 97\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 101\n",
      "            Function evaluations: 988\n",
      "            Gradient evaluations: 98\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1030\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511294\n",
      "            Iterations: 86\n",
      "            Function evaluations: 808\n",
      "            Gradient evaluations: 82\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1025\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 84\n",
      "            Function evaluations: 795\n",
      "            Gradient evaluations: 80\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.00124181306485\n",
      "            Iterations: 62\n",
      "            Function evaluations: 597\n",
      "            Gradient evaluations: 58\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 90\n",
      "            Function evaluations: 896\n",
      "            Gradient evaluations: 86\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1019\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 89\n",
      "            Function evaluations: 872\n",
      "            Gradient evaluations: 85\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1023\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 86\n",
      "            Function evaluations: 812\n",
      "            Gradient evaluations: 82\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 95\n",
      "            Function evaluations: 944\n",
      "            Gradient evaluations: 91\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1006\n",
      "            Gradient evaluations: 98\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306484\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1015\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 33\n",
      "            Function evaluations: 278\n",
      "            Gradient evaluations: 29\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.00124181306485\n",
      "            Iterations: 70\n",
      "            Function evaluations: 689\n",
      "            Gradient evaluations: 66\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 983\n",
      "            Gradient evaluations: 97\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00124181306485\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1018\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 10\n",
      "            Function evaluations: 41\n",
      "            Gradient evaluations: 6\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 0.00124181306485\n",
      "            Iterations: 70\n",
      "            Function evaluations: 681\n",
      "            Gradient evaluations: 66\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 58\n",
      "            Function evaluations: 566\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00122921592928\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511294\n",
      "            Iterations: 101\n",
      "            Function evaluations: 952\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00120979621874\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1031\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00119198913731\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 48\n",
      "            Function evaluations: 445\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00117565031826\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 998\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00116027942511\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 101\n",
      "            Function evaluations: 968\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00114583392588\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 81\n",
      "            Function evaluations: 808\n",
      "            Gradient evaluations: 77\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00113231382056\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 965\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00111971910915\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 90\n",
      "            Function evaluations: 913\n",
      "            Gradient evaluations: 86\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00110804979166\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183797511293\n",
      "            Iterations: 69\n",
      "            Function evaluations: 663\n",
      "            Gradient evaluations: 65\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00109730586809\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 994\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00108748733843\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 101\n",
      "            Function evaluations: 959\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00107859420269\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 971\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00107062646086\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511297\n",
      "            Iterations: 101\n",
      "            Function evaluations: 989\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00106358411295\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1009\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00105746715895\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1017\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00105227559887\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511292\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1014\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010480094327\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1015\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00104466866045\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511297\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1010\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00104225328211\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1050\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00104076329769\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 977\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00104019870718\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511298\n",
      "            Iterations: 101\n",
      "            Function evaluations: 987\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00104054881769\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1021\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00104179938678\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511294\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1019\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00104395034388\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1016\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00104700168853\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 999\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00105095342119\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511295\n",
      "            Iterations: 101\n",
      "            Function evaluations: 997\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00105580554195\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511297\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1015\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00106155805006\n",
      "            Iterations: 18\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 18\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511297\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1049\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00106821094628\n",
      "            Iterations: 22\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 22\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511283\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1006\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00107561834087\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1009\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00108358788188\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.0018379751129\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1024\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00109211867934\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 988\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00110121073347\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511296\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1015\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00111086404417\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511297\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1013\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00112107861153\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511294\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1037\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00113185443556\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511299\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1002\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00114319151643\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511297\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1029\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00115508985334\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511297\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1034\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00116754944715\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511299\n",
      "            Iterations: 101\n",
      "            Function evaluations: 989\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00118055015015\n",
      "            Iterations: 29\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 29\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511299\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1031\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011940294501\n",
      "            Iterations: 31\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 31\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511297\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1036\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00120798289691\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00183797511298\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1041\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0012224104904\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00180857526093\n",
      "            Iterations: 6\n",
      "            Function evaluations: 6\n",
      "            Gradient evaluations: 6\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00123731223078\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017039979566\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00125268811797\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00161763788238\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00126853815196\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00154949503827\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00128486233277\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015008188084\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00130166066087\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00149823314025\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131893368547\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00150718845797\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00133668457649\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00151721124715\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00135495295831\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00152830150776\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00137376749616\n",
      "            Iterations: 28\n",
      "            Function evaluations: 28\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00154040226784\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00139312818851\n",
      "            Iterations: 29\n",
      "            Function evaluations: 29\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00155327751153\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00141303503654\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00156690146705\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00143348803982\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00158127413439\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00145448730731\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00159639551357\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00147603251211\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00161226560508\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00149812398114\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00162888440741\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00152076160541\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00164625192207\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00154394538493\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00166436814856\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00156767531969\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00168323308443\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00159195140971\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00170284672055\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00161677365497\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0017232090685\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00164214205549\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00174432012827\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00166805661125\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00176617989988\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00169451732226\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00178878838331\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00172152418852\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00181214557857\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00174907721002\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183625148566\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00177717638678\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00186110610458\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00180582171878\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00188670943533\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00183501320604\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0019130614779\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00186475084854\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00194016223231\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00189503464629\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00196801169856\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00192586459929\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00199660987661\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00195724070754\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020259567666\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00198916297103\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00205613977271\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00202163138978\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00208947084891\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00205464596377\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00212402809124\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00208820669301\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00215914554599\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0021223135775\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00219482321318\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00215696661724\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0022310610928\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00219216581223\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00226785918485\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00222791116246\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def obj_func(w, sigma):\n",
    "    return (np.dot(  np.dot( w, sigma), w)* .5)\n",
    "\n",
    "def obj_func_derivative( w, sigma): \n",
    "    return (np.dot( w, sigma))\n",
    "\n",
    "\n",
    "cons_eq0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "# cons_ineq0= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[0]-w[1]+ 0.5, \n",
    "#              'jac': lambda w: np.array([-1]*2+ [0]*10)}\n",
    "# cons_ineq1= {'type': 'ineq',\n",
    "#              'fun': lambda w: -w[2]-w[3]-w[4]-w[5]-w[6]+ 0.5,\n",
    "#              'jac': lambda w: np.array([0]*2+ [-1]*5+ [0]*5)}\n",
    "# cons_ineq2= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[7]-w[8]-w[9]-w[10]+ 0.5, \n",
    "#              'jac': lambda w: np.array([0]*7+ [-1]*4+ [0])}\n",
    "# cons_ineq3= {'type': 'ineq', \n",
    "#             'fun': lambda w: -w[11]+ 0.5,\n",
    "#             'jac': lambda w: np.array( [0]*11+ [-1])}\n",
    "\n",
    "\n",
    "\n",
    "fronter1_w= {}\n",
    "fronter1_vol= {}\n",
    "fronter2_w= {}\n",
    "fronter2_vol= {}\n",
    "\n",
    "for target_ret in np.linspace(0.07, 0.1, 100 ): \n",
    "    cons_ineq4= {'type': 'eq', \n",
    "                'fun': lambda w: -np.dot(w, CMA_ExpRet_arith*4)+ target_ret,\n",
    "                'jac': lambda w: -CMA_ExpRet_arith*4}\n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          , cons_ineq4\n",
    "          )\n",
    "\n",
    "    MV_opt_2= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= (LW_cov+np.diag( np.array([0, 0, 0.0004/4, 0.0009/4, 0.0009/4, 0.0009/4, 0.0009/4]))), \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    #bounds= [[0,0.25]]+[[0, 0.4]]+[[0,None]]* (N-2),\n",
    "                    bounds= [[0,0.3],[0,0.3],[0,0.0000001]]+ [[0, None]]*(N-3),\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "\n",
    "    MV_opt_1= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= (LW_cov+np.diag( np.array([0, 0, 0.0004/4, 0.0009/4, 0.0009/4, 0.0009/4, 0.0009/4]))), \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,None],[0,None],[0,0.0000001]]+ [[0, None]]*(N-3),\n",
    "                    tol= 1e-12)  # long only constrain\n",
    "    \n",
    "    fronter1_w[target_ret]= MV_opt_1.x\n",
    "    fronter1_vol[target_ret]= np.sqrt(MV_opt_1.fun*2)*2\n",
    "    \n",
    "    fronter2_w[target_ret]= MV_opt_2.x\n",
    "    fronter2_vol[target_ret]= np.sqrt(MV_opt_2.fun*2)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.070303030303030312, 0.12125923017934614),\n",
       " (0.08787878787878789, 0.12125923017991405),\n",
       " (0.091818181818181827, 0.11247307711245642),\n",
       " (0.078181818181818186, 0.12125923017943373),\n",
       " (0.099696969696969701, 0.13359823629972054),\n",
       " (0.09757575757575758, 0.12638385582362127),\n",
       " (0.08606060606060606, 0.12125923018025674),\n",
       " (0.081212121212121222, 0.12125923017917099),\n",
       " (0.089090909090909096, 0.11133714701822535),\n",
       " (0.071212121212121213, 0.12125923017948645),\n",
       " (0.070606060606060617, 0.12125923017927533),\n",
       " (0.091212121212121217, 0.11147295677524176),\n",
       " (0.092121212121212132, 0.11300957529587717),\n",
       " (0.078484848484848491, 0.1212592301790828),\n",
       " (0.093636363636363643, 0.1160425123628278),\n",
       " (0.086363636363636365, 0.12125923017949475),\n",
       " (0.081515151515151527, 0.12125923017991749),\n",
       " (0.07575757575757576, 0.12125923017937904),\n",
       " (0.097272727272727275, 0.12547547006679494),\n",
       " (0.070909090909090922, 0.12125923017944819),\n",
       " (0.092424242424242437, 0.11356991168724437),\n",
       " (0.078787878787878796, 0.12125923017942652),\n",
       " (0.08666666666666667, 0.12125923017955206),\n",
       " (0.094545454545454544, 0.11812942489569531),\n",
       " (0.089696969696969706, 0.1094799758951468),\n",
       " (0.076060606060606065, 0.12125923017902727),\n",
       " (0.074242424242424249, 0.1212592301789322),\n",
       " (0.080000000000000002, 0.12125923017783746),\n",
       " (0.092727272727272742, 0.11415373519629013),\n",
       " (0.079090909090909101, 0.12125923017972023),\n",
       " (0.086969696969696975, 0.12125923018042613),\n",
       " (0.073333333333333334, 0.12125923017911878),\n",
       " (0.094848484848484849, 0.11886731762355085),\n",
       " (0.090000000000000011, 0.10980668314721596),\n",
       " (0.07636363636363637, 0.12125923017929488),\n",
       " (0.097878787878787885, 0.12730928533610517),\n",
       " (0.084242424242424244, 0.12125923017925536),\n",
       " (0.079393939393939406, 0.12125923017908662),\n",
       " (0.08727272727272728, 0.1212592301803143),\n",
       " (0.089393939393939401, 0.10957440607731657),\n",
       " (0.095151515151515154, 0.11962569567813863),\n",
       " (0.076666666666666675, 0.1212592301790188),\n",
       " (0.09818181818181819, 0.12825411565204708),\n",
       " (0.084545454545454549, 0.12125923017741697),\n",
       " (0.10000000000000001, 0.13469548425540742),\n",
       " (0.079696969696969711, 0.12125923017918541),\n",
       " (0.087575757575757585, 0.12125923017979655),\n",
       " (0.073939393939393944, 0.12125923017933139),\n",
       " (0.095454545454545459, 0.12040417197327186),\n",
       " (0.073636363636363639, 0.12125923017938046),\n",
       " (0.081818181818181818, 0.12125923017908172),\n",
       " (0.07696969696969698, 0.1212592301792885),\n",
       " (0.098484848484848495, 0.12928946898839311),\n",
       " (0.084848484848484854, 0.12125923017918422),\n",
       " (0.070000000000000007, 0.121259230178897),\n",
       " (0.082121212121212123, 0.12125923017852809),\n",
       " (0.095757575757575764, 0.12120235923978502),\n",
       " (0.077272727272727285, 0.12125923017944282),\n",
       " (0.0987878787878788, 0.13035422789421575),\n",
       " (0.093030303030303033, 0.11476068741762119),\n",
       " (0.088181818181818195, 0.12028550239939415),\n",
       " (0.074545454545454554, 0.12125923017946465),\n",
       " (0.096060606060606069, 0.12201987066310419),\n",
       " (0.093939393939393948, 0.11671663876421894),\n",
       " (0.090303030303030302, 0.11017118487682574),\n",
       " (0.085454545454545464, 0.12125923017973611),\n",
       " (0.071818181818181823, 0.12125923017894114),\n",
       " (0.093333333333333338, 0.11539040336395086),\n",
       " (0.0884848484848485, 0.1167560861489732),\n",
       " (0.074848484848484859, 0.12125923017928632),\n",
       " (0.096363636363636374, 0.12285632048299973),\n",
       " (0.082727272727272733, 0.12125923017933156),\n",
       " (0.090606060606060607, 0.11057310731870497),\n",
       " (0.085757575757575769, 0.12125923017874189),\n",
       " (0.072121212121212128, 0.12125923017914729),\n",
       " (0.083939393939393953, 0.12125923017511661),\n",
       " (0.085151515151515159, 0.12125923017939559),\n",
       " (0.075151515151515164, 0.1212592301789068),\n",
       " (0.096666666666666679, 0.12371132455532309),\n",
       " (0.083030303030303038, 0.12125923017885937),\n",
       " (0.082424242424242428, 0.12125923017944788),\n",
       " (0.090909090909090912, 0.11100999118410571),\n",
       " (0.072424242424242433, 0.12125923017876104),\n",
       " (0.080303030303030307, 0.12125923017937565),\n",
       " (0.075454545454545469, 0.12125923017876143),\n",
       " (0.096969696969696983, 0.12458450087580529),\n",
       " (0.083333333333333343, 0.12125923017974112),\n",
       " (0.088787878787878791, 0.11375896913674205),\n",
       " (0.071515151515151518, 0.12125923017913616),\n",
       " (0.077575757575757576, 0.12125923017934603),\n",
       " (0.099090909090909091, 0.13142741102199779),\n",
       " (0.072727272727272738, 0.12125923017916232),\n",
       " (0.094242424242424253, 0.11741240372289211),\n",
       " (0.080606060606060612, 0.12125923017973303),\n",
       " (0.083636363636363648, 0.12125923017956369),\n",
       " (0.091515151515151522, 0.11196075980612448),\n",
       " (0.077878787878787881, 0.12125923017843647),\n",
       " (0.099393939393939396, 0.1325088136896741),\n",
       " (0.073030303030303043, 0.12125923017912328),\n",
       " (0.080909090909090917, 0.12125923017936062)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fronter2_wtemp = {}\n",
    "fronter_2= list( fronter2_vol.items())\n",
    "fronter_2\n",
    "#fronter_temp = [[x[0]-.5*x[1]**2, x[1]] for x in fronter_2]\n",
    "#fronter_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = 0\n",
    "for x in fronter_2:\n",
    "   fronter2_wtemp[y] = fronter2_w[x[0]]\n",
    "   y = y + 1\n",
    "\n",
    "writer= pd.ExcelWriter('output.xlsx') \n",
    "pd.DataFrame(fronter2_wtemp, ).T.to_excel(writer, 'Sheet1')\n",
    "writer.save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.085353535353535348, 0.094556285624879874)\n",
      "[  5.66559010e-01   3.27614595e-01   1.00000000e-07   6.25152482e-02\n",
      "   0.00000000e+00   1.49243928e-02   2.83866534e-02]\n",
      "(0.090909090909090912, 0.11100999118410571)\n",
      "[  3.00000000e-01   3.00000000e-01   1.00000000e-07   2.84699322e-01\n",
      "   5.28476420e-03   6.76555746e-02   4.23602387e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAFyCAYAAABYwciPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xl8TdfawPHfOkmIOTXPs7aoebiUaFRITH0raupAaWmv\nmlVvSxsRilJDTa1e7cUtqqVXDSUERYxttFVtzIKWqimmIJLzvH+ckyMnkyRykuD59nM+etZee+1n\n75PhydprrW1EBKWUUkqpzGbJ7gCUUkop9WDSJEMppZRSLqFJhlJKKaVcQpMMpZRSSrmEJhlKKaWU\ncglNMpRSSinlEppkKKWUUsolNMlQSimllEtokqGUUkopl9AkQ6lsZIzJZ4yZZ4w5Y4yxGmOm2suL\nG2OWGWPOG2PijDGDjDFP2eu0SOcxgowxVtecgVJKpUyTDKUymTGmlz0ZSO4VZ4xpnKD6KKAnMBt4\nEfivvXw60Bp4H3gJWGcvz8hzAARwaZJhjClljBltjKmdxvqpXaPxrow1lZia2c8hf3YcX6kHkXt2\nB6DUA0qA94DIZLYdSfD/LYFdIjIuUZ2WwAoRmZag7JAxJo+IxKQzlrHAhHTuk16lgdHAcWBfGvdJ\n6Rrtz7yw0qU5EAj8G7iWTTEo9UDRJEMp11knInvvUqc48FsK5ZcTF2YgwUBErEC690snk8H90nKN\n7hzEGAPkEpFbGTxeqs27oE3sieENV7StVE6nt0uUygbx4yuAikCHBLdSeiUYPzEgvty+j09yYzKM\nMf8wxnxnjLlojLlmjPnFGDMowfZkx2QYY140xvxojIk2xlwwxiwxxpRNVOd7Y8w+Y0x1Y8xmY8x1\nY8wfxpgRCc8F2IOtZ2J+gnPpeY/XyC1+nIox5iVjzG/ATaCVfXt+Y8w0Y8wpY8xNY0yEMWZIKm0E\nGGP22+v+aozxTVBvLBB/m+aPBOdQOkGdXomu16KE2+11wowxe40xjYwx24wx14Ex93IdlLqfaU+G\nUq5TyBhTJFGZiMhF4HdsYzCmA6eAKfbtP9nLvwDWAwsT7kuiMRnGmNbAKuC0va2/gOpAe2BGKvuN\nAoKBL7HdHigGDAK2GGPqiciVBPsWBtYC39jrPwdMNMbsE5EQIALbbYZgYC6wzb7vjrteoWSukYhc\nSFTHD+iObdzKReCkvUdjDdDMHv8+oC0w1RhTSkT+lagNH6ALMAfbrZAhwHJjTHkRuQx8BVQFugID\ngCj7fhft12u0/RwX249XHBgMNLZfr/jbK2LfthpYBCwAzqThOij1YBIRfelLX5n4AnphG2iZ3Cs6\nUd3jwMpk2rACMxKVPQXEAS3s7y3AMeAoUCCVeEYDcQnelwduA/9KVK8Gttsqbyco22w/5vMJyjyw\nJTVfJShrYI+55z1eo4RxutnLYoCqifbvbN/2ZqLy5fZzK5+ojej4Mnt5PXt5vwRl/7Kfa+lEbVYG\nYoHhicpr2Y/1ZoKybfY2Xs7ur0N96SsnvLQnQynXEKA/cDhReVwmHqMettstg0Xkajr264xt/MHX\niXoR/sYWb0tgYoLyayKyOP6NiNw2xuzB9sv3XqR0jRLbKCJHEpW1xZZ8zE5UPhXoBPgDnyYoXyci\nJx0HFvnJfisjLefQ2R7r8kTX6wy2JK8l8GGC8mjuzBJS6qGmSYZSrvODpGNQYwZUwfbLL7mBo6mp\niq0XJPEvbuztJR4k+kcy9S5h+0v+XqXlGkUmU1YB+EOSDqiMSLA9oVPJtBEFPHLXCG3Xyw1bQpGY\nAFcSlf0hIpmZTCp139IkQ6mHjwXbrQJ/kl8/I/H0zZR+YbpkNkYyMmNmxr2cgwXb7RL/FLYn7kXS\nmSRK2WmSodT96yi2X5JPAJsysF9kMrchMioji4TdixOAdzLTQ6sn2J5eKZ3DUew9GSISmYF2lXpo\n6RRWpe5fe7ENHB1ijCmUjv2+wdaDMTq5jcaYwhmI5br9X68M7JsR3wG5sI3pSGgotl6LtRloM6Vz\nWI4tAcnM66XUQ0F7MpRyDQO0M8ZUT2bbDhE5fg/tAra5sMaYfwIrgZ+NMf/BNhjxcaCGiLRNrgER\nOWaMeRcYb4ypBKzA1uVfGXgW2zTUqemM6yi2MQ6vG2OuYfuFvfsuf/nfy+2W/wFbgQ+MMVW5M4W1\nPTBZRJIbg3E34faYJhhjvsY2c2SFiBy2T2ENNsZUwXa9r2G7Xp2AmdyZLqyUSkCTDKVcQ0h5Eabe\n2Hog4usl102fWvmdNyLrjTEtsf2VPQxb7+RRnGdWJLffB8aYg9j+8g+0F5/C9oyUlantm1y5iMTa\nF9+aAHyM7WdLb5IftHm3dhPXSVLPnmC1x7ZketcExxomIh+lpY3E5SKyy55M9APaYbuW5YDTIvK+\nMSYC2/oaCa/XGmxrYqT3vJR6KBgR/X5QSimlVObL0JgMY8wbxpjjxpgbxphdxphGqdQtaV9+96B9\nmd4k3bDGmBrG9ljr4/blfAcl15ZSSiml7h/pTjKMMd2wLYE8GttiQL8AIcaYoinskhvbIj9jgZ9T\nqJMXWxfvv9AleJVSSqkHQrpvlxhjdmEb0DXY/t5guzc5Q0Qm3WXfzcBPIjIslTrHgWkiogOplFJK\nqftYunoyjDEe2J5RsDG+TGxZSijQNHNDU0oppdT9LL2zS4piW5TmbKLys8BjmRJRGtmfIeCHbUT5\nzaw8tlJKKXWf88T27KMQSfrk40xzP09h9cP2KGWllFJKZcwLwOK71sqg9CYZ57GtplciUXkJ4K9M\niSjtIgG++OILqldPbr2jh8fQoUOZNm1adoeR7fQ63KHXwkavwx16LWz0OthERETw4osvQupr2dyz\ndCUZ9kc8hwOtsC/YYx/42YqsX/HuJkD16tWpX79+Fh86ZylUqNBDfw1Ar0NCei1s9DrcodfCRq9D\nEi4dbpCR2yVTgfn2ZGMPthUD8wLzAYwxE4DSItIrfgdjTB1sy/XmB4rZ38eISIR9uwdQw14nF1DG\nXueaiBzN4LkppZRSKhulO8kQka/sa2IEY7tN8jPgJyLn7FVKYluKN6GfuLPUbn3geWxPSaxsLyud\nqM6b9tcW4On0xqiUUkqp7JehgZ8iMgeYk8K23smUpTpVVkROoE+EVUoppR4o+ov9AdCjR4/sDiFH\n0Otwh14LG70Od+i1sNHrkLXu2wekGWPqA+Hh4eE6iEcppZRKh71799KgQQOABiKy11XHuZ/XyVA5\n3MmTJzl//nx2h6GUUg+dokWLUr58+ewOQ5MM5RonT56kevXqREdHZ3coSin10MmbNy8RERHZnmho\nkqFc4vz580RHR+tiaUoplcXiF9o6f/68JhnqwaaLpSml1MNLZ5copZRSyiU0yVBKKaWUS2iSoZRS\nSimX0CRDKaWUUi6hSYZS6TR//nwsFgsnT57M7lCylI+PD08/rY8SUkqlnSYZSqWTMQZjTHaHkeUe\nxnNWSt0bTTKUUkop5RKaZCillFLKJTTJUCqTzJkzhyeeeAJPT0/KlCnDgAEDuHz5slMdHx8fateu\nTUREBC1btiRfvnyULVuWyZMnJ2nv5MmTPPPMM+TPn58SJUowbNgw1q9fj8ViYevWrXeN56effqJt\n27YUKlSIAgUK4Ovry+7du53qLFiwAIvFwo4dOxg2bBjFixcnf/78BAQEcOHChRTbvn79Ovnz52fo\n0KFJtv3555+4u7vzwQcf3DVGpdSDTZMMdV85ffo0w4cPZ+DAgRw6dCi7w3EICgpiwIABlC1blqlT\np/Lcc88xd+5c/Pz8iIuLc9QzxnDx4kXatm1LvXr1mDp1KtWrV+ftt98mJCTEUS86OpqWLVuyadMm\nhgwZwrvvvsvOnTv517/+laaxEb///jstWrTg119/5e233yYwMJDIyEh8fHz44YcfktQfOHAgv/76\nK0FBQfTv359Vq1YxYMCAFNvPly8fnTp1YunSpSR+kvPixYsBePHFF+8ap1LqASci9+ULqA9IeHi4\nqJwnPDxc0vr5XL16VQ4cOCAxMTGp1rt165ZUq1pVihTyklJFi0mxosXk/PnzmRVyms2fP18sFouc\nOHFCRETOnTsnuXPnlrZt2zrVmz17tlgsFpk/f76jzMfHRywWiyxatMhRFhMTI6VKlZIuXbo4yqZM\nmSIWi0VWrVrlKLt165ZUr15dLBaLbNmyJdUYn332WfH09JTIyEhH2ZkzZ6RgwYLi4+PjdC7GGPHz\n83Paf9iwYeLh4SFXrlxxir1ly5aO9+vXrxeLxSIhISFO+9apU8epnlIqa6Xl5298HaC+uPB3tfZk\nqGy1fft2ypUrx+OPP06tJ57gzJkzKdY9cuQIh48cYdGoYDZMnsm58+cIDw9Ptf3IyEjmzJnD6tWr\nk/zFnVlCQ0O5ffs2Q4YMcSrv27cvBQoUYM2aNU7l+fPn5/nnn3e89/DwoHHjxhw7dsxRFhISQpky\nZejQoYOjLFeuXPTt2/eu8VitVjZs2ECnTp2oUKGCo7xkyZI8//zzhIWFce3aNUe5MYZ+/fo5teHt\n7U1cXBwnTpxI8Ti+vr6UKlWKRYsWOcr279/Pvn37eOmll+4ap1LqwadJhspWb40YQdWSpVk9YRp/\n//UXU6ZMSbFu2bJlKViwIO99PpdBM6fg4eFBtWrVUqx/+PBh6taty8CBA+nYsSPvvvuuK07B8Yv4\n0UcfdSr38PCgcuXKSX5Rly1bNkkbjzzyCJcuXXJqs0qVKknqVa1a9a7xnDt3jujo6CTxgO2BdVar\nlVOnTjmVlytXLkk8gFNMiRljeOGFF1ixYgU3b94EYNGiReTJk4fnnnvurnEqpR58mmSobHXr1i28\n8uWnSumy5Mntya1bt1KsW7BgQVavXo27VwEuE8fXX39NpUqVUqy/dOlSrLGxXFy5kcGdu/PxnI9d\ncQrp5ubmlmy5q3pa0iKjMfXs2ZOrV6+yYsUKAJYsWULHjh0pUKBApseolLr/6KPeVbYa9e67dO3a\nleq9ulCkcBHeeOONVOt7e3uzY+fONLVdvHhxrkVH8+/V/2P7b/soXrxYZoScRPwtiYMHD1KxYkVH\n+e3btzl+/DitW7fOUJsRERFJyg8fPnzXfYsVK0bevHk5ePBgkm0RERFYLJYkPRcZVbNmTerVq8ei\nRYsoU6YMJ0+eZPbs2ZnStlLq/qc9GSpbderUiYiICL777jsiDkTw+OOPZ1rbvXv3plvXroz4ZAZn\nrkQxf8GCTGs7IV9fXzw8PJgxY4ZT+bx587hy5YrTuIq08vPz488//2TVqlWOsps3bzJv3ry77mux\nWGjTpg3ffvut09LnZ8+eZcmSJXh7e5M/f/50x5SSl156iZCQEKZPn07RokXx9/fPtLaVUvc3TTJU\ntqtatSpt27alWLHM7Wnw8PBgyZdfEhMTw6k//qBJkyaZ2n68okWL8s4777Bu3Tr8/f2ZM2cOgwYN\nYtCgQTRu3JgXXngh3W2+9tprVKhQge7duzNy5EhmzpyJj48PefLkAe6+xPe4ceNwd3enWbNmTJgw\ngUmTJtGsWTNiYmKYNGmSU92Ubomk9fZN/CDWFStW0K1btxRvvSilHj6aZKgHnoeHh8ufuzF69Ghm\nzZrFqVOnGDZsGMuWLeP1118nJCQkyS/dlGJJWJ4vXz42b95Mq1atmDFjBuPGjaN58+aMGjUKAE9P\nz1TjqVGjBtu2baNWrVpMnDiRsWPHUqlSJb7//nsaNmyY7nhSKytevDht2rQBdG0MpZQzk52Dze6F\nMaY+EB4eHk79+vWzOxyVyN69e2nQoAH6+WSu6dOnM3z4cP744w9KlSqV3eE4BAQEsH///hy1QJpS\nD6u0/PyNrwM0EJG9ropFezKUyqHip4UmfD937lyqVauWoxKMM2fOsGbNGnr27JndoSilchidXaJU\nDhUQEED58uWpW7cuUVFRfPHFFxw6dMixbHd2i4yMJCwsjHnz5pErV64kC3oppZQmGUrlUP7+/syb\nN4/FixcTFxdHjRo1WLp0aY5Z6GrLli307t2bihUrsnDhQooXL57dISmlchhNMpTKoeJnqORUvXr1\nolevXtkdhlIqB9MxGUoppZRyCU0ylFJKKeUSmmQopZRSyiU0yVBKKaWUS2QoyTDGvGGMOW6MuWGM\n2WWMaZRK3ZLGmEXGmIPGmDhjzNQU6nUxxkTY2/zFGNM2I7EppZRSKmdId5JhjOkGTAFGA/WAX4AQ\nY0zRFHbJDfwNjAV+TqHNJ4HFwL+BusC3wApjTI30xqeUUkqpnCEjPRlDgbkislBEDgCvA9FAn+Qq\ni8gJERkqIl8AV1JocxCwVkSmishBEQkE9gIDMhCfUkoppXKAdCUZxhgPoAGwMb5MbA8/CQWa3kMc\nTe1tJBRyj20q5RLz58/HYrE4PUb9YeDj48PTTz+d3WGoLBAUFITFokP2spLFYiE4ODi7w8h06f0q\nKgq4AWcTlZ8FSt5DHCVd0KZSLmGMcflTXXOih/Gcs9vatWsZM2aMS9q+ceMGY8aMYevWrUm2GWM0\nyUjElZ8FPLg/V/SrSCmlcqjvvvvOZX/dRkdHM2bMGL7//vsk29577z2io6Ndctz7lSs/C7AlfaNG\njXJZ+9klvcuKnwfigBKJyksAf91DHH9ltM2hQ4dSqFAhp7IePXrQo0ePewhHKeVKvXv35sSJE2za\ntCm7Q8nRbHej0yYuLg6r1YqHh8c9t22xWMiVK1eaj/0wcOVnAbj0ei9ZsoQlS5Y4lV2+fNllx3Mi\nIul6AbuAjxK8N8ApYEQa9t0MTE2m/Evg20Rl24E5qbRVH5Dw8HBROU94eLg8qJ/P/PnzxWKxyIkT\nJ5zKZ8+eLTVr1pTcuXNL6dKl5Y033pCoqCinOk899ZTUqlVLfv/9d/Hx8ZG8efNKmTJlZNKkSUmO\nc+LECenYsaPky5dPihcvLkOHDpWQkBAxxsiWLVvuGufevXvF399fChYsKPnz55dWrVrJrl27kpyL\nMUa2b98uQ4cOlWLFikm+fPmkU6dOcv78eae6Pj4+0rJlSxERuXbtmuTLl0+GDBmS5Lh//PGHuLm5\nycSJE1OM7eWXX3a0lV43b96U0aNHy6OPPiqenp5SqlQpCQgIkGPHjjnqXL9+XYYNGyblypWT3Llz\ny2OPPSYffvhhkraMMTJw4EBZsWKFPPHEE5I7d26pWbOmrFu3LkndP//8U/r06SOlS5eW3LlzS6VK\nleSf//yn3L5921EnKipKBg8e7Dhu1apV5YMPPhCr1eqoExkZKcYYmTJlinz66adSpUoVyZ07tzRq\n1Eh++OEHp2tkjBGLxSLGGMf/J25j+vTpUqVKFXF3d5dffvlFYmJi5L333pMGDRpIoUKFJF++fOLt\n7S2bN29OEkPCto0xMmbMGBERGT16tBhjnM4/NjZWgoODHfFWrFhRRo4cKbdu3XKqV6FCBenYsaOE\nhYVJ48aNxdPTUypXriwLFy5My8crVqtVpk+fLrVq1RJPT08pVqyY+Pv7O/0syexYbt++LUFBQVKt\nWjXx9PSUIkWKSPPmzSU0NNTln0W8hNc/4Wdw5MgR6dWrl3h5eUmhQoWkd+/ecuPGjVSvYVp+/sbX\nAepLOvOA9Lwy8oC0qcB8Y0w4sAfbbJO8wHwAY8wEoLSIOJ6cZIypY09G8gPF7O9jRCTCXuUj4Htj\nzDBgDdAD2wDTvhmITz3ARITdu3cTExPDk08+ibt7znjGX1BQEMHBwbRp04b+/ftz8OBB5syZw48/\n/sj27dtxc3MDbPddL168SNu2bQkICKB79+4sW7aMt99+m9q1a+Pn5wfYurJbtmzJ2bNnGTJkCCVK\nlGDx4sVs3rw5Tfdtf//9d1q0aEGhQoV4++23cXd3Z+7cufj4+LB161YaNXJe2mbgwIEULlyYoKAg\nIiMjmTZtGgMGDEjy10+8fPny0alTJ5YuXcrUqVOdYop/FP2LL76YoWuZGqvVSvv27dm8eTM9evRg\nyJAhXL16lQ0bNrB//34qVaoEQMeOHdmyZQuvvvoqderUISQkhBEjRnD69GmmTJni1Oa2bdv45ptv\n6N+/PwUKFGDGjBk899xznDx5kkceeQSAM2fO0KhRI65cucJrr73GY489xp9//smyZcuIjo6mYMGC\n3LhxgxYtWnDmzBlef/11ypUrx44dO3jnnXf466+/mDrVeYmgRYsWce3aNV5//XWMMXzwwQd07tyZ\nY8eO4ebmxuuvv87p06cJDQ1l0aJFyf4l/fnnn3Pr1i1ee+01cufOTeHChbly5Qqff/45PXr0oF+/\nfly9epXPPvsMf39/9uzZQ+3atSlWrBiffPIJr7/+OgEBAQQEBABQu3ZtIPnxAa+88goLFy6ka9eu\nvPnmm+zevZsJEyZw4MABli9f7qhnjOHw4cN06dKFV155hZdffpnPP/+c3r1707BhQ6pXr57qZ9yn\nTx8WLFhA+/bt6du3L7GxsWzbto1du3ZRv359l8QyevRoJk6cSL9+/Ryf848//sjevXtp1aqVSz+L\nlMRf/65du1K5cmUmTpzI3r17mTdvHiVKlGDChAmpXsccIyOZCdAfiARuADuBhgm2/QfYlKi+Fdtt\nloSvY4nqdAYO2NvcB/jdJQbtycjBXNGTYbVapVev3vHZt7Ru7e/0V2RWSdyTce7cOcmdO7e0bdvW\nqd7s2bPFYrHI/PnzHWU+Pj5isVhk0aJFjrKYmBgpVaqUdOnSxVE2ZcoUsVgssmrVKkfZrVu3pHr1\n6mKxWO7ak/Hss8+Kp6enREZGOsrOnDkjBQsWFB8fH6dzMcaIn5+f0/7Dhg0TDw8PuXLlilPsCXsf\n1q9fLxaLRUJCQpz2rVOnzl17KTLak/H555+LMUY++uijFOusWLFCjDEyYcIEp/IuXbqIm5ubU4+H\nMUY8PT3l+PHjjrJ9+/aJMUZmz57tKOvZs6e4u7vL3r17Uzzu2LFjpUCBAnL06FGn8nfeeUc8PDzk\njz/+EJE7f/kWK1ZMLl++7Ki3cuVKsVgssmbNGkfZgAEDHH8xJxTfhpeXl1y4cMFpm9VqTfJ9cfny\nZSlZsqS8+uqrjrLz588n+es5XlBQkNNxf/nlFzHGyGuvveZUb8SIEWKxWOT77793lFWsWFEsFots\n377dUXbu3Dnx9PSUESNGJDlWQps2bRJjjAwdOjTFOq6IpW7dutKxY8dUY3PlZyGStCcjKChIjDHS\nt29fp3oBAQFSrFixVGPNST0ZGRr4KSJzRKSiiOQRkaYi8mOCbb1F5OlE9S0i4pboVTlRneUi8ri9\nzdoiEpKR2NT95eLFi/To8QLVq9fmnXfeIS4uLsW6x48fZ8GC/wCTgS/YsGEdO3bsSLV9EeHcuXPc\nunUrcwNPIDQ0lNu3bzNkyBCn8r59+1KgQAHWrFnjVJ4/f36ef/55x3sPDw8aN27MsWPHHGUhISGU\nKVOGDh06OMpy5cpF375379yzWq1s2LCBTp06UaFCBUd5yZIlef755wkLC+PatWuOcmMM/fr1c2rD\n29ubuLg4Tpw4keJxfH19KVWqFIsWLXKU7d+/n3379vHSSy85ykSECxcuOF7nz5/n1q1b3L5926n8\nwoULxMbGpnpu33zzDcWKFWPAgJSX0Fm7di3u7u4MHDjQqXz48OFYrVbWrl3rVN66dWsqVqzoeF+r\nVi0KFizo+DxEhG+//ZZnnnmGevXqpXjcZcuW4e3tTaFChZzOqVWrVsTGxiaZxdG9e3cKFizoeO/t\n7Y2IOH0d3M1zzz1H4cKFncqMMY4ePhHh0qVLxMTE0LBhQ/bu3ZvmthP67rvvMMYwdOhQp/Lhw4cj\nIkm+xmvUqMGTTz7peF+0aFEee+yxu57b8uXLsVgsBAYGZmksXl5e/Pbbbxw5ciTV+FLjis/CGMNr\nr73mVObt7c2FCxecvodzMp1dorLVP//5Bl9/vZYDB+ozceIHzJ49O8W6dwZG/Q2cSVSW1I0bN/D1\n9aN48eIULVqC0NDES7FkjvhfxI8++qhTuYeHB5UrV07yi7ps2bJJ2njkkUe4dOmSU5tVqlRJUq9q\n1ap3jefcuXNER0cniQegevXqWK1WTp065VRerly5JPEATjElZozhhRdeYMWKFdy8eROw3QLIkycP\nzz33nKPeyZMnKVasmONVvHhxvvzyS7Zv356k/G5J49GjR3nsscdSnV554sQJSpcuTb58+ZKce/z2\n1M49/vzjz/3cuXNcuXKFmjVrphrb4cOHWbdundM5FStWjNatW2OM4e+//071uF5eXkDq1zyxhMlR\nQgsWLKBOnTp4enpSpEgRihcvzpo1azI82O/EiRNYLJYkX38lSpTAy8sryTUtX758kjYSf40n59ix\nY5QuXdpxLbIqluDgYKKionj00UepXbs2b731Fr/++muqsSbmqs8icfxp+d7MSXLGDW310Prpp33E\nxQUA/8bNbU+q39hly5bl3XffZdy4cQD06tWbf/zjHynW/+yzz9i8eRPwGdevL6BPn36cPJn2vxJd\nJX58RmKSjtHrmS2jMfXs2ZPJkyezYsUKunfvzpIlS+jYsSMFChRw1ClZsmSSBG/SpEmcPXuWqVOn\nOh2jTp0693AWGZNZn4fVaqV169b861//SnbfxElfZhw3T548Scq++OILevfuTUBAAG+99RbFixfH\nzc2N8ePHp6uXJDlpXcchK77GMzMWb29vjh49yrfffsv69ev57LPPmDZtGnPnzqVPn2QXs07CVZ9F\nTvx5kR6aZKhs1aGDP9Onf4TFspu4uAj8/FKfhz527Fhee+01bt++7Rjkl5IrV65gjCcivojs5MqV\n3zIzdIf4WxIHDx50+mvm9u3bHD9+nNatW2eozYiIiCTlhw8fvuu+xYoVI2/evBw8eDDJtoiICCwW\nS7J/vWdEzZo1qVevHosWLaJMmTKcPHkySW9U7ty5k6wU+t///peYmBhatmyZruNVqVKFPXv2EBcX\nl+IP3woVKrBx40auX7/u1JsRfz0T3kJKi2LFilGwYEH2799/19iuXbuW7nNKTUYWZ1q+fDlVqlRh\n2bJlTuWJb0Gkp+0KFSpgtVo5fPgwjz32mKP877//JioqKt3XNCVVqlRh/fr1REVFpdib4apYvLy8\n6NWrF736O+unAAAgAElEQVR69SI6Ohpvb2+CgoIcSYYrP4sHmd4uUdlq0qQPmDz5A156qSFLly51\n6mZPSdmyZe+aYIBtdkPhwvmBCsA83nlnxL0HnAxfX188PDyYMWOGU/m8efO4cuWK07iKtPLz8+PP\nP/9k1apVjrKbN28yb968u+5rsVho06YN3377rdPS52fPnmXJkiV4e3uTP3/+dMeUkpdeeomQkBCm\nT59O0aJF8ff3z7S2E+vcuTPnzp1j1qxZKdZp164dsbGxSepMmzYNi8VC27bpe8CzMYZnn32WVatW\npXofvWvXruzcuZP169cn2Xb58uVUxxulJD5JunIlpcc+JZVc8rV792527tzpVJY3b14AoqKi7tpm\nu3btEBGmT5/uVD5lyhSMMbRv3z7N8aWmc+fOWK3WVFfWdEUsFy9edHqfN29eqlat6jSWy5WfxYNM\nezJUtnJ3d2f48OEuabt8+fL89ts+Nm3aRPny5Z0Gf2WmokWL8s477xAcHIy/vz/PPPMMBw4c4OOP\nP6Zx48a88MIL6W7ztddeY9asWXTv3p3Bgwc7BljGd8ne7a+qcePGERoaSrNmzejfvz9ubm58+umn\nxMTEMGnSJKe6KXW7prU79vnnn+ett95ixYoVjmO5Ss+ePVm4cCHDhg1j9+7deHt7c+3aNTZu3Mgb\nb7xBx44d6dixIy1btmTUqFEcP37cMYV11apVDB06NE0JamLjx49nw4YNtGjRgn79+lG9enVOnz7N\nsmXL2L59OwULFmTEiBGsXLmSDh068PLLL9OgQQOuX7/Ovn37+Oabb4iMjEwyMPBuGjRogIgwcOBA\n/Pz8cHNzo1u3bqnu06FDB7755hueffZZ2rdvz7Fjx5g7dy41a9Z0Gizo6elJjRo1WLp0KdWqVaNw\n4cI88cQTyY49qV27Nr169eLTTz/l0qVLPPXUU+zevZuFCxcSEBDAU089la7zSomPjw8vvfQSM2bM\n4NChQ/j7+2O1Wtm2bRtPP/00/fv3d0ksNWrUwMfHhwYNGlC4cGF++OEHli1bxqBBgxx1XPlZPNBc\nOXXFlS90CmuO9jAuxjVnzhypUaOG5M6dW0qVKiUDBgxwmqIoYpsGWrt27SRtvvzyy1K5cmWnssjI\nSKfFuIYPHy7Lly8Xi8Uie/bsuWucP//8s7Rt29axGJevr6/s3r072XNJ/Dl9//33SabK+vj4yNNP\nP53ssdq3by8WiyXJYl8pudfFuN577z3HQkylS5eWbt26OU1DvX79ugwfPlzKli3rWIxr6tSpSdqy\nWCwyaNCgJOWVKlWSPn36OJWdOnVKXn75ZSlRooTkyZNHqlatKoMGDXKaonj9+nUZNWqUY6Gw4sWL\nS/PmzWXatGkSGxsrIrbP1WKxpBhPcHCw431cXJwMHjxYSpQoIW5ubk4LQKXUhojIxIkTpVKlSpIn\nTx5p0KCBfPfdd8l+je3atUsaNWoknp6eYrFYHFMog4KCxM3NzaluXFycjB071nHdK1SoIO+++67E\nxMQkuXbPPPNMkphS+/pJyGq1ypQpU6RGjRri6ekpJUqUkPbt28tPP/3ksljGjx8vTZo0kcKFC0u+\nfPmkRo0aMnHiRMdnFn9MV34WiT/7+GnEiafFpvTzJ6GcNIXVyH0yeCQxY0x9IDw8PNyxQIvKOfbu\n3UuDBg3QzydzTZ8+neHDh/PHH39QqlSp7A7HISAggP3793Po0KHsDkWph15afv7G1wEaiEjG5jan\ngY7JUCqHip8WmvD93LlzqVatWo5KMM6cOcOaNWvo2bNndoeilMphdEyGUjlUQEAA5cuXp27dukRF\nRfHFF19w6NAhx7Ld2S0yMpKwsDDmzZtHrly5kizopZRSmmQolUP5+/szb948Fi9eTFxcnGOQXlpm\n4GSFLVu20Lt3bypWrMjChQspXrx4doeklMphNMlQKocaNGiQ0+j2nCZ+TQGllEqJjslQSimllEto\nkqGUUkopl9AkQymllFIuoUmGUkoppVxCB34ql0ruIV9KKaVcJyf93NUkQ7lE0aJFyZs3Ly+++GJ2\nh6KUUg+dvHnzUrRo0ewOQ5MM5Rrly5cnIiKC8+fPZ3coSt3XYmNj+fzzz/nl55+pU7cuffr0YfCg\nQZir0cwa8hYDpk8iLp8ndevVY82a7zAIVjGcPl0OmAUMoHFjK/Xq1eXnn3+hbt069OnTB3d3/fH/\nICtatCjly5fP7jA0yVCuU758+RzxRa7U/Sw4OJh58+bhW78R8+bNo3Tp0rRt147g4GBG/ns2ew7+\nTosWLfj3vz9DxBdjQvHxacGZM1sRGYkxe2jfPpDAwMDsPhX1ENIkQymlcrDtYWH41m/Euskz8R8x\nkO1hYaz57jvHtsDAQLZtC0PEF1iHiD9ublaCggIJC9tO8+aBjBw5MntPQj20dHaJUkrlELGxsQQH\nB+PXpg3BwcHExsbSrHlzQvf+gP+IgYTu/YFmzZs76gsGgGbNnsSYUMAfY0Lx9m5OYGAg69eHEBgY\nqLdGVLbRrzyllMohxo8fT3BwML71GxEcHAzg6IWI77UYOXIk48ePJygoGBFfQkODee+9UdpzoXIk\nTTKUUiobxMbGMn78eLaHhdGseXNGjhyZ7K0Rd3d3R2IRFrad8ePHJ7k9snPnLtavD8nuU1IqCb1d\nopRS2SC+18JEXSU4OJjx48eneGskvudiwwZDUFAwcXGxTrdHmjdvlr0no1QKtCdDKaVcLK29FgkH\ndI4aNQqr1UqbNn4cPXoUkaeJ77mwWOL09oi6L2iSoZRSLhbfa9G0xhOMHj2a8+fP06x5c4KDgx29\nFvEDNOOnmgYHBzvGXUAkcIz4nosWLXRKqro/aJKhlFKZLHHPRdg2W69Fkxq1CPv1F75bs4YDBw8C\ndwZ0vvXWWwQHB9t7J5o5jbsAfypXPkqVKqI9F+q+okmGUkplssSzRFq0aMHWvT+w69efAYi+csWp\n1wKcey5CQ4Px8WmBMVsRsfVe9OqlvRfq/qMDP5VSKpMlHG/hW78RbhYL/fv35/LNm/QCzpw/z6FD\nh5z2CQvbnmDGiC8WixtBQYG0bi0EBWnvhbo/aZKhlFL3IC0LaHm3aEHJkiXJ5+bGVCCvxcLy5csd\n+7Zp40ds7G1gA3fGXXjrglrqvqdftUopdQ/SuoDWPxo0oJ3VSmGgndXK8qVLuX37tuMWiTFbadny\nKdzdddyFenBokqGUUumQeFDntq1b8a3fiBXjPuSpwa+xevVqWrVq5XgBrF27lr379vGWvY3OQI9f\nfuGPv84iUh94D5FLXLt2jWnTpmGMITY2Vnsv1H3PiEh2x5Ahxpj6QHh4eDj169fP7nCUUg+J4OBg\nR89F6N4fbIM6t26lWplyHDgZmeJ++S0WTlutFACuAiWB6FSOM2PGDAYOHJi5wStlt3fvXho0aADQ\nQET2uuo4miYrpVQqUuq5iF9Ey+pmmyWydcsWCpUszu49e6hlDHNEKJKgnSL2BAOgALZVLy4m2H4e\n6G8M+0UYOHAgffv2zapTVMplMjTw0xjzhjHmuDHmhjFmlzGm0V3q+xhjwo0xN40xh4wxvRJtdzfG\nBBpjjtjb/MkY45eR2JRSKjMlXv47zmp1GtTZ3P7E09CNG9m1ezfffvstpwsWpLubG2eB6vaXF9AL\nWGpvt0SCbX8B3d3dOVOoECtXrmTGjBl4enpmx+kqlanSnWQYY7oBU4DRQD3gFyDEGFM0hfoVgdXA\nRqAO8BEwzxjTOkG194G+wBvYvufmAv8zxtRJb3xKKXUvEs8WiV9IK346qru950K8CjgGdcaLiori\n+PHjFCzsxZm4OJ4G3sPWS+EPfJnoWLeBd4FWwGNPPskv+/fTsWPHLDpTpbKAiKTrBewCPkrw3gB/\nAG+lUP8DYF+isiXAdwne/wm8nqjOMmBhKnHUByQ8PFyUUiqzjBkzRtzc3MSvURNxc3OTli1bOr0f\nM2ZMsvutW7dOChbMJ+7uRlq2NPLee0jbtogBKQbiBbIFRBK8RoJYjJH3339fYmNjs/hM1cMsPDxc\nAAHqSzrzgPS80jUmwxjjATQAxidIUsTYHgfYNIXdmgChicpCgGkJ3ucGbiWqcwNonp74lFIqvVJa\nAjx+zEWcxUJgYKDTdNTEQkJC6NChPQ0bCiNGCIUL28q9vGDtWrACO7B10yZU0f5v3759cXNzc91J\nKpVN0nu7pCjgBpxNVH4W22Dp5JRMoX5BY0xu+/sQYJgxpqqxaQ0EAKXSGZ9SSqVL4jEXsXGxSRbS\nCgwMJGT9+mQXxYqKiqJr1840bCiMG2d1JBh79sDbb9v+fwu2BOM68IX9X4Bn7f+uWLHC5eepVHbI\nKbNLBgOfAgewJf1Hgc+BPnfbcejQoRQqVMiprEePHvTo0cMFYSqlHjSJH7melp6LhBYsWEB0dDQj\nRgjxnRHffQdTpkCB/FA7FmoK/Ax0c4NDcVAF2/3gusBTFgvLv/pKZ5Mol1myZAlLlixxKrt8+XKW\nHDtd62TYb5dEA51FZGWC8vlAIRHplMw+W4BwERmWoOxlYJqIPJKobi6giIicMcZMBNqLSK0UYtF1\nMpRS6Zb49khcXBzvv/++Y92LwMC0P4hMRHj88WqUKXOMwEBBBObPh4ULwc8PQtfDRwJxwAgDFSpC\n774w8X24cR0+xNadPNTNjb/PneORRx5J9XhKZZasWicjXbdLROQ2EI5tMDQAxhhjf78jhd12Jqxv\n18Zenrj9GHuC4YFtUTztQ1RKZarEt0eMMSnOFrmbCxcucOjQUVq0EG7fhg8+sCUYr74KdepAnMB8\nY+uq7RgAsz6Bpk1hwGDbzJLBwAJjiI2LY+XKlXc5mlL3n4zcLpkKzDfGhAN7gKFAXmA+gDFmAlBa\nROLXwvgEeMMY8wG2WyCtgOeAdvENGmMaA2Ww9SiWxTY91gCTMxCfUko53G1g584dOwhZvz5DbV+7\ndg0ADw945x345RcYORJat4aR9vEYR/LB+JG25CJefIfFvHnzePvNNyEqirfefJMTJ04wcuRIXU5c\nPTDSvU6GiHwFvAkEAz8BtQE/ETlnr1ISKJegfiTQHvDFlkQMBV4RkYQzTjyBccBvwHLgFNBcRK6k\nNz6llErobgM7mzXP+CS2/PnzAzBzJhw4AJMm2RIMgOPHoUFdmDffOcEAuHrV9u+zzz5Lr1dewQKc\nO3+NoKBgxo8fj1IPigylyyIyB5iTwrbeyZRtxTb1NaX2tgI1MxKLUkollrD34ujRozxdr2GGB3am\n5vTp07i7uxEVFcfHH0OlSne2fT4fPD3BmKT7bdtmePTRyhQuXJh9+37FShtgOchzhIVtz/D5hoVt\np3nzZtobonIM/SpUSj1wEj5+PTIykmPHjzt6LtIzsDM1GzduJCAggBIlSvLXX3+SaJIbefIkv9+F\nC7BtG0yZMghjDM2bNyM0NBiR5zAmlObN0x/b+PHjHY+MDw21PW4+M85RqXuVoWeXKKVUTpNwOfD/\nLlx4ZynwBo2pUrlyhgZ2pmThwoX4+/vTtGlTdu7cSb58+Zg82UJcXOr7xcXBlCkW8ubNS8+ePQEY\nOXIkQUGBtG4tBAVlLL6wsO2I+ALrEPFNtTck/jq1aeNnu30UG5vu4ymVZq5cTtSVL3RZcaVUAgmX\nAzfGiJvFctelwNPLarXK2LFjBZBXXnlFYmJiRMS2pLi7u5s0aWKRZcuQzZuTvpYtQ5o0sYi7u5uE\nhIRkSjzxxowZI8a4CfiJMamfb3rqqgdXjlxWXCmlcqqEi2q1eXMAxy6ey9Tei9u3b9O/f3/mzZvH\n2LFjGTVqFMY+4MLPz4/Vq9fQtWtnunePxtsbvL2FAgVsgzy3bTNs2wZ58+ZhzZpvaNOmzT3Hk1D8\n+dnGZKR+vs69Hv4ZGgOiVFppkqGUui8lnprapGlT3n//ffxHDGTTTz9m2tgLgKtXr9K1a1dCQ0NZ\nsGCB41ZHQn5+fpw48QcLFy5k9uwZBAcfdWx79NHKTJkyiF69eiVZoTgzuLu7p/lcmzZtwoYNY4Fi\nwAWaNn0v0+NRKp6OyVBK5SiHDh2iZMmSHDp0KNV6mbmoVmpOnz5NixYt2LFjB+vWrUs2wYjn5eXF\noEGDOHDgMOfPn+f48eOcP3+eAwcOM2jQIJckGOll632xYJvwZ3H0xijlCtqToZTKURYvXszZs2dZ\nsmQJo0ePdtqW2tTUe1lUKyW//fYb7dq1Iy4ujrCwMGrVSvYpB0kYYyhSpAhFihTJ1Hgyg+32SEVs\nt+Mr6u0S5VLak6GUylGWLV3m9G9CCXsvIiMjCQ3fkymLaiVn8+bNNGvWDC8vL3bt2pXmBCOns1rj\ngOPYFlU+bn+vlGtokqGUyjEOHjzIbwd+ww8/9kfs59ChQ1k6NTXe4sWL8fPzo1GjRmzdupWyZctm\nWtvZzRg3oDWwDmhtf6+Ua+jtEqVUjrF8+XLyuOWhf1x/tli2sHz5cm7fvu1YWOvosWMcd8HCWvFE\nhIkTJzJy5Eh69erFp59+Sq5cuTKt/ZxAJA7YBPgDGxB5KpsjUg8yTTKUUjnGsqXLaGxtTEEK8g/r\nP5j10SxiYm9RsUQpVk+YRru3h2T61NR4sbGxDBgwgLlz5xIYGEhQUNADOijSAIWwPVC7kP29Uq6h\nSYZSKsvcvHmTvXv3xi+o5+TixYv8tO8n3sM2pbIFLdhydgv1qj3Gz4cPUqHbM/x16QK9e/emd+/e\nGGOIjY3NlGd0XLt2jW7duhESEsJnn31Gnz597rnNnEuAy9humWywv1fKNTTJUEplmX//+98MGjQo\nxe15LXlpYm0CQBOa4IknPx0+CMDpC7YHPX/22Wd89tlnAMyYMYOBAwfeU0x//fUXHTp04ODBg6xZ\nswY/P797ai+nc3Nz586YDH/c3KzZHJF6kGmSoZTKMn379uXQoUPMmjWLyqYyQ2QIBSno2F7QWpBc\n5OJP/qQMZVjEIq5y1bH9MpeZbqZzXI4zcOBA+vbte0/xHDhwgLZt23Lr1i22bdtG3bp176m9+8GT\nTzYlNPTOYlxPPqmLcSnX0dklSqks4+npycyZM/n222+JKhTFWPexXOISFez/5SMfoxnNUIYSQwyF\nKezYdpGLjHMfx+VCl1m5ciUzZszA09Mzw7Fs27aNJ598knz58rFr166HIsEAXYxLZS1NMpRSWe6Z\nZ55h3/591Ghag2EM43M+5xrXeId3+JEfeZM3yYVtVkcssXzGZwxnODWfrMm+/fvo2LHjPR1/6dKl\n+Pr6UrduXcLCwihfvnxmnNZ9Yfv2HYDt2SXga3+vlGtokqGUyhZlypRh4+aNjHt/HP/lv/ShDxFE\n8AEf0JjGjnrzmc9is5hx748jdFMoZcqUyfAxRYQPP/yQ7t2707VrV9atW4eXl1dmnM59Iy4uFtuA\nT9sUVtt7pVxDkwylVLYREU6fPg3AVa4yhSnUxfm2RUlKArbxHG5uGV84Ki4ujoEDBzJixAhGjRrF\nwoULH7g1MNJGp7CqrKNJhlIq27z99tvMnj0bgIlMpDrVucENNrCBG9wAoDm25cJXrFiR4eNER0cT\nEBDAJ598wty5cxk3btxDPBYhfgprA/u/OoVVuY4mGUqpLBcbG8uwYcOYNm0aFmOoYapThzoc4Qj9\nLP0Yz3hed3+dIxzBCy/qWOqw7KukzzJJi7///puWLVuyceNGVq5cSb9+/TL5bO4vuqy4ykqaZCil\nslzCBMMqgq+0ZjnL+af5J0VqFmH16tV4PeZFf0t/lrMc7zhvNm3exKVLl9J1nEOHDtG0aVNOnjzJ\n1q1badeunYvO6P5hW1b8zpgM23ulXEOTDKVUltq3bx9z584ln2ceJvYbAMA61jGLWfxzwD/Z/cNu\n2rdvz+4fd9N/YH9mMYsQE0JsXCwrV65M83G2b99O06ZNyZ07Nzt37qR+/fquOqX7isXiBlTCdpuk\nkv29Uq6hSYZSKsvs2LGDJk2aYIDrN2/wwaKFAPzp+SerV69mxowZ5M6dG7CtqTF9+nRWrVrFea/z\nACz7Om23TJYvX06rVq2oVasW27dvp2LFiq44nftSs2ZPAseAvcAx+3ulXEOTDKVUlti6dSstW7bk\nxo0bNKtZGzeLhajoa1SuWJmIQxG0b98+2f06dOjAvv37aPlUS37b/9tdjzNt2jS6dOlCp06dCAkJ\n4ZFHHsnsU7mv6WJcKitpkqGUcikR4auvvsLPzw+LxcLT9RqycdrH+DZojLd3c44cO0K5cuVSbaN0\n6dJs3LyRffv3pVgnLi6OIUOGMGzYMN566y0WLVrk6BVRd+hiXCoraZKhlHKJqKgoPvroI8qUKkO3\nbt24efMmN2/e5Puf9lL9pefY8ONunvLxSfNf0sYY8ufPn+y2Gzdu0KVLF2bOnMns2bOZOHEiFov+\neEuOLsalspI+IE0plelCQkLo0rkL165fQxDKUpaneIoYYvid3/n91O9YjIWGDRve87HOnTtnW6Z8\n3z5WrFhxz0uOP+iMsZBw4KftvVKuoUmGUipThYSE0KF9BwpbC3OVq9SlLs/wDBZ7x2lNanKVq6xk\nJf/3zP+xes3qDD9e/ciRI7Rt25YrV67w/fff06hRo8w8lQeSiBU4DlQFjiPy8Dy3RWU9TWGVUpkm\nKiqKLp274GX14m/5m8Y0dkow4hWgAN2lO5WlMl06dyEqKirdx9q1axdNmzbFYrGwc+dOTTDSTJcV\nV1lHkwylVKaZP38+165f47ycxxtv2tI2SYIRzw03Olo7Eh0dzcKFC9N1nBUrVvD000/z2GOPsWPH\nDipXrpwZ4T8kdFlxlXU0yVBKZQqr1cqYoDEIQiv7f+YufyUXoADVqc6sGbMQSdsvu5kzZxIQEECH\nDh0IDQ2lSJEimRH+Q0PHZKispF9dSql7ZrVaeeWVV4i6HEVd6uKNd5r3fVwe5/DRw1y8ePGux3jz\nzTcZNGgQw4YN48svv8TT0/NeQ3/o3BmTYbCNybBmc0TqQaYDP5VS9yQ2NpY+ffqwaNEiAGpRK137\n5yEPAFevXk2xV+LmzZv07NmTZcuWMWPGDAYOHHhvQT/E3NzcufOANH/c3DTJUK6ToZ4MY8wbxpjj\nxpgbxphdxphUR1wZY3yMMeHGmJvGmEPGmF7J1BlijDlgjIk2xpw0xkw1xuhKOkrlYLdu3aJbt24s\nWbKETz75BICb3ExXG/GPdC9QoECy2y9cuICvry+rVq3im2++0QTjHtmWEQ/Ftk5GqC4rrlwq3UmG\nMaYbMAUYDdQDfgFCjDFFU6hfEVgNbATqAB8B84wxrRPUeR6YYG/zcaAP0BV4P73xKaWyRnR0NP/3\nf//HmjVr+Oabb3j11VepVqUaESYiXe0cMAeoVqUahQsXTrLt2LFjNGvWjIMHD7J582aeffbZzAr/\noWUb+2LFNrvEmuaxMEplREZ6MoYCc0VkoYgcAF4HorElBsn5J3BMRN4SkYMiMhtYZm8nXlMgTESW\nishJEQkFvgQaZyA+pZSLXblyhbZt27Jt2zbWrFlDx44dMcbwxsA3iCCCq1xNUztXuUoEEQwYNCDJ\nyp8//PADTZs2JS4ujp07d9KkSRNXnMpDx7aMeGWgPlBZlxVXLpWuJMMY44Ft3tPG+DKxpcGh2BKF\n5DSxb08oJFH9HUCD+NsuxpjKQDtgTXriU0q53sWLF/H19eWXX35hw4YNtGrVyrGtV69e5M2bl1WW\nVcQRl2o7ccSx2rKavHnz0rNnT6dtq1atwsfHhypVqrBz506qVq3qknN5GFmtcSQc+Gl7r5RrpLcn\noyjgBpxNVH4WKJnCPiVTqF8wfsyFiCzBdqskzBgTAxwGNovIB+mMTynlQmfPnsXHx4djx46xadMm\nnnzS+X6+l5cXXy//mmPmGEstS1Ps0bjKVZZalnLUHGXZN8vw8vJybPv444959tln8fPzY+PGjRQt\nmuydWJVBxrhxZ+Bna/t7pVwjR8wuMcb4ACOx3XrZg2292xnGmDMiMi61fYcOHUqhQoWcynr06EGP\nHj1cFK1SD6dTp07h6+vL1atX2bp1KzVq1Ei2np+fH6vXrKZL5y5Mj55OdarzuDxOHvJwgxv8zu9E\nEEEut1ysWb2GNm3aALYpqu+88w6TJk1i8ODBTJkyBTc3/QWY2UTigE3EPyBN5Klsjki52pIlS1iy\nZIlT2eXLl7Pm4CKS5hfgAdwGnklUPh/4Xwr7bAGmJip7GbiU4P1WYFKiOi8A11KJpT4g4eHhopRy\nrSNHjkiFChWkQoUKcuTIkTTtc+nSJfnoo4+kWpVqgm3lJwEkX648kje3p1SsWFFu374tIiI3b96U\n7t27izFGpk2b5spTeei1bPm0wCMCRQUekZYtn87ukFQ2CA8Pj/+erC/pyAPS+0rX7RIRuY1tSLLj\nJqyxjdZqhW1cRXJ2Jqxv18ZeHi8vkPh5w9YE7Sulssnvv/+Ot7c3uXPnZtu2bVSpUiVN+3l5eTFo\n0CAOHj7I+fPnGTJkCADRt2/iXbsup06eZPz48Vy6dIk2bdrwv//9j6+//tpRT7mKLiuusk5GZpdM\nBfoaY3oaYx4HPsGWJMwHMMZMMMYsSFD/E6CyMeYDY8xjxpj+wHP2duKtAvobY7oZYyrap7cGAytF\ndH6VUtll7969tGjRgqJFi7J161bKlSuX7jaMMRQpUoTJkydTtUoV2jT8B+smz8S3QWNCN2ygWbNm\n7N+/n40bN9K5c2cXnIVKyHkxrtb290q5Rrq/ukTkK/uaGMFACeBnwE9EztmrlATKJagfaYxpD0wD\nBgF/AK+IbZpqvLHYei7GAmWAc8BK4N10n5FSKlPs2LGDtm3b8vjjj7N27dpk17FID3d3d17q2ZPg\n4GD8Rwxkw4+7MRYLBQsWJCwsLMUxHipzNWv2JKGh47izGJf+mFWuk6EUVkTmAHNS2NY7mbKt2Prm\nUmovPsEYm5F4lFKZa+PGjTzzzDM0bNiQ1atXp7gaZ3qNHDkSgE8+/hirCAVze3L58mWWLVtGYGBg\npqd49I0AACAASURBVBxDpU50MS6VhfQBaUopJ6tWraJ9+/a0aNGCtWvXZlqCAbbejFKlSvHX2bMU\n8/JiYEBXChcoyMIFC4iNTTwsS7mCLsalspImGUoph6VLlxIQEEC7du1YsWIFefPmzbS2RYR3332X\nfv360ahRI85FRTFh8QIaPPo4kZGRjB8/PtOOpVKmi3GprKRJhlIKgP/85z88//zzdO/ena+++orc\nuTPv+YQxMTH07NmT999/n8mTJxMWFkbVKlVo3aAx6ybP5On6jVi4YAF+bdoQHBysvRouZIwFqIRt\nVkkl+3ulXEO/upRSzJw5kz59+tC3b18WLFiAu3vmzTiIiorC39+fr776ii+//JI333wTDw8PXurZ\nk9C9P+A/YiCh4XuIjIzERF0lODhYezVcyDYE7k5Phu29Uq6hc5eUesiNHz+eUaNGMXz4cCZPnpzk\nQWX34tSpU7Rt25bTp08TGhqKt7e3Y1v8INDtYWFUqVyZKoWLsXrCNB7v2YWZM2Y46mRmwqO0J0Nl\nLf3qUuohJSKMHDmSUaNGERQUlOkJxs8//0yTJk24fv0627dvd0owwDYINDAwkJD16x29Go/37MLx\nM3/SoHI17dFwEe3JUFlJkwylHkJWq5XBgwczYcIEPvzwQ0aPHp2pCUZISAje3t6UKlWKnTt3Ur16\n9VTrjxw5ksDAQC7fukHr+MW66jdie1hYpsWkbHQxLpWVNMlQ6iETFxfHq6++yqxZs/jkk08YPnx4\nprb/+eef0759e5566qn/b+/ew6Oq7v2Pv1cCBS+ItlRBvKBYivVHLaBAEgLRhJAQBIQCchGhoIIV\nRBFowYJGCnpQqaLcLCggBkQUwSCXhEtCLmKhyjkocDzAo3IrXgARBDKzfn/MIJNILpPMnpkkn9fz\n5Gn3zNor31nObL7Zs9Z3sXHjRurXL26D5vPO3dUYPmLE+Xka2z7ibEGBJoMGWExMNJDB+WJc0aWc\nIVJ+SjJEqpGzZ8/Sr18/FixYwIIFC3jwwQcD1re1lokTJzJ48GCGDBnC8uXLufTSS/3q49wdDXt5\nHdq1a8emTZs0GTTAVIxLgklJhkg18eOPP9KjRw/eeecdli5dSv/+/QPW95kzZxg0aBCpqalMmTKF\nmTNnlmvCpu88jZo1avy0xDWhxe1kZ2WRmpqqOxsVpGJcEkxKMkSqgRMnTtC5c2fWrVvHihUruPvu\nuwPW9/Hjx0lJSeHNN99k0aJF/OUvfwnI/I6Ytm0LfXXicrtJTU3VnY0KUjEuCSYlGSJV3NGjR0lM\nTOTDDz9k9erVJCUlBazvr776itjYWD766CPWrl1L3759A9a371cnEyZMoEZkDRJa3P7TnY2FCxbo\nrkY5GBOJ78RPz7GIMzStWKQKO3LkCB07dmTfvn1kZmbSqlWrgPW9fft2OnXqREREBDk5Odxyyy0B\n6xvOf3VyTmpq6k87uGZs3YLbWhr/8tekpqYCaIO1MrLWBazHM/FzHda2D3FEUpUpyRCpog4cOEBC\nQgLffPMNGzdu5Pe//33A+s7IyKBHjx7ceOONpKenc/XVVwes7+L4Fu9q1KgRN/7y16yeOp2k0cPJ\n2byZgoICJk+eTM7mzcS0batCXsUyQF08Ez/reo9FnKGvS0SqoH379hEbG8v3339PdnZ2QBOM+fPn\nk5ycTFRUFFlZWUFJMKDwpNAB993H+n//66f5GjFt2zJ58mTN2SgTCxwDWnr/V6tLxDlKMkSqmF27\ndhEbG4sxhuzsbJo0aRKQfq21PP300wwcOJD77ruPlStXBnQbeH8Una8xbtw4cjZvLjRnQ4W8LkzF\nuCSYlGSIVCHbt2+nXbt2XHbZZWRlZdGoUaOA9Hv27FkeeOABJkyYwNNPP82rr75KzZo1A9J3efje\n1ZgwYQI1atQovBpl6xb+7//+T5NCL0DFuCSYlMKKVBFbtmwhKSmJRo0asXbtWurVqxeQfr///nt6\n9epFRkYG8+fPZ8CAAQHpN9DOzdlYuGABbmu5UZNCL0jFuCSYdCdDpArYtGkT8fHx3Hzzzaxfvz5g\nCcaBAwdo164dubm5rF69OmwTDDh/d+OGG24k8bbWrH3uZRJa3M7mbH1t4is3Nw9IBI4Aid5jEWco\nyRCp5M7VvmjdujVr1qzh8ssvD0i/O3bsICoqiiNHjrB582bi4+MD0q/TClwFrPvXhySNHs66f31I\ngUtfl/hyuQqAdZxbwurS+IiDlGSIVGLvvPMOXbp0oUOHDrz//vt+7xVSnA0bNhATE8Pll19Ofn4+\nzZo1C0i/wWCAupfWYevundS9tI4WaP6MlrBK8CjJEKmk3njjDXr16kX37t1ZtmwZtWvXDki/b775\nJh07dqRVq1ZkZ2dzzTXXBKTfYLHAsRPf07JJU46d+F4LNH9GS1gleJRkiFRCs2fPZsCAAdx3330s\nWrQoICs9rLVMmTKFfv360a9fP9LT07nssssCEG1wRUZE0uG21qyeOp0Ot7UmMkJls32prLgEk5IM\nkUrm+eefZ+jQoQwfPpxXX32VyMiK/yNRUFDAsGHDGDduHBMnTmTevHkhXaJaES63q9CcDJc2ACvE\nU1b8/JwMz7GIM7SEVaSSsNby1FNP8dRTTzFu3DgmTZoUkN1OT5w4Qe/evVm7di3z5s1j0KBBAYg2\ndCIjIrihQUMscEODhkRG6G8pXxERkcANeL4mucF7LOIMffpEKgFrLY8//jhPPfUUkydP5u9//3tA\nEoxDhw4RFxdHVlYW6enplT7BAM8W8fsOHcAA+w4dIKZt21CHFFbato0B9uGZ8LnPeyziDN3JEAlz\nbrebhx56iNmzZ/PSSy8xfPjwgPT72WefkZyczNmzZ8nOzuYPf/hDQPoNNWstbmvZunsnbmtVbKoI\nFeOSYNKdDJEwVlBQwH333cerr77KvHnzApZgZGVlERMTQ506dcjPz68yCQZAXm4eibe15sh760i8\nrTV5KjZViIpxSTApyRAJU6dPn6ZXr14sXryYtLS0gH2VsXjxYjp06EDz5s3Jzs7m2muvDUi/4ULF\nuEqmYlwSTEoyRMLQyZMn6dq1K6tWreLdd9+lV69eFe7TWsvUqVPp06cPvXr14oMPPghYddBwomJc\npVExLgkeJRkiYeb48eMkJyezefNm0tPT6dy5c4X7dLlcPPzww4wZM4bx48ezYMECfvGLXwQg2vCj\nYlylUTEuCR5N/BQJI99++y1JSUns3r2btWvXEh1d8W24T548SZ8+fUhPT2f27Nk88MADAYg0fPkW\n40oaPRyXlmgWUrgYVxLGqE6GOEd3MkTCxOHDh4mLi2PPnj2sX78+IAnGf/7zH+644w4yMzNZsWJF\nlU8wQMW4SqNiXBJM5UoyjDF/NsbsNcacMsbkG2NuL6V9nDFmqzHmR2PMbmPMfUWe32CMcV/gZ2V5\n4hOpbL788ktiY2P5+uuvycrKokWLFhXuc/fu3URFRfHFF1+QlZVFp06dAhBp+NOcjNJoToYEj99J\nhjGmN/A8MBFoDnwCrDHG1CumfSPgfSATuBV4EfinMaaDT7O7gfo+P/8PcAFv+RufSGXz+eefExsb\ny5kzZ8jOzuZ3v/tdhfvMyckhKiqKWrVqkZeXF5CkpbLQnIzSaE6GBE957mQ8Csy21i6w1u4EhgIn\ngT8V034YsMdaO8Zau8ta+wrwtrcfAKy1R621/zn3g2cR9w/ediJV1qeffkq7du2oVasW2dnZNG7c\nuMJ9Llu2jPj4eJo1a0ZOTg6NGjWqeKCVSI3IGoU2SKsRqalnviIja+C7QVqkxkcc5FeSYYypiSf9\nzTz3mPWUi8sAooo5rY33eV9rSmgPnoQlzVp7yp/4RCqTbdu20a5dO37961+TlZUVkHoV06ZNo2fP\nntx9992sWbOGK664IgCRVi5R0VGs/deH/LprB9b+60Oioku61FQ/0dFRwFrg18Ba77GIM/y9k1EP\niAQOF3n8MJ6vOS6kfjHtLzPG1Cra2BjTCrgF+KefsYlUGrm5udxxxx00btyYDRs2cNVVV1WoP5fL\nxciRI3nssccYM2YMixYtolatn328qgVjDBHG0LJJUyKMCcgeL1WJZzwi8Py9GKHxEUeF432ywcB/\nW2u3hjoQESdkZGTQtWtXbrvtNt5//33q1KlTof5OnTpFv379eO+995gxYwbDhg0LUKSVU87mzTSq\nfzUWaFT/anI2bw51SGFl8+YcoBGeuRiNvMcizvA3yfgaz4TMon92XQUcKuacQ8W0P26tPe37oDHm\nYqA38ERZA3r00UepW7duocf69OlDnz59ytqFSNCsXLmSP/7xj9x5550sW7aMiy++uEL9HTlyhC5d\nurB9+3bee++9gBTuquxcbjd7D+7npobXsPfgfq777W9CHVJYcbtdwF7gJmAvbvd1IY5InJaWlkZa\nWlqhx44dOxaU3+1XkmGtPWuM2QrEAysAjOdeWzzwUjGn5QHJRR5L9D5eVC/gF8CissY0bdq0ajVz\nXiqvJUuW0L9/f7p06cKbb75Z4a8zPv/8c5KTkzl+/DgbN27k9ttLXElebagYV8lUjKv6udAf3tu2\nbaNly5aO/+7yrC55AbjfGDPAGNMUmAVcDLwOYIyZYoyZ79N+FnCjMeZZY8xvjTEPAX/09lPUYGC5\ntfa7csQlErbmzZv30wd9yZIlFU4w8vPziYqKIjIykvz8fCUYPlSMq2QqxiXB5HeSYa19C3gcSAX+\nDfwe6GitPeJtUh+41qf9PiAFSAA+xrN0dbC1ttCKE2NMEyAaTfiUKuall15i8ODBPPjgg7z++uvU\nqFGxqVDvvvsud9xxB02bNiUnJ4cbbrghQJFWDSrGVRoV45LgKVfFT2vtDGttI2vtRdbaKGvtv3ye\nG2StvbNI+yxrbUtv+99YaxdeoM/d1tpIa+368sQkEo4mT57MI488wuOPP86MGTOIiKhYJf/p06fT\no0cPunTpwrp16/jVr34VoEirDhXjKo2KcUnwaO8SEQdYaxk3bhzjx4/nqaee4r/+678qtFTQ7XYz\natQoRowYwahRo0hLS6N27doBjLjqUDGukqkYlwSTkgyRAHO73TzyyCNMmTKF5557jgkTJlQowfjx\nxx+55557mDZtGtOnT2fq1KkVviNSlakYV8lUjEuCSVcqkQByuVwMHjyYl19+mVmzZjFq1KgK9ffN\nN9+QkJDAypUreeedd3j44YcDFGnVpWJcJVMxLgkm3ScTCZAzZ85w7733smzZMhYsWED//v0r1N+e\nPXvo1KkT33zzDRs2bKBNmzYBirRqy83JJaFlq5+WsObm5IY6pLCSk5OLZx6+ZwlrjsZHHKQ7GSIB\n8OOPP9KjRw+WL1/O0qVLK5xgfPTRR0RFReFyucjLy1OC4YcCV0GhJawFroJQhxRWXK4CfJewujQ+\n4iAlGSIVdOLECVJSUsjMzGTFihXcfffdFepv5cqVxMXF0bhxY/Ly8rjpppsCFGn1oCWspdESVgke\nJRkiFXD06FESExP56KOPWL16NR07dqxQfzNnzqRbt2507NiRzMxM6tWrF6BIqw8tYS2NlrBK8CjJ\nECmnI0eOcOedd7Jz504yMzNp165duftyu92MHTuWhx56iOHDh7N06VIuuuiiAEZbfUSYCG5o0BAL\n3NCgIRFGlzlfxkQAN+BJLm7wHos4Q+8ukXI4cOAA7du3Z//+/RXeN+T06dP069ePqVOnMm3aNP7x\nj38QGan9NsrLbT0bpBlg78H9uK071CGFFWvdeDZIM8Be77GIM7S6RMRP+/btIz4+njNnzpCdnU2T\nJk3K3dd3331Ht27d2LJlC0uXLqVHjx4BjLR68i3GlTR6OG4VmyqkcDGuJCIjlWSIc3QnQ8QPu3bt\nom3bthhjKpxg7Nu3j5iYGHbs2EFmZqYSjACJjokmY+sWkkYPJ2PrFqJjokMdUliJiYkGMvCsLsnw\nHos4Q0mGSBlt376ddu3aUbduXbKzs2nUqFG5+9q6dStRUVGcPn2a3NxcoqN1oQ8Uay1ua9m6eydu\na7FWExt9ecbDjWd1iVvjI45SkiFSBlu2bCEuLo5rrrmGTZs20aBBg3L3tWrVKtq3b891111HXl5e\nhe6GyM/l5eaReFtrjry3jsTbWpOXmxfqkMJKbm4ekAgcARK9xyLOUJIhUopNmzYRHx/PzTffzPr1\n6yu0rHTOnDl06dKFhIQENmzYwJVXXhnASAVUjKs0KsYlwaQkQ6QEq1evJikpidatW7N27Vrq1q1b\nrn6stYwfP54HH3yQoUOHsmzZMi6++OIARyugYlylUzEuCR4lGSLFWLZsGV26dKFDhw68//77XHLJ\nJeXq59yeJpMnT+a5555j+vTpWqLqIBXjKo2KcUnwKMkQuYCFCxfSq1cvunfvzrJly6hdu3a5+jl6\n9ChJSUksXbqUJUuWMGrUKO166bDIiMiflrB2uK01kRFK6HwZE8n5JawdvMcizlCSIVLErFmzGDBg\nAAMHDmTRokXUrFmzXP18+eWXtG3blo8//piMjAx69eoV4EjlQlxuV6E5GS63K9QhhRVrXfjOyfAc\nizhDSYaIj+eee45hw4YxYsQIXn311XJ/rfHxxx/Tpk0bfvjhB3Jzc4mNjQ1wpFKcyIjCZcUjI3SZ\n8xUREYlvWfEI3ekRB+nTJ4JnYuaTTz7J6NGjGT9+PP/4xz+IKOc/TmvWrCE2NpYGDRqQl5dH06ZN\nAxytlCQ6JoY9B/ezbfdO9hzcT3RMTKhDCiue4lt7gG3AHhXjEkcpyZBqz1rL448/zlNPPcWUKVOY\nNGlSuedNzJs3j5SUFNq3b8/GjRupX79+gKOV0hhjiDCGlk2aEmGM5sAU4RmPCDwTPyM0PuIoJRlS\nrbndboYNG8YLL7zA9OnT+ctf/lKufqy1TJw4kcGDBzNkyBCWL1/OpZdeGuBopSxyc3JJaNmK1VOn\nk9CyFbk5uaEOKazk5OQCCXgmfiZ4j0WcoSRDqq2CggIGDBjAq6++yrx583j44YfL1c+ZM2cYNGgQ\nqampTJkyhZkzZ1KjhjblChUV4yqZinFJMOlKKNXS6dOnueeee3j//fdJS0sr98qP48eP06NHDzZt\n2sSiRYvo27dvgCMVf6kYV2lUjEuCR3cypNo5efIkXbp04YMPPuDdd98td4Lx1VdfERsby0cffcTa\ntWuVYIQJFeMqjYpxSfDoToZUK8ePH6dz585s27aNVatWceedd5arn+3bt9OpUyciIyPJycnhlltu\nCXCkUl4RpvAS1gijv6V8GROB7xJWo/ERB+ndJdXGt99+S0JCAtu3b2fdunXlTjAyMjKIjY3lyiuv\nJC8vTwlGmHFbN3sP7scAew/ux23doQ4prFjrBvbi+Zpkr/dYxBlKMqRaOHz4MHFxcezdu5cNGzYQ\nFRVVrn7mz59PcnIy0dHRbNq0iauvvjrAkUpFqax4yVRWXIJJSYZUeV9++SWxsbF8/fXXbNq0iebN\nm/vdh7WWp59+moEDBzJw4EBWrFhBnTp1HIhWKkplxUumsuISTJqTIVXa559/TkJCAgDZ2dk0btzY\n7z7Onj3LsGHDmDt3LpMmTWLcuHEqYBTGVFa8ZCorLsGkT59UWTt27CA2NpZatWqVO8H4/vvvueuu\nu5g/fz4LFixg/PjxSjDCXEzbtuw7dAAD7Dt0gJi2bUMdUlhp2zYG2IdnTsY+77GIM3QnQ6qkrVu3\n0rFjRxo2bMjatWu56qqr/O7jwIEDpKSksGfPHlavXk18fLwDkUqgWWtxW8vW3TtxW4u1WqLpyzMe\nbjx1MtwaH3GU7mRIlZOTk8Odd95J48aN2bBhQ7kSjB07dtCmTRu+/vprNm/erASjEsnLzSPxttYc\neW8dibe1Ji83L9QhhZXc3DwgETgCJHqPRZxRriTDGPNnY8xeY8wpY0y+Meb2UtrHGWO2GmN+NMbs\nNsbcd4E2dY0xrxhjDnjb7TTGJJUnPqm+MjIySExMpHnz5mRkZPDLX/7S7z42bNhATEwMV1xxBfn5\n+TRr1syBSMUpKiteMpUVl2DyO8kwxvQGngcmAs2BT4A1xph6xbRvBLwPZAK3Ai8C/zTGdPBpUxPI\nAK4DugNNgPuB/f7GJ9XXypUrSUlJoV27dqxatapcqz/efPNNOnbsSKtWrcjOzqZhw4YORCpOUlnx\n0qisuARPee5kPArMttYusNbuBIYCJ4E/FdN+GLDHWjvGWrvLWvsK8La3n3MGA5cD3ay1+dbaL6y1\n2dba/y5HfFINLVmyhO7du9O5c2eWL1/OxRdf7Nf51lqmTJlCv3796NevH+np6Vx22WUORStOUlnx\n0qisuASPX0mG945DSzx3JQCwnllDGUBx1Y3aeJ/3taZI+7uAPGCGMeaQMea/jTF/Nap3K2Uwd+5c\n+vTpQ58+fViyZAm1atXy6/yCggKGDRvGuHHjmDhxIvPmzaNmzZoORStOU1nxkqmsuASTv++uekAk\ncLjI44eB+sWcU7+Y9pcZY879a3Aj0NMbTzKQCowCxvsZn1QzL774IkOGDOHBBx/k9ddf93uL9RMn\nTtC1a1fmzp3LvHnzePLJJ7VEtZJTWfGSqay4BFO4pLAReBKPB6y1/7bWLgX+juerGJELmjx5MiNH\njmT06NHMmDGDCD+LLh06dIi4uDiysrJIT09n0KBBDkUqwVQjskahsuI1IrVS31dkZA18y4pHanzE\nQf6+u74GXEDRNYFXAYeKOedQMe2PW2tPe48PAmds4QXbnwH1jTE1rLXFTn9+9NFHqVu3bqHHzt06\nl6rJWsu4ceN45plnSE1N5YknnvD77sNnn31GcnIyZ8+eJTs7mz/84Q8ORSvBFh0TzaSnnyZp9HAy\ntm7hib/9LdQhhZWYmGgyMibhWV2SQUzME6EOSRyWlpZGWlpaoceOHTsWlN/tV5JhrT1rjNkKxAMr\nAIzn6h4PvFTMaXl4vgLxleh9/JwcoGhW8FvgYEkJBsC0adNo0aJF2V6AVHput5tHHnmEl19+meef\nf57HHnvM7z6ysrLo1q0bDRs2ZNWqVVx77bUORCqhomJcJVMxrurnQn94b9u2jZYtWzr+u8vzdckL\nwP3GmAHGmKbALOBi4HUAY8wUY8x8n/azgBuNMc8aY35rjHkI+KO3n3NmAr80xrxkjPmNMSYF+Cvw\ncjnikyrK5XIxePBgXnnlFWbPnl2uBGPx4sV06NCB5s2bk52drQSjCsrNyeHGBg1p0aQpNzZoSG5O\nTqhDCis5Obl4psG1AG70Hos4w+8kw1r7FvA4nsmZ/wZ+D3S01h7xNqkPXOvTfh+QAiQAH+NZujrY\nWpvh0+YroCNwG566G/8ApgHP+v2KpEo6c+YMffv2ZeHChSxcuJAHHnjAr/OttUydOpU+ffrQu3dv\nPvjgAy6//HKHopVQcrkLT/x0uTWx0Zfb7cJ34qdbu9SKg8o148daOwOYUcxzP5s9Z63NwrP0taQ+\nPwSiyxOPVG2nTp2iZ8+erFu3jqVLl3L33Xf7db7L5WLEiBHMmDGDJ554gtTUVK0gqcIiIyJ/mviZ\nNHo4Lu0yWogxkZyf+JmEMUoyxDnhsrpE5IJOnDhBSkoK69evZ8WKFX4nGD/88AN33303s2fPZs6c\nOTz99NNKMKo4l9tVqKy4S3+pF2KtC9+y4p5jEWdo7ZKEraNHj9KpUyf+53/+hzVr1hAbG+vX+YcP\nH+auu+7i008/ZeXKlSQnF51/LFWRinGVTMW4JJj07pKwdOTIEe644w527dpFZmam3wnGrl27iIqK\n4ssvvyQrK0sJRjWiYlwlUzEuCSYlGRJ29u/fT/v27Tl48CAbN27k9ttL3OT3Z3JycoiOjqZ27drk\n5+driXM1ExlR+E5GpJ9F2qq6iIhIfO9kRGjOijhInz4JK/v27aNdu3acOHGCrKwsv7dZX7ZsGfHx\n8TRr1oycnByuv/56hyKVcBUdE8Oeg/vZtnsnew7uJzomJtQhhZWYmGhgD7AN2OM9FnGGkgwJG7t2\n7aJt27YYY8jOzqZJkyZ+nT9t2jR69uxJ9+7dWbNmDVdccYVDkUo4M8YQYQwtmzQlwhhN9C3CMx4R\neBb8RWh8xFFKMiQsfPLJJ7Rr1466deuSnZ3t1x0Il8vFyJEjeeyxxxg7dixvvPGG3zuxStWRm5NL\nQstWrJ46nYSWrchVsalCPMW3EvAsYU1QMS5xlJIMCbkPP/yQuLg4rrnmGjZt2kSDBg3KfO65GhrT\np09n5syZTJkyxe+N0qRqKXAVFFrCWuAqcWeCasflKsB3CatL4yMO0hJWCamNGzdy1113ceutt5Ke\nnv6zze5KcuTIEbp06cL27dt577336Ny5s4ORSmVhgLqX1mHr7p3UvbQO+jKgKAPUxbN3SV3vsYgz\n9CefhMwHH3xAcnIybdq0Yc2aNX4lGJ9//jnR0dHs2bOHjRs3KsGQn1jg2InvadmkKcdOfI+2/yrK\nAsfwzMk45j0WcYaSDAmJZcuW0bVrVxITE1m5ciWXXHJJmc/Nz88nKiqKyMhI8vPz/V7iKlWbinGV\nTMW4JJj07pKgW7hwIb169aJHjx68/fbb1K5du8znvvvuu9xxxx00bdqUnJwcbrjhBgcjlcpIxbhK\npmJcEkxKMiSoZs2axYABAxg0aBBvvPEGNWvWLPO506dPp0ePHnTp0oV169bxq1/9ysFIpbKqEVnj\npw3SOtzWmhqRmnrmKzKyBuc3SOvgPRZxhpIMCZqpU6cybNgwRowYwZw5c4iMLFulQbfbzahRoxgx\nYgSjRo0iLS3Nr7sfUr1Ex0STsXULSaOHk7F1C9EqNlWIp/hWBp7VJRkqxiWOUgorjrPW8uSTT5Ka\nmsr48eP92gn1xx9/5N5772XZsmVMnz6dhx9+2OFopbKz1uK2lq27d+K2Fms1sdGXZzzceFaXuDU+\n4ijdyRBHWWsZNWoUqampPPPMM0yaNKnMCcY333xDQkIC6enpvPvuu0owpEzycvNIvK01R95bv+TY\nNAAAFBFJREFUR+JtrcnLzQt1SGElNzcPSASOAIneYxFnKMkQx7hcLoYOHcq0adN4+eWXGTt2bJnP\n3bNnD9HR0ezevZsNGzbQtWtXByOVqkTFuEqmYlwSTPq6RBxRUFDAwIEDSUtL47XXXmPgwIFlPnfL\nli107tyZyy+/nLy8PBo3buxcoFLlqBhXaVSMS4JHdzIk4E6fPk3Pnj1ZsmQJixcv9ivBWLlyJXFx\ncdx0003k5uYqwRC/qRhXaVSMS4JHSYYE1MmTJ+nSpQsffPABy5cvp2fPnmU+d+bMmXTr1o3k5GQy\nMzOpV6+eg5FKVRUZEVloCWtkRNlWMVUXxkTiu4TVcyziDCUZEjDHjx8nKSmJnJwcVq1aRUpKSpnO\nc7vdjB07loceeogRI0bw1ltvcdFFFzkcrVRVLrer0JwMl9sV6pDCirUufOdkeI5FnKE5GRIQ33zz\nDUlJSfzv//4v69atIyoqqkznnT59moEDB7JkyRKmTZvGyJEjHY5UqrrIiMJlxSO1K28hERGR+JYV\nj9CdHnGQPn1SYYcOHSIuLo59+/axYcOGMicY3333HYmJiSxfvpylS5cqwZCAiI6JYc/B/WzbvZM9\nB/cTHRMT6pDCiqf41h5gG7BHxbjEUUoypEK++OIL2rVrx7fffktWVhbNmzcv03n79u0jJiaGHTt2\nkJmZSY8ePRyOVKoLYwwRxtCySVMijClzXZbqwjMeEXgmfkZofMRRSjKk3D7//HNiY2M5e/Ys2dnZ\n3HzzzWU6b+vWrURFRXH69Glyc3OJjtZfUhI4uTm5JLRsxeqp00lo2YrcnNxQhxRWcnJygQQ8Ez8T\nvMcizlCSIeWyY8cOYmNjueiii8jOzubGG28s03mrVq2iffv2XHfddeTl5dGkSROHI5XqRsW4SqZi\nXBJMSjLEb1u3bqV9+/ZceeWVZGVlcc0115TpvDlz5tClSxcSEhLYsGEDV155pcORSnUUYQpP/Iww\nusz5MiYC34mfRuMjDtK7S/ySk5PDnXfeSePGjcucKFhrGT9+PA8++CBDhw5l2bJlXHzxxUGIVqoj\nt3Wz9+B+DLD34H7c1h3qkMKKtW5gL55Kn3u9xyLO0BJWKbOMjAy6du1Kq1atWLFiBXXq1Cn1nDNn\nzvCnP/2JRYsW8dxzz/HYY49popk4SmXFS6Oy4hI8upMhZbJixQpSUlJo3749q1atKlOCcfToUZKS\nkli6dClLlixh1KhRSjDEcSorXhqVFZfgUZIhpVq8eDHdu3fnrrvuYvny5WWqxvnFF1/Qtm1bPv74\nYzIyMujVq1cQIhVRWfHSqKy4BJOSDCnR3Llz6du3L/369WPx4sX84he/KPWcjz/+mDZt2vDDDz+Q\nm5tLbGxsECIV8VBZ8ZKprLgEk5IMKdaLL77IkCFDGDp0KK+99ho1apQ+hWfNmjXExsbSsGFD8vPz\nadq0aRAiFTlPZcVLprLiEkz69MnPWGv5+9//zsiRIxk9ejSvvPIKEWW4UM+dO5eUlBTi4uLYuHEj\nV111VRCiFSlMZcVLprLiEkzlSjKMMX82xuw1xpwyxuQbY24vpX2cMWarMeZHY8xuY8x9RZ6/zxjj\nNsa4vP/rNsacLE9sUjHWWv7617/yxBNPkJqayrPPPlvqZE1rLRMnTmTIkCHcf//9vPvuu1xyySVB\nilikMJUVL5nKiksw+Z1kGGN6A88DE4HmwCfAGmNMvWLaNwLeBzKBW4EXgX8aYzoUaXoMqO/zc72/\nsUnFuN1uhg8fzrPPPssLL7zA3/72t1IvQGfOnGHQoEGkpqbyzDPPMGPGjDJ9rSLiFJUVL5nKiksw\nledOxqPAbGvtAmvtTmAocBL4UzHthwF7rLVjrLW7rLWvAG97+/FlrbVHrLX/8f4cKUdsUk4FBQUM\nHjyYGTNmMGfOHB59tOh/np87fvw4KSkppKWl8eabbzJ27Fj9VSQhp7LiJVNZcQkmv5IMY0xNPPfY\nMs89Zq21QAZQ3P7ebbzP+1pzgfaXGmP2GWO+MMYsN8b8zp/YpPzOnDlD3759WbhwIW+88Qb3339/\nqed89dVXxMbG8q9//Yu1a9fSp0+fIEQqUjoV4yqNinFJ8Ph7J6MeEAkcLvL4YTxfcVxI/WLaX2aM\nqeU93oXnTkgXoJ83rlxjzNV+xid+OnXqFN27d+e9997j7bffpm/fvqWes337dtq0acPRo0fJycmh\nffv2QYhUpGxUjKs0KsYlwRMWX55ba/OB/HPHxpg84DPgQTxzP4r16KOPUrdu3UKP9enTR39Zl8GJ\nEyfo0qUL+fn5rFy5ksTExFLPycjIoEePHjRu3Jj09HQaNGgQhEhFyq5GZI2finEljR6OOzIsLnNh\nIzKyBueLcSURGam9S6q6tLQ00tLSCj127NixoPxufz99XwMuoOjaxKuAQ8Wcc6iY9settacvdIK1\ntsAY82/gptICmjZtGi1atCitmRTx3Xff0alTJ3bs2PFTbYvSzJ8/nyFDhpCQkMDSpUu59NJLgxCp\niH/axrYlNTWVpNHDydj2ERMmTAh1SGElNrYtmZmpWJuEMRnExmp8qroL/eG9bds2WrZs6fjv9ivJ\nsNaeNcZsBeKBFQDGM9MvHnipmNPygOQijyV6H78g49l7uBmQ7k98UjZHjhwhMTGRL774gszMTG6/\nvcQVyFhrmTRpEhMmTGDIkCHMmDGDmjVrBilaEf+MGzcOgJzNm5kwYcJPx+Jxbjw2b86hbVuNjzir\nPPcRXwBe9yYbW/CsErkYeB3AGDMFuNpae64Wxizgz8aYZ4F5eBKSPwKdznVojPkbnq9LPgcuB8YA\n1wH/LEd8UoL9+/eTkJDAd999x8aNG2nWrFmJ7c+ePcuwYcOYO3cukyZNYty4cVpBImGtRo0auntR\nAo2PBJPfSYa19i1vTYxUPF97fAx09FlyWh+41qf9PmNMCjANGAF8BQy21vquOLkCmOM99zs8056j\nvEtkJUD27t1LfHw8BQUFZGdn85vf/KbE9t9//z09e/YkMzOTBQsWcO+99wYpUhERqQrKNSPKWjsD\nmFHMc4Mu8FgWnqnMxfX3GPBYeWKRstm5cycJCQlcdNFFbNiwgeuvL7nW2YEDB0hJSWHPnj2sXr2a\n+Pj4IEUqIiJVhaZdVwOffPIJHTp04Morr2TdunWlrgjZsWMHycnJWGvZvHlzqV+piIiIXIg2SKvi\nPvzwQ+Li4rj22mvZuHFjqQnGhg0biImJ4YorriA/P18JhoiIlJuSjCps48aNJCQkcMstt7B+/Xrq\n1bvg9jI/WbRoER07dqRVq1ZkZ2fTsGHDIEUqIiJVkZKMKmrVqlUkJyfTpk0b1qxZ87OCZb6stUye\nPJn+/fvTv39/0tPTueyyy4IYrYiIVEVKMqqgZcuW0a1bNxITE1m5cmWJ264XFBQwdOhQxo8fz5NP\nPsncuXNVA0NERAJCEz+rmAULFjBo0CB69+7N/PnzS0wYTpw4Qe/evVm7di2vvfYaAwcODF6gIiJS\n5SnJqEJmzpzJQw89xJAhQ5g1axaRkZHFtj106BCdO3dm9+7dpKenl2nfEhEREX8oyagipk6dypgx\nY3jkkUeYNm1aiVU5P/vsM5KTkzl79izZ2dnceuutQYxURESqC83JqOSstUycOJExY8bwxBNPlJpg\nZGVlERMTQ506dcjPz1eCISIijlGSUcmNHj2a1NRUnnnmGZ5++ukSE4zFixfToUMHWrRowebNm7n2\n2muLbSsiIlJRSjIquQYNGvDyyy8zduzYYttYa5k6dSp9+vThnnvuYdWqVSUuaRUREQkEzcmo5EaN\nGlXi8y6XixEjRjBjxgyeeOIJUlNTtYuqiIgEhZKMKuyHH36gT58+rFq1ijlz5nD//feHOiQREalG\nlGRUUYcPH+auu+7i008/ZeXKlSQnJ4c6JBERqWaUZFRBu3btIjk5mVOnTpGVlUWLFi1CHZKIiFRD\nmvhZxeTk5BAdHU3t2rXJz89XgiEiIiGjJKMKefvtt4mPj6dZs2bk5ORw/fXXhzokERGpxpRkVAHW\nWl544QV69epF9+7dWbNmDVdccUWowxIRkWpOSUYl53K5GDlyJKNGjWLs2LG88cYb1KpVK9RhiYiI\naOJnZde/f3/eeustZs6cydChQ0MdjoiIyE+UZFRy3bp1o1+/fnTu3DnUoYiIiBSiJKOS6927d6hD\nEBERuSDNyRARERFHKMkQERERRyjJEBEREUcoyRARERFHKMkQERERRyjJEBEREUcoyRARERFHKMkQ\nERERRyjJEBEREUcoyRARERFHKMmoAtLS0kIdQljQOJynsfDQOJynsfDQOARXuZIMY8yfjTF7jTGn\njDH5xpjbS2kfZ4zZaoz50Riz2xhzXwlt7zHGuI0x75QntupIHxoPjcN5GgsPjcN5GgsPjUNw+Z1k\nGGN6A88DE4HmwCfAGmNMvWLaNwLeBzKBW4EXgX8aYzoU03YqkOVvXCIiIhJeynMn41FgtrV2gbV2\nJzAUOAn8qZj2w4A91tox1tpd1tpXgLe9/fzEGBMBvAFMAPaWIy4REREJI34lGcaYmkBLPHclALDW\nWiADiCrmtDbe532tuUD7icBha+1r/sQkIiIi4amGn+3rAZHA4SKPHwZ+W8w59Ytpf5kxppa19rQx\npi0wCM/XKWVVG+Czzz7z45Sq6dixY2zbti3UYYScxuE8jYWHxuE8jYWHxsHD59/O2k7+Hn+TjIAz\nxlwKLADut9Z+58epjQD69+/vRFiVTsuWLUMdQljQOJynsfDQOJynsfDQOBTSCMh1qnN/k4yvARdw\nVZHHrwIOFXPOoWLaH/fexWgKXA+sNMYY7/MRAMaYM8BvrbUXmqOxBugH7AN+9PN1iIiIVGe18SQY\na5z8JX4lGdbas8aYrUA8sALAmxjEAy8Vc1oekFzksUTv4wA7gWZFnv87cCkwAviymFi+Ad70J34R\nERH5iWN3MM4pz9clLwCve5ONLXhWiVwMvA5gjJkCXG2tPVcLYxbwZ2PMs8A8PAnJH4FOANba08Cn\nvr/AGHPU85TVhAsREZFKyu8kw1r7lrcmRiqerz0+Bjpaa494m9QHrvVpv88YkwJMw3Nn4itgsLW2\n6IoTERERqUKMZwWqiIiISGBp7xIRERFxhJIMERERcUTYJBmB3nTNGDPEGJNljPnW+7OutD7DgTaf\nO8+JsTDG1DXGvGKMOeBtt9MYk+Tcq6g4h8ZhpPe1nzTGfGGMecEYU8u5VxEY/oyFMaa+MWaRMWaX\nMcZljHmhmHY9jTGfefv8xBhTdDVc2An0OFTW6yU4857waV9prpkOfTYqfr201ob8B+iNp9bFAKAp\nMBv4FqhXTPtGwAngv/BUGv0zcBbo4NNmIZ59VX4PNMGzsuU7oEGoX28wx6FI2y+BjcA7oX6tIXpP\n1AQ+AlbiKXd/HRALNAv16w3yOPQFTnn7vg5IwDMh+7lQv94Aj8X1eCac9we2Ai9coE20d3we845X\nKnAa+F2oX2+Qx6HSXS+dGguftpXmmunQeyIg18uQD473xeQDL/ocG+9Fb0wx7Z8Fthd5LA1YVcLv\niACOAf1D/XqDPQ7e174ZT+n218L9A+PUWHgvov8LRIb69YV4HKYD64q0eQ7ICvXrDeRYFDl3QzEX\n0sXAiiKP5QEzQv16gzkOF2gX9tdLJ8eisl0zHfpsBOR6GfKvS4yzm675ugRPZvZtuYN1kMPjUKk2\nn3NwLO7C+w+IMeaQMea/jTF/NZ4dgMOOg+OQC7Q8dzvVGHMjnro16YGJPPDKORZlEYX/15KQcXAc\nigrr6yU4PhaV5prp4DgE5HoZ8r1LcGjTtQuc8yywn59fUMJFOG0+F2pOvSduBO4E3sBThfYmYCae\nz8HTgQk9oBwZB2ttmvHUutlsjDHe3zHLWvtsAGMPtPKMRVkUN171K9Cnk5wah6LC/XoJDo1FJbxm\nOvWeCMj1MhySDMcZY/4C9ALaW2vPhDqeYDHl33yuqorA88F7wJvp/9sYcw3wOOGZZDjCGBMHjMNz\nO3QLnovHS8aYg9baSaGMTUKvul4vQdfMIgJyvQyHJCPgm675PmiMeRwYA8Rba3dUPFzHhNPmc6Hm\n1HviIHDG+4E55zOgvjGmhrW2oGJhB5xT45AKLPS5FbzDe3GdDYRrklGesSiL4sarIn06yalxACrV\n9RKcGYvGVL5rplPviYBcL0P+XbS19iye2a3x5x7z/seNp/jNW/J823v5brp2rp8xwHg8Zc//HaiY\nneDQOJzbfO4PeG793YpnY7v13v9/wc3nQs3B90QOnr/aff0WOBiGCYaT43AxUPT1un36DzvlHIuy\nuNB4daDItSRcODgOlep6CY6NxWdUsmumg++JwFwvQz0r1psk9QJOUnj5zTfAr73PTwHm+7RvBHyP\n53vD3wIPAWeABJ82Y/Es6bkbT0Z37ueSUL/eYI7DBX5H2M+UdvA9cQ1wFM+Owb8BUvBk+n8J9esN\n8jhM9I5Db2/7Dnhmkb8Z6tcbyLHwPnYrnn8wPsKzTPNW4Gaf56PwLFk9t4T1Se91I5yXsDoxDpXu\neunUWFzgd4T9NdOh90RArpchHxyfF/QQsA/P+v084LYi/5HXF2nfDk/2dsp7gby3yPN78dxCKvoz\nIdSvNZjjcIH+w/4D4+RYAK3xZPcnvW3G4t3DJ1x/HPhsRAB/A3YDP3j7fgm4LNSv1YGxcF/gGrCn\nSJseeO76nQK24/lLPuSvNZjjUFmvl069J4q0rxTXTIc+GxW+XmqDNBEREXFEyOdkiIiISNWkJENE\nREQcoSRDREREHKEkQ0RERByhJENEREQcoSRDREREHKEkQ0RERByhJENEREQcoSRDREREHKEkQ0RE\nRByhJENEREQc8f8BO7idE+xanNgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc761668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fronter_1= list( fronter1_vol.items())\n",
    "fronter_1.sort( key=lambda x: x[1])\n",
    "minvar_portf1= fronter_1[0]\n",
    "minvar_portf1_w= fronter1_w[minvar_portf1[0]]\n",
    "fronter_1.sort( key= lambda x: (x[0]- rf)/ x[1], reverse=True)\n",
    "efficient_portf1= fronter_1[0]\n",
    "efficient_portf1_w= fronter1_w[efficient_portf1[0]]\n",
    "\n",
    "fronter_2= list(fronter2_vol.items())\n",
    "fronter_2.sort(key= lambda x: x[1])\n",
    "minvar_portf2= fronter_2[0]\n",
    "minvar_portf2_w= fronter2_w[minvar_portf2[0]]\n",
    "fronter_2.sort(key= lambda x: (x[0]-rf)/x[1], reverse= True)\n",
    "efficient_portf2= fronter_2[0]\n",
    "efficient_portf2_w= fronter2_w[efficient_portf2[0]]\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip( * list( fronter1_vol.items())) \n",
    "fig= plt.figure( )\n",
    "plt.scatter(x= tmp_vol, y= tmp_ret, marker=\".\", c= 'pink' , label= 'long only')\n",
    "plt.scatter(x= minvar_portf1[1], y= minvar_portf1[0], marker= 'o', c='purple', s= 100 )\n",
    "plt.scatter(x= efficient_portf1[1], y = efficient_portf1[0], marker= '*', c='m', s=200)\n",
    "plt.plot( [0.04, efficient_portf1[1]], [ (efficient_portf1[0]-rf)/efficient_portf1[1]* 0.04+rf, efficient_portf1[0]], 'k-')\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip(* list(fronter2_vol.items()))\n",
    "plt.scatter( x= tmp_vol, y= tmp_ret, marker= '.', c='blue', label= 'long only+ concentration constrain')\n",
    "plt.scatter( x= minvar_portf2[1], y=minvar_portf2[0], marker= 'o', c= 'y', s=100)\n",
    "plt.scatter(x= efficient_portf2[1], y = efficient_portf2[0], marker= '*', c='r', s=200)\n",
    "plt.plot( [0.04, efficient_portf2[1]], [ (efficient_portf2[0]-rf)/efficient_portf2[1]* 0.04+rf, efficient_portf2[0]], 'k-')\n",
    "plt.legend()\n",
    "plt.title('Efficient Fronter')\n",
    "\n",
    "print(efficient_portf1)\n",
    "print(efficient_portf1_w)\n",
    "print(efficient_portf2)\n",
    "print(efficient_portf2_w)\n",
    "\n",
    "weight_longonly= efficient_portf1_w\n",
    "weight_longonly_conc= efficient_portf2_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_CORP</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.139113</td>\n",
       "      <td>0.289315</td>\n",
       "      <td>0.046371</td>\n",
       "      <td>0.239919</td>\n",
       "      <td>2.620968e-02</td>\n",
       "      <td>2.127016e-01</td>\n",
       "      <td>0.046371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.206808</td>\n",
       "      <td>0.105522</td>\n",
       "      <td>0.403146</td>\n",
       "      <td>0.085036</td>\n",
       "      <td>6.786336e-02</td>\n",
       "      <td>7.438370e-02</td>\n",
       "      <td>0.057241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly</th>\n",
       "      <td>0.362450</td>\n",
       "      <td>0.234198</td>\n",
       "      <td>0.379326</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>3.455894e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly_conc</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.086827</td>\n",
       "      <td>7.847271e-19</td>\n",
       "      <td>2.082001e-19</td>\n",
       "      <td>0.013173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             US_RE     US_PE   US_CORP     SP500  \\\n",
       "weight_eq                 0.142857  0.142857  0.142857  0.142857   \n",
       "weight_peer               0.139113  0.289315  0.046371  0.239919   \n",
       "weight_erc                0.206808  0.105522  0.403146  0.085036   \n",
       "CMA_weight_longonly       0.362450  0.234198  0.379326  0.014618   \n",
       "CMA_weight_longonly_conc  0.300000  0.300000  0.300000  0.086827   \n",
       "\n",
       "                            Rusell2000          EAFE        EM  \n",
       "weight_eq                 1.428571e-01  1.428571e-01  0.142857  \n",
       "weight_peer               2.620968e-02  2.127016e-01  0.046371  \n",
       "weight_erc                6.786336e-02  7.438370e-02  0.057241  \n",
       "CMA_weight_longonly       3.455894e-19  0.000000e+00  0.009407  \n",
       "CMA_weight_longonly_conc  7.847271e-19  2.082001e-19  0.013173  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_2= pd.DataFrame([efficient_portf1_w, efficient_portf2_w], \n",
    "                             index=['CMA_weight_longonly', 'CMA_weight_longonly_conc'], columns=LW_cov.columns)\n",
    "pd.concat([portf_weight_1, portf_weight_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0194798260073\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0184502664699\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017475220857\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0165767919112\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0157394024998\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n"
     ]
    }
   ],
   "source": [
    "## risk adj return optimal long only portfolio with CMA expected ret\n",
    "\n",
    "\n",
    "def obj_func_CMA(w, ARGS):  # ARGS= [sigma, ExpRet, gamma]\n",
    "    return (np.dot(  np.dot( w, ARGS[0]), w)* .5* ARGS[2]- np.dot( ARGS[1], w))\n",
    "\n",
    "def obj_func_derivative_CMA( w, ARGS): \n",
    "    return (np.dot( w, ARGS[0])* ARGS[2]- ARGS[1])\n",
    "\n",
    "\n",
    "cons_eq0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "# cons_ineq0= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[0]-w[1]+ 0.5, \n",
    "#              'jac': lambda w: np.array([-1]*2+ [0]*10)}\n",
    "# cons_ineq1= {'type': 'ineq',\n",
    "#              'fun': lambda w: -w[2]-w[3]-w[4]-w[5]-w[6]+ 0.5,\n",
    "#              'jac': lambda w: np.array([0]*2+ [-1]*5+ [0]*5)}\n",
    "# cons_ineq2= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[7]-w[8]-w[9]-w[10]+ 0.5, \n",
    "#              'jac': lambda w: np.array([0]*7+ [-1]*4+ [0])}\n",
    "# cons_ineq3= {'type': 'ineq', \n",
    "#             'fun': lambda w: -w[11]+ 0.5,\n",
    "#             'jac': lambda w: np.array( [0]*11+ [-1])}\n",
    "\n",
    "\n",
    "CMA_riskAdj_opt={}\n",
    "\n",
    "for g in [2,2.5,3,3.5,4]: \n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          )\n",
    "\n",
    "    MV_opt= minimize( obj_func_CMA, \n",
    "                    x0= weight_eq, \n",
    "                    args= [LW_cov, CMA_ExpRet_arith, g], \n",
    "                    jac= obj_func_derivative_CMA ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    #bounds= [[0, 0.25]]+[[0, .4]]+[[0,None]]* (N-2),\n",
    "                    bounds= [[0,0.3]]* (N),\n",
    "                    tol= 1e-12)\n",
    "    \n",
    "    CMA_riskAdj_opt[g]= MV_opt.x\n",
    "    \n",
    "CMA_riskAdj_portf_w= pd.DataFrame( CMA_riskAdj_opt, index=LW_cov.columns).T\n",
    "CMA_riskAdj_portf_w.index= ['weight_CMA_MVO_gamma_'+str(x) for x in CMA_riskAdj_portf_w.index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_2.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.180607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_2.5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.996748e-17</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_3.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.599354e-02</td>\n",
       "      <td>0.161141</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.144495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_3.5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.711936e-17</td>\n",
       "      <td>1.405892e-01</td>\n",
       "      <td>0.113584</td>\n",
       "      <td>0.030060</td>\n",
       "      <td>0.115767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMA_MVO_gamma_4.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.582843e-02</td>\n",
       "      <td>1.621623e-01</td>\n",
       "      <td>0.077544</td>\n",
       "      <td>0.032376</td>\n",
       "      <td>0.092089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          US_RE  US_PE         US_HY         SP500  \\\n",
       "weight_CMA_MVO_gamma_2.0    0.3    0.3  0.000000e+00  0.000000e+00   \n",
       "weight_CMA_MVO_gamma_2.5    0.3    0.3  0.000000e+00  3.996748e-17   \n",
       "weight_CMA_MVO_gamma_3.0    0.3    0.3  0.000000e+00  7.599354e-02   \n",
       "weight_CMA_MVO_gamma_3.5    0.3    0.3  9.711936e-17  1.405892e-01   \n",
       "weight_CMA_MVO_gamma_4.0    0.3    0.3  3.582843e-02  1.621623e-01   \n",
       "\n",
       "                          Rusell2000      EAFE        EM  \n",
       "weight_CMA_MVO_gamma_2.0    0.180607  0.000000  0.219393  \n",
       "weight_CMA_MVO_gamma_2.5    0.216500  0.000000  0.183500  \n",
       "weight_CMA_MVO_gamma_3.0    0.161141  0.018371  0.144495  \n",
       "weight_CMA_MVO_gamma_3.5    0.113584  0.030060  0.115767  \n",
       "weight_CMA_MVO_gamma_4.0    0.077544  0.032376  0.092089  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMA_riskAdj_portf_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Introducing active management\n",
    "# Apply active management to Equity (SP500, Rusell2000, EAFE and EM), \n",
    "# assuming IR of 1/3 and active alpha 1% and hence tracking error 3%, both annualized \n",
    "\n",
    "\n",
    "LW_vol= np.sqrt(np.diag(LW_cov))\n",
    "LW_corr= pd.DataFrame(np.dot(np.dot(np.diag(1/LW_vol), LW_cov), np.diag(1/LW_vol)), columns= LW_cov.columns, index=LW_cov.index)\n",
    "LW_cov_active= pd.DataFrame(LW_cov+ np.diag( np.array([0, 0, 0.0009/4, 0.0009/4, 0.0009/4, 0.0009/4, 0.0009/4])),\n",
    "                           index= LW_cov.index,\n",
    "                           columns= LW_cov.columns)\n",
    "LW_vol_active= np.sqrt(np.diag(LW_cov_active))\n",
    "\n",
    "CMA_ExpRet_active_geo= CMA_ExpRet_geo+ np.array([0,0,0.0075/4, 0.01/4, 0.01/4, 0.01/4, 0.01/4])\n",
    "CMA_ExpRet_active_arith= CMA_ExpRet_arith+ np.array( [0,0,0.0075/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4, 0.01/4+ .5* 0.0009/4 ])\n",
    "\n",
    "LW_corr_active= pd.DataFrame(np.dot(np.dot(np.diag(1/LW_vol_active), LW_cov_active), np.diag(1/LW_vol_active)), \n",
    "                            index= LW_cov_active.index,\n",
    "                            columns= LW_cov_active.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 18\n",
      "            Function evaluations: 116\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0020345040048\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 8\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 4\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00192702470341\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 21\n",
      "            Function evaluations: 121\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00182540926847\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 24\n",
      "            Function evaluations: 200\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00172965769997\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 31\n",
      "            Function evaluations: 277\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00163976999793\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384917\n",
      "            Iterations: 33\n",
      "            Function evaluations: 229\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00155574616234\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 26\n",
      "            Function evaluations: 138\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0014775861932\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 19\n",
      "            Function evaluations: 110\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00140529009052\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384917\n",
      "            Iterations: 41\n",
      "            Function evaluations: 277\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00133885785428\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 14\n",
      "            Function evaluations: 90\n",
      "            Gradient evaluations: 10\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00127828948449\n",
      "            Iterations: 2\n",
      "            Function evaluations: 2\n",
      "            Gradient evaluations: 2\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 27\n",
      "            Function evaluations: 233\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00122358498115\n",
      "            Iterations: 4\n",
      "            Function evaluations: 4\n",
      "            Gradient evaluations: 4\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.001313573849\n",
      "            Iterations: 101\n",
      "            Function evaluations: 989\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00117474434427\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 55\n",
      "            Function evaluations: 423\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00113176757383\n",
      "            Iterations: 8\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 8\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1047\n",
      "            Gradient evaluations: 98\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00109465466985\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 8\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 4\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00106340563231\n",
      "            Iterations: 9\n",
      "            Function evaluations: 9\n",
      "            Gradient evaluations: 9\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 9\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00103802046123\n",
      "            Iterations: 11\n",
      "            Function evaluations: 11\n",
      "            Gradient evaluations: 11\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 41\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00101849915659\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 35\n",
      "            Function evaluations: 232\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00100484171841\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 58\n",
      "            Function evaluations: 426\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000995617527367\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 50\n",
      "            Function evaluations: 454\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000987203310446\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 43\n",
      "            Function evaluations: 404\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000979421646194\n",
      "            Iterations: 13\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 13\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 40\n",
      "            Function evaluations: 368\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000972272534612\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 28\n",
      "            Function evaluations: 171\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0009657559757\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00131357384903\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1000\n",
      "            Gradient evaluations: 100\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000959871969456\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 45\n",
      "            Function evaluations: 313\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000954620515882\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 81\n",
      "            Function evaluations: 682\n",
      "            Gradient evaluations: 77\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000950001614978\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00131357384898\n",
      "            Iterations: 101\n",
      "            Function evaluations: 989\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000946015266743\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 23\n",
      "            Function evaluations: 187\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000942661471177\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 90\n",
      "            Function evaluations: 728\n",
      "            Gradient evaluations: 86\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00093994022828\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 37\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000937851538053\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 101\n",
      "            Function evaluations: 868\n",
      "            Gradient evaluations: 97\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000936395400495\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 32\n",
      "            Function evaluations: 279\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000935571815607\n",
      "            Iterations: 14\n",
      "            Function evaluations: 14\n",
      "            Gradient evaluations: 14\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 98\n",
      "            Function evaluations: 1001\n",
      "            Gradient evaluations: 94\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000935380783388\n",
      "            Iterations: 15\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 15\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 25\n",
      "            Function evaluations: 152\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000935822303838\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 40\n",
      "            Function evaluations: 297\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000936896376957\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00131357384902\n",
      "            Iterations: 101\n",
      "            Function evaluations: 995\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000938581575345\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1007\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000940833170767\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 72\n",
      "            Function evaluations: 681\n",
      "            Gradient evaluations: 68\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000943649764069\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 74\n",
      "            Function evaluations: 726\n",
      "            Gradient evaluations: 70\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000947031355252\n",
      "            Iterations: 16\n",
      "            Function evaluations: 16\n",
      "            Gradient evaluations: 16\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00131357384901\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1017\n",
      "            Gradient evaluations: 100\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000950977944315\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Iteration limit exceeded    (Exit mode 9)\n",
      "            Current function value: 0.00131357384909\n",
      "            Iterations: 101\n",
      "            Function evaluations: 1004\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000955489531259\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Inequality constraints incompatible    (Exit mode 4)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 38\n",
      "            Function evaluations: 346\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000960566116083\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131357384918\n",
      "            Iterations: 9\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 5\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000966207698789\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00115809811383\n",
      "            Iterations: 7\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 7\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000972413133788\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00112422490767\n",
      "            Iterations: 12\n",
      "            Function evaluations: 12\n",
      "            Gradient evaluations: 12\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000979165192282\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00112449367733\n",
      "            Iterations: 17\n",
      "            Function evaluations: 17\n",
      "            Gradient evaluations: 17\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000986458090358\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011305186505\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.000994291827006\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00113723792582\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00100266640335\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00114465150327\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010115818187\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00115275938286\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00102098131837\n",
      "            Iterations: 35\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011615615646\n",
      "            Iterations: 18\n",
      "            Function evaluations: 18\n",
      "            Gradient evaluations: 18\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00103077749334\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00117105804848\n",
      "            Iterations: 19\n",
      "            Function evaluations: 19\n",
      "            Gradient evaluations: 19\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0010409693728\n",
      "            Iterations: 35\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011812488345\n",
      "            Iterations: 21\n",
      "            Function evaluations: 21\n",
      "            Gradient evaluations: 21\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00105155695675\n",
      "            Iterations: 34\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0011921308588\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00106254024527\n",
      "            Iterations: 37\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00120354236679\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00107391923833\n",
      "            Iterations: 37\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00121539169974\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00108569393592\n",
      "            Iterations: 39\n",
      "            Function evaluations: 39\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00122767885725\n",
      "            Iterations: 30\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00109786433806\n",
      "            Iterations: 39\n",
      "            Function evaluations: 39\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00124040383968\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00111043044478\n",
      "            Iterations: 38\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00125356664696\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00112339225605\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00126716727906\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00113674977157\n",
      "            Iterations: 29\n",
      "            Function evaluations: 30\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00128120564993\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00115050299179\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00129565095905\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00116465191656\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131047835322\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00117920405667\n",
      "            Iterations: 35\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00132568783219\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00119433545498\n",
      "            Iterations: 39\n",
      "            Function evaluations: 39\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00134127939593\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00121011802708\n",
      "            Iterations: 31\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00135725304447\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00122655149068\n",
      "            Iterations: 39\n",
      "            Function evaluations: 39\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00137360889713\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00124363612796\n",
      "            Iterations: 37\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00139034662581\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00126137184484\n",
      "            Iterations: 36\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00140746649877\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00127975864174\n",
      "            Iterations: 36\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00142496851706\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00129879651745\n",
      "            Iterations: 34\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00144285268156\n",
      "            Iterations: 20\n",
      "            Function evaluations: 20\n",
      "            Gradient evaluations: 20\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00131848547375\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00146111871615\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00133882550851\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00147976695818\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00135981662346\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00149879728499\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00138145881803\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00151820969659\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00140375584449\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00153800419297\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00142676256837\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00155818077414\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00145050768271\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015787394401\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00147499118752\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00159968019084\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0015002130828\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00162100302636\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00152617336855\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.0016427079467\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00155287204476\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00166479495177\n",
      "            Iterations: 33\n",
      "            Function evaluations: 34\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00158030911144\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00168726404164\n",
      "            Iterations: 25\n",
      "            Function evaluations: 25\n",
      "            Gradient evaluations: 25\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00160848456858\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00171041315091\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00163739841619\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00173460820193\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00166705065426\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00175985013764\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00169744128281\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00178613895805\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00172857030182\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00181347466315\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00176043771129\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00184185725296\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00179304351123\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00187128672745\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00182638770164\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00190176308665\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00186047028251\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00193328633054\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00189529125385\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00196585645913\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00193085061566\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00199947347241\n",
      "            Iterations: 26\n",
      "            Function evaluations: 26\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00196714836793\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00203413737039\n",
      "            Iterations: 27\n",
      "            Function evaluations: 27\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00200418451067\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00207094419582\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00204195904388\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00211041605127\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00208047196755\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00215064190274\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00211972328169\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00219162175003\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00215971298629\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00223335559314\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.00220044108136\n",
      "            Iterations: 24\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 24\n"
     ]
    }
   ],
   "source": [
    "## Fronter Construction with active management\n",
    "\n",
    "\n",
    "\n",
    "fronter1_active_w= {}\n",
    "fronter1_active_vol= {}\n",
    "fronter2_active_w= {}\n",
    "fronter2_active_vol= {}\n",
    "\n",
    "for target_ret in np.linspace(0.065, 0.1, 100 ): \n",
    "    cons_ineq4_active= {'type': 'eq', \n",
    "                'fun': lambda w: -np.dot(w, CMA_ExpRet_active_arith*4)+ target_ret,\n",
    "                'jac': lambda w: -CMA_ExpRet_active_arith*4}\n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          , cons_ineq4_active\n",
    "          )\n",
    "\n",
    "    MV_active_opt_2= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov_active, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    #bounds= [[0,0.25]]+[[0, 0.4]]+[[0,None]]* (N-2),\n",
    "                    bounds= [[0,0.3]]* (N),\n",
    "                    tol= 1e-12)  # long only+ concentration constrain\n",
    "\n",
    "    MV_active_opt_1= minimize( obj_func, \n",
    "                    x0= weight_eq, \n",
    "                    args= LW_cov_active, \n",
    "                    jac= obj_func_derivative ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0, None]]* N,\n",
    "                    tol= 1e-12)  # long only constrain\n",
    "    \n",
    "    fronter1_active_w[target_ret]= MV_active_opt_1.x\n",
    "    fronter1_active_vol[target_ret]= np.sqrt(MV_active_opt_1.fun*2) \n",
    "    \n",
    "    fronter2_active_w[target_ret]= MV_active_opt_2.x\n",
    "    fronter2_active_vol[target_ret]= np.sqrt(MV_active_opt_2.fun*2)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.084343434343434345, 0.047081945661880828)\n",
      "[  5.76958650e-01   3.92525584e-01   1.58869429e-02   0.00000000e+00\n",
      "   1.51788304e-18   5.28548559e-19   1.46288226e-02]\n",
      "(0.081313131313131309, 0.049596874650441915)\n",
      "[  3.00000000e-01   3.00000000e-01   1.78278771e-01   1.69614120e-01\n",
      "   1.53898000e-17   2.93300999e-02   2.27770094e-02]\n",
      "(0.084090909090909091, 0.04634477831055471)\n",
      "[  5.39163618e-01   3.12269699e-01   5.54793646e-02   5.79459741e-02\n",
      "   1.75674633e-18   1.39161193e-02   2.12252243e-02]\n",
      "(0.085151515151515159, 0.049807707027761085)\n",
      "[  3.00000000e-01   3.00000000e-01   1.71646197e-01   1.70585862e-01\n",
      "   1.43857954e-17   3.95984112e-02   1.81695300e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABloAAANDCAYAAADFLMKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGOj/AJgLgrMZoLUVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc7079e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fronter_1= list( fronter1_vol.items())\n",
    "fronter_1.sort( key=lambda x: x[1])\n",
    "minvar_portf1= fronter_1[0]\n",
    "minvar_portf1_w= fronter1_w[minvar_portf1[0]]\n",
    "fronter_1.sort( key= lambda x: (x[0]- rf)/ x[1], reverse=True)\n",
    "efficient_portf1= fronter_1[0]\n",
    "efficient_portf1_w= fronter1_w[efficient_portf1[0]]\n",
    "\n",
    "fronter_2= list(fronter2_vol.items())\n",
    "fronter_2.sort(key= lambda x: x[1])\n",
    "minvar_portf2= fronter_2[0]\n",
    "minvar_portf2_w= fronter2_w[minvar_portf2[0]]\n",
    "fronter_2.sort(key= lambda x: (x[0]-rf)/x[1], reverse= True)\n",
    "efficient_portf2= fronter_2[0]\n",
    "efficient_portf2_w= fronter2_w[efficient_portf2[0]]\n",
    "\n",
    "fronter_active_1= list( fronter1_active_vol.items())\n",
    "fronter_active_1.sort(key= lambda x: x[1])\n",
    "minvar_active_portf1= fronter_active_1[0]\n",
    "minvar_active_portf1_w= fronter1_active_w[minvar_active_portf1[0]]\n",
    "fronter_active_1.sort(key= lambda x: (x[0]-rf)/x[1], reverse =True)\n",
    "efficient_portf1_active= fronter_active_1[0]\n",
    "efficient_portf1_active_w= fronter1_active_w[efficient_portf1_active[0]]\n",
    "\n",
    "\n",
    "fronter_active_2= list( fronter2_active_vol.items())\n",
    "fronter_active_2.sort( key= lambda x: x[1])\n",
    "minvar_active_portf2= fronter_active_2[0]\n",
    "minvar_active_portf2_w= fronter2_active_w[ minvar_active_portf2[0]]\n",
    "fronter_active_2.sort(key= lambda x: (x[0]-rf)/x[1], reverse= True)\n",
    "efficient_portf2_active= fronter_active_2[0]\n",
    "efficient_portf2_active_w= fronter2_active_w[efficient_portf2_active[0]]\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize= (20,10))\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip( * list( fronter1_vol.items())) \n",
    "plt.scatter(x= tmp_vol, y= tmp_ret, marker=\".\", c= 'pink' , label= 'CMA:long only')\n",
    "plt.scatter(x= minvar_portf1[1], y= minvar_portf1[0], marker= 'o', c='pink', s= 100 )\n",
    "plt.scatter(x= efficient_portf1[1], y = efficient_portf1[0], marker= '*', c='pink', s=200)\n",
    "# plt.plot( [0.04, efficient_portf1[1]], [ (efficient_portf1[0]-rf)/efficient_portf1[1]* 0.04+rf, efficient_portf1[0]], \n",
    "#          linestyle='-', c='pink')\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip(* list(fronter2_vol.items()))\n",
    "plt.scatter( x= tmp_vol, y= tmp_ret, marker= '.', c='blue', label= 'CMA:long only+ concentration constrain')\n",
    "plt.scatter( x= minvar_portf2[1], y=minvar_portf2[0], marker= 'o', c= 'blue', s=100)\n",
    "plt.scatter(x= efficient_portf2[1], y = efficient_portf2[0], marker= '*', c='blue', s=200)\n",
    "# plt.plot( [0.04, efficient_portf2[1]], [ (efficient_portf2[0]-rf)/efficient_portf2[1]* 0.04+rf, efficient_portf2[0]], \n",
    "#          linestyle= '-', c= 'blue')\n",
    "\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip( * list( fronter1_active_vol.items())) \n",
    "plt.scatter(x= tmp_vol, y= tmp_ret, marker=\".\", c= 'orange' , label= 'CMA_active:long only')\n",
    "plt.scatter(x= minvar_active_portf1[1], y= minvar_active_portf1[0], marker= 'o', c='orange', s= 100 )\n",
    "plt.scatter(x= efficient_portf1_active[1], y = efficient_portf1_active[0], marker= '*', c='orange', s=200)\n",
    "# plt.plot( [0.04, efficient_portf1_active[1]], [ (efficient_portf1_active[0]-rf)/efficient_portf1_active[1]* 0.04+rf, efficient_portf1_active[0]], \n",
    "#          linestyle='-', c='orange')\n",
    "\n",
    "[tmp_ret, tmp_vol]= zip(* list(fronter2_active_vol.items()))\n",
    "plt.scatter( x= tmp_vol, y= tmp_ret, marker= '.', c='red', label= 'CMA_active:long only+ concentration constrain')\n",
    "plt.scatter( x= minvar_active_portf2[1], y=minvar_active_portf2[0], marker= 'o', c= 'red', s=100)\n",
    "plt.scatter(x= efficient_portf2_active[1], y = efficient_portf2_active[0], marker= '*', c='red', s=200)\n",
    "# plt.plot( [0.04, efficient_portf2_active[1]], [ (efficient_portf2_active[0]-rf)/efficient_portf2_active[1]* 0.04+rf, efficient_portf2_active[0]], \n",
    "#          linestyle= '-', c='red')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Efficient Fronter')\n",
    "\n",
    "print(efficient_portf1)\n",
    "print(efficient_portf1_w)\n",
    "print(efficient_portf2)\n",
    "print(efficient_portf2_w)\n",
    "print(efficient_portf1_active)\n",
    "print(efficient_portf1_active_w)\n",
    "print(efficient_portf2_active)\n",
    "print(efficient_portf2_active_w)\n",
    "\n",
    "weight_longonly= efficient_portf1_w\n",
    "weight_longonly_conc= efficient_portf2_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>2.079208e-01</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>0.177851</td>\n",
       "      <td>0.118734</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>1.058735e-01</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly</th>\n",
       "      <td>0.576959</td>\n",
       "      <td>0.392526</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.517883e-18</td>\n",
       "      <td>5.285486e-19</td>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_weight_longonly_conc</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.178279</td>\n",
       "      <td>0.169614</td>\n",
       "      <td>1.538980e-17</td>\n",
       "      <td>2.933010e-02</td>\n",
       "      <td>0.022777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active_weight_longonly</th>\n",
       "      <td>0.539164</td>\n",
       "      <td>0.312270</td>\n",
       "      <td>0.055479</td>\n",
       "      <td>0.057946</td>\n",
       "      <td>1.756746e-18</td>\n",
       "      <td>1.391612e-02</td>\n",
       "      <td>0.021225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active_weight_longonly_conc</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.171646</td>\n",
       "      <td>0.170586</td>\n",
       "      <td>1.438580e-17</td>\n",
       "      <td>3.959841e-02</td>\n",
       "      <td>0.018170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    US_RE     US_PE     US_HY     SP500  \\\n",
       "weight_eq                        0.142857  0.142857  0.142857  0.142857   \n",
       "weight_peer                      0.138614  0.287129  0.049505  0.237624   \n",
       "weight_erc                       0.282415  0.142979  0.177851  0.118734   \n",
       "CMA_weight_longonly              0.576959  0.392526  0.015887  0.000000   \n",
       "CMA_weight_longonly_conc         0.300000  0.300000  0.178279  0.169614   \n",
       "CMA_active_weight_longonly       0.539164  0.312270  0.055479  0.057946   \n",
       "CMA_active_weight_longonly_conc  0.300000  0.300000  0.171646  0.170586   \n",
       "\n",
       "                                   Rusell2000          EAFE        EM  \n",
       "weight_eq                        1.428571e-01  1.428571e-01  0.142857  \n",
       "weight_peer                      2.970297e-02  2.079208e-01  0.049505  \n",
       "weight_erc                       9.272408e-02  1.058735e-01  0.079423  \n",
       "CMA_weight_longonly              1.517883e-18  5.285486e-19  0.014629  \n",
       "CMA_weight_longonly_conc         1.538980e-17  2.933010e-02  0.022777  \n",
       "CMA_active_weight_longonly       1.756746e-18  1.391612e-02  0.021225  \n",
       "CMA_active_weight_longonly_conc  1.438580e-17  3.959841e-02  0.018170  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_3= pd.DataFrame( [efficient_portf1_active_w, efficient_portf2_active_w],\n",
    "                            index= ['CMA_active_weight_longonly', 'CMA_active_weight_longonly_conc'], \n",
    "                            columns= LW_cov.columns)\n",
    "\n",
    "pd.concat([portf_weight_1, portf_weight_2, portf_weight_3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0185026477575\n",
      "            Iterations: 22\n",
      "            Function evaluations: 22\n",
      "            Gradient evaluations: 22\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0186737278728\n",
      "            Iterations: 33\n",
      "            Function evaluations: 33\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0176035904487\n",
      "            Iterations: 23\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 23\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.017893465271\n",
      "            Iterations: 36\n",
      "            Function evaluations: 37\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.016750084655\n",
      "            Iterations: 32\n",
      "            Function evaluations: 32\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -0.0171762350377\n",
      "            Iterations: 38\n",
      "            Function evaluations: 38\n",
      "            Gradient evaluations: 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight_CMAactive_MVO_gamma_3.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078008</td>\n",
       "      <td>0.155415</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>0.143006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMAactive_MVO_gamma_3.5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133980</td>\n",
       "      <td>0.114633</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>0.114561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_CMAactive_MVO_gamma_4.0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.168906</td>\n",
       "      <td>0.083499</td>\n",
       "      <td>0.044666</td>\n",
       "      <td>0.092601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                US_RE  US_PE     US_HY     SP500  Rusell2000  \\\n",
       "weight_CMAactive_MVO_gamma_3.0    0.3    0.3  0.000000  0.078008    0.155415   \n",
       "weight_CMAactive_MVO_gamma_3.5    0.3    0.3  0.000000  0.133980    0.114633   \n",
       "weight_CMAactive_MVO_gamma_4.0    0.3    0.3  0.010328  0.168906    0.083499   \n",
       "\n",
       "                                    EAFE        EM  \n",
       "weight_CMAactive_MVO_gamma_3.0  0.023572  0.143006  \n",
       "weight_CMAactive_MVO_gamma_3.5  0.036827  0.114561  \n",
       "weight_CMAactive_MVO_gamma_4.0  0.044666  0.092601  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Risk adj return utility constrained optimal with active management \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def obj_func_CMAactive(w, ARGS):  # ARGS= [sigma, ExpRet, gamma]\n",
    "    return (np.dot(  np.dot( w, ARGS[0]), w)* .5* ARGS[2]- np.dot( ARGS[1], w))\n",
    "\n",
    "def obj_func_derivative_CMAactive( w, ARGS): \n",
    "    return (np.dot( w, ARGS[0])* ARGS[2]- ARGS[1])\n",
    "\n",
    "\n",
    "cons_eq0= {'type': 'eq',\n",
    "          'fun': lambda w: np.array( [np.sum(w)-1] ) ,\n",
    "          'jac': lambda w: np.array( [1]*N)}\n",
    "# cons_ineq0= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[0]-w[1]+ 0.5, \n",
    "#              'jac': lambda w: np.array([-1]*2+ [0]*10)}\n",
    "# cons_ineq1= {'type': 'ineq',\n",
    "#              'fun': lambda w: -w[2]-w[3]-w[4]-w[5]-w[6]+ 0.5,\n",
    "#              'jac': lambda w: np.array([0]*2+ [-1]*5+ [0]*5)}\n",
    "# cons_ineq2= {'type': 'ineq', \n",
    "#              'fun': lambda w: -w[7]-w[8]-w[9]-w[10]+ 0.5, \n",
    "#              'jac': lambda w: np.array([0]*7+ [-1]*4+ [0])}\n",
    "# cons_ineq3= {'type': 'ineq', \n",
    "#             'fun': lambda w: -w[11]+ 0.5,\n",
    "#             'jac': lambda w: np.array( [0]*11+ [-1])}\n",
    "\n",
    "\n",
    "CMAactive_riskAdj_opt={}\n",
    "CMAactive_riskAdj_opt2={}\n",
    "for g in [3,3.5,4]: \n",
    "\n",
    "    cons= (cons_eq0\n",
    "    #        cons_ineq0,\n",
    "    #        cons_ineq1,\n",
    "    #        cons_ineq2,\n",
    "    #        cons_ineq3\n",
    "          )\n",
    "\n",
    "    MV_opt= minimize( obj_func_CMAactive, \n",
    "                    x0= weight_eq, \n",
    "                    args= [LW_cov_active, CMA_ExpRet_active_arith, g], \n",
    "                    jac= obj_func_derivative_CMAactive ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    #bounds= [[0, 0.25]]+[[0, .4]]+[[0,None]]* (N-2),\n",
    "                    bounds= [[0,0.3]]* (N),\n",
    "                    tol= 1e-12)\n",
    "\n",
    "    MV_opt2= minimize( obj_func_CMAactive, \n",
    "                    x0= weight_eq, \n",
    "                    args= [LW_cov_active, CMA_ExpRet_active_arith, g], \n",
    "                    jac= obj_func_derivative_CMAactive ,\n",
    "                    method= 'SLSQP',\n",
    "                    options= {'disp': True},\n",
    "                    constraints= cons, \n",
    "                    bounds= [[0,None]]* N,\n",
    "                    tol= 1e-12)\n",
    "    \n",
    "    CMAactive_riskAdj_opt[g]= MV_opt.x\n",
    "    CMAactive_riskAdj_opt2[g]= MV_opt2.x\n",
    "    \n",
    "CMAactive_riskAdj_portf_w= pd.DataFrame( CMAactive_riskAdj_opt, index=LW_cov_active.columns).T\n",
    "CMAactive_riskAdj_portf_w.index= ['weight_CMAactive_MVO_gamma_'+str(x) for x in CMAactive_riskAdj_portf_w.index]\n",
    "CMAactive_riskAdj_portf_w2= pd.DataFrame( CMAactive_riskAdj_opt2, index= LW_cov_active.columns).T\n",
    "CMAactive_riskAdj_portf_w2.index= ['weight_CMAactive_MVO_gamma_'+str(x)+'uncons' for x in CMAactive_riskAdj_portf_w.index]\n",
    "CMAactive_riskAdj_portf_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  #pd.DataFrame(CMAactive_riskAdj_opt[2],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>4.950495e-02</td>\n",
       "      <td>2.376238e-01</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>2.079208e-01</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>1.778511e-01</td>\n",
       "      <td>1.187341e-01</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>1.058735e-01</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_1</th>\n",
       "      <td>0.576959</td>\n",
       "      <td>0.392526</td>\n",
       "      <td>1.588694e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.517883e-18</td>\n",
       "      <td>5.285486e-19</td>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_2</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.782788e-01</td>\n",
       "      <td>1.696141e-01</td>\n",
       "      <td>1.538980e-17</td>\n",
       "      <td>2.933010e-02</td>\n",
       "      <td>0.022777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.599354e-02</td>\n",
       "      <td>1.611408e-01</td>\n",
       "      <td>1.837060e-02</td>\n",
       "      <td>0.144495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>9.711936e-17</td>\n",
       "      <td>1.405892e-01</td>\n",
       "      <td>1.135842e-01</td>\n",
       "      <td>3.005979e-02</td>\n",
       "      <td>0.115767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_4</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3.582843e-02</td>\n",
       "      <td>1.621623e-01</td>\n",
       "      <td>7.754428e-02</td>\n",
       "      <td>3.237553e-02</td>\n",
       "      <td>0.092089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_1</th>\n",
       "      <td>0.539164</td>\n",
       "      <td>0.312270</td>\n",
       "      <td>5.547936e-02</td>\n",
       "      <td>5.794597e-02</td>\n",
       "      <td>1.756746e-18</td>\n",
       "      <td>1.391612e-02</td>\n",
       "      <td>0.021225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_2</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.716462e-01</td>\n",
       "      <td>1.705859e-01</td>\n",
       "      <td>1.438580e-17</td>\n",
       "      <td>3.959841e-02</td>\n",
       "      <td>0.018170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.800752e-02</td>\n",
       "      <td>1.554151e-01</td>\n",
       "      <td>2.357154e-02</td>\n",
       "      <td>0.143006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.339801e-01</td>\n",
       "      <td>1.146326e-01</td>\n",
       "      <td>3.682659e-02</td>\n",
       "      <td>0.114561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.032750e-02</td>\n",
       "      <td>1.689064e-01</td>\n",
       "      <td>8.349900e-02</td>\n",
       "      <td>4.466580e-02</td>\n",
       "      <td>0.092601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3unc</th>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.410367</td>\n",
       "      <td>6.037227e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.032986e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.131823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5unc</th>\n",
       "      <td>0.408589</td>\n",
       "      <td>0.397578</td>\n",
       "      <td>1.737243e-17</td>\n",
       "      <td>8.192079e-18</td>\n",
       "      <td>8.344910e-02</td>\n",
       "      <td>1.182034e-17</td>\n",
       "      <td>0.110384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4unc</th>\n",
       "      <td>0.448397</td>\n",
       "      <td>0.386824</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.910225e-03</td>\n",
       "      <td>6.679204e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.094077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE         US_HY         SP500    Rusell2000  \\\n",
       "w_eq           0.142857  0.142857  1.428571e-01  1.428571e-01  1.428571e-01   \n",
       "w_peer         0.138614  0.287129  4.950495e-02  2.376238e-01  2.970297e-02   \n",
       "w_erc          0.282415  0.142979  1.778511e-01  1.187341e-01  9.272408e-02   \n",
       "w_MVO_1        0.576959  0.392526  1.588694e-02  0.000000e+00  1.517883e-18   \n",
       "w_MVO_2        0.300000  0.300000  1.782788e-01  1.696141e-01  1.538980e-17   \n",
       "w_RUO_3        0.300000  0.300000  0.000000e+00  7.599354e-02  1.611408e-01   \n",
       "w_RUO_3.5      0.300000  0.300000  9.711936e-17  1.405892e-01  1.135842e-01   \n",
       "w_RUO_4        0.300000  0.300000  3.582843e-02  1.621623e-01  7.754428e-02   \n",
       "w_aMVO_1       0.539164  0.312270  5.547936e-02  5.794597e-02  1.756746e-18   \n",
       "w_aMVO_2       0.300000  0.300000  1.716462e-01  1.705859e-01  1.438580e-17   \n",
       "w_aRUO_3       0.300000  0.300000  0.000000e+00  7.800752e-02  1.554151e-01   \n",
       "w_aRUO_3.5     0.300000  0.300000  0.000000e+00  1.339801e-01  1.146326e-01   \n",
       "w_aRUO_4       0.300000  0.300000  1.032750e-02  1.689064e-01  8.349900e-02   \n",
       "w_aRUO_3unc    0.354512  0.410367  6.037227e-19  0.000000e+00  1.032986e-01   \n",
       "w_aRUO_3.5unc  0.408589  0.397578  1.737243e-17  8.192079e-18  8.344910e-02   \n",
       "w_aRUO_4unc    0.448397  0.386824  0.000000e+00  3.910225e-03  6.679204e-02   \n",
       "\n",
       "                       EAFE        EM  \n",
       "w_eq           1.428571e-01  0.142857  \n",
       "w_peer         2.079208e-01  0.049505  \n",
       "w_erc          1.058735e-01  0.079423  \n",
       "w_MVO_1        5.285486e-19  0.014629  \n",
       "w_MVO_2        2.933010e-02  0.022777  \n",
       "w_RUO_3        1.837060e-02  0.144495  \n",
       "w_RUO_3.5      3.005979e-02  0.115767  \n",
       "w_RUO_4        3.237553e-02  0.092089  \n",
       "w_aMVO_1       1.391612e-02  0.021225  \n",
       "w_aMVO_2       3.959841e-02  0.018170  \n",
       "w_aRUO_3       2.357154e-02  0.143006  \n",
       "w_aRUO_3.5     3.682659e-02  0.114561  \n",
       "w_aRUO_4       4.466580e-02  0.092601  \n",
       "w_aRUO_3unc    0.000000e+00  0.131823  \n",
       "w_aRUO_3.5unc  1.182034e-17  0.110384  \n",
       "w_aRUO_4unc    0.000000e+00  0.094077  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight= pd.concat( [portf_weight_1, \n",
    "                          portf_weight_2, \n",
    "                          CMA_riskAdj_portf_w.iloc[ -3:] ,\n",
    "                          portf_weight_3, \n",
    "                          CMAactive_riskAdj_portf_w,\n",
    "                         CMAactive_riskAdj_portf_w2], axis= 0 )\n",
    "portf_weight.index= ['w_eq', # equal weight \n",
    "                    'w_peer', # peer weight\n",
    "                    'w_erc', # equal risk contribution weight \n",
    "                    'w_MVO_1', # mean-variance optimal weight with long only constrain\n",
    "                    'w_MVO_2', # mean-variance optimal weight with long only+ concentration constrain\n",
    "                    'w_RUO_3', # risk adj utility optimal weight with long only+ concentration constrain, give risk aversion 3 \n",
    "                    'w_RUO_3.5', # risk adj utility optimal weight with long only+ concentration constrain, given risk aversion 3.5\n",
    "                    'w_RUO_4', # risk adj utility optimal weight with long only+ concentration constrain, give risk aversion 4\n",
    "                    'w_aMVO_1', # mean-variance optimal weight with long only constrain, and active management \n",
    "                    'w_aMVO_2', # mean-variance optimal weight with long only+ concentration constrain, and active management \n",
    "                    'w_aRUO_3', # risk adj utility optimal weight with long only+ concentration constrain, and active management, give risk aversion 3 \n",
    "                    'w_aRUO_3.5', # risk adj utility optimal weight with long only+ concentration constrain, and active management, give risk aversion 3.5 \n",
    "                    'w_aRUO_4', # risk adj utility optimal weight with long only+ concentration constrain, and active management, give risk aversion 4\n",
    "                    'w_aRUO_3unc',\n",
    "                    'w_aRUO_3.5unc',\n",
    "                    'w_aRUO_4unc'] \n",
    "portf_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3</th>\n",
       "      <td>2.946497</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.975123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3.5</th>\n",
       "      <td>3.223899</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>8.370075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_4</th>\n",
       "      <td>3.501302</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>9.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3</th>\n",
       "      <td>2.875835</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>5.785744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.141460</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3</th>\n",
       "      <td>3.116898</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.129680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3.5</th>\n",
       "      <td>3.422701</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.217058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_4</th>\n",
       "      <td>3.728504</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>4.770000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>8.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_eq_3      2.946497  5.112730  4.197299  5.940288    6.745272  6.198200   \n",
       "iRet_eq_3.5    3.223899  5.834154  4.742391  6.827058    7.894844  7.209535   \n",
       "iRet_eq_4      3.501302  6.555578  5.287484  7.713828    9.044416  8.220869   \n",
       "iRet_peer_3    2.875835  5.296642  3.655122  5.827752    6.117100  6.102522   \n",
       "iRet_peer_3.5  3.141460  6.048718  4.109852  6.695766    7.161977  7.097910   \n",
       "iRet_peer_4    3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "iRet_erc_3     3.116898  4.408355  3.840304  4.983875    5.436244  5.024522   \n",
       "iRet_erc_3.5   3.422701  5.012383  4.325897  5.711243    6.367644  5.840244   \n",
       "iRet_erc_4     3.728504  5.616411  4.811491  6.438610    7.299045  6.655965   \n",
       "CMA            7.000000  8.800000  4.770000  7.210000    8.060000  7.070000   \n",
       "CMA_active     7.000000  8.800000  5.520000  8.210000    9.060000  8.070000   \n",
       "\n",
       "                     EM  \n",
       "iRet_eq_3      6.975123  \n",
       "iRet_eq_3.5    8.370075  \n",
       "iRet_eq_4      9.765026  \n",
       "iRet_peer_3    5.785744  \n",
       "iRet_peer_3.5  6.982466  \n",
       "iRet_peer_4    8.179187  \n",
       "iRet_erc_3     5.129680  \n",
       "iRet_erc_3.5   6.217058  \n",
       "iRet_erc_4     7.304435  \n",
       "CMA            8.030000  \n",
       "CMA_active     9.030000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpRet=  pd.concat([implied_ExpRet['weight_eq'][['3_shrunk', '3.5_shrunk', '4_shrunk']].T, \n",
    "                   implied_ExpRet['weight_peer'][['3_shrunk', '3.5_shrunk', '4_shrunk']].T,\n",
    "                   implied_ExpRet['weight_erc'][['3_shrunk', '3.5_shrunk', '4_shrunk']].T,\n",
    "                   pd.DataFrame([CMA_ExpRet_geo,CMA_ExpRet_active_geo], columns= LW_cov.columns)], \n",
    "                   axis=0)* 400\n",
    "ExpRet.index= ['iRet_eq_3', # implied expected return from equal weight with risk aversion 3\n",
    "               'iRet_eq_3.5', # implied expected return from equal weight with risk aversion 3.5\n",
    "               'iRet_eq_4',\n",
    "               'iRet_peer_3', # implied expected return from peer weight with risk aversion 3\n",
    "               'iRet_peer_3.5', # implied expected return from peer weight with risk aversion 3.5\n",
    "               'iRet_peer_4',\n",
    "               'iRet_erc_3', # implied expected return from equal risk contribution weight with risk aversion 3\n",
    "               'iRet_erc_3.5',# implied expected return from equal risk contribution weight with risk aversion 3.5\n",
    "               'iRet_erc_4',\n",
    "               'CMA', # CMA expected return \n",
    "               'CMA_active' # CMA expected return, and active management\n",
    "              ]\n",
    "\n",
    "ExpRet # annualized expected ret in percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Black-Litterman Framework \n",
    "\n",
    "Construct BL framework to incorporate benchmark(prior) and views(observations) and produce a reasonable distribution of expected return (posterior). \n",
    "Apply mean-variance optimization based on posterior to achieve optimal allocation. \n",
    "\n",
    "#### Benckmark/Equilibrium Portfolio\n",
    "\n",
    "Set the benchmark as peer holding `w_peer`, then `iRet_peer_3.5` is the implied equilibrium\\benchmark expected return, given risk aversion factor 3.5.\n",
    "\n",
    "#### The prior confidence  $\\tau$\n",
    "\n",
    "Follow BL's initial setting, $\\tau = 0.05$\n",
    "\n",
    "#### Views\n",
    "\n",
    "`CMA_active` is the subjective view to expected return of each asset. The confidence is proportional to view portfolio (prior) variance with multiplier $\\tau$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### As summary, input: \n",
    "\n",
    "$\\tau$\n",
    "\n",
    "prior expected ret distribution, assuming normal, so the prior mean and variance \n",
    "\n",
    "views, the view portfolio weight, asserted expected ret, and view confidence. \n",
    "\n",
    "#### output: \n",
    "\n",
    "the posterior distribution, mean and variance of post expected return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## prepare input\n",
    "\n",
    "tau = 5e-2\n",
    "prior_cov= LW_cov* tau\n",
    "prior_cov_inv= np.linalg.inv(prior_cov)\n",
    "prior_mean= np.array(ExpRet.loc['iRet_peer_3.5'].tolist())/100/4+ 0.5* np.diag(LW_cov)\n",
    "\n",
    "\n",
    "\n",
    "# CMA_ExpRet_active_arith \n",
    "# is the asserted expected return \n",
    "view_w= np.identity(N)\n",
    "view_ExpRet= CMA_ExpRet_active_arith\n",
    "view_cov= ( (LW_cov_active)* tau * 2)\n",
    "view_cov_inv= np.linalg.inv( view_cov)\n",
    "\n",
    "##  output: post \n",
    "\n",
    "A= prior_cov_inv\n",
    "B= np.dot( np.dot(view_w.T, view_cov_inv), view_w)\n",
    "C= np.dot(prior_cov_inv, prior_mean)\n",
    "D= np.dot(np.dot(view_w.T, view_cov_inv), view_ExpRet)\n",
    "\n",
    "post_mean_arith= pd.DataFrame( np.dot(np.linalg.inv( A+B), C+D), index=LW_cov.index, columns= ['post_ExpRet']) .T\n",
    "post_cov= pd.DataFrame( np.linalg.inv( prior_cov_inv+ np.dot( np.dot( view_w.T, view_cov_inv), view_w)), index= LW_cov.index, columns= LW_cov.columns)\n",
    "post_mean_geo= post_mean_arith- .5* np.diag( LW_cov_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.14146</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.09791</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.00000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.07000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_ExpRet</th>\n",
       "      <td>4.42764</td>\n",
       "      <td>6.965812</td>\n",
       "      <td>4.543940</td>\n",
       "      <td>7.173288</td>\n",
       "      <td>7.772621</td>\n",
       "      <td>7.40399</td>\n",
       "      <td>7.634548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 US_RE     US_PE     US_HY     SP500  Rusell2000     EAFE  \\\n",
       "iRet_peer_3.5  3.14146  6.048718  4.109852  6.695766    7.161977  7.09791   \n",
       "CMA_active     7.00000  8.800000  5.520000  8.210000    9.060000  8.07000   \n",
       "post_ExpRet    4.42764  6.965812  4.543940  7.173288    7.772621  7.40399   \n",
       "\n",
       "                     EM  \n",
       "iRet_peer_3.5  6.982466  \n",
       "CMA_active     9.030000  \n",
       "post_ExpRet    7.634548  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([ ExpRet.loc[['iRet_peer_3.5', 'CMA_active']], \n",
    "          post_mean_geo*400], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       0.000085  0.000035  0.000027  0.000039    0.000051  0.000039   \n",
       "US_PE       0.000035  0.000168  0.000059  0.000124    0.000156  0.000130   \n",
       "US_HY       0.000027  0.000059  0.000146  0.000083    0.000106  0.000091   \n",
       "SP500       0.000039  0.000124  0.000083  0.000197    0.000209  0.000177   \n",
       "Rusell2000  0.000051  0.000156  0.000106  0.000209    0.000326  0.000209   \n",
       "EAFE        0.000039  0.000130  0.000091  0.000177    0.000209  0.000279   \n",
       "EM          0.000049  0.000171  0.000127  0.000207    0.000286  0.000257   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.000049  \n",
       "US_PE       0.000171  \n",
       "US_HY       0.000127  \n",
       "SP500       0.000207  \n",
       "Rusell2000  0.000286  \n",
       "EAFE        0.000257  \n",
       "EM          0.000533  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: [-0.01217562]\n",
      "            Iterations: 40\n",
      "            Function evaluations: 36\n",
      "            Gradient evaluations: 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.3       ,  0.3       ,  0.0250876 ,  0.15948793,  0.03391084,\n",
       "        0.12635039,  0.05516323])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MVO based over post expected mean and variance\n",
    "\n",
    "\n",
    "MV_opt= minimize( obj_func_CMA, \n",
    "                x0= weight_eq, \n",
    "                args= [LW_cov_active+ post_cov, post_mean_arith, 4], \n",
    "                jac= obj_func_derivative_CMA ,\n",
    "                method= 'SLSQP',\n",
    "                options= {'disp': True},\n",
    "                constraints= cons, \n",
    "                #bounds= [[0, 0.25]]+[[0, .4]]+[[0,None]]* (N-2),\n",
    "                bounds= [[0,0.3]]* (N),\n",
    "                tol= 1e-120)\n",
    "\n",
    "MV_opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: [-0.01218049]\n",
      "            Iterations: 45\n",
      "            Function evaluations: 56\n",
      "            Gradient evaluations: 45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.30986589,  0.32137822,  0.01415427,  0.14598855,  0.03094773,\n",
       "        0.12262675,  0.05503858])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MV_unc_opt= minimize( obj_func_CMA, \n",
    "                x0= weight_eq, \n",
    "                args= [LW_cov_active+ post_cov, post_mean_arith, 4], \n",
    "                jac= obj_func_derivative_CMA ,\n",
    "                method= 'SLSQP',\n",
    "                options= {'disp': True},\n",
    "                constraints= cons, \n",
    "                bounds= [[0,None]]* N,\n",
    "                tol= 1e-120)\n",
    "\n",
    "MV_unc_opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_eq</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>4.950495e-02</td>\n",
       "      <td>2.376238e-01</td>\n",
       "      <td>2.970297e-02</td>\n",
       "      <td>2.079208e-01</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_erc</th>\n",
       "      <td>0.282415</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>1.778511e-01</td>\n",
       "      <td>1.187341e-01</td>\n",
       "      <td>9.272408e-02</td>\n",
       "      <td>1.058735e-01</td>\n",
       "      <td>0.079423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_1</th>\n",
       "      <td>0.576959</td>\n",
       "      <td>0.392526</td>\n",
       "      <td>1.588694e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.517883e-18</td>\n",
       "      <td>5.285486e-19</td>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_MVO_2</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.782788e-01</td>\n",
       "      <td>1.696141e-01</td>\n",
       "      <td>1.538980e-17</td>\n",
       "      <td>2.933010e-02</td>\n",
       "      <td>0.022777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.599354e-02</td>\n",
       "      <td>1.611408e-01</td>\n",
       "      <td>1.837060e-02</td>\n",
       "      <td>0.144495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>9.711936e-17</td>\n",
       "      <td>1.405892e-01</td>\n",
       "      <td>1.135842e-01</td>\n",
       "      <td>3.005979e-02</td>\n",
       "      <td>0.115767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_RUO_4</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3.582843e-02</td>\n",
       "      <td>1.621623e-01</td>\n",
       "      <td>7.754428e-02</td>\n",
       "      <td>3.237553e-02</td>\n",
       "      <td>0.092089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_1</th>\n",
       "      <td>0.539164</td>\n",
       "      <td>0.312270</td>\n",
       "      <td>5.547936e-02</td>\n",
       "      <td>5.794597e-02</td>\n",
       "      <td>1.756746e-18</td>\n",
       "      <td>1.391612e-02</td>\n",
       "      <td>0.021225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aMVO_2</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.716462e-01</td>\n",
       "      <td>1.705859e-01</td>\n",
       "      <td>1.438580e-17</td>\n",
       "      <td>3.959841e-02</td>\n",
       "      <td>0.018170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.800752e-02</td>\n",
       "      <td>1.554151e-01</td>\n",
       "      <td>2.357154e-02</td>\n",
       "      <td>0.143006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.339801e-01</td>\n",
       "      <td>1.146326e-01</td>\n",
       "      <td>3.682659e-02</td>\n",
       "      <td>0.114561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.032750e-02</td>\n",
       "      <td>1.689064e-01</td>\n",
       "      <td>8.349900e-02</td>\n",
       "      <td>4.466580e-02</td>\n",
       "      <td>0.092601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3unc</th>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.410367</td>\n",
       "      <td>6.037227e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.032986e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.131823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5unc</th>\n",
       "      <td>0.408589</td>\n",
       "      <td>0.397578</td>\n",
       "      <td>1.737243e-17</td>\n",
       "      <td>8.192079e-18</td>\n",
       "      <td>8.344910e-02</td>\n",
       "      <td>1.182034e-17</td>\n",
       "      <td>0.110384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_4unc</th>\n",
       "      <td>0.448397</td>\n",
       "      <td>0.386824</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.910225e-03</td>\n",
       "      <td>6.679204e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.094077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.508760e-02</td>\n",
       "      <td>1.594879e-01</td>\n",
       "      <td>3.391084e-02</td>\n",
       "      <td>1.263504e-01</td>\n",
       "      <td>0.055163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL_unc</th>\n",
       "      <td>0.309866</td>\n",
       "      <td>0.321378</td>\n",
       "      <td>1.415427e-02</td>\n",
       "      <td>1.459886e-01</td>\n",
       "      <td>3.094773e-02</td>\n",
       "      <td>1.226268e-01</td>\n",
       "      <td>0.055039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE         US_HY         SP500    Rusell2000  \\\n",
       "w_eq           0.142857  0.142857  1.428571e-01  1.428571e-01  1.428571e-01   \n",
       "w_peer         0.138614  0.287129  4.950495e-02  2.376238e-01  2.970297e-02   \n",
       "w_erc          0.282415  0.142979  1.778511e-01  1.187341e-01  9.272408e-02   \n",
       "w_MVO_1        0.576959  0.392526  1.588694e-02  0.000000e+00  1.517883e-18   \n",
       "w_MVO_2        0.300000  0.300000  1.782788e-01  1.696141e-01  1.538980e-17   \n",
       "w_RUO_3        0.300000  0.300000  0.000000e+00  7.599354e-02  1.611408e-01   \n",
       "w_RUO_3.5      0.300000  0.300000  9.711936e-17  1.405892e-01  1.135842e-01   \n",
       "w_RUO_4        0.300000  0.300000  3.582843e-02  1.621623e-01  7.754428e-02   \n",
       "w_aMVO_1       0.539164  0.312270  5.547936e-02  5.794597e-02  1.756746e-18   \n",
       "w_aMVO_2       0.300000  0.300000  1.716462e-01  1.705859e-01  1.438580e-17   \n",
       "w_aRUO_3       0.300000  0.300000  0.000000e+00  7.800752e-02  1.554151e-01   \n",
       "w_aRUO_3.5     0.300000  0.300000  0.000000e+00  1.339801e-01  1.146326e-01   \n",
       "w_aRUO_4       0.300000  0.300000  1.032750e-02  1.689064e-01  8.349900e-02   \n",
       "w_aRUO_3unc    0.354512  0.410367  6.037227e-19  0.000000e+00  1.032986e-01   \n",
       "w_aRUO_3.5unc  0.408589  0.397578  1.737243e-17  8.192079e-18  8.344910e-02   \n",
       "w_aRUO_4unc    0.448397  0.386824  0.000000e+00  3.910225e-03  6.679204e-02   \n",
       "w_BL           0.300000  0.300000  2.508760e-02  1.594879e-01  3.391084e-02   \n",
       "w_BL_unc       0.309866  0.321378  1.415427e-02  1.459886e-01  3.094773e-02   \n",
       "\n",
       "                       EAFE        EM  \n",
       "w_eq           1.428571e-01  0.142857  \n",
       "w_peer         2.079208e-01  0.049505  \n",
       "w_erc          1.058735e-01  0.079423  \n",
       "w_MVO_1        5.285486e-19  0.014629  \n",
       "w_MVO_2        2.933010e-02  0.022777  \n",
       "w_RUO_3        1.837060e-02  0.144495  \n",
       "w_RUO_3.5      3.005979e-02  0.115767  \n",
       "w_RUO_4        3.237553e-02  0.092089  \n",
       "w_aMVO_1       1.391612e-02  0.021225  \n",
       "w_aMVO_2       3.959841e-02  0.018170  \n",
       "w_aRUO_3       2.357154e-02  0.143006  \n",
       "w_aRUO_3.5     3.682659e-02  0.114561  \n",
       "w_aRUO_4       4.466580e-02  0.092601  \n",
       "w_aRUO_3unc    0.000000e+00  0.131823  \n",
       "w_aRUO_3.5unc  1.182034e-17  0.110384  \n",
       "w_aRUO_4unc    0.000000e+00  0.094077  \n",
       "w_BL           1.263504e-01  0.055163  \n",
       "w_BL_unc       1.226268e-01  0.055039  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_final= pd.concat( [portf_weight,\n",
    "                         pd.DataFrame( [MV_opt.x, MV_unc_opt.x], columns= portf_weight.columns, index= ['w_BL', 'w_BL_unc'])], axis=0)\n",
    "portf_weight_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w_peer</th>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_aRUO_3.5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133980</td>\n",
       "      <td>0.114633</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>0.114561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.025088</td>\n",
       "      <td>0.159488</td>\n",
       "      <td>0.033911</td>\n",
       "      <td>0.126350</td>\n",
       "      <td>0.055163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_BL_unc</th>\n",
       "      <td>0.309866</td>\n",
       "      <td>0.321378</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.145989</td>\n",
       "      <td>0.030948</td>\n",
       "      <td>0.122627</td>\n",
       "      <td>0.055039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "w_peer      0.138614  0.287129  0.049505  0.237624    0.029703  0.207921   \n",
       "w_aRUO_3.5  0.300000  0.300000  0.000000  0.133980    0.114633  0.036827   \n",
       "w_BL        0.300000  0.300000  0.025088  0.159488    0.033911  0.126350   \n",
       "w_BL_unc    0.309866  0.321378  0.014154  0.145989    0.030948  0.122627   \n",
       "\n",
       "                  EM  \n",
       "w_peer      0.049505  \n",
       "w_aRUO_3.5  0.114561  \n",
       "w_BL        0.055163  \n",
       "w_BL_unc    0.055039  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portf_weight_final.loc[['w_peer', 'w_aRUO_3.5', 'w_BL', 'w_BL_unc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3</th>\n",
       "      <td>2.946497</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.975123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3.5</th>\n",
       "      <td>3.223899</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>8.370075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_4</th>\n",
       "      <td>3.501302</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>9.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3</th>\n",
       "      <td>2.875835</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>5.785744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.141460</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3</th>\n",
       "      <td>3.116898</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.129680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3.5</th>\n",
       "      <td>3.422701</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.217058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_4</th>\n",
       "      <td>3.728504</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>4.770000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>8.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_ExpRet</th>\n",
       "      <td>4.427640</td>\n",
       "      <td>6.965812</td>\n",
       "      <td>4.543940</td>\n",
       "      <td>7.173288</td>\n",
       "      <td>7.772621</td>\n",
       "      <td>7.403990</td>\n",
       "      <td>7.634548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_eq_3      2.946497  5.112730  4.197299  5.940288    6.745272  6.198200   \n",
       "iRet_eq_3.5    3.223899  5.834154  4.742391  6.827058    7.894844  7.209535   \n",
       "iRet_eq_4      3.501302  6.555578  5.287484  7.713828    9.044416  8.220869   \n",
       "iRet_peer_3    2.875835  5.296642  3.655122  5.827752    6.117100  6.102522   \n",
       "iRet_peer_3.5  3.141460  6.048718  4.109852  6.695766    7.161977  7.097910   \n",
       "iRet_peer_4    3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "iRet_erc_3     3.116898  4.408355  3.840304  4.983875    5.436244  5.024522   \n",
       "iRet_erc_3.5   3.422701  5.012383  4.325897  5.711243    6.367644  5.840244   \n",
       "iRet_erc_4     3.728504  5.616411  4.811491  6.438610    7.299045  6.655965   \n",
       "CMA            7.000000  8.800000  4.770000  7.210000    8.060000  7.070000   \n",
       "CMA_active     7.000000  8.800000  5.520000  8.210000    9.060000  8.070000   \n",
       "post_ExpRet    4.427640  6.965812  4.543940  7.173288    7.772621  7.403990   \n",
       "\n",
       "                     EM  \n",
       "iRet_eq_3      6.975123  \n",
       "iRet_eq_3.5    8.370075  \n",
       "iRet_eq_4      9.765026  \n",
       "iRet_peer_3    5.785744  \n",
       "iRet_peer_3.5  6.982466  \n",
       "iRet_peer_4    8.179187  \n",
       "iRet_erc_3     5.129680  \n",
       "iRet_erc_3.5   6.217058  \n",
       "iRet_erc_4     7.304435  \n",
       "CMA            8.030000  \n",
       "CMA_active     9.030000  \n",
       "post_ExpRet    7.634548  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpRet_final= pd.concat([ExpRet, \n",
    "                        post_mean_geo*400], axis=0)\n",
    "ExpRet_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100789</td>\n",
       "      <td>0.141832</td>\n",
       "      <td>0.131397</td>\n",
       "      <td>0.152992</td>\n",
       "      <td>0.197087</td>\n",
       "      <td>0.182198</td>\n",
       "      <td>0.252372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  0.100789  0.141832  0.131397  0.152992  0.197087  0.182198  0.252372"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.sqrt(np.diag( LW_cov))).T*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290357</td>\n",
       "      <td>0.243449</td>\n",
       "      <td>0.301545</td>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.255969</td>\n",
       "      <td>0.229836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.290357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>0.682977</td>\n",
       "      <td>0.671396</td>\n",
       "      <td>0.604658</td>\n",
       "      <td>0.572320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.243449</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.459033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.301545</td>\n",
       "      <td>0.682977</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832526</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>0.644399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.307428</td>\n",
       "      <td>0.671396</td>\n",
       "      <td>0.488964</td>\n",
       "      <td>0.832526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698464</td>\n",
       "      <td>0.691124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.255969</td>\n",
       "      <td>0.604658</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.763682</td>\n",
       "      <td>0.698464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.229836</td>\n",
       "      <td>0.572320</td>\n",
       "      <td>0.459033</td>\n",
       "      <td>0.644399</td>\n",
       "      <td>0.691124</td>\n",
       "      <td>0.669628</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       1.000000  0.290357  0.243449  0.301545    0.307428  0.255969   \n",
       "US_PE       0.290357  1.000000  0.377413  0.682977    0.671396  0.604658   \n",
       "US_HY       0.243449  0.377413  1.000000  0.497447    0.488964  0.455539   \n",
       "SP500       0.301545  0.682977  0.497447  1.000000    0.832526  0.763682   \n",
       "Rusell2000  0.307428  0.671396  0.488964  0.832526    1.000000  0.698464   \n",
       "EAFE        0.255969  0.604658  0.455539  0.763682    0.698464  1.000000   \n",
       "EM          0.229836  0.572320  0.459033  0.644399    0.691124  0.669628   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.229836  \n",
       "US_PE       0.572320  \n",
       "US_HY       0.459033  \n",
       "SP500       0.644399  \n",
       "Rusell2000  0.691124  \n",
       "EAFE        0.669628  \n",
       "EM          1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290357</td>\n",
       "      <td>0.237342</td>\n",
       "      <td>0.295909</td>\n",
       "      <td>0.303927</td>\n",
       "      <td>0.252569</td>\n",
       "      <td>0.228229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.290357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367945</td>\n",
       "      <td>0.670214</td>\n",
       "      <td>0.663750</td>\n",
       "      <td>0.596624</td>\n",
       "      <td>0.568319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.237342</td>\n",
       "      <td>0.367945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.471268</td>\n",
       "      <td>0.438210</td>\n",
       "      <td>0.444389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.295909</td>\n",
       "      <td>0.670214</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807664</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>0.627936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.303927</td>\n",
       "      <td>0.663750</td>\n",
       "      <td>0.471268</td>\n",
       "      <td>0.807664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>0.678477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.252569</td>\n",
       "      <td>0.596624</td>\n",
       "      <td>0.438210</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.228229</td>\n",
       "      <td>0.568319</td>\n",
       "      <td>0.444389</td>\n",
       "      <td>0.627936</td>\n",
       "      <td>0.678477</td>\n",
       "      <td>0.656112</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       1.000000  0.290357  0.237342  0.295909    0.303927  0.252569   \n",
       "US_PE       0.290357  1.000000  0.367945  0.670214    0.663750  0.596624   \n",
       "US_HY       0.237342  0.367945  1.000000  0.475904    0.471268  0.438210   \n",
       "SP500       0.295909  0.670214  0.475904  1.000000    0.807664  0.739453   \n",
       "Rusell2000  0.303927  0.663750  0.471268  0.807664    1.000000  0.681336   \n",
       "EAFE        0.252569  0.596624  0.438210  0.739453    0.681336  1.000000   \n",
       "EM          0.228229  0.568319  0.444389  0.627936    0.678477  0.656112   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.228229  \n",
       "US_PE       0.568319  \n",
       "US_HY       0.444389  \n",
       "SP500       0.627936  \n",
       "Rusell2000  0.678477  \n",
       "EAFE        0.656112  \n",
       "EM          1.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_corr_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130784</td>\n",
       "      <td>0.124802</td>\n",
       "      <td>0.109958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.130784  0.124802  0.109958"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.sqrt(np.diag(np.dot(np.dot(portf_weight.iloc[0:3], LW_cov), portf_weight.iloc[0:3].T)))*2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3</th>\n",
       "      <td>2.946497</td>\n",
       "      <td>5.112730</td>\n",
       "      <td>4.197299</td>\n",
       "      <td>5.940288</td>\n",
       "      <td>6.745272</td>\n",
       "      <td>6.198200</td>\n",
       "      <td>6.975123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_3.5</th>\n",
       "      <td>3.223899</td>\n",
       "      <td>5.834154</td>\n",
       "      <td>4.742391</td>\n",
       "      <td>6.827058</td>\n",
       "      <td>7.894844</td>\n",
       "      <td>7.209535</td>\n",
       "      <td>8.370075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_eq_4</th>\n",
       "      <td>3.501302</td>\n",
       "      <td>6.555578</td>\n",
       "      <td>5.287484</td>\n",
       "      <td>7.713828</td>\n",
       "      <td>9.044416</td>\n",
       "      <td>8.220869</td>\n",
       "      <td>9.765026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3</th>\n",
       "      <td>2.875835</td>\n",
       "      <td>5.296642</td>\n",
       "      <td>3.655122</td>\n",
       "      <td>5.827752</td>\n",
       "      <td>6.117100</td>\n",
       "      <td>6.102522</td>\n",
       "      <td>5.785744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_3.5</th>\n",
       "      <td>3.141460</td>\n",
       "      <td>6.048718</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>6.695766</td>\n",
       "      <td>7.161977</td>\n",
       "      <td>7.097910</td>\n",
       "      <td>6.982466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_peer_4</th>\n",
       "      <td>3.407086</td>\n",
       "      <td>6.800794</td>\n",
       "      <td>4.564582</td>\n",
       "      <td>7.563779</td>\n",
       "      <td>8.206854</td>\n",
       "      <td>8.093298</td>\n",
       "      <td>8.179187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3</th>\n",
       "      <td>3.116898</td>\n",
       "      <td>4.408355</td>\n",
       "      <td>3.840304</td>\n",
       "      <td>4.983875</td>\n",
       "      <td>5.436244</td>\n",
       "      <td>5.024522</td>\n",
       "      <td>5.129680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_3.5</th>\n",
       "      <td>3.422701</td>\n",
       "      <td>5.012383</td>\n",
       "      <td>4.325897</td>\n",
       "      <td>5.711243</td>\n",
       "      <td>6.367644</td>\n",
       "      <td>5.840244</td>\n",
       "      <td>6.217058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iRet_erc_4</th>\n",
       "      <td>3.728504</td>\n",
       "      <td>5.616411</td>\n",
       "      <td>4.811491</td>\n",
       "      <td>6.438610</td>\n",
       "      <td>7.299045</td>\n",
       "      <td>6.655965</td>\n",
       "      <td>7.304435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>4.770000</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>8.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA_active</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>9.060000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>9.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_ExpRet</th>\n",
       "      <td>4.427640</td>\n",
       "      <td>6.965812</td>\n",
       "      <td>4.543940</td>\n",
       "      <td>7.173288</td>\n",
       "      <td>7.772621</td>\n",
       "      <td>7.403990</td>\n",
       "      <td>7.634548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "iRet_eq_3      2.946497  5.112730  4.197299  5.940288    6.745272  6.198200   \n",
       "iRet_eq_3.5    3.223899  5.834154  4.742391  6.827058    7.894844  7.209535   \n",
       "iRet_eq_4      3.501302  6.555578  5.287484  7.713828    9.044416  8.220869   \n",
       "iRet_peer_3    2.875835  5.296642  3.655122  5.827752    6.117100  6.102522   \n",
       "iRet_peer_3.5  3.141460  6.048718  4.109852  6.695766    7.161977  7.097910   \n",
       "iRet_peer_4    3.407086  6.800794  4.564582  7.563779    8.206854  8.093298   \n",
       "iRet_erc_3     3.116898  4.408355  3.840304  4.983875    5.436244  5.024522   \n",
       "iRet_erc_3.5   3.422701  5.012383  4.325897  5.711243    6.367644  5.840244   \n",
       "iRet_erc_4     3.728504  5.616411  4.811491  6.438610    7.299045  6.655965   \n",
       "CMA            7.000000  8.800000  4.770000  7.210000    8.060000  7.070000   \n",
       "CMA_active     7.000000  8.800000  5.520000  8.210000    9.060000  8.070000   \n",
       "post_ExpRet    4.427640  6.965812  4.543940  7.173288    7.772621  7.403990   \n",
       "\n",
       "                     EM  \n",
       "iRet_eq_3      6.975123  \n",
       "iRet_eq_3.5    8.370075  \n",
       "iRet_eq_4      9.765026  \n",
       "iRet_peer_3    5.785744  \n",
       "iRet_peer_3.5  6.982466  \n",
       "iRet_peer_4    8.179187  \n",
       "iRet_erc_3     5.129680  \n",
       "iRet_erc_3.5   6.217058  \n",
       "iRet_erc_4     7.304435  \n",
       "CMA            8.030000  \n",
       "CMA_active     9.030000  \n",
       "post_ExpRet    7.634548  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpRet_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ew</th>\n",
       "      <th>peer</th>\n",
       "      <th>erc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.006116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.014428</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>0.012081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.009712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.017735</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.014547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.020898</td>\n",
       "      <td>0.018628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>0.016314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.023934</td>\n",
       "      <td>0.021748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ew      peer       erc\n",
       "US_RE       0.005548  0.005313  0.006116\n",
       "US_PE       0.014428  0.015042  0.012081\n",
       "US_HY       0.010902  0.009095  0.009712\n",
       "SP500       0.017735  0.017360  0.014547\n",
       "Rusell2000  0.022991  0.020898  0.018628\n",
       "EAFE        0.020227  0.019908  0.016314\n",
       "EM          0.027899  0.023934  0.021748"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.dot(LW_cov, portf_weight.loc[['w_eq', 'w_peer', 'w_erc']].T), index=LW_cov.index, columns= ['ew', 'peer', 'erc'])*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081116</td>\n",
       "      <td>0.082102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.081116  0.082102"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_w= portf_weight_final.loc[[ 'w_aRUO_3.5unc', 'w_aRUO_3.5']]\n",
    "\n",
    "tmp_ret= np.dot(tmp_w, ExpRet_final.loc['CMA_active'])/100\n",
    "tmp_vol= np.sqrt(np.diag(np.dot(np.dot(tmp_w, LW_cov_active), tmp_w.T)))*2\n",
    "\n",
    "pd.DataFrame(tmp_ret).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109126</td>\n",
       "      <td>0.118232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.109126  0.118232"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tmp_vol).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(view_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CMA_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>9.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CMA_active\n",
       "US_RE             7.00\n",
       "US_PE             8.80\n",
       "US_HY             5.52\n",
       "SP500             8.21\n",
       "Rusell2000        9.06\n",
       "EAFE              8.07\n",
       "EM                9.03"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ExpRet_final.loc['CMA_active'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_BL_unc</th>\n",
       "      <th>w_BL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.309866</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.321378</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.025088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.145989</td>\n",
       "      <td>0.159488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.030948</td>\n",
       "      <td>0.033911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.122627</td>\n",
       "      <td>0.126350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.055039</td>\n",
       "      <td>0.055163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            w_BL_unc      w_BL\n",
       "US_RE       0.309866  0.300000\n",
       "US_PE       0.321378  0.300000\n",
       "US_HY       0.014154  0.025088\n",
       "SP500       0.145989  0.159488\n",
       "Rusell2000  0.030948  0.033911\n",
       "EAFE        0.122627  0.126350\n",
       "EM          0.055039  0.055163"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl_w= portf_weight_final.loc[['w_BL_unc', 'w_BL']]\n",
    "bl_ret= ExpRet_final.loc['post_ExpRet'].values/100\n",
    "bl_w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062908</td>\n",
       "      <td>0.062963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112647</td>\n",
       "      <td>0.113087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.062908  0.062963\n",
       "0  0.112647  0.113087"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_ret_BL=pd.DataFrame(np.dot(bl_w, bl_ret)).T\n",
    "tmp_vol_BL= pd.DataFrame(np.sqrt(np.diag(np.dot(np.dot(bl_w, LW_cov_active+ post_cov), bl_w.T)))*2).T\n",
    "\n",
    "pd.concat( [tmp_ret_BL, tmp_vol_BL], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.006220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.008594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.007698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.016148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       0.002540  0.001038  0.000806  0.001162    0.001527  0.001175   \n",
       "US_PE       0.001038  0.005029  0.001758  0.003705    0.004692  0.003906   \n",
       "US_HY       0.000806  0.001758  0.004541  0.002500    0.003166  0.002726   \n",
       "SP500       0.001162  0.003705  0.002500  0.006077    0.006276  0.005322   \n",
       "Rusell2000  0.001527  0.004692  0.003166  0.006276    0.009936  0.006270   \n",
       "EAFE        0.001175  0.003906  0.002726  0.005322    0.006270  0.008524   \n",
       "EM          0.001462  0.005121  0.003805  0.006220    0.008594  0.007698   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.001462  \n",
       "US_PE       0.005121  \n",
       "US_HY       0.003805  \n",
       "SP500       0.006220  \n",
       "Rusell2000  0.008594  \n",
       "EAFE        0.007698  \n",
       "EM          0.016148  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_cov_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_RE</th>\n",
       "      <th>US_PE</th>\n",
       "      <th>US_HY</th>\n",
       "      <th>SP500</th>\n",
       "      <th>Rusell2000</th>\n",
       "      <th>EAFE</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US_RE</th>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_PE</th>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.005292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_HY</th>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.003932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.006428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rusell2000</th>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.010262</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.008880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAFE</th>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.007954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>0.016681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               US_RE     US_PE     US_HY     SP500  Rusell2000      EAFE  \\\n",
       "US_RE       0.002624  0.001072  0.000833  0.001201    0.001578  0.001214   \n",
       "US_PE       0.001072  0.005197  0.001817  0.003829    0.004848  0.004037   \n",
       "US_HY       0.000833  0.001817  0.004688  0.002583    0.003271  0.002817   \n",
       "SP500       0.001201  0.003829  0.002583  0.006274    0.006485  0.005499   \n",
       "Rusell2000  0.001578  0.004848  0.003271  0.006485    0.010262  0.006479   \n",
       "EAFE        0.001214  0.004037  0.002817  0.005499    0.006479  0.008803   \n",
       "EM          0.001510  0.005292  0.003932  0.006428    0.008880  0.007954   \n",
       "\n",
       "                  EM  \n",
       "US_RE       0.001510  \n",
       "US_PE       0.005292  \n",
       "US_HY       0.003932  \n",
       "SP500       0.006428  \n",
       "Rusell2000  0.008880  \n",
       "EAFE        0.007954  \n",
       "EM          0.016681  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LW_cov_active+ post_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.082102</td>\n",
       "      <td>0.082102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.082102  0.082102"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tmp_w= portf_weight_final.loc[[ 'w_aRUO_3.5', 'w_aRUO_3.5']]\n",
    "\n",
    "tmp_ret= np.dot(tmp_w, ExpRet_final.loc['CMA_active'])/100\n",
    "\n",
    "\n",
    "tmp_vol= pd.DataFrame(np.sqrt(np.diag(np.dot(np.dot(tmp_w, LW_cov_active), tmp_w.T)))*2).T\n",
    "\n",
    "pd.DataFrame(tmp_ret).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.118232\n",
       "1  0.118232"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tmp_vol).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
